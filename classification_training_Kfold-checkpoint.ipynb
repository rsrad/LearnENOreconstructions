{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://androidkt.com/k-fold-cross-validation-with-tensorflow-keras/\n",
    "\n",
    "https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md\n",
    "\n",
    "https://github.com/SadmanSakib93/ANN-Stratified-K-Fold-Cross-Validation-Keras-Tensorflow/blob/master/CV_ClassificationExample.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:90%!important}<\\style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML('<style>.container{width:90%!important}<\\style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import LeakyReLU, ReLU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.regularizers import l2\n",
    "from plot_keras_history import show_history, plot_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plot-keras-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To reproducible results in keras using seed \n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(in_dim=6, hidden_layer_n =3, out_dim =3):\n",
    "    # Build model\n",
    "    keras.backend.clear_session()\n",
    "    keras.backend.set_floatx('float64')        \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_n, input_dim=in_dim, activation=\"relu\"))\n",
    "#     model.add(ReLU())\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(Dense(out_dim, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_weights(model = None, data_dir =None, hidden_layer_n =3, datachoice=None):\n",
    "#   Saving model weights in mat file format\n",
    "    weight_file = data_dir+\"/model/\"+\"trained_weights_\"+\"Hn_\"+str(hidden_layer_n) + datachoice+\".mat\"\n",
    "    bias_file = data_dir+\"/model/\"+\"trained_biases_\"+\"Hn_\"+str(hidden_layer_n) + datachoice + \".mat\"\n",
    "    print(\"name weight\", weight_file)\n",
    "\n",
    "    weight_mat_key = \"WEIGHT_\"+ datachoice\n",
    "    bias_mat_key= \"BIAS_\"+ datachoice\n",
    "    \n",
    "    # Saving trained model \n",
    "    ws=model.get_weights()\n",
    "    pyobj = np.empty((len(ws),), dtype=object)\n",
    "    for i in range(len(ws)):\n",
    "        pyobj[i] = ws[i]\n",
    "    \n",
    "#     print(\"\\n THIS IS\\n\", weight_mat_key, bias_mat_key)\n",
    "    sio.savemat(weight_file, {weight_mat_key:pyobj[0:len(ws):2]})\n",
    "    sio.savemat(bias_file, {bias_mat_key:pyobj[1:len(ws):2]})\n",
    "    return [weight_file, bias_file]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_metrics_log(myDict =None, log_file=None):\n",
    "    df_this = pd.DataFrame([myDict], columns=myDict.keys())   \n",
    "    if os.path.isfile(log_file):    \n",
    "        df_load =pd.read_csv(log_file)\n",
    "        df_now = pd.concat([df_load, df_this], axis=0) \n",
    "        df_now.to_csv(log_file, index=False )\n",
    "    else:    \n",
    "        df_this.to_csv(log_file, index=False )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=None,  datachoice=None):    \n",
    "    # Import and preprocessing input data        \n",
    "    read_data_file = data_dir+\"train_input_\" + datachoice  +\".csv\"\n",
    "    read_label_file = data_dir+ \"train_label_\" + datachoice +\".csv\"\n",
    "    print('Data file being used is:', read_data_file)\n",
    "        \n",
    "    df = pd.read_csv(read_data_file)\n",
    "    df1 = pd.read_csv(read_label_file)    \n",
    "    X = df.to_numpy()  # input data \n",
    "#     print(\"ENO method is\", method)\n",
    "    Y = df1[\"train_label\"]\n",
    "    print(\"In load data\", X.shape, Y.shape)\n",
    "#     print(Y)\n",
    "    return X, Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResults(test, pred):\n",
    "#   input test and pred are converted from one hot encoded test label to label    \n",
    "    target_names = ['0','1','2']\n",
    "#     print(classification_report(test, pred, target_names=target_names))\n",
    "    accuracy = accuracy_score(test, pred)\n",
    "    precision=precision_score(test, pred, average='weighted')\n",
    "    f1Score=f1_score(test, pred, average='weighted') \n",
    "    print(\"here\")\n",
    "    print(\"Accuracy  : {}\".format(accuracy))\n",
    "    print(\"Precision : {}\".format(precision))\n",
    "    print(\"f1Score : {}\".format(f1Score))\n",
    "   \n",
    "    cm=confusion_matrix(test, pred)\n",
    "    print(cm)     \n",
    "    return [accuracy, precision, f1Score]\n",
    "\n",
    "#  \n",
    "# yPredict = model.predict(X_val)\n",
    "\n",
    "#  #Converting one hot encoded test label to label    \n",
    "#         pred = np.argmax(yPredict, axis=1)\n",
    "#         val = np.argmax(Y_val, axis=1)        \n",
    "#         showResults(val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold_test(model=None, nfolds = 1, xTrain=None, yTrain=None, log_file=None, \n",
    "                    hidden_layer_n=3, datachoice=None, epochs=100):   \n",
    "    print(\" k cross validation log will be written in\", log_file)\n",
    "    \n",
    "    verbose, batch_size = 1, 512\n",
    "    skf = StratifiedKFold(n_splits=nfolds, shuffle=True)\n",
    "    skf.get_n_splits(xTrain, yTrain)\n",
    "    tr_acc =[]\n",
    "    vali_acc=[]\n",
    "    \n",
    "    \n",
    "    foldNum=0\n",
    "    for train_index, val_index in skf.split(xTrain, yTrain):\n",
    "        foldNum+=1\n",
    "        print(\"Results for fold\",foldNum)\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "       \n",
    "        # one hot encode\n",
    "        Y_train = to_categorical(Y_train)\n",
    "        Y_val = to_categorical(Y_val)\n",
    "  \n",
    "\n",
    "        history = model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=epochs, batch_size=batch_size)        \n",
    "        \n",
    "        tr_acc.append(history.history['accuracy'][-1])\n",
    "        vali_acc.append(history.history['val_accuracy'][-1])\n",
    "        \n",
    "    dicn ={\"data\": datachoice,  \"nfolds\": nfolds, \"Hn\":hidden_layer_n, \"epoch\":epochs, \n",
    "           \"mean train acc\":np.mean(tr_acc), \"var train\":np.var(tr_acc), \n",
    "           \"average val acc\": np.mean(vali_acc), \"var val\":np.var(vali_acc) }       \n",
    "        \n",
    "    write_metrics_log(myDict=dicn, log_file=log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(model=None,xTrain=None, yTrain=None, xTest =None, yTest=None, data_dir=None, log_file=None, \n",
    "                             datachoice=None,  hidden_layer_n=3, num_epochs=100, batchsize=1, file2write=\"my_cm.txt\"):    \n",
    "    #create callback\n",
    "    filepath = data_dir+\"/Details/\"+\"best_model\"+\"Hn_\"+str(hidden_layer_n) + datachoice+\".hdf5\"\n",
    "#     matlab_model_dir =data_dir+\"/trainedmodel/\" \n",
    "    checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks = [checkpoint]    \n",
    "    \n",
    "    yTrain = to_categorical(yTrain)\n",
    "    # Train model\n",
    "    history=model.fit(xTrain, yTrain, validation_split=0.15, epochs=num_epochs, callbacks=callbacks, batch_size=batchsize)\n",
    "    # weight and bais saving   \n",
    "    lst = save_model_weights(model =model, data_dir = data_dir, hidden_layer_n=hidden_layer_n,datachoice=datachoice) \n",
    "    \n",
    "    #============Test Phase============\n",
    "    yPred = model.predict(xTest)\n",
    "    yTest = to_categorical(yTest)\n",
    "    pred = np.argmax(yPred, axis=1)\n",
    "    test = np.argmax(yTest, axis=1)\n",
    "    test_acc=showResults(test, pred)\n",
    "    \n",
    "    L=[\"Accuracy  : {}\".format(test_acc[0]), \"Precision : {}\".format(test_acc[1]), \"f1Score : {}\".format(test_acc[2])]\n",
    "     \n",
    "    \n",
    "    ## Writing the models metrics info and dictionary \n",
    "    dicson ={\"data\": datachoice,  \"Hn\":hidden_layer_n, \"epoch\":num_epochs, \n",
    "                \"train_accuracy\":history.history['accuracy'][-1], \n",
    "                \"validation accuracy\":history.history['val_accuracy'][-1], \"test accuracy\": test_acc,\n",
    "             \"weight matrics path\":lst[0], \"bias matrics path\":lst[1]}\n",
    "\n",
    "    write_metrics_log(myDict =dicson, log_file=log_file)\n",
    "        \n",
    "    # Storing the dictionary of history of each trained model  \n",
    "    df_history_file = data_dir+\"History/history-\"+\"Hn_\"+str(hidden_layer_n) + datachoice+\".dat\"\n",
    "    print(\"train history is strored in\", df_history_file)\n",
    "    write_metrics_log(myDict=history.history, log_file=df_history_file)\n",
    "    \n",
    "    show_history(history)\n",
    "#     save_matlab_model(model,mat_wt, mat_bias, matlabfiles_dir =matlab_model_dir)\n",
    "    return df_history_file, L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is smoothdata\n",
      "Data file being used is: ENO3/train_input_smoothdata.csv\n",
      "In load data (31720, 6) (31720,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 49        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73 (584.00 Byte)\n",
      "Trainable params: 73 (584.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.7193 - accuracy: 0.7567\n",
      "Epoch 1: val_loss improved from inf to 0.55075, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 1s 1ms/step - loss: 0.7131 - accuracy: 0.7574 - val_loss: 0.5508 - val_accuracy: 0.7765\n",
      "Epoch 2/400\n",
      "243/359 [===================>..........] - ETA: 0s - loss: 0.5319 - accuracy: 0.7717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\xai\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/359 [==========================>...] - ETA: 0s - loss: 0.5271 - accuracy: 0.7717\n",
      "Epoch 2: val_loss improved from 0.55075 to 0.49641, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 820us/step - loss: 0.5259 - accuracy: 0.7707 - val_loss: 0.4964 - val_accuracy: 0.7765\n",
      "Epoch 3/400\n",
      "348/359 [============================>.] - ETA: 0s - loss: 0.4970 - accuracy: 0.7709\n",
      "Epoch 3: val_loss improved from 0.49641 to 0.47767, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 747us/step - loss: 0.4966 - accuracy: 0.7707 - val_loss: 0.4777 - val_accuracy: 0.7765\n",
      "Epoch 4/400\n",
      "270/359 [=====================>........] - ETA: 0s - loss: 0.4820 - accuracy: 0.7783\n",
      "Epoch 4: val_loss improved from 0.47767 to 0.46707, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 741us/step - loss: 0.4826 - accuracy: 0.7794 - val_loss: 0.4671 - val_accuracy: 0.7827\n",
      "Epoch 5/400\n",
      "271/359 [=====================>........] - ETA: 0s - loss: 0.4825 - accuracy: 0.7952\n",
      "Epoch 5: val_loss improved from 0.46707 to 0.45769, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 758us/step - loss: 0.4732 - accuracy: 0.8012 - val_loss: 0.4577 - val_accuracy: 0.8205\n",
      "Epoch 6/400\n",
      "310/359 [========================>.....] - ETA: 0s - loss: 0.4675 - accuracy: 0.8231\n",
      "Epoch 6: val_loss improved from 0.45769 to 0.45291, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 834us/step - loss: 0.4670 - accuracy: 0.8251 - val_loss: 0.4529 - val_accuracy: 0.8339\n",
      "Epoch 7/400\n",
      "326/359 [==========================>...] - ETA: 0s - loss: 0.4615 - accuracy: 0.8349\n",
      "Epoch 7: val_loss improved from 0.45291 to 0.44948, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 813us/step - loss: 0.4627 - accuracy: 0.8352 - val_loss: 0.4495 - val_accuracy: 0.8413\n",
      "Epoch 8/400\n",
      "272/359 [=====================>........] - ETA: 0s - loss: 0.4584 - accuracy: 0.8369\n",
      "Epoch 8: val_loss improved from 0.44948 to 0.44638, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 737us/step - loss: 0.4594 - accuracy: 0.8379 - val_loss: 0.4464 - val_accuracy: 0.8440\n",
      "Epoch 9/400\n",
      "272/359 [=====================>........] - ETA: 0s - loss: 0.4594 - accuracy: 0.8411\n",
      "Epoch 9: val_loss improved from 0.44638 to 0.44402, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 729us/step - loss: 0.4564 - accuracy: 0.8401 - val_loss: 0.4440 - val_accuracy: 0.8482\n",
      "Epoch 10/400\n",
      "271/359 [=====================>........] - ETA: 0s - loss: 0.4512 - accuracy: 0.8486\n",
      "Epoch 10: val_loss improved from 0.44402 to 0.44133, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 719us/step - loss: 0.4537 - accuracy: 0.8467 - val_loss: 0.4413 - val_accuracy: 0.8502\n",
      "Epoch 11/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.4493 - accuracy: 0.8456\n",
      "Epoch 11: val_loss improved from 0.44133 to 0.44110, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 774us/step - loss: 0.4504 - accuracy: 0.8448 - val_loss: 0.4411 - val_accuracy: 0.8440\n",
      "Epoch 12/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.4472 - accuracy: 0.8452\n",
      "Epoch 12: val_loss improved from 0.44110 to 0.43653, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 792us/step - loss: 0.4479 - accuracy: 0.8451 - val_loss: 0.4365 - val_accuracy: 0.8512\n",
      "Epoch 13/400\n",
      "324/359 [==========================>...] - ETA: 0s - loss: 0.4426 - accuracy: 0.8483\n",
      "Epoch 13: val_loss improved from 0.43653 to 0.43332, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 798us/step - loss: 0.4448 - accuracy: 0.8468 - val_loss: 0.4333 - val_accuracy: 0.8512\n",
      "Epoch 14/400\n",
      "272/359 [=====================>........] - ETA: 0s - loss: 0.4448 - accuracy: 0.8494\n",
      "Epoch 14: val_loss improved from 0.43332 to 0.42968, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 724us/step - loss: 0.4419 - accuracy: 0.8495 - val_loss: 0.4297 - val_accuracy: 0.8524\n",
      "Epoch 15/400\n",
      "321/359 [=========================>....] - ETA: 0s - loss: 0.4411 - accuracy: 0.8499\n",
      "Epoch 15: val_loss improved from 0.42968 to 0.42695, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 825us/step - loss: 0.4390 - accuracy: 0.8504 - val_loss: 0.4269 - val_accuracy: 0.8507\n",
      "Epoch 16/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.4346 - accuracy: 0.8530\n",
      "Epoch 16: val_loss improved from 0.42695 to 0.42630, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 776us/step - loss: 0.4362 - accuracy: 0.8527 - val_loss: 0.4263 - val_accuracy: 0.8569\n",
      "Epoch 17/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.4347 - accuracy: 0.8526\n",
      "Epoch 17: val_loss improved from 0.42630 to 0.42324, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 774us/step - loss: 0.4334 - accuracy: 0.8533 - val_loss: 0.4232 - val_accuracy: 0.8593\n",
      "Epoch 18/400\n",
      "348/359 [============================>.] - ETA: 0s - loss: 0.4329 - accuracy: 0.8546\n",
      "Epoch 18: val_loss improved from 0.42324 to 0.41934, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 761us/step - loss: 0.4308 - accuracy: 0.8558 - val_loss: 0.4193 - val_accuracy: 0.8517\n",
      "Epoch 19/400\n",
      "333/359 [==========================>...] - ETA: 0s - loss: 0.4305 - accuracy: 0.8519\n",
      "Epoch 19: val_loss improved from 0.41934 to 0.41696, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 778us/step - loss: 0.4282 - accuracy: 0.8525 - val_loss: 0.4170 - val_accuracy: 0.8532\n",
      "Epoch 20/400\n",
      "353/359 [============================>.] - ETA: 0s - loss: 0.4251 - accuracy: 0.8546\n",
      "Epoch 20: val_loss improved from 0.41696 to 0.41450, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 747us/step - loss: 0.4252 - accuracy: 0.8543 - val_loss: 0.4145 - val_accuracy: 0.8559\n",
      "Epoch 21/400\n",
      "341/359 [===========================>..] - ETA: 0s - loss: 0.4246 - accuracy: 0.8528\n",
      "Epoch 21: val_loss improved from 0.41450 to 0.41210, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 767us/step - loss: 0.4225 - accuracy: 0.8534 - val_loss: 0.4121 - val_accuracy: 0.8613\n",
      "Epoch 22/400\n",
      "350/359 [============================>.] - ETA: 0s - loss: 0.4209 - accuracy: 0.8584\n",
      "Epoch 22: val_loss improved from 0.41210 to 0.40938, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 750us/step - loss: 0.4198 - accuracy: 0.8588 - val_loss: 0.4094 - val_accuracy: 0.8603\n",
      "Epoch 23/400\n",
      "272/359 [=====================>........] - ETA: 0s - loss: 0.4160 - accuracy: 0.8593\n",
      "Epoch 23: val_loss improved from 0.40938 to 0.40910, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 726us/step - loss: 0.4171 - accuracy: 0.8584 - val_loss: 0.4091 - val_accuracy: 0.8482\n",
      "Epoch 24/400\n",
      "356/359 [============================>.] - ETA: 0s - loss: 0.4146 - accuracy: 0.8609\n",
      "Epoch 24: val_loss improved from 0.40910 to 0.40334, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 756us/step - loss: 0.4142 - accuracy: 0.8609 - val_loss: 0.4033 - val_accuracy: 0.8601\n",
      "Epoch 25/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.4089 - accuracy: 0.8634\n",
      "Epoch 25: val_loss improved from 0.40334 to 0.40210, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 764us/step - loss: 0.4106 - accuracy: 0.8632 - val_loss: 0.4021 - val_accuracy: 0.8675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.4087 - accuracy: 0.8645\n",
      "Epoch 26: val_loss improved from 0.40210 to 0.39722, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 759us/step - loss: 0.4075 - accuracy: 0.8648 - val_loss: 0.3972 - val_accuracy: 0.8670\n",
      "Epoch 27/400\n",
      "348/359 [============================>.] - ETA: 0s - loss: 0.4057 - accuracy: 0.8674\n",
      "Epoch 27: val_loss improved from 0.39722 to 0.39232, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 753us/step - loss: 0.4042 - accuracy: 0.8679 - val_loss: 0.3923 - val_accuracy: 0.8677\n",
      "Epoch 28/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.4002 - accuracy: 0.8688\n",
      "Epoch 28: val_loss improved from 0.39232 to 0.38912, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 766us/step - loss: 0.4004 - accuracy: 0.8687 - val_loss: 0.3891 - val_accuracy: 0.8687\n",
      "Epoch 29/400\n",
      "357/359 [============================>.] - ETA: 0s - loss: 0.3967 - accuracy: 0.8700\n",
      "Epoch 29: val_loss improved from 0.38912 to 0.38534, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 734us/step - loss: 0.3969 - accuracy: 0.8697 - val_loss: 0.3853 - val_accuracy: 0.8685\n",
      "Epoch 30/400\n",
      "356/359 [============================>.] - ETA: 0s - loss: 0.3938 - accuracy: 0.8714\n",
      "Epoch 30: val_loss improved from 0.38534 to 0.38340, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 737us/step - loss: 0.3938 - accuracy: 0.8714 - val_loss: 0.3834 - val_accuracy: 0.8801\n",
      "Epoch 31/400\n",
      "341/359 [===========================>..] - ETA: 0s - loss: 0.3913 - accuracy: 0.8759\n",
      "Epoch 31: val_loss improved from 0.38340 to 0.37960, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 774us/step - loss: 0.3905 - accuracy: 0.8763 - val_loss: 0.3796 - val_accuracy: 0.8742\n",
      "Epoch 32/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.3857 - accuracy: 0.8762\n",
      "Epoch 32: val_loss improved from 0.37960 to 0.37649, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 779us/step - loss: 0.3867 - accuracy: 0.8750 - val_loss: 0.3765 - val_accuracy: 0.8771\n",
      "Epoch 33/400\n",
      "339/359 [===========================>..] - ETA: 0s - loss: 0.3837 - accuracy: 0.8792\n",
      "Epoch 33: val_loss improved from 0.37649 to 0.37466, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 779us/step - loss: 0.3832 - accuracy: 0.8797 - val_loss: 0.3747 - val_accuracy: 0.8801\n",
      "Epoch 34/400\n",
      "336/359 [===========================>..] - ETA: 0s - loss: 0.3802 - accuracy: 0.8830\n",
      "Epoch 34: val_loss improved from 0.37466 to 0.36981, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 771us/step - loss: 0.3801 - accuracy: 0.8829 - val_loss: 0.3698 - val_accuracy: 0.8816\n",
      "Epoch 35/400\n",
      "336/359 [===========================>..] - ETA: 0s - loss: 0.3783 - accuracy: 0.8855\n",
      "Epoch 35: val_loss improved from 0.36981 to 0.36688, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 775us/step - loss: 0.3777 - accuracy: 0.8854 - val_loss: 0.3669 - val_accuracy: 0.8878\n",
      "Epoch 36/400\n",
      "311/359 [========================>.....] - ETA: 0s - loss: 0.3750 - accuracy: 0.8888\n",
      "Epoch 36: val_loss improved from 0.36688 to 0.36606, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 811us/step - loss: 0.3750 - accuracy: 0.8891 - val_loss: 0.3661 - val_accuracy: 0.8791\n",
      "Epoch 37/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.3729 - accuracy: 0.8882\n",
      "Epoch 37: val_loss improved from 0.36606 to 0.36340, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 761us/step - loss: 0.3730 - accuracy: 0.8886 - val_loss: 0.3634 - val_accuracy: 0.8984\n",
      "Epoch 38/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.3719 - accuracy: 0.8913\n",
      "Epoch 38: val_loss improved from 0.36340 to 0.36136, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 813us/step - loss: 0.3707 - accuracy: 0.8915 - val_loss: 0.3614 - val_accuracy: 0.8981\n",
      "Epoch 39/400\n",
      "312/359 [=========================>....] - ETA: 0s - loss: 0.3692 - accuracy: 0.8958\n",
      "Epoch 39: val_loss improved from 0.36136 to 0.35840, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 824us/step - loss: 0.3688 - accuracy: 0.8954 - val_loss: 0.3584 - val_accuracy: 0.8912\n",
      "Epoch 40/400\n",
      "316/359 [=========================>....] - ETA: 0s - loss: 0.3681 - accuracy: 0.8930\n",
      "Epoch 40: val_loss improved from 0.35840 to 0.35748, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 824us/step - loss: 0.3672 - accuracy: 0.8926 - val_loss: 0.3575 - val_accuracy: 0.8821\n",
      "Epoch 41/400\n",
      "309/359 [========================>.....] - ETA: 0s - loss: 0.3644 - accuracy: 0.8938\n",
      "Epoch 41: val_loss improved from 0.35748 to 0.35671, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 844us/step - loss: 0.3653 - accuracy: 0.8946 - val_loss: 0.3567 - val_accuracy: 0.8897\n",
      "Epoch 42/400\n",
      "299/359 [=======================>......] - ETA: 0s - loss: 0.3646 - accuracy: 0.8961\n",
      "Epoch 42: val_loss improved from 0.35671 to 0.35496, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 865us/step - loss: 0.3638 - accuracy: 0.8963 - val_loss: 0.3550 - val_accuracy: 0.8843\n",
      "Epoch 43/400\n",
      "297/359 [=======================>......] - ETA: 0s - loss: 0.3660 - accuracy: 0.8941\n",
      "Epoch 43: val_loss improved from 0.35496 to 0.35200, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 856us/step - loss: 0.3621 - accuracy: 0.8950 - val_loss: 0.3520 - val_accuracy: 0.8915\n",
      "Epoch 44/400\n",
      "324/359 [==========================>...] - ETA: 0s - loss: 0.3615 - accuracy: 0.8957\n",
      "Epoch 44: val_loss did not improve from 0.35200\n",
      "359/359 [==============================] - 0s 765us/step - loss: 0.3606 - accuracy: 0.8957 - val_loss: 0.3533 - val_accuracy: 0.8888\n",
      "Epoch 45/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.3596 - accuracy: 0.8968\n",
      "Epoch 45: val_loss did not improve from 0.35200\n",
      "359/359 [==============================] - 0s 723us/step - loss: 0.3595 - accuracy: 0.8969 - val_loss: 0.3547 - val_accuracy: 0.8880\n",
      "Epoch 46/400\n",
      "342/359 [===========================>..] - ETA: 0s - loss: 0.3573 - accuracy: 0.8987\n",
      "Epoch 46: val_loss improved from 0.35200 to 0.34928, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 776us/step - loss: 0.3579 - accuracy: 0.8984 - val_loss: 0.3493 - val_accuracy: 0.8905\n",
      "Epoch 47/400\n",
      "340/359 [===========================>..] - ETA: 0s - loss: 0.3552 - accuracy: 0.8977\n",
      "Epoch 47: val_loss improved from 0.34928 to 0.34897, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 777us/step - loss: 0.3559 - accuracy: 0.8976 - val_loss: 0.3490 - val_accuracy: 0.9031\n",
      "Epoch 48/400\n",
      "340/359 [===========================>..] - ETA: 0s - loss: 0.3537 - accuracy: 0.9009\n",
      "Epoch 48: val_loss improved from 0.34897 to 0.34599, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 768us/step - loss: 0.3544 - accuracy: 0.9008 - val_loss: 0.3460 - val_accuracy: 0.9001\n",
      "Epoch 49/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.3537 - accuracy: 0.9022\n",
      "Epoch 49: val_loss did not improve from 0.34599\n",
      "359/359 [==============================] - 0s 727us/step - loss: 0.3525 - accuracy: 0.9028 - val_loss: 0.3462 - val_accuracy: 0.8922\n",
      "Epoch 50/400\n",
      "338/359 [===========================>..] - ETA: 0s - loss: 0.3502 - accuracy: 0.9018\n",
      "Epoch 50: val_loss improved from 0.34599 to 0.34281, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - 0s 807us/step - loss: 0.3509 - accuracy: 0.9015 - val_loss: 0.3428 - val_accuracy: 0.8996\n",
      "Epoch 51/400\n",
      "306/359 [========================>.....] - ETA: 0s - loss: 0.3527 - accuracy: 0.9033\n",
      "Epoch 51: val_loss improved from 0.34281 to 0.34049, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 830us/step - loss: 0.3491 - accuracy: 0.9046 - val_loss: 0.3405 - val_accuracy: 0.9006\n",
      "Epoch 52/400\n",
      "342/359 [===========================>..] - ETA: 0s - loss: 0.3488 - accuracy: 0.9056\n",
      "Epoch 52: val_loss improved from 0.34049 to 0.33831, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 776us/step - loss: 0.3469 - accuracy: 0.9058 - val_loss: 0.3383 - val_accuracy: 0.9066\n",
      "Epoch 53/400\n",
      "337/359 [===========================>..] - ETA: 0s - loss: 0.3443 - accuracy: 0.9086\n",
      "Epoch 53: val_loss improved from 0.33831 to 0.33779, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 776us/step - loss: 0.3448 - accuracy: 0.9088 - val_loss: 0.3378 - val_accuracy: 0.9066\n",
      "Epoch 54/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.3398 - accuracy: 0.9099\n",
      "Epoch 54: val_loss did not improve from 0.33779\n",
      "359/359 [==============================] - 0s 749us/step - loss: 0.3429 - accuracy: 0.9092 - val_loss: 0.3393 - val_accuracy: 0.9063\n",
      "Epoch 55/400\n",
      "339/359 [===========================>..] - ETA: 0s - loss: 0.3402 - accuracy: 0.9117\n",
      "Epoch 55: val_loss improved from 0.33779 to 0.33288, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 767us/step - loss: 0.3405 - accuracy: 0.9118 - val_loss: 0.3329 - val_accuracy: 0.9058\n",
      "Epoch 56/400\n",
      "336/359 [===========================>..] - ETA: 0s - loss: 0.3380 - accuracy: 0.9122\n",
      "Epoch 56: val_loss did not improve from 0.33288\n",
      "359/359 [==============================] - 0s 768us/step - loss: 0.3384 - accuracy: 0.9123 - val_loss: 0.3341 - val_accuracy: 0.9112\n",
      "Epoch 57/400\n",
      "299/359 [=======================>......] - ETA: 0s - loss: 0.3371 - accuracy: 0.9163\n",
      "Epoch 57: val_loss improved from 0.33288 to 0.32957, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 850us/step - loss: 0.3357 - accuracy: 0.9180 - val_loss: 0.3296 - val_accuracy: 0.9033\n",
      "Epoch 58/400\n",
      "304/359 [========================>.....] - ETA: 0s - loss: 0.3335 - accuracy: 0.9156\n",
      "Epoch 58: val_loss improved from 0.32957 to 0.32610, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 842us/step - loss: 0.3325 - accuracy: 0.9154 - val_loss: 0.3261 - val_accuracy: 0.9216\n",
      "Epoch 59/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.3289 - accuracy: 0.9181\n",
      "Epoch 59: val_loss improved from 0.32610 to 0.32269, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 778us/step - loss: 0.3292 - accuracy: 0.9186 - val_loss: 0.3227 - val_accuracy: 0.9187\n",
      "Epoch 60/400\n",
      "338/359 [===========================>..] - ETA: 0s - loss: 0.3255 - accuracy: 0.9228\n",
      "Epoch 60: val_loss improved from 0.32269 to 0.31987, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 780us/step - loss: 0.3256 - accuracy: 0.9227 - val_loss: 0.3199 - val_accuracy: 0.9169\n",
      "Epoch 61/400\n",
      "338/359 [===========================>..] - ETA: 0s - loss: 0.3208 - accuracy: 0.9222\n",
      "Epoch 61: val_loss improved from 0.31987 to 0.31509, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 775us/step - loss: 0.3204 - accuracy: 0.9224 - val_loss: 0.3151 - val_accuracy: 0.9251\n",
      "Epoch 62/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.3121 - accuracy: 0.9256\n",
      "Epoch 62: val_loss improved from 0.31509 to 0.31195, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 788us/step - loss: 0.3159 - accuracy: 0.9246 - val_loss: 0.3120 - val_accuracy: 0.9120\n",
      "Epoch 63/400\n",
      "321/359 [=========================>....] - ETA: 0s - loss: 0.3139 - accuracy: 0.9241\n",
      "Epoch 63: val_loss improved from 0.31195 to 0.30735, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 814us/step - loss: 0.3123 - accuracy: 0.9246 - val_loss: 0.3074 - val_accuracy: 0.9206\n",
      "Epoch 64/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.3102 - accuracy: 0.9242\n",
      "Epoch 64: val_loss improved from 0.30735 to 0.30381, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 788us/step - loss: 0.3091 - accuracy: 0.9244 - val_loss: 0.3038 - val_accuracy: 0.9110\n",
      "Epoch 65/400\n",
      "352/359 [============================>.] - ETA: 0s - loss: 0.3067 - accuracy: 0.9217\n",
      "Epoch 65: val_loss improved from 0.30381 to 0.30151, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 899us/step - loss: 0.3062 - accuracy: 0.9218 - val_loss: 0.3015 - val_accuracy: 0.9236\n",
      "Epoch 66/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.3040 - accuracy: 0.9236\n",
      "Epoch 66: val_loss improved from 0.30151 to 0.29906, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 751us/step - loss: 0.3036 - accuracy: 0.9240 - val_loss: 0.2991 - val_accuracy: 0.9194\n",
      "Epoch 67/400\n",
      "351/359 [============================>.] - ETA: 0s - loss: 0.3013 - accuracy: 0.9221\n",
      "Epoch 67: val_loss improved from 0.29906 to 0.29646, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 757us/step - loss: 0.3009 - accuracy: 0.9225 - val_loss: 0.2965 - val_accuracy: 0.9174\n",
      "Epoch 68/400\n",
      "347/359 [===========================>..] - ETA: 0s - loss: 0.2999 - accuracy: 0.9217\n",
      "Epoch 68: val_loss improved from 0.29646 to 0.29358, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 748us/step - loss: 0.2988 - accuracy: 0.9223 - val_loss: 0.2936 - val_accuracy: 0.9201\n",
      "Epoch 69/400\n",
      "323/359 [=========================>....] - ETA: 0s - loss: 0.2973 - accuracy: 0.9216\n",
      "Epoch 69: val_loss improved from 0.29358 to 0.29163, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 791us/step - loss: 0.2958 - accuracy: 0.9221 - val_loss: 0.2916 - val_accuracy: 0.9199\n",
      "Epoch 70/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.2927 - accuracy: 0.9232\n",
      "Epoch 70: val_loss improved from 0.29163 to 0.28923, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 759us/step - loss: 0.2930 - accuracy: 0.9227 - val_loss: 0.2892 - val_accuracy: 0.9187\n",
      "Epoch 71/400\n",
      "293/359 [=======================>......] - ETA: 0s - loss: 0.2896 - accuracy: 0.9229\n",
      "Epoch 71: val_loss improved from 0.28923 to 0.28553, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 866us/step - loss: 0.2899 - accuracy: 0.9229 - val_loss: 0.2855 - val_accuracy: 0.9216\n",
      "Epoch 72/400\n",
      "340/359 [===========================>..] - ETA: 0s - loss: 0.2859 - accuracy: 0.9254\n",
      "Epoch 72: val_loss improved from 0.28553 to 0.28363, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 807us/step - loss: 0.2866 - accuracy: 0.9247 - val_loss: 0.2836 - val_accuracy: 0.9194\n",
      "Epoch 73/400\n",
      "308/359 [========================>.....] - ETA: 0s - loss: 0.2854 - accuracy: 0.9242\n",
      "Epoch 73: val_loss improved from 0.28363 to 0.27967, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 865us/step - loss: 0.2838 - accuracy: 0.9241 - val_loss: 0.2797 - val_accuracy: 0.9211\n",
      "Epoch 74/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.2817 - accuracy: 0.9229\n",
      "Epoch 74: val_loss improved from 0.27967 to 0.27686, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 790us/step - loss: 0.2806 - accuracy: 0.9226 - val_loss: 0.2769 - val_accuracy: 0.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/400\n",
      "325/359 [==========================>...] - ETA: 0s - loss: 0.2796 - accuracy: 0.9233\n",
      "Epoch 75: val_loss improved from 0.27686 to 0.27403, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 797us/step - loss: 0.2779 - accuracy: 0.9232 - val_loss: 0.2740 - val_accuracy: 0.9192\n",
      "Epoch 76/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.2754 - accuracy: 0.9239\n",
      "Epoch 76: val_loss improved from 0.27403 to 0.27135, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 786us/step - loss: 0.2754 - accuracy: 0.9242 - val_loss: 0.2713 - val_accuracy: 0.9184\n",
      "Epoch 77/400\n",
      "326/359 [==========================>...] - ETA: 0s - loss: 0.2706 - accuracy: 0.9227\n",
      "Epoch 77: val_loss did not improve from 0.27135\n",
      "359/359 [==============================] - 0s 776us/step - loss: 0.2726 - accuracy: 0.9227 - val_loss: 0.2714 - val_accuracy: 0.9177\n",
      "Epoch 78/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.2711 - accuracy: 0.9222\n",
      "Epoch 78: val_loss improved from 0.27135 to 0.26686, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 790us/step - loss: 0.2708 - accuracy: 0.9221 - val_loss: 0.2669 - val_accuracy: 0.9214\n",
      "Epoch 79/400\n",
      "336/359 [===========================>..] - ETA: 0s - loss: 0.2677 - accuracy: 0.9225\n",
      "Epoch 79: val_loss improved from 0.26686 to 0.26537, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 791us/step - loss: 0.2689 - accuracy: 0.9221 - val_loss: 0.2654 - val_accuracy: 0.9189\n",
      "Epoch 80/400\n",
      "333/359 [==========================>...] - ETA: 0s - loss: 0.2664 - accuracy: 0.9212\n",
      "Epoch 80: val_loss improved from 0.26537 to 0.26516, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 775us/step - loss: 0.2668 - accuracy: 0.9216 - val_loss: 0.2652 - val_accuracy: 0.9189\n",
      "Epoch 81/400\n",
      "350/359 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.9217\n",
      "Epoch 81: val_loss improved from 0.26516 to 0.26208, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 749us/step - loss: 0.2664 - accuracy: 0.9218 - val_loss: 0.2621 - val_accuracy: 0.9201\n",
      "Epoch 82/400\n",
      "268/359 [=====================>........] - ETA: 0s - loss: 0.2631 - accuracy: 0.9223\n",
      "Epoch 82: val_loss improved from 0.26208 to 0.26044, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 726us/step - loss: 0.2637 - accuracy: 0.9222 - val_loss: 0.2604 - val_accuracy: 0.9192\n",
      "Epoch 83/400\n",
      "351/359 [============================>.] - ETA: 0s - loss: 0.2630 - accuracy: 0.9207\n",
      "Epoch 83: val_loss improved from 0.26044 to 0.25857, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 742us/step - loss: 0.2622 - accuracy: 0.9213 - val_loss: 0.2586 - val_accuracy: 0.9229\n",
      "Epoch 84/400\n",
      "355/359 [============================>.] - ETA: 0s - loss: 0.2605 - accuracy: 0.9216\n",
      "Epoch 84: val_loss improved from 0.25857 to 0.25745, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 736us/step - loss: 0.2605 - accuracy: 0.9218 - val_loss: 0.2575 - val_accuracy: 0.9268\n",
      "Epoch 85/400\n",
      "275/359 [=====================>........] - ETA: 0s - loss: 0.2594 - accuracy: 0.9199\n",
      "Epoch 85: val_loss improved from 0.25745 to 0.25612, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 715us/step - loss: 0.2592 - accuracy: 0.9212 - val_loss: 0.2561 - val_accuracy: 0.9197\n",
      "Epoch 86/400\n",
      "271/359 [=====================>........] - ETA: 0s - loss: 0.2568 - accuracy: 0.9212\n",
      "Epoch 86: val_loss improved from 0.25612 to 0.25482, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 723us/step - loss: 0.2580 - accuracy: 0.9209 - val_loss: 0.2548 - val_accuracy: 0.9199\n",
      "Epoch 87/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.2559 - accuracy: 0.9231\n",
      "Epoch 87: val_loss improved from 0.25482 to 0.25398, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 812us/step - loss: 0.2566 - accuracy: 0.9228 - val_loss: 0.2540 - val_accuracy: 0.9147\n",
      "Epoch 88/400\n",
      "325/359 [==========================>...] - ETA: 0s - loss: 0.2554 - accuracy: 0.9210\n",
      "Epoch 88: val_loss improved from 0.25398 to 0.25183, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 800us/step - loss: 0.2554 - accuracy: 0.9209 - val_loss: 0.2518 - val_accuracy: 0.9226\n",
      "Epoch 89/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.2518 - accuracy: 0.9235\n",
      "Epoch 89: val_loss improved from 0.25183 to 0.25154, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 784us/step - loss: 0.2543 - accuracy: 0.9223 - val_loss: 0.2515 - val_accuracy: 0.9157\n",
      "Epoch 90/400\n",
      "331/359 [==========================>...] - ETA: 0s - loss: 0.2517 - accuracy: 0.9230\n",
      "Epoch 90: val_loss improved from 0.25154 to 0.25039, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 774us/step - loss: 0.2525 - accuracy: 0.9224 - val_loss: 0.2504 - val_accuracy: 0.9157\n",
      "Epoch 91/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.2514 - accuracy: 0.9220\n",
      "Epoch 91: val_loss improved from 0.25039 to 0.24852, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 770us/step - loss: 0.2515 - accuracy: 0.9220 - val_loss: 0.2485 - val_accuracy: 0.9182\n",
      "Epoch 92/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.2493 - accuracy: 0.9234\n",
      "Epoch 92: val_loss improved from 0.24852 to 0.24842, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 757us/step - loss: 0.2499 - accuracy: 0.9230 - val_loss: 0.2484 - val_accuracy: 0.9135\n",
      "Epoch 93/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.2495 - accuracy: 0.9229\n",
      "Epoch 93: val_loss improved from 0.24842 to 0.24712, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 781us/step - loss: 0.2490 - accuracy: 0.9228 - val_loss: 0.2471 - val_accuracy: 0.9157\n",
      "Epoch 94/400\n",
      "326/359 [==========================>...] - ETA: 0s - loss: 0.2472 - accuracy: 0.9230\n",
      "Epoch 94: val_loss improved from 0.24712 to 0.24381, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 793us/step - loss: 0.2477 - accuracy: 0.9231 - val_loss: 0.2438 - val_accuracy: 0.9224\n",
      "Epoch 95/400\n",
      "310/359 [========================>.....] - ETA: 0s - loss: 0.2475 - accuracy: 0.9241\n",
      "Epoch 95: val_loss did not improve from 0.24381\n",
      "359/359 [==============================] - 0s 795us/step - loss: 0.2464 - accuracy: 0.9243 - val_loss: 0.2441 - val_accuracy: 0.9204\n",
      "Epoch 96/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.2468 - accuracy: 0.9232\n",
      "Epoch 96: val_loss did not improve from 0.24381\n",
      "359/359 [==============================] - 0s 758us/step - loss: 0.2456 - accuracy: 0.9238 - val_loss: 0.2440 - val_accuracy: 0.9216\n",
      "Epoch 97/400\n",
      "338/359 [===========================>..] - ETA: 0s - loss: 0.2451 - accuracy: 0.9242\n",
      "Epoch 97: val_loss improved from 0.24381 to 0.24145, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 781us/step - loss: 0.2451 - accuracy: 0.9244 - val_loss: 0.2414 - val_accuracy: 0.9219\n",
      "Epoch 98/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.2436 - accuracy: 0.9254\n",
      "Epoch 98: val_loss improved from 0.24145 to 0.24113, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 767us/step - loss: 0.2436 - accuracy: 0.9253 - val_loss: 0.2411 - val_accuracy: 0.9219\n",
      "Epoch 99/400\n",
      "337/359 [===========================>..] - ETA: 0s - loss: 0.2421 - accuracy: 0.9266\n",
      "Epoch 99: val_loss improved from 0.24113 to 0.23950, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - 0s 783us/step - loss: 0.2425 - accuracy: 0.9262 - val_loss: 0.2395 - val_accuracy: 0.9201\n",
      "Epoch 100/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.2411 - accuracy: 0.9247\n",
      "Epoch 100: val_loss improved from 0.23950 to 0.23775, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 774us/step - loss: 0.2414 - accuracy: 0.9243 - val_loss: 0.2377 - val_accuracy: 0.9221\n",
      "Epoch 101/400\n",
      "326/359 [==========================>...] - ETA: 0s - loss: 0.2413 - accuracy: 0.9252\n",
      "Epoch 101: val_loss did not improve from 0.23775\n",
      "359/359 [==============================] - 0s 769us/step - loss: 0.2405 - accuracy: 0.9254 - val_loss: 0.2378 - val_accuracy: 0.9214\n",
      "Epoch 102/400\n",
      "333/359 [==========================>...] - ETA: 0s - loss: 0.2385 - accuracy: 0.9261\n",
      "Epoch 102: val_loss improved from 0.23775 to 0.23694, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 824us/step - loss: 0.2395 - accuracy: 0.9251 - val_loss: 0.2369 - val_accuracy: 0.9192\n",
      "Epoch 103/400\n",
      "323/359 [=========================>....] - ETA: 0s - loss: 0.2374 - accuracy: 0.9273\n",
      "Epoch 103: val_loss improved from 0.23694 to 0.23635, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 803us/step - loss: 0.2389 - accuracy: 0.9256 - val_loss: 0.2363 - val_accuracy: 0.9234\n",
      "Epoch 104/400\n",
      "331/359 [==========================>...] - ETA: 0s - loss: 0.2374 - accuracy: 0.9253\n",
      "Epoch 104: val_loss did not improve from 0.23635\n",
      "359/359 [==============================] - 0s 753us/step - loss: 0.2381 - accuracy: 0.9252 - val_loss: 0.2377 - val_accuracy: 0.9234\n",
      "Epoch 105/400\n",
      "340/359 [===========================>..] - ETA: 0s - loss: 0.2369 - accuracy: 0.9266\n",
      "Epoch 105: val_loss improved from 0.23635 to 0.23606, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 782us/step - loss: 0.2368 - accuracy: 0.9267 - val_loss: 0.2361 - val_accuracy: 0.9194\n",
      "Epoch 106/400\n",
      "328/359 [==========================>...] - ETA: 0s - loss: 0.2347 - accuracy: 0.9274\n",
      "Epoch 106: val_loss improved from 0.23606 to 0.23256, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 814us/step - loss: 0.2359 - accuracy: 0.9266 - val_loss: 0.2326 - val_accuracy: 0.9231\n",
      "Epoch 107/400\n",
      "329/359 [==========================>...] - ETA: 0s - loss: 0.2345 - accuracy: 0.9270\n",
      "Epoch 107: val_loss improved from 0.23256 to 0.23232, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 812us/step - loss: 0.2350 - accuracy: 0.9267 - val_loss: 0.2323 - val_accuracy: 0.9234\n",
      "Epoch 108/400\n",
      "315/359 [=========================>....] - ETA: 0s - loss: 0.2339 - accuracy: 0.9259\n",
      "Epoch 108: val_loss improved from 0.23232 to 0.23156, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 852us/step - loss: 0.2347 - accuracy: 0.9263 - val_loss: 0.2316 - val_accuracy: 0.9229\n",
      "Epoch 109/400\n",
      "313/359 [=========================>....] - ETA: 0s - loss: 0.2334 - accuracy: 0.9263\n",
      "Epoch 109: val_loss improved from 0.23156 to 0.23025, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 867us/step - loss: 0.2336 - accuracy: 0.9265 - val_loss: 0.2303 - val_accuracy: 0.9273\n",
      "Epoch 110/400\n",
      "300/359 [========================>.....] - ETA: 0s - loss: 0.2325 - accuracy: 0.9268\n",
      "Epoch 110: val_loss improved from 0.23025 to 0.22961, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 859us/step - loss: 0.2325 - accuracy: 0.9270 - val_loss: 0.2296 - val_accuracy: 0.9286\n",
      "Epoch 111/400\n",
      "307/359 [========================>.....] - ETA: 0s - loss: 0.2326 - accuracy: 0.9268\n",
      "Epoch 111: val_loss improved from 0.22961 to 0.22817, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 856us/step - loss: 0.2316 - accuracy: 0.9278 - val_loss: 0.2282 - val_accuracy: 0.9241\n",
      "Epoch 112/400\n",
      "303/359 [========================>.....] - ETA: 0s - loss: 0.2326 - accuracy: 0.9266\n",
      "Epoch 112: val_loss improved from 0.22817 to 0.22722, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 872us/step - loss: 0.2310 - accuracy: 0.9267 - val_loss: 0.2272 - val_accuracy: 0.9244\n",
      "Epoch 113/400\n",
      "296/359 [=======================>......] - ETA: 0s - loss: 0.2315 - accuracy: 0.9266\n",
      "Epoch 113: val_loss did not improve from 0.22722\n",
      "359/359 [==============================] - 0s 834us/step - loss: 0.2304 - accuracy: 0.9277 - val_loss: 0.2284 - val_accuracy: 0.9221\n",
      "Epoch 114/400\n",
      "322/359 [=========================>....] - ETA: 0s - loss: 0.2296 - accuracy: 0.9270\n",
      "Epoch 114: val_loss improved from 0.22722 to 0.22669, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 805us/step - loss: 0.2294 - accuracy: 0.9273 - val_loss: 0.2267 - val_accuracy: 0.9330\n",
      "Epoch 115/400\n",
      "354/359 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9276\n",
      "Epoch 115: val_loss improved from 0.22669 to 0.22468, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 933us/step - loss: 0.2292 - accuracy: 0.9279 - val_loss: 0.2247 - val_accuracy: 0.9278\n",
      "Epoch 116/400\n",
      "303/359 [========================>.....] - ETA: 0s - loss: 0.2283 - accuracy: 0.9262\n",
      "Epoch 116: val_loss improved from 0.22468 to 0.22443, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 863us/step - loss: 0.2277 - accuracy: 0.9274 - val_loss: 0.2244 - val_accuracy: 0.9246\n",
      "Epoch 117/400\n",
      "331/359 [==========================>...] - ETA: 0s - loss: 0.2274 - accuracy: 0.9285\n",
      "Epoch 117: val_loss did not improve from 0.22443\n",
      "359/359 [==============================] - 0s 773us/step - loss: 0.2272 - accuracy: 0.9288 - val_loss: 0.2265 - val_accuracy: 0.9189\n",
      "Epoch 118/400\n",
      "333/359 [==========================>...] - ETA: 0s - loss: 0.2252 - accuracy: 0.9271\n",
      "Epoch 118: val_loss improved from 0.22443 to 0.22241, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 798us/step - loss: 0.2265 - accuracy: 0.9268 - val_loss: 0.2224 - val_accuracy: 0.9320\n",
      "Epoch 119/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.2244 - accuracy: 0.9287\n",
      "Epoch 119: val_loss did not improve from 0.22241\n",
      "359/359 [==============================] - 0s 757us/step - loss: 0.2256 - accuracy: 0.9284 - val_loss: 0.2227 - val_accuracy: 0.9315\n",
      "Epoch 120/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.2245 - accuracy: 0.9297\n",
      "Epoch 120: val_loss improved from 0.22241 to 0.22197, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 799us/step - loss: 0.2250 - accuracy: 0.9292 - val_loss: 0.2220 - val_accuracy: 0.9234\n",
      "Epoch 121/400\n",
      "300/359 [========================>.....] - ETA: 0s - loss: 0.2267 - accuracy: 0.9279\n",
      "Epoch 121: val_loss improved from 0.22197 to 0.21993, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 901us/step - loss: 0.2243 - accuracy: 0.9292 - val_loss: 0.2199 - val_accuracy: 0.9298\n",
      "Epoch 122/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.2248 - accuracy: 0.9292\n",
      "Epoch 122: val_loss did not improve from 0.21993\n",
      "359/359 [==============================] - 0s 762us/step - loss: 0.2235 - accuracy: 0.9294 - val_loss: 0.2213 - val_accuracy: 0.9226\n",
      "Epoch 123/400\n",
      "312/359 [=========================>....] - ETA: 0s - loss: 0.2238 - accuracy: 0.9293\n",
      "Epoch 123: val_loss improved from 0.21993 to 0.21973, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 845us/step - loss: 0.2228 - accuracy: 0.9291 - val_loss: 0.2197 - val_accuracy: 0.9337\n",
      "Epoch 124/400\n",
      "325/359 [==========================>...] - ETA: 0s - loss: 0.2215 - accuracy: 0.9292\n",
      "Epoch 124: val_loss improved from 0.21973 to 0.21884, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - 0s 801us/step - loss: 0.2219 - accuracy: 0.9289 - val_loss: 0.2188 - val_accuracy: 0.9281\n",
      "Epoch 125/400\n",
      "333/359 [==========================>...] - ETA: 0s - loss: 0.2195 - accuracy: 0.9300\n",
      "Epoch 125: val_loss improved from 0.21884 to 0.21881, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 780us/step - loss: 0.2214 - accuracy: 0.9294 - val_loss: 0.2188 - val_accuracy: 0.9246\n",
      "Epoch 126/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.2212 - accuracy: 0.9282\n",
      "Epoch 126: val_loss improved from 0.21881 to 0.21631, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 761us/step - loss: 0.2207 - accuracy: 0.9283 - val_loss: 0.2163 - val_accuracy: 0.9278\n",
      "Epoch 127/400\n",
      "324/359 [==========================>...] - ETA: 0s - loss: 0.2212 - accuracy: 0.9285\n",
      "Epoch 127: val_loss did not improve from 0.21631\n",
      "359/359 [==============================] - 0s 777us/step - loss: 0.2198 - accuracy: 0.9295 - val_loss: 0.2173 - val_accuracy: 0.9357\n",
      "Epoch 128/400\n",
      "341/359 [===========================>..] - ETA: 0s - loss: 0.2201 - accuracy: 0.9294\n",
      "Epoch 128: val_loss improved from 0.21631 to 0.21547, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 771us/step - loss: 0.2192 - accuracy: 0.9297 - val_loss: 0.2155 - val_accuracy: 0.9335\n",
      "Epoch 129/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.2167 - accuracy: 0.9298\n",
      "Epoch 129: val_loss improved from 0.21547 to 0.21492, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 769us/step - loss: 0.2181 - accuracy: 0.9297 - val_loss: 0.2149 - val_accuracy: 0.9330\n",
      "Epoch 130/400\n",
      "355/359 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9307\n",
      "Epoch 130: val_loss improved from 0.21492 to 0.21427, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 735us/step - loss: 0.2179 - accuracy: 0.9302 - val_loss: 0.2143 - val_accuracy: 0.9263\n",
      "Epoch 131/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.2174 - accuracy: 0.9290\n",
      "Epoch 131: val_loss improved from 0.21427 to 0.21331, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 768us/step - loss: 0.2170 - accuracy: 0.9293 - val_loss: 0.2133 - val_accuracy: 0.9328\n",
      "Epoch 132/400\n",
      "270/359 [=====================>........] - ETA: 0s - loss: 0.2188 - accuracy: 0.9291\n",
      "Epoch 132: val_loss improved from 0.21331 to 0.21216, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 734us/step - loss: 0.2166 - accuracy: 0.9300 - val_loss: 0.2122 - val_accuracy: 0.9266\n",
      "Epoch 133/400\n",
      "350/359 [============================>.] - ETA: 0s - loss: 0.2149 - accuracy: 0.9311\n",
      "Epoch 133: val_loss improved from 0.21216 to 0.21176, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 748us/step - loss: 0.2156 - accuracy: 0.9307 - val_loss: 0.2118 - val_accuracy: 0.9278\n",
      "Epoch 134/400\n",
      "347/359 [===========================>..] - ETA: 0s - loss: 0.2143 - accuracy: 0.9305\n",
      "Epoch 134: val_loss did not improve from 0.21176\n",
      "359/359 [==============================] - 0s 731us/step - loss: 0.2151 - accuracy: 0.9304 - val_loss: 0.2132 - val_accuracy: 0.9300\n",
      "Epoch 135/400\n",
      "356/359 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9304\n",
      "Epoch 135: val_loss improved from 0.21176 to 0.21019, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 746us/step - loss: 0.2141 - accuracy: 0.9306 - val_loss: 0.2102 - val_accuracy: 0.9273\n",
      "Epoch 136/400\n",
      "275/359 [=====================>........] - ETA: 0s - loss: 0.2134 - accuracy: 0.9301\n",
      "Epoch 136: val_loss improved from 0.21019 to 0.20937, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 731us/step - loss: 0.2136 - accuracy: 0.9294 - val_loss: 0.2094 - val_accuracy: 0.9345\n",
      "Epoch 137/400\n",
      "350/359 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.9319\n",
      "Epoch 137: val_loss did not improve from 0.20937\n",
      "359/359 [==============================] - 0s 733us/step - loss: 0.2129 - accuracy: 0.9318 - val_loss: 0.2096 - val_accuracy: 0.9266\n",
      "Epoch 138/400\n",
      "352/359 [============================>.] - ETA: 0s - loss: 0.2130 - accuracy: 0.9319\n",
      "Epoch 138: val_loss did not improve from 0.20937\n",
      "359/359 [==============================] - 0s 710us/step - loss: 0.2124 - accuracy: 0.9322 - val_loss: 0.2104 - val_accuracy: 0.9330\n",
      "Epoch 139/400\n",
      "336/359 [===========================>..] - ETA: 0s - loss: 0.2102 - accuracy: 0.9323\n",
      "Epoch 139: val_loss improved from 0.20937 to 0.20805, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 786us/step - loss: 0.2115 - accuracy: 0.9321 - val_loss: 0.2081 - val_accuracy: 0.9330\n",
      "Epoch 140/400\n",
      "331/359 [==========================>...] - ETA: 0s - loss: 0.2086 - accuracy: 0.9346\n",
      "Epoch 140: val_loss did not improve from 0.20805\n",
      "359/359 [==============================] - 0s 745us/step - loss: 0.2110 - accuracy: 0.9336 - val_loss: 0.2100 - val_accuracy: 0.9248\n",
      "Epoch 141/400\n",
      "347/359 [===========================>..] - ETA: 0s - loss: 0.2102 - accuracy: 0.9319\n",
      "Epoch 141: val_loss improved from 0.20805 to 0.20680, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 750us/step - loss: 0.2101 - accuracy: 0.9320 - val_loss: 0.2068 - val_accuracy: 0.9283\n",
      "Epoch 142/400\n",
      "342/359 [===========================>..] - ETA: 0s - loss: 0.2098 - accuracy: 0.9339\n",
      "Epoch 142: val_loss did not improve from 0.20680\n",
      "359/359 [==============================] - 0s 727us/step - loss: 0.2093 - accuracy: 0.9342 - val_loss: 0.2070 - val_accuracy: 0.9295\n",
      "Epoch 143/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.2075 - accuracy: 0.9335\n",
      "Epoch 143: val_loss improved from 0.20680 to 0.20584, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 758us/step - loss: 0.2085 - accuracy: 0.9335 - val_loss: 0.2058 - val_accuracy: 0.9360\n",
      "Epoch 144/400\n",
      "336/359 [===========================>..] - ETA: 0s - loss: 0.2084 - accuracy: 0.9333\n",
      "Epoch 144: val_loss improved from 0.20584 to 0.20502, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 791us/step - loss: 0.2079 - accuracy: 0.9340 - val_loss: 0.2050 - val_accuracy: 0.9286\n",
      "Epoch 145/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.2057 - accuracy: 0.9357\n",
      "Epoch 145: val_loss improved from 0.20502 to 0.20395, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 760us/step - loss: 0.2070 - accuracy: 0.9351 - val_loss: 0.2040 - val_accuracy: 0.9290\n",
      "Epoch 146/400\n",
      "348/359 [============================>.] - ETA: 0s - loss: 0.2065 - accuracy: 0.9347\n",
      "Epoch 146: val_loss improved from 0.20395 to 0.20218, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 765us/step - loss: 0.2061 - accuracy: 0.9351 - val_loss: 0.2022 - val_accuracy: 0.9357\n",
      "Epoch 147/400\n",
      "273/359 [=====================>........] - ETA: 0s - loss: 0.2024 - accuracy: 0.9360\n",
      "Epoch 147: val_loss did not improve from 0.20218\n",
      "359/359 [==============================] - 0s 695us/step - loss: 0.2060 - accuracy: 0.9338 - val_loss: 0.2050 - val_accuracy: 0.9384\n",
      "Epoch 148/400\n",
      "350/359 [============================>.] - ETA: 0s - loss: 0.2040 - accuracy: 0.9363\n",
      "Epoch 148: val_loss improved from 0.20218 to 0.20178, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 747us/step - loss: 0.2050 - accuracy: 0.9360 - val_loss: 0.2018 - val_accuracy: 0.9367\n",
      "Epoch 149/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.2031 - accuracy: 0.9362\n",
      "Epoch 149: val_loss improved from 0.20178 to 0.20056, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - 0s 782us/step - loss: 0.2043 - accuracy: 0.9356 - val_loss: 0.2006 - val_accuracy: 0.9325\n",
      "Epoch 150/400\n",
      "346/359 [===========================>..] - ETA: 0s - loss: 0.2039 - accuracy: 0.9354\n",
      "Epoch 150: val_loss improved from 0.20056 to 0.20020, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 759us/step - loss: 0.2041 - accuracy: 0.9356 - val_loss: 0.2002 - val_accuracy: 0.9328\n",
      "Epoch 151/400\n",
      "355/359 [============================>.] - ETA: 0s - loss: 0.2032 - accuracy: 0.9352\n",
      "Epoch 151: val_loss did not improve from 0.20020\n",
      "359/359 [==============================] - 0s 710us/step - loss: 0.2028 - accuracy: 0.9353 - val_loss: 0.2003 - val_accuracy: 0.9303\n",
      "Epoch 152/400\n",
      "274/359 [=====================>........] - ETA: 0s - loss: 0.2018 - accuracy: 0.9367\n",
      "Epoch 152: val_loss improved from 0.20020 to 0.19985, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 728us/step - loss: 0.2025 - accuracy: 0.9360 - val_loss: 0.1998 - val_accuracy: 0.9300\n",
      "Epoch 153/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.2014 - accuracy: 0.9365\n",
      "Epoch 153: val_loss improved from 0.19985 to 0.19850, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 773us/step - loss: 0.2017 - accuracy: 0.9365 - val_loss: 0.1985 - val_accuracy: 0.9293\n",
      "Epoch 154/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.2006 - accuracy: 0.9383\n",
      "Epoch 154: val_loss improved from 0.19850 to 0.19691, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 796us/step - loss: 0.2015 - accuracy: 0.9381 - val_loss: 0.1969 - val_accuracy: 0.9323\n",
      "Epoch 155/400\n",
      "340/359 [===========================>..] - ETA: 0s - loss: 0.2005 - accuracy: 0.9382\n",
      "Epoch 155: val_loss did not improve from 0.19691\n",
      "359/359 [==============================] - 0s 733us/step - loss: 0.2005 - accuracy: 0.9379 - val_loss: 0.1981 - val_accuracy: 0.9320\n",
      "Epoch 156/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.2005 - accuracy: 0.9382\n",
      "Epoch 156: val_loss improved from 0.19691 to 0.19530, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 772us/step - loss: 0.1998 - accuracy: 0.9382 - val_loss: 0.1953 - val_accuracy: 0.9313\n",
      "Epoch 157/400\n",
      "351/359 [============================>.] - ETA: 0s - loss: 0.2000 - accuracy: 0.9375\n",
      "Epoch 157: val_loss improved from 0.19530 to 0.19437, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 743us/step - loss: 0.1995 - accuracy: 0.9381 - val_loss: 0.1944 - val_accuracy: 0.9404\n",
      "Epoch 158/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.1979 - accuracy: 0.9380\n",
      "Epoch 158: val_loss improved from 0.19437 to 0.19376, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 751us/step - loss: 0.1986 - accuracy: 0.9382 - val_loss: 0.1938 - val_accuracy: 0.9384\n",
      "Epoch 159/400\n",
      "347/359 [===========================>..] - ETA: 0s - loss: 0.1982 - accuracy: 0.9380\n",
      "Epoch 159: val_loss did not improve from 0.19376\n",
      "359/359 [==============================] - 0s 722us/step - loss: 0.1982 - accuracy: 0.9381 - val_loss: 0.1948 - val_accuracy: 0.9330\n",
      "Epoch 160/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.1975 - accuracy: 0.9386\n",
      "Epoch 160: val_loss improved from 0.19376 to 0.19285, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 767us/step - loss: 0.1970 - accuracy: 0.9388 - val_loss: 0.1929 - val_accuracy: 0.9394\n",
      "Epoch 161/400\n",
      "346/359 [===========================>..] - ETA: 0s - loss: 0.1958 - accuracy: 0.9395\n",
      "Epoch 161: val_loss did not improve from 0.19285\n",
      "359/359 [==============================] - 0s 717us/step - loss: 0.1963 - accuracy: 0.9394 - val_loss: 0.1930 - val_accuracy: 0.9377\n",
      "Epoch 162/400\n",
      "341/359 [===========================>..] - ETA: 0s - loss: 0.1976 - accuracy: 0.9380\n",
      "Epoch 162: val_loss improved from 0.19285 to 0.19106, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 765us/step - loss: 0.1961 - accuracy: 0.9386 - val_loss: 0.1911 - val_accuracy: 0.9392\n",
      "Epoch 163/400\n",
      "278/359 [======================>.......] - ETA: 0s - loss: 0.1940 - accuracy: 0.9399\n",
      "Epoch 163: val_loss did not improve from 0.19106\n",
      "359/359 [==============================] - 0s 691us/step - loss: 0.1946 - accuracy: 0.9390 - val_loss: 0.1915 - val_accuracy: 0.9333\n",
      "Epoch 164/400\n",
      "359/359 [==============================] - ETA: 0s - loss: 0.1944 - accuracy: 0.9396\n",
      "Epoch 164: val_loss did not improve from 0.19106\n",
      "359/359 [==============================] - 0s 705us/step - loss: 0.1944 - accuracy: 0.9396 - val_loss: 0.1923 - val_accuracy: 0.9318\n",
      "Epoch 165/400\n",
      "278/359 [======================>.......] - ETA: 0s - loss: 0.1920 - accuracy: 0.9401\n",
      "Epoch 165: val_loss improved from 0.19106 to 0.18990, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 754us/step - loss: 0.1943 - accuracy: 0.9396 - val_loss: 0.1899 - val_accuracy: 0.9340\n",
      "Epoch 166/400\n",
      "350/359 [============================>.] - ETA: 0s - loss: 0.1941 - accuracy: 0.9405\n",
      "Epoch 166: val_loss improved from 0.18990 to 0.18900, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 750us/step - loss: 0.1934 - accuracy: 0.9407 - val_loss: 0.1890 - val_accuracy: 0.9337\n",
      "Epoch 167/400\n",
      "272/359 [=====================>........] - ETA: 0s - loss: 0.1909 - accuracy: 0.9403\n",
      "Epoch 167: val_loss did not improve from 0.18900\n",
      "359/359 [==============================] - 0s 695us/step - loss: 0.1929 - accuracy: 0.9390 - val_loss: 0.1899 - val_accuracy: 0.9422\n",
      "Epoch 168/400\n",
      "359/359 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9414\n",
      "Epoch 168: val_loss did not improve from 0.18900\n",
      "359/359 [==============================] - 0s 700us/step - loss: 0.1919 - accuracy: 0.9414 - val_loss: 0.1900 - val_accuracy: 0.9308\n",
      "Epoch 169/400\n",
      "359/359 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.9397\n",
      "Epoch 169: val_loss improved from 0.18900 to 0.18824, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 733us/step - loss: 0.1913 - accuracy: 0.9397 - val_loss: 0.1882 - val_accuracy: 0.9392\n",
      "Epoch 170/400\n",
      "348/359 [============================>.] - ETA: 0s - loss: 0.1913 - accuracy: 0.9400\n",
      "Epoch 170: val_loss did not improve from 0.18824\n",
      "359/359 [==============================] - 0s 721us/step - loss: 0.1910 - accuracy: 0.9403 - val_loss: 0.1917 - val_accuracy: 0.9352\n",
      "Epoch 171/400\n",
      "273/359 [=====================>........] - ETA: 0s - loss: 0.1850 - accuracy: 0.9440\n",
      "Epoch 171: val_loss improved from 0.18824 to 0.18738, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 735us/step - loss: 0.1898 - accuracy: 0.9413 - val_loss: 0.1874 - val_accuracy: 0.9318\n",
      "Epoch 172/400\n",
      "347/359 [===========================>..] - ETA: 0s - loss: 0.1898 - accuracy: 0.9405\n",
      "Epoch 172: val_loss improved from 0.18738 to 0.18438, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 771us/step - loss: 0.1896 - accuracy: 0.9407 - val_loss: 0.1844 - val_accuracy: 0.9417\n",
      "Epoch 173/400\n",
      "273/359 [=====================>........] - ETA: 0s - loss: 0.1910 - accuracy: 0.9392\n",
      "Epoch 173: val_loss improved from 0.18438 to 0.18390, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 717us/step - loss: 0.1888 - accuracy: 0.9400 - val_loss: 0.1839 - val_accuracy: 0.9422\n",
      "Epoch 174/400\n",
      "277/359 [======================>.......] - ETA: 0s - loss: 0.1882 - accuracy: 0.9412\n",
      "Epoch 174: val_loss did not improve from 0.18390\n",
      "359/359 [==============================] - 0s 686us/step - loss: 0.1880 - accuracy: 0.9409 - val_loss: 0.1843 - val_accuracy: 0.9335\n",
      "Epoch 175/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357/359 [============================>.] - ETA: 0s - loss: 0.1874 - accuracy: 0.9407\n",
      "Epoch 175: val_loss improved from 0.18390 to 0.18383, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 738us/step - loss: 0.1876 - accuracy: 0.9405 - val_loss: 0.1838 - val_accuracy: 0.9360\n",
      "Epoch 176/400\n",
      "275/359 [=====================>........] - ETA: 0s - loss: 0.1865 - accuracy: 0.9398\n",
      "Epoch 176: val_loss improved from 0.18383 to 0.18242, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 726us/step - loss: 0.1872 - accuracy: 0.9409 - val_loss: 0.1824 - val_accuracy: 0.9422\n",
      "Epoch 177/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.1869 - accuracy: 0.9410\n",
      "Epoch 177: val_loss did not improve from 0.18242\n",
      "359/359 [==============================] - 0s 734us/step - loss: 0.1866 - accuracy: 0.9410 - val_loss: 0.1825 - val_accuracy: 0.9387\n",
      "Epoch 178/400\n",
      "309/359 [========================>.....] - ETA: 0s - loss: 0.1865 - accuracy: 0.9426\n",
      "Epoch 178: val_loss improved from 0.18242 to 0.18238, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 802us/step - loss: 0.1863 - accuracy: 0.9417 - val_loss: 0.1824 - val_accuracy: 0.9325\n",
      "Epoch 179/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.1855 - accuracy: 0.9412\n",
      "Epoch 179: val_loss improved from 0.18238 to 0.18124, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 776us/step - loss: 0.1855 - accuracy: 0.9412 - val_loss: 0.1812 - val_accuracy: 0.9379\n",
      "Epoch 180/400\n",
      "325/359 [==========================>...] - ETA: 0s - loss: 0.1844 - accuracy: 0.9414\n",
      "Epoch 180: val_loss improved from 0.18124 to 0.18067, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 826us/step - loss: 0.1848 - accuracy: 0.9414 - val_loss: 0.1807 - val_accuracy: 0.9333\n",
      "Epoch 181/400\n",
      "326/359 [==========================>...] - ETA: 0s - loss: 0.1839 - accuracy: 0.9420\n",
      "Epoch 181: val_loss did not improve from 0.18067\n",
      "359/359 [==============================] - 0s 796us/step - loss: 0.1842 - accuracy: 0.9419 - val_loss: 0.1829 - val_accuracy: 0.9333\n",
      "Epoch 182/400\n",
      "330/359 [==========================>...] - ETA: 0s - loss: 0.1839 - accuracy: 0.9403\n",
      "Epoch 182: val_loss improved from 0.18067 to 0.17971, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 771us/step - loss: 0.1836 - accuracy: 0.9401 - val_loss: 0.1797 - val_accuracy: 0.9402\n",
      "Epoch 183/400\n",
      "357/359 [============================>.] - ETA: 0s - loss: 0.1833 - accuracy: 0.9414\n",
      "Epoch 183: val_loss improved from 0.17971 to 0.17859, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 736us/step - loss: 0.1832 - accuracy: 0.9415 - val_loss: 0.1786 - val_accuracy: 0.9446\n",
      "Epoch 184/400\n",
      "333/359 [==========================>...] - ETA: 0s - loss: 0.1829 - accuracy: 0.9421\n",
      "Epoch 184: val_loss did not improve from 0.17859\n",
      "359/359 [==============================] - 0s 739us/step - loss: 0.1826 - accuracy: 0.9425 - val_loss: 0.1805 - val_accuracy: 0.9412\n",
      "Epoch 185/400\n",
      "329/359 [==========================>...] - ETA: 0s - loss: 0.1809 - accuracy: 0.9427\n",
      "Epoch 185: val_loss did not improve from 0.17859\n",
      "359/359 [==============================] - 0s 767us/step - loss: 0.1819 - accuracy: 0.9422 - val_loss: 0.1792 - val_accuracy: 0.9407\n",
      "Epoch 186/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.1815 - accuracy: 0.9420\n",
      "Epoch 186: val_loss improved from 0.17859 to 0.17819, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 759us/step - loss: 0.1813 - accuracy: 0.9417 - val_loss: 0.1782 - val_accuracy: 0.9347\n",
      "Epoch 187/400\n",
      "273/359 [=====================>........] - ETA: 0s - loss: 0.1806 - accuracy: 0.9413\n",
      "Epoch 187: val_loss improved from 0.17819 to 0.17592, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 729us/step - loss: 0.1810 - accuracy: 0.9419 - val_loss: 0.1759 - val_accuracy: 0.9441\n",
      "Epoch 188/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.1801 - accuracy: 0.9427\n",
      "Epoch 188: val_loss did not improve from 0.17592\n",
      "359/359 [==============================] - 0s 733us/step - loss: 0.1801 - accuracy: 0.9427 - val_loss: 0.1759 - val_accuracy: 0.9389\n",
      "Epoch 189/400\n",
      "339/359 [===========================>..] - ETA: 0s - loss: 0.1812 - accuracy: 0.9413\n",
      "Epoch 189: val_loss did not improve from 0.17592\n",
      "359/359 [==============================] - 0s 740us/step - loss: 0.1800 - accuracy: 0.9418 - val_loss: 0.1790 - val_accuracy: 0.9357\n",
      "Epoch 190/400\n",
      "354/359 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 0.9419\n",
      "Epoch 190: val_loss improved from 0.17592 to 0.17492, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 764us/step - loss: 0.1802 - accuracy: 0.9417 - val_loss: 0.1749 - val_accuracy: 0.9417\n",
      "Epoch 191/400\n",
      "351/359 [============================>.] - ETA: 0s - loss: 0.1792 - accuracy: 0.9419\n",
      "Epoch 191: val_loss did not improve from 0.17492\n",
      "359/359 [==============================] - 0s 716us/step - loss: 0.1792 - accuracy: 0.9417 - val_loss: 0.1765 - val_accuracy: 0.9333\n",
      "Epoch 192/400\n",
      "355/359 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9415\n",
      "Epoch 192: val_loss did not improve from 0.17492\n",
      "359/359 [==============================] - 0s 709us/step - loss: 0.1786 - accuracy: 0.9417 - val_loss: 0.1749 - val_accuracy: 0.9384\n",
      "Epoch 193/400\n",
      "308/359 [========================>.....] - ETA: 0s - loss: 0.1770 - accuracy: 0.9428\n",
      "Epoch 193: val_loss improved from 0.17492 to 0.17335, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 817us/step - loss: 0.1777 - accuracy: 0.9422 - val_loss: 0.1734 - val_accuracy: 0.9394\n",
      "Epoch 194/400\n",
      "338/359 [===========================>..] - ETA: 0s - loss: 0.1773 - accuracy: 0.9422\n",
      "Epoch 194: val_loss did not improve from 0.17335\n",
      "359/359 [==============================] - 0s 748us/step - loss: 0.1777 - accuracy: 0.9422 - val_loss: 0.1748 - val_accuracy: 0.9449\n",
      "Epoch 195/400\n",
      "310/359 [========================>.....] - ETA: 0s - loss: 0.1749 - accuracy: 0.9435\n",
      "Epoch 195: val_loss did not improve from 0.17335\n",
      "359/359 [==============================] - 0s 807us/step - loss: 0.1772 - accuracy: 0.9430 - val_loss: 0.1743 - val_accuracy: 0.9397\n",
      "Epoch 196/400\n",
      "340/359 [===========================>..] - ETA: 0s - loss: 0.1760 - accuracy: 0.9426\n",
      "Epoch 196: val_loss did not improve from 0.17335\n",
      "359/359 [==============================] - 0s 745us/step - loss: 0.1765 - accuracy: 0.9425 - val_loss: 0.1746 - val_accuracy: 0.9365\n",
      "Epoch 197/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.1760 - accuracy: 0.9432\n",
      "Epoch 197: val_loss improved from 0.17335 to 0.17289, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 793us/step - loss: 0.1760 - accuracy: 0.9430 - val_loss: 0.1729 - val_accuracy: 0.9419\n",
      "Epoch 198/400\n",
      "315/359 [=========================>....] - ETA: 0s - loss: 0.1766 - accuracy: 0.9424\n",
      "Epoch 198: val_loss did not improve from 0.17289\n",
      "359/359 [==============================] - 0s 786us/step - loss: 0.1764 - accuracy: 0.9429 - val_loss: 0.1734 - val_accuracy: 0.9335\n",
      "Epoch 199/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9418\n",
      "Epoch 199: val_loss improved from 0.17289 to 0.17220, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 768us/step - loss: 0.1757 - accuracy: 0.9417 - val_loss: 0.1722 - val_accuracy: 0.9419\n",
      "Epoch 200/400\n",
      "341/359 [===========================>..] - ETA: 0s - loss: 0.1752 - accuracy: 0.9424\n",
      "Epoch 200: val_loss improved from 0.17220 to 0.17040, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 805us/step - loss: 0.1753 - accuracy: 0.9423 - val_loss: 0.1704 - val_accuracy: 0.9397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/400\n",
      "346/359 [===========================>..] - ETA: 0s - loss: 0.1756 - accuracy: 0.9426\n",
      "Epoch 201: val_loss improved from 0.17040 to 0.17018, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 753us/step - loss: 0.1755 - accuracy: 0.9425 - val_loss: 0.1702 - val_accuracy: 0.9454\n",
      "Epoch 202/400\n",
      "357/359 [============================>.] - ETA: 0s - loss: 0.1742 - accuracy: 0.9440\n",
      "Epoch 202: val_loss improved from 0.17018 to 0.16889, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 727us/step - loss: 0.1741 - accuracy: 0.9439 - val_loss: 0.1689 - val_accuracy: 0.9439\n",
      "Epoch 203/400\n",
      "358/359 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9439\n",
      "Epoch 203: val_loss did not improve from 0.16889\n",
      "359/359 [==============================] - 0s 706us/step - loss: 0.1741 - accuracy: 0.9439 - val_loss: 0.1716 - val_accuracy: 0.9426\n",
      "Epoch 204/400\n",
      "272/359 [=====================>........] - ETA: 0s - loss: 0.1727 - accuracy: 0.9440\n",
      "Epoch 204: val_loss did not improve from 0.16889\n",
      "359/359 [==============================] - 0s 691us/step - loss: 0.1741 - accuracy: 0.9431 - val_loss: 0.1693 - val_accuracy: 0.9451\n",
      "Epoch 205/400\n",
      "271/359 [=====================>........] - ETA: 0s - loss: 0.1738 - accuracy: 0.9440\n",
      "Epoch 205: val_loss improved from 0.16889 to 0.16826, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 738us/step - loss: 0.1734 - accuracy: 0.9437 - val_loss: 0.1683 - val_accuracy: 0.9402\n",
      "Epoch 206/400\n",
      "275/359 [=====================>........] - ETA: 0s - loss: 0.1715 - accuracy: 0.9441\n",
      "Epoch 206: val_loss did not improve from 0.16826\n",
      "359/359 [==============================] - 0s 697us/step - loss: 0.1731 - accuracy: 0.9437 - val_loss: 0.1712 - val_accuracy: 0.9357\n",
      "Epoch 207/400\n",
      "337/359 [===========================>..] - ETA: 0s - loss: 0.1737 - accuracy: 0.9436\n",
      "Epoch 207: val_loss improved from 0.16826 to 0.16720, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 810us/step - loss: 0.1724 - accuracy: 0.9444 - val_loss: 0.1672 - val_accuracy: 0.9426\n",
      "Epoch 208/400\n",
      "311/359 [========================>.....] - ETA: 0s - loss: 0.1721 - accuracy: 0.9439\n",
      "Epoch 208: val_loss improved from 0.16720 to 0.16688, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 850us/step - loss: 0.1725 - accuracy: 0.9440 - val_loss: 0.1669 - val_accuracy: 0.9417\n",
      "Epoch 209/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.1709 - accuracy: 0.9456\n",
      "Epoch 209: val_loss did not improve from 0.16688\n",
      "359/359 [==============================] - 0s 740us/step - loss: 0.1717 - accuracy: 0.9445 - val_loss: 0.1673 - val_accuracy: 0.9377\n",
      "Epoch 210/400\n",
      "329/359 [==========================>...] - ETA: 0s - loss: 0.1710 - accuracy: 0.9443\n",
      "Epoch 210: val_loss did not improve from 0.16688\n",
      "359/359 [==============================] - 0s 754us/step - loss: 0.1713 - accuracy: 0.9447 - val_loss: 0.1669 - val_accuracy: 0.9389\n",
      "Epoch 211/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.1718 - accuracy: 0.9440\n",
      "Epoch 211: val_loss improved from 0.16688 to 0.16579, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 782us/step - loss: 0.1712 - accuracy: 0.9443 - val_loss: 0.1658 - val_accuracy: 0.9439\n",
      "Epoch 212/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.1706 - accuracy: 0.9443\n",
      "Epoch 212: val_loss did not improve from 0.16579\n",
      "359/359 [==============================] - 0s 731us/step - loss: 0.1712 - accuracy: 0.9439 - val_loss: 0.1696 - val_accuracy: 0.9367\n",
      "Epoch 213/400\n",
      "354/359 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9446\n",
      "Epoch 213: val_loss improved from 0.16579 to 0.16527, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 751us/step - loss: 0.1710 - accuracy: 0.9447 - val_loss: 0.1653 - val_accuracy: 0.9424\n",
      "Epoch 214/400\n",
      "341/359 [===========================>..] - ETA: 0s - loss: 0.1701 - accuracy: 0.9447\n",
      "Epoch 214: val_loss did not improve from 0.16527\n",
      "359/359 [==============================] - 0s 736us/step - loss: 0.1700 - accuracy: 0.9449 - val_loss: 0.1675 - val_accuracy: 0.9372\n",
      "Epoch 215/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.1706 - accuracy: 0.9439\n",
      "Epoch 215: val_loss improved from 0.16527 to 0.16523, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 782us/step - loss: 0.1696 - accuracy: 0.9447 - val_loss: 0.1652 - val_accuracy: 0.9478\n",
      "Epoch 216/400\n",
      "301/359 [========================>.....] - ETA: 0s - loss: 0.1685 - accuracy: 0.9465\n",
      "Epoch 216: val_loss did not improve from 0.16523\n",
      "359/359 [==============================] - 0s 802us/step - loss: 0.1695 - accuracy: 0.9453 - val_loss: 0.1656 - val_accuracy: 0.9412\n",
      "Epoch 217/400\n",
      "338/359 [===========================>..] - ETA: 0s - loss: 0.1690 - accuracy: 0.9458\n",
      "Epoch 217: val_loss improved from 0.16523 to 0.16473, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 798us/step - loss: 0.1693 - accuracy: 0.9458 - val_loss: 0.1647 - val_accuracy: 0.9459\n",
      "Epoch 218/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.1686 - accuracy: 0.9456\n",
      "Epoch 218: val_loss did not improve from 0.16473\n",
      "359/359 [==============================] - 0s 739us/step - loss: 0.1690 - accuracy: 0.9458 - val_loss: 0.1706 - val_accuracy: 0.9434\n",
      "Epoch 219/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.1694 - accuracy: 0.9449\n",
      "Epoch 219: val_loss did not improve from 0.16473\n",
      "359/359 [==============================] - 0s 758us/step - loss: 0.1688 - accuracy: 0.9453 - val_loss: 0.1656 - val_accuracy: 0.9429\n",
      "Epoch 220/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.1685 - accuracy: 0.9465\n",
      "Epoch 220: val_loss improved from 0.16473 to 0.16343, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 770us/step - loss: 0.1689 - accuracy: 0.9465 - val_loss: 0.1634 - val_accuracy: 0.9444\n",
      "Epoch 221/400\n",
      "325/359 [==========================>...] - ETA: 0s - loss: 0.1699 - accuracy: 0.9447\n",
      "Epoch 221: val_loss improved from 0.16343 to 0.16267, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 796us/step - loss: 0.1681 - accuracy: 0.9456 - val_loss: 0.1627 - val_accuracy: 0.9449\n",
      "Epoch 222/400\n",
      "348/359 [============================>.] - ETA: 0s - loss: 0.1664 - accuracy: 0.9462\n",
      "Epoch 222: val_loss did not improve from 0.16267\n",
      "359/359 [==============================] - 0s 716us/step - loss: 0.1673 - accuracy: 0.9460 - val_loss: 0.1627 - val_accuracy: 0.9436\n",
      "Epoch 223/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.1663 - accuracy: 0.9470\n",
      "Epoch 223: val_loss did not improve from 0.16267\n",
      "359/359 [==============================] - 0s 764us/step - loss: 0.1673 - accuracy: 0.9466 - val_loss: 0.1642 - val_accuracy: 0.9407\n",
      "Epoch 224/400\n",
      "353/359 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9453\n",
      "Epoch 224: val_loss improved from 0.16267 to 0.16250, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 743us/step - loss: 0.1668 - accuracy: 0.9452 - val_loss: 0.1625 - val_accuracy: 0.9414\n",
      "Epoch 225/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.1675 - accuracy: 0.9456\n",
      "Epoch 225: val_loss improved from 0.16250 to 0.16182, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 758us/step - loss: 0.1669 - accuracy: 0.9456 - val_loss: 0.1618 - val_accuracy: 0.9394\n",
      "Epoch 226/400\n",
      "358/359 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9465\n",
      "Epoch 226: val_loss did not improve from 0.16182\n",
      "359/359 [==============================] - 0s 702us/step - loss: 0.1665 - accuracy: 0.9465 - val_loss: 0.1667 - val_accuracy: 0.9454\n",
      "Epoch 227/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/359 [==========================>...] - ETA: 0s - loss: 0.1659 - accuracy: 0.9467\n",
      "Epoch 227: val_loss improved from 0.16182 to 0.16079, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 791us/step - loss: 0.1659 - accuracy: 0.9465 - val_loss: 0.1608 - val_accuracy: 0.9392\n",
      "Epoch 228/400\n",
      "327/359 [==========================>...] - ETA: 0s - loss: 0.1665 - accuracy: 0.9456\n",
      "Epoch 228: val_loss did not improve from 0.16079\n",
      "359/359 [==============================] - 0s 767us/step - loss: 0.1654 - accuracy: 0.9461 - val_loss: 0.1626 - val_accuracy: 0.9441\n",
      "Epoch 229/400\n",
      "353/359 [============================>.] - ETA: 0s - loss: 0.1649 - accuracy: 0.9452\n",
      "Epoch 229: val_loss did not improve from 0.16079\n",
      "359/359 [==============================] - 0s 719us/step - loss: 0.1653 - accuracy: 0.9451 - val_loss: 0.1614 - val_accuracy: 0.9424\n",
      "Epoch 230/400\n",
      "272/359 [=====================>........] - ETA: 0s - loss: 0.1647 - accuracy: 0.9469\n",
      "Epoch 230: val_loss improved from 0.16079 to 0.16066, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 742us/step - loss: 0.1652 - accuracy: 0.9461 - val_loss: 0.1607 - val_accuracy: 0.9434\n",
      "Epoch 231/400\n",
      "323/359 [=========================>....] - ETA: 0s - loss: 0.1648 - accuracy: 0.9475\n",
      "Epoch 231: val_loss did not improve from 0.16066\n",
      "359/359 [==============================] - 0s 780us/step - loss: 0.1649 - accuracy: 0.9471 - val_loss: 0.1617 - val_accuracy: 0.9370\n",
      "Epoch 232/400\n",
      "348/359 [============================>.] - ETA: 0s - loss: 0.1630 - accuracy: 0.9472\n",
      "Epoch 232: val_loss did not improve from 0.16066\n",
      "359/359 [==============================] - 0s 720us/step - loss: 0.1640 - accuracy: 0.9466 - val_loss: 0.1608 - val_accuracy: 0.9382\n",
      "Epoch 233/400\n",
      "347/359 [===========================>..] - ETA: 0s - loss: 0.1628 - accuracy: 0.9468\n",
      "Epoch 233: val_loss improved from 0.16066 to 0.16024, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 771us/step - loss: 0.1639 - accuracy: 0.9468 - val_loss: 0.1602 - val_accuracy: 0.9439\n",
      "Epoch 234/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.1629 - accuracy: 0.9470\n",
      "Epoch 234: val_loss did not improve from 0.16024\n",
      "359/359 [==============================] - 0s 729us/step - loss: 0.1638 - accuracy: 0.9468 - val_loss: 0.1610 - val_accuracy: 0.9451\n",
      "Epoch 235/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.1635 - accuracy: 0.9469\n",
      "Epoch 235: val_loss improved from 0.16024 to 0.15859, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 776us/step - loss: 0.1637 - accuracy: 0.9467 - val_loss: 0.1586 - val_accuracy: 0.9446\n",
      "Epoch 236/400\n",
      "347/359 [===========================>..] - ETA: 0s - loss: 0.1636 - accuracy: 0.9470\n",
      "Epoch 236: val_loss did not improve from 0.15859\n",
      "359/359 [==============================] - 0s 716us/step - loss: 0.1630 - accuracy: 0.9469 - val_loss: 0.1589 - val_accuracy: 0.9446\n",
      "Epoch 237/400\n",
      "355/359 [============================>.] - ETA: 0s - loss: 0.1641 - accuracy: 0.9467\n",
      "Epoch 237: val_loss improved from 0.15859 to 0.15762, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 752us/step - loss: 0.1642 - accuracy: 0.9466 - val_loss: 0.1576 - val_accuracy: 0.9454\n",
      "Epoch 238/400\n",
      "351/359 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9467\n",
      "Epoch 238: val_loss did not improve from 0.15762\n",
      "359/359 [==============================] - 0s 718us/step - loss: 0.1630 - accuracy: 0.9467 - val_loss: 0.1580 - val_accuracy: 0.9471\n",
      "Epoch 239/400\n",
      "315/359 [=========================>....] - ETA: 0s - loss: 0.1637 - accuracy: 0.9469\n",
      "Epoch 239: val_loss did not improve from 0.15762\n",
      "359/359 [==============================] - 0s 770us/step - loss: 0.1621 - accuracy: 0.9472 - val_loss: 0.1622 - val_accuracy: 0.9491\n",
      "Epoch 240/400\n",
      "342/359 [===========================>..] - ETA: 0s - loss: 0.1643 - accuracy: 0.9454\n",
      "Epoch 240: val_loss improved from 0.15762 to 0.15660, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 788us/step - loss: 0.1634 - accuracy: 0.9460 - val_loss: 0.1566 - val_accuracy: 0.9431\n",
      "Epoch 241/400\n",
      "331/359 [==========================>...] - ETA: 0s - loss: 0.1618 - accuracy: 0.9472\n",
      "Epoch 241: val_loss did not improve from 0.15660\n",
      "359/359 [==============================] - 0s 752us/step - loss: 0.1620 - accuracy: 0.9472 - val_loss: 0.1585 - val_accuracy: 0.9419\n",
      "Epoch 242/400\n",
      "346/359 [===========================>..] - ETA: 0s - loss: 0.1626 - accuracy: 0.9459\n",
      "Epoch 242: val_loss did not improve from 0.15660\n",
      "359/359 [==============================] - 0s 724us/step - loss: 0.1616 - accuracy: 0.9466 - val_loss: 0.1569 - val_accuracy: 0.9441\n",
      "Epoch 243/400\n",
      "354/359 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 0.9468\n",
      "Epoch 243: val_loss did not improve from 0.15660\n",
      "359/359 [==============================] - 0s 735us/step - loss: 0.1610 - accuracy: 0.9467 - val_loss: 0.1569 - val_accuracy: 0.9436\n",
      "Epoch 244/400\n",
      "352/359 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9461\n",
      "Epoch 244: val_loss improved from 0.15660 to 0.15635, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 758us/step - loss: 0.1614 - accuracy: 0.9463 - val_loss: 0.1563 - val_accuracy: 0.9464\n",
      "Epoch 245/400\n",
      "272/359 [=====================>........] - ETA: 0s - loss: 0.1622 - accuracy: 0.9463\n",
      "Epoch 245: val_loss improved from 0.15635 to 0.15495, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 737us/step - loss: 0.1612 - accuracy: 0.9470 - val_loss: 0.1549 - val_accuracy: 0.9451\n",
      "Epoch 246/400\n",
      "353/359 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9467\n",
      "Epoch 246: val_loss did not improve from 0.15495\n",
      "359/359 [==============================] - 0s 745us/step - loss: 0.1604 - accuracy: 0.9467 - val_loss: 0.1552 - val_accuracy: 0.9493\n",
      "Epoch 247/400\n",
      "325/359 [==========================>...] - ETA: 0s - loss: 0.1602 - accuracy: 0.9472\n",
      "Epoch 247: val_loss did not improve from 0.15495\n",
      "359/359 [==============================] - 0s 769us/step - loss: 0.1598 - accuracy: 0.9475 - val_loss: 0.1554 - val_accuracy: 0.9468\n",
      "Epoch 248/400\n",
      "305/359 [========================>.....] - ETA: 0s - loss: 0.1622 - accuracy: 0.9468\n",
      "Epoch 248: val_loss did not improve from 0.15495\n",
      "359/359 [==============================] - 0s 808us/step - loss: 0.1602 - accuracy: 0.9474 - val_loss: 0.1611 - val_accuracy: 0.9379\n",
      "Epoch 249/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.1596 - accuracy: 0.9458\n",
      "Epoch 249: val_loss did not improve from 0.15495\n",
      "359/359 [==============================] - 0s 751us/step - loss: 0.1591 - accuracy: 0.9462 - val_loss: 0.1569 - val_accuracy: 0.9449\n",
      "Epoch 250/400\n",
      "352/359 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9470\n",
      "Epoch 250: val_loss improved from 0.15495 to 0.15448, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 759us/step - loss: 0.1593 - accuracy: 0.9471 - val_loss: 0.1545 - val_accuracy: 0.9461\n",
      "Epoch 251/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.1595 - accuracy: 0.9474\n",
      "Epoch 251: val_loss did not improve from 0.15448\n",
      "359/359 [==============================] - 0s 722us/step - loss: 0.1593 - accuracy: 0.9472 - val_loss: 0.1597 - val_accuracy: 0.9459\n",
      "Epoch 252/400\n",
      "348/359 [============================>.] - ETA: 0s - loss: 0.1590 - accuracy: 0.9477\n",
      "Epoch 252: val_loss did not improve from 0.15448\n",
      "359/359 [==============================] - 0s 728us/step - loss: 0.1588 - accuracy: 0.9477 - val_loss: 0.1546 - val_accuracy: 0.9382\n",
      "Epoch 253/400\n",
      "333/359 [==========================>...] - ETA: 0s - loss: 0.1593 - accuracy: 0.9474\n",
      "Epoch 253: val_loss improved from 0.15448 to 0.15325, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 787us/step - loss: 0.1599 - accuracy: 0.9474 - val_loss: 0.1533 - val_accuracy: 0.9473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/400\n",
      "307/359 [========================>.....] - ETA: 0s - loss: 0.1576 - accuracy: 0.9480\n",
      "Epoch 254: val_loss did not improve from 0.15325\n",
      "359/359 [==============================] - 0s 818us/step - loss: 0.1587 - accuracy: 0.9477 - val_loss: 0.1545 - val_accuracy: 0.9451\n",
      "Epoch 255/400\n",
      "325/359 [==========================>...] - ETA: 0s - loss: 0.1590 - accuracy: 0.9467\n",
      "Epoch 255: val_loss improved from 0.15325 to 0.15265, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 801us/step - loss: 0.1583 - accuracy: 0.9472 - val_loss: 0.1526 - val_accuracy: 0.9459\n",
      "Epoch 256/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.1590 - accuracy: 0.9467\n",
      "Epoch 256: val_loss did not improve from 0.15265\n",
      "359/359 [==============================] - 0s 738us/step - loss: 0.1585 - accuracy: 0.9469 - val_loss: 0.1542 - val_accuracy: 0.9464\n",
      "Epoch 257/400\n",
      "356/359 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 0.9475\n",
      "Epoch 257: val_loss did not improve from 0.15265\n",
      "359/359 [==============================] - 0s 705us/step - loss: 0.1579 - accuracy: 0.9473 - val_loss: 0.1548 - val_accuracy: 0.9424\n",
      "Epoch 258/400\n",
      "353/359 [============================>.] - ETA: 0s - loss: 0.1577 - accuracy: 0.9473\n",
      "Epoch 258: val_loss did not improve from 0.15265\n",
      "359/359 [==============================] - 0s 710us/step - loss: 0.1574 - accuracy: 0.9475 - val_loss: 0.1541 - val_accuracy: 0.9488\n",
      "Epoch 259/400\n",
      "273/359 [=====================>........] - ETA: 0s - loss: 0.1597 - accuracy: 0.9469\n",
      "Epoch 259: val_loss improved from 0.15265 to 0.15240, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 721us/step - loss: 0.1573 - accuracy: 0.9474 - val_loss: 0.1524 - val_accuracy: 0.9471\n",
      "Epoch 260/400\n",
      "350/359 [============================>.] - ETA: 0s - loss: 0.1567 - accuracy: 0.9475\n",
      "Epoch 260: val_loss did not improve from 0.15240\n",
      "359/359 [==============================] - 0s 723us/step - loss: 0.1573 - accuracy: 0.9473 - val_loss: 0.1547 - val_accuracy: 0.9404\n",
      "Epoch 261/400\n",
      "337/359 [===========================>..] - ETA: 0s - loss: 0.1588 - accuracy: 0.9467\n",
      "Epoch 261: val_loss improved from 0.15240 to 0.15234, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 789us/step - loss: 0.1580 - accuracy: 0.9472 - val_loss: 0.1523 - val_accuracy: 0.9451\n",
      "Epoch 262/400\n",
      "289/359 [=======================>......] - ETA: 0s - loss: 0.1591 - accuracy: 0.9460\n",
      "Epoch 262: val_loss did not improve from 0.15234\n",
      "359/359 [==============================] - 0s 825us/step - loss: 0.1566 - accuracy: 0.9465 - val_loss: 0.1582 - val_accuracy: 0.9419\n",
      "Epoch 263/400\n",
      "326/359 [==========================>...] - ETA: 0s - loss: 0.1572 - accuracy: 0.9463\n",
      "Epoch 263: val_loss improved from 0.15234 to 0.15182, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 793us/step - loss: 0.1567 - accuracy: 0.9470 - val_loss: 0.1518 - val_accuracy: 0.9449\n",
      "Epoch 264/400\n",
      "328/359 [==========================>...] - ETA: 0s - loss: 0.1568 - accuracy: 0.9478\n",
      "Epoch 264: val_loss did not improve from 0.15182\n",
      "359/359 [==============================] - 0s 762us/step - loss: 0.1564 - accuracy: 0.9476 - val_loss: 0.1523 - val_accuracy: 0.9399\n",
      "Epoch 265/400\n",
      "348/359 [============================>.] - ETA: 0s - loss: 0.1562 - accuracy: 0.9474\n",
      "Epoch 265: val_loss improved from 0.15182 to 0.15159, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 773us/step - loss: 0.1562 - accuracy: 0.9474 - val_loss: 0.1516 - val_accuracy: 0.9473\n",
      "Epoch 266/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.1557 - accuracy: 0.9479\n",
      "Epoch 266: val_loss did not improve from 0.15159\n",
      "359/359 [==============================] - 0s 734us/step - loss: 0.1558 - accuracy: 0.9478 - val_loss: 0.1545 - val_accuracy: 0.9375\n",
      "Epoch 267/400\n",
      "356/359 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9476\n",
      "Epoch 267: val_loss improved from 0.15159 to 0.15053, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 764us/step - loss: 0.1555 - accuracy: 0.9473 - val_loss: 0.1505 - val_accuracy: 0.9449\n",
      "Epoch 268/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.1558 - accuracy: 0.9478\n",
      "Epoch 268: val_loss did not improve from 0.15053\n",
      "359/359 [==============================] - 0s 729us/step - loss: 0.1557 - accuracy: 0.9479 - val_loss: 0.1517 - val_accuracy: 0.9451\n",
      "Epoch 269/400\n",
      "313/359 [=========================>....] - ETA: 0s - loss: 0.1573 - accuracy: 0.9472\n",
      "Epoch 269: val_loss improved from 0.15053 to 0.15018, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 881us/step - loss: 0.1562 - accuracy: 0.9474 - val_loss: 0.1502 - val_accuracy: 0.9464\n",
      "Epoch 270/400\n",
      "347/359 [===========================>..] - ETA: 0s - loss: 0.1561 - accuracy: 0.9466\n",
      "Epoch 270: val_loss improved from 0.15018 to 0.14974, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 764us/step - loss: 0.1550 - accuracy: 0.9472 - val_loss: 0.1497 - val_accuracy: 0.9511\n",
      "Epoch 271/400\n",
      "358/359 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.9467\n",
      "Epoch 271: val_loss did not improve from 0.14974\n",
      "359/359 [==============================] - 0s 706us/step - loss: 0.1551 - accuracy: 0.9467 - val_loss: 0.1554 - val_accuracy: 0.9434\n",
      "Epoch 272/400\n",
      "354/359 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9470\n",
      "Epoch 272: val_loss did not improve from 0.14974\n",
      "359/359 [==============================] - 0s 708us/step - loss: 0.1551 - accuracy: 0.9469 - val_loss: 0.1507 - val_accuracy: 0.9473\n",
      "Epoch 273/400\n",
      "338/359 [===========================>..] - ETA: 0s - loss: 0.1560 - accuracy: 0.9478\n",
      "Epoch 273: val_loss improved from 0.14974 to 0.14925, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 765us/step - loss: 0.1550 - accuracy: 0.9484 - val_loss: 0.1492 - val_accuracy: 0.9444\n",
      "Epoch 274/400\n",
      "336/359 [===========================>..] - ETA: 0s - loss: 0.1534 - accuracy: 0.9472\n",
      "Epoch 274: val_loss did not improve from 0.14925\n",
      "359/359 [==============================] - 0s 759us/step - loss: 0.1544 - accuracy: 0.9473 - val_loss: 0.1513 - val_accuracy: 0.9434\n",
      "Epoch 275/400\n",
      "327/359 [==========================>...] - ETA: 0s - loss: 0.1553 - accuracy: 0.9474\n",
      "Epoch 275: val_loss improved from 0.14925 to 0.14841, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 813us/step - loss: 0.1546 - accuracy: 0.9475 - val_loss: 0.1484 - val_accuracy: 0.9454\n",
      "Epoch 276/400\n",
      "352/359 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9478\n",
      "Epoch 276: val_loss improved from 0.14841 to 0.14805, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 743us/step - loss: 0.1548 - accuracy: 0.9475 - val_loss: 0.1481 - val_accuracy: 0.9459\n",
      "Epoch 277/400\n",
      "296/359 [=======================>......] - ETA: 0s - loss: 0.1537 - accuracy: 0.9478\n",
      "Epoch 277: val_loss did not improve from 0.14805\n",
      "359/359 [==============================] - 0s 820us/step - loss: 0.1534 - accuracy: 0.9478 - val_loss: 0.1488 - val_accuracy: 0.9461\n",
      "Epoch 278/400\n",
      "329/359 [==========================>...] - ETA: 0s - loss: 0.1550 - accuracy: 0.9476\n",
      "Epoch 278: val_loss improved from 0.14805 to 0.14769, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 795us/step - loss: 0.1541 - accuracy: 0.9481 - val_loss: 0.1477 - val_accuracy: 0.9459\n",
      "Epoch 279/400\n",
      "352/359 [============================>.] - ETA: 0s - loss: 0.1525 - accuracy: 0.9481\n",
      "Epoch 279: val_loss did not improve from 0.14769\n",
      "359/359 [==============================] - 0s 727us/step - loss: 0.1531 - accuracy: 0.9479 - val_loss: 0.1478 - val_accuracy: 0.9476\n",
      "Epoch 280/400\n",
      "327/359 [==========================>...] - ETA: 0s - loss: 0.1525 - accuracy: 0.9486\n",
      "Epoch 280: val_loss did not improve from 0.14769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - 0s 765us/step - loss: 0.1533 - accuracy: 0.9482 - val_loss: 0.1480 - val_accuracy: 0.9446\n",
      "Epoch 281/400\n",
      "325/359 [==========================>...] - ETA: 0s - loss: 0.1529 - accuracy: 0.9505\n",
      "Epoch 281: val_loss did not improve from 0.14769\n",
      "359/359 [==============================] - 0s 767us/step - loss: 0.1535 - accuracy: 0.9502 - val_loss: 0.1484 - val_accuracy: 0.9456\n",
      "Epoch 282/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.1537 - accuracy: 0.9489\n",
      "Epoch 282: val_loss improved from 0.14769 to 0.14756, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 785us/step - loss: 0.1526 - accuracy: 0.9494 - val_loss: 0.1476 - val_accuracy: 0.9483\n",
      "Epoch 283/400\n",
      "333/359 [==========================>...] - ETA: 0s - loss: 0.1537 - accuracy: 0.9505\n",
      "Epoch 283: val_loss did not improve from 0.14756\n",
      "359/359 [==============================] - 0s 758us/step - loss: 0.1524 - accuracy: 0.9504 - val_loss: 0.1482 - val_accuracy: 0.9535\n",
      "Epoch 284/400\n",
      "309/359 [========================>.....] - ETA: 0s - loss: 0.1505 - accuracy: 0.9517\n",
      "Epoch 284: val_loss improved from 0.14756 to 0.14721, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 894us/step - loss: 0.1525 - accuracy: 0.9512 - val_loss: 0.1472 - val_accuracy: 0.9525\n",
      "Epoch 285/400\n",
      "354/359 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9514\n",
      "Epoch 285: val_loss did not improve from 0.14721\n",
      "359/359 [==============================] - 0s 725us/step - loss: 0.1519 - accuracy: 0.9514 - val_loss: 0.1477 - val_accuracy: 0.9520\n",
      "Epoch 286/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.1535 - accuracy: 0.9502\n",
      "Epoch 286: val_loss improved from 0.14721 to 0.14687, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 800us/step - loss: 0.1524 - accuracy: 0.9506 - val_loss: 0.1469 - val_accuracy: 0.9557\n",
      "Epoch 287/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.1524 - accuracy: 0.9519\n",
      "Epoch 287: val_loss improved from 0.14687 to 0.14636, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 781us/step - loss: 0.1521 - accuracy: 0.9518 - val_loss: 0.1464 - val_accuracy: 0.9466\n",
      "Epoch 288/400\n",
      "336/359 [===========================>..] - ETA: 0s - loss: 0.1500 - accuracy: 0.9513\n",
      "Epoch 288: val_loss did not improve from 0.14636\n",
      "359/359 [==============================] - 0s 748us/step - loss: 0.1514 - accuracy: 0.9513 - val_loss: 0.1511 - val_accuracy: 0.9481\n",
      "Epoch 289/400\n",
      "338/359 [===========================>..] - ETA: 0s - loss: 0.1509 - accuracy: 0.9507\n",
      "Epoch 289: val_loss did not improve from 0.14636\n",
      "359/359 [==============================] - 0s 751us/step - loss: 0.1516 - accuracy: 0.9505 - val_loss: 0.1471 - val_accuracy: 0.9498\n",
      "Epoch 290/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.1506 - accuracy: 0.9522\n",
      "Epoch 290: val_loss did not improve from 0.14636\n",
      "359/359 [==============================] - 0s 758us/step - loss: 0.1519 - accuracy: 0.9520 - val_loss: 0.1464 - val_accuracy: 0.9491\n",
      "Epoch 291/400\n",
      "313/359 [=========================>....] - ETA: 0s - loss: 0.1536 - accuracy: 0.9517\n",
      "Epoch 291: val_loss did not improve from 0.14636\n",
      "359/359 [==============================] - 0s 785us/step - loss: 0.1518 - accuracy: 0.9525 - val_loss: 0.1478 - val_accuracy: 0.9528\n",
      "Epoch 292/400\n",
      "307/359 [========================>.....] - ETA: 0s - loss: 0.1516 - accuracy: 0.9520\n",
      "Epoch 292: val_loss did not improve from 0.14636\n",
      "359/359 [==============================] - 0s 787us/step - loss: 0.1513 - accuracy: 0.9524 - val_loss: 0.1477 - val_accuracy: 0.9481\n",
      "Epoch 293/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.1510 - accuracy: 0.9518\n",
      "Epoch 293: val_loss did not improve from 0.14636\n",
      "359/359 [==============================] - 0s 726us/step - loss: 0.1516 - accuracy: 0.9518 - val_loss: 0.1464 - val_accuracy: 0.9528\n",
      "Epoch 294/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.1519 - accuracy: 0.9519\n",
      "Epoch 294: val_loss improved from 0.14636 to 0.14491, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 770us/step - loss: 0.1507 - accuracy: 0.9527 - val_loss: 0.1449 - val_accuracy: 0.9503\n",
      "Epoch 295/400\n",
      "356/359 [============================>.] - ETA: 0s - loss: 0.1515 - accuracy: 0.9524\n",
      "Epoch 295: val_loss did not improve from 0.14491\n",
      "359/359 [==============================] - 0s 711us/step - loss: 0.1513 - accuracy: 0.9524 - val_loss: 0.1467 - val_accuracy: 0.9523\n",
      "Epoch 296/400\n",
      "358/359 [============================>.] - ETA: 0s - loss: 0.1504 - accuracy: 0.9521\n",
      "Epoch 296: val_loss did not improve from 0.14491\n",
      "359/359 [==============================] - 0s 706us/step - loss: 0.1507 - accuracy: 0.9520 - val_loss: 0.1463 - val_accuracy: 0.9515\n",
      "Epoch 297/400\n",
      "269/359 [=====================>........] - ETA: 0s - loss: 0.1508 - accuracy: 0.9534\n",
      "Epoch 297: val_loss did not improve from 0.14491\n",
      "359/359 [==============================] - 0s 698us/step - loss: 0.1501 - accuracy: 0.9530 - val_loss: 0.1462 - val_accuracy: 0.9483\n",
      "Epoch 298/400\n",
      "325/359 [==========================>...] - ETA: 0s - loss: 0.1509 - accuracy: 0.9528\n",
      "Epoch 298: val_loss did not improve from 0.14491\n",
      "359/359 [==============================] - 0s 765us/step - loss: 0.1509 - accuracy: 0.9534 - val_loss: 0.1482 - val_accuracy: 0.9473\n",
      "Epoch 299/400\n",
      "328/359 [==========================>...] - ETA: 0s - loss: 0.1515 - accuracy: 0.9524\n",
      "Epoch 299: val_loss improved from 0.14491 to 0.14403, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 831us/step - loss: 0.1502 - accuracy: 0.9522 - val_loss: 0.1440 - val_accuracy: 0.9488\n",
      "Epoch 300/400\n",
      "296/359 [=======================>......] - ETA: 0s - loss: 0.1525 - accuracy: 0.9508\n",
      "Epoch 300: val_loss did not improve from 0.14403\n",
      "359/359 [==============================] - 0s 816us/step - loss: 0.1498 - accuracy: 0.9520 - val_loss: 0.1450 - val_accuracy: 0.9543\n",
      "Epoch 301/400\n",
      "352/359 [============================>.] - ETA: 0s - loss: 0.1494 - accuracy: 0.9531\n",
      "Epoch 301: val_loss did not improve from 0.14403\n",
      "359/359 [==============================] - 0s 717us/step - loss: 0.1496 - accuracy: 0.9529 - val_loss: 0.1448 - val_accuracy: 0.9476\n",
      "Epoch 302/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.1500 - accuracy: 0.9524\n",
      "Epoch 302: val_loss did not improve from 0.14403\n",
      "359/359 [==============================] - 0s 722us/step - loss: 0.1501 - accuracy: 0.9524 - val_loss: 0.1448 - val_accuracy: 0.9471\n",
      "Epoch 303/400\n",
      "321/359 [=========================>....] - ETA: 0s - loss: 0.1497 - accuracy: 0.9533\n",
      "Epoch 303: val_loss improved from 0.14403 to 0.14336, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 817us/step - loss: 0.1496 - accuracy: 0.9532 - val_loss: 0.1434 - val_accuracy: 0.9557\n",
      "Epoch 304/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.1501 - accuracy: 0.9525\n",
      "Epoch 304: val_loss did not improve from 0.14336\n",
      "359/359 [==============================] - 0s 725us/step - loss: 0.1498 - accuracy: 0.9523 - val_loss: 0.1472 - val_accuracy: 0.9538\n",
      "Epoch 305/400\n",
      "359/359 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.9534\n",
      "Epoch 305: val_loss did not improve from 0.14336\n",
      "359/359 [==============================] - 0s 714us/step - loss: 0.1502 - accuracy: 0.9534 - val_loss: 0.1455 - val_accuracy: 0.9503\n",
      "Epoch 306/400\n",
      "327/359 [==========================>...] - ETA: 0s - loss: 0.1489 - accuracy: 0.9520\n",
      "Epoch 306: val_loss did not improve from 0.14336\n",
      "359/359 [==============================] - 0s 779us/step - loss: 0.1490 - accuracy: 0.9525 - val_loss: 0.1447 - val_accuracy: 0.9530\n",
      "Epoch 307/400\n",
      "316/359 [=========================>....] - ETA: 0s - loss: 0.1485 - accuracy: 0.9546\n",
      "Epoch 307: val_loss did not improve from 0.14336\n",
      "359/359 [==============================] - 0s 828us/step - loss: 0.1492 - accuracy: 0.9540 - val_loss: 0.1461 - val_accuracy: 0.9513\n",
      "Epoch 308/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/359 [===========================>..] - ETA: 0s - loss: 0.1477 - accuracy: 0.9533\n",
      "Epoch 308: val_loss improved from 0.14336 to 0.14279, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 778us/step - loss: 0.1486 - accuracy: 0.9534 - val_loss: 0.1428 - val_accuracy: 0.9553\n",
      "Epoch 309/400\n",
      "350/359 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9544\n",
      "Epoch 309: val_loss did not improve from 0.14279\n",
      "359/359 [==============================] - 0s 722us/step - loss: 0.1486 - accuracy: 0.9543 - val_loss: 0.1431 - val_accuracy: 0.9565\n",
      "Epoch 310/400\n",
      "273/359 [=====================>........] - ETA: 0s - loss: 0.1449 - accuracy: 0.9532\n",
      "Epoch 310: val_loss did not improve from 0.14279\n",
      "359/359 [==============================] - 0s 698us/step - loss: 0.1483 - accuracy: 0.9533 - val_loss: 0.1428 - val_accuracy: 0.9548\n",
      "Epoch 311/400\n",
      "330/359 [==========================>...] - ETA: 0s - loss: 0.1477 - accuracy: 0.9545\n",
      "Epoch 311: val_loss improved from 0.14279 to 0.14231, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 818us/step - loss: 0.1474 - accuracy: 0.9545 - val_loss: 0.1423 - val_accuracy: 0.9501\n",
      "Epoch 312/400\n",
      "333/359 [==========================>...] - ETA: 0s - loss: 0.1507 - accuracy: 0.9531\n",
      "Epoch 312: val_loss did not improve from 0.14231\n",
      "359/359 [==============================] - 0s 760us/step - loss: 0.1487 - accuracy: 0.9535 - val_loss: 0.1433 - val_accuracy: 0.9478\n",
      "Epoch 313/400\n",
      "328/359 [==========================>...] - ETA: 0s - loss: 0.1455 - accuracy: 0.9551\n",
      "Epoch 313: val_loss did not improve from 0.14231\n",
      "359/359 [==============================] - 0s 776us/step - loss: 0.1476 - accuracy: 0.9541 - val_loss: 0.1451 - val_accuracy: 0.9503\n",
      "Epoch 314/400\n",
      "331/359 [==========================>...] - ETA: 0s - loss: 0.1482 - accuracy: 0.9550\n",
      "Epoch 314: val_loss did not improve from 0.14231\n",
      "359/359 [==============================] - 0s 760us/step - loss: 0.1480 - accuracy: 0.9548 - val_loss: 0.1436 - val_accuracy: 0.9538\n",
      "Epoch 315/400\n",
      "311/359 [========================>.....] - ETA: 0s - loss: 0.1474 - accuracy: 0.9547\n",
      "Epoch 315: val_loss did not improve from 0.14231\n",
      "359/359 [==============================] - 0s 779us/step - loss: 0.1474 - accuracy: 0.9541 - val_loss: 0.1456 - val_accuracy: 0.9520\n",
      "Epoch 316/400\n",
      "341/359 [===========================>..] - ETA: 0s - loss: 0.1480 - accuracy: 0.9529\n",
      "Epoch 316: val_loss did not improve from 0.14231\n",
      "359/359 [==============================] - 0s 732us/step - loss: 0.1480 - accuracy: 0.9530 - val_loss: 0.1430 - val_accuracy: 0.9508\n",
      "Epoch 317/400\n",
      "323/359 [=========================>....] - ETA: 0s - loss: 0.1476 - accuracy: 0.9544\n",
      "Epoch 317: val_loss did not improve from 0.14231\n",
      "359/359 [==============================] - 0s 784us/step - loss: 0.1480 - accuracy: 0.9540 - val_loss: 0.1426 - val_accuracy: 0.9530\n",
      "Epoch 318/400\n",
      "273/359 [=====================>........] - ETA: 0s - loss: 0.1476 - accuracy: 0.9547\n",
      "Epoch 318: val_loss did not improve from 0.14231\n",
      "359/359 [==============================] - 0s 697us/step - loss: 0.1478 - accuracy: 0.9543 - val_loss: 0.1425 - val_accuracy: 0.9533\n",
      "Epoch 319/400\n",
      "338/359 [===========================>..] - ETA: 0s - loss: 0.1483 - accuracy: 0.9559\n",
      "Epoch 319: val_loss improved from 0.14231 to 0.14135, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 807us/step - loss: 0.1475 - accuracy: 0.9557 - val_loss: 0.1414 - val_accuracy: 0.9592\n",
      "Epoch 320/400\n",
      "326/359 [==========================>...] - ETA: 0s - loss: 0.1455 - accuracy: 0.9563\n",
      "Epoch 320: val_loss improved from 0.14135 to 0.14122, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 806us/step - loss: 0.1475 - accuracy: 0.9554 - val_loss: 0.1412 - val_accuracy: 0.9493\n",
      "Epoch 321/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.1465 - accuracy: 0.9547\n",
      "Epoch 321: val_loss did not improve from 0.14122\n",
      "359/359 [==============================] - 0s 747us/step - loss: 0.1465 - accuracy: 0.9545 - val_loss: 0.1424 - val_accuracy: 0.9481\n",
      "Epoch 322/400\n",
      "337/359 [===========================>..] - ETA: 0s - loss: 0.1472 - accuracy: 0.9543\n",
      "Epoch 322: val_loss did not improve from 0.14122\n",
      "359/359 [==============================] - 0s 762us/step - loss: 0.1475 - accuracy: 0.9541 - val_loss: 0.1437 - val_accuracy: 0.9535\n",
      "Epoch 323/400\n",
      "320/359 [=========================>....] - ETA: 0s - loss: 0.1481 - accuracy: 0.9540\n",
      "Epoch 323: val_loss did not improve from 0.14122\n",
      "359/359 [==============================] - 0s 780us/step - loss: 0.1467 - accuracy: 0.9543 - val_loss: 0.1417 - val_accuracy: 0.9478\n",
      "Epoch 324/400\n",
      "321/359 [=========================>....] - ETA: 0s - loss: 0.1470 - accuracy: 0.9548\n",
      "Epoch 324: val_loss improved from 0.14122 to 0.14109, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 829us/step - loss: 0.1465 - accuracy: 0.9548 - val_loss: 0.1411 - val_accuracy: 0.9511\n",
      "Epoch 325/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.1453 - accuracy: 0.9544\n",
      "Epoch 325: val_loss did not improve from 0.14109\n",
      "359/359 [==============================] - 0s 760us/step - loss: 0.1465 - accuracy: 0.9543 - val_loss: 0.1464 - val_accuracy: 0.9478\n",
      "Epoch 326/400\n",
      "341/359 [===========================>..] - ETA: 0s - loss: 0.1457 - accuracy: 0.9553\n",
      "Epoch 326: val_loss improved from 0.14109 to 0.14063, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 790us/step - loss: 0.1466 - accuracy: 0.9554 - val_loss: 0.1406 - val_accuracy: 0.9555\n",
      "Epoch 327/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.1468 - accuracy: 0.9547\n",
      "Epoch 327: val_loss did not improve from 0.14063\n",
      "359/359 [==============================] - 0s 725us/step - loss: 0.1461 - accuracy: 0.9550 - val_loss: 0.1420 - val_accuracy: 0.9525\n",
      "Epoch 328/400\n",
      "327/359 [==========================>...] - ETA: 0s - loss: 0.1484 - accuracy: 0.9537\n",
      "Epoch 328: val_loss improved from 0.14063 to 0.14059, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 787us/step - loss: 0.1468 - accuracy: 0.9539 - val_loss: 0.1406 - val_accuracy: 0.9483\n",
      "Epoch 329/400\n",
      "330/359 [==========================>...] - ETA: 0s - loss: 0.1454 - accuracy: 0.9553\n",
      "Epoch 329: val_loss improved from 0.14059 to 0.13970, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 860us/step - loss: 0.1463 - accuracy: 0.9550 - val_loss: 0.1397 - val_accuracy: 0.9562\n",
      "Epoch 330/400\n",
      "340/359 [===========================>..] - ETA: 0s - loss: 0.1456 - accuracy: 0.9557\n",
      "Epoch 330: val_loss did not improve from 0.13970\n",
      "359/359 [==============================] - 0s 903us/step - loss: 0.1456 - accuracy: 0.9552 - val_loss: 0.1432 - val_accuracy: 0.9557\n",
      "Epoch 331/400\n",
      "320/359 [=========================>....] - ETA: 0s - loss: 0.1458 - accuracy: 0.9571\n",
      "Epoch 331: val_loss did not improve from 0.13970\n",
      "359/359 [==============================] - 0s 786us/step - loss: 0.1454 - accuracy: 0.9570 - val_loss: 0.1418 - val_accuracy: 0.9503\n",
      "Epoch 332/400\n",
      "323/359 [=========================>....] - ETA: 0s - loss: 0.1463 - accuracy: 0.9547\n",
      "Epoch 332: val_loss did not improve from 0.13970\n",
      "359/359 [==============================] - 0s 768us/step - loss: 0.1454 - accuracy: 0.9551 - val_loss: 0.1404 - val_accuracy: 0.9557\n",
      "Epoch 333/400\n",
      "328/359 [==========================>...] - ETA: 0s - loss: 0.1465 - accuracy: 0.9542\n",
      "Epoch 333: val_loss did not improve from 0.13970\n",
      "359/359 [==============================] - 0s 757us/step - loss: 0.1461 - accuracy: 0.9549 - val_loss: 0.1401 - val_accuracy: 0.9538\n",
      "Epoch 334/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.1450 - accuracy: 0.9553\n",
      "Epoch 334: val_loss did not improve from 0.13970\n",
      "359/359 [==============================] - 0s 731us/step - loss: 0.1453 - accuracy: 0.9550 - val_loss: 0.1398 - val_accuracy: 0.9540\n",
      "Epoch 335/400\n",
      "354/359 [============================>.] - ETA: 0s - loss: 0.1452 - accuracy: 0.9563\n",
      "Epoch 335: val_loss did not improve from 0.13970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - 0s 710us/step - loss: 0.1450 - accuracy: 0.9563 - val_loss: 0.1405 - val_accuracy: 0.9473\n",
      "Epoch 336/400\n",
      "279/359 [======================>.......] - ETA: 0s - loss: 0.1477 - accuracy: 0.9541\n",
      "Epoch 336: val_loss did not improve from 0.13970\n",
      "359/359 [==============================] - 0s 677us/step - loss: 0.1453 - accuracy: 0.9551 - val_loss: 0.1417 - val_accuracy: 0.9501\n",
      "Epoch 337/400\n",
      "270/359 [=====================>........] - ETA: 0s - loss: 0.1465 - accuracy: 0.9555\n",
      "Epoch 337: val_loss did not improve from 0.13970\n",
      "359/359 [==============================] - 0s 719us/step - loss: 0.1448 - accuracy: 0.9558 - val_loss: 0.1400 - val_accuracy: 0.9530\n",
      "Epoch 338/400\n",
      "302/359 [========================>.....] - ETA: 0s - loss: 0.1461 - accuracy: 0.9553\n",
      "Epoch 338: val_loss improved from 0.13970 to 0.13930, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 865us/step - loss: 0.1446 - accuracy: 0.9558 - val_loss: 0.1393 - val_accuracy: 0.9550\n",
      "Epoch 339/400\n",
      "336/359 [===========================>..] - ETA: 0s - loss: 0.1458 - accuracy: 0.9555\n",
      "Epoch 339: val_loss improved from 0.13930 to 0.13834, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 784us/step - loss: 0.1450 - accuracy: 0.9558 - val_loss: 0.1383 - val_accuracy: 0.9498\n",
      "Epoch 340/400\n",
      "357/359 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.9557\n",
      "Epoch 340: val_loss did not improve from 0.13834\n",
      "359/359 [==============================] - 0s 713us/step - loss: 0.1447 - accuracy: 0.9556 - val_loss: 0.1392 - val_accuracy: 0.9545\n",
      "Epoch 341/400\n",
      "350/359 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 0.9552\n",
      "Epoch 341: val_loss did not improve from 0.13834\n",
      "359/359 [==============================] - 0s 721us/step - loss: 0.1456 - accuracy: 0.9552 - val_loss: 0.1392 - val_accuracy: 0.9565\n",
      "Epoch 342/400\n",
      "325/359 [==========================>...] - ETA: 0s - loss: 0.1440 - accuracy: 0.9572\n",
      "Epoch 342: val_loss did not improve from 0.13834\n",
      "359/359 [==============================] - 0s 759us/step - loss: 0.1444 - accuracy: 0.9573 - val_loss: 0.1388 - val_accuracy: 0.9543\n",
      "Epoch 343/400\n",
      "349/359 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9549\n",
      "Epoch 343: val_loss did not improve from 0.13834\n",
      "359/359 [==============================] - 0s 715us/step - loss: 0.1441 - accuracy: 0.9551 - val_loss: 0.1393 - val_accuracy: 0.9560\n",
      "Epoch 344/400\n",
      "354/359 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9575\n",
      "Epoch 344: val_loss did not improve from 0.13834\n",
      "359/359 [==============================] - 0s 718us/step - loss: 0.1445 - accuracy: 0.9577 - val_loss: 0.1429 - val_accuracy: 0.9493\n",
      "Epoch 345/400\n",
      "331/359 [==========================>...] - ETA: 0s - loss: 0.1442 - accuracy: 0.9551\n",
      "Epoch 345: val_loss did not improve from 0.13834\n",
      "359/359 [==============================] - 0s 781us/step - loss: 0.1442 - accuracy: 0.9553 - val_loss: 0.1395 - val_accuracy: 0.9560\n",
      "Epoch 346/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.1458 - accuracy: 0.9562\n",
      "Epoch 346: val_loss improved from 0.13834 to 0.13823, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 797us/step - loss: 0.1441 - accuracy: 0.9563 - val_loss: 0.1382 - val_accuracy: 0.9585\n",
      "Epoch 347/400\n",
      "309/359 [========================>.....] - ETA: 0s - loss: 0.1446 - accuracy: 0.9562\n",
      "Epoch 347: val_loss did not improve from 0.13823\n",
      "359/359 [==============================] - 0s 810us/step - loss: 0.1435 - accuracy: 0.9563 - val_loss: 0.1390 - val_accuracy: 0.9543\n",
      "Epoch 348/400\n",
      "302/359 [========================>.....] - ETA: 0s - loss: 0.1439 - accuracy: 0.9562\n",
      "Epoch 348: val_loss improved from 0.13823 to 0.13800, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 876us/step - loss: 0.1434 - accuracy: 0.9563 - val_loss: 0.1380 - val_accuracy: 0.9525\n",
      "Epoch 349/400\n",
      "308/359 [========================>.....] - ETA: 0s - loss: 0.1439 - accuracy: 0.9563\n",
      "Epoch 349: val_loss improved from 0.13800 to 0.13789, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 828us/step - loss: 0.1432 - accuracy: 0.9563 - val_loss: 0.1379 - val_accuracy: 0.9545\n",
      "Epoch 350/400\n",
      "334/359 [==========================>...] - ETA: 0s - loss: 0.1445 - accuracy: 0.9557\n",
      "Epoch 350: val_loss did not improve from 0.13789\n",
      "359/359 [==============================] - 0s 762us/step - loss: 0.1440 - accuracy: 0.9563 - val_loss: 0.1383 - val_accuracy: 0.9577\n",
      "Epoch 351/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.1437 - accuracy: 0.9553\n",
      "Epoch 351: val_loss did not improve from 0.13789\n",
      "359/359 [==============================] - 0s 751us/step - loss: 0.1435 - accuracy: 0.9558 - val_loss: 0.1390 - val_accuracy: 0.9622\n",
      "Epoch 352/400\n",
      "328/359 [==========================>...] - ETA: 0s - loss: 0.1431 - accuracy: 0.9571\n",
      "Epoch 352: val_loss did not improve from 0.13789\n",
      "359/359 [==============================] - 0s 803us/step - loss: 0.1429 - accuracy: 0.9569 - val_loss: 0.1408 - val_accuracy: 0.9488\n",
      "Epoch 353/400\n",
      "333/359 [==========================>...] - ETA: 0s - loss: 0.1440 - accuracy: 0.9559\n",
      "Epoch 353: val_loss improved from 0.13789 to 0.13692, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 796us/step - loss: 0.1435 - accuracy: 0.9562 - val_loss: 0.1369 - val_accuracy: 0.9565\n",
      "Epoch 354/400\n",
      "356/359 [============================>.] - ETA: 0s - loss: 0.1432 - accuracy: 0.9561\n",
      "Epoch 354: val_loss did not improve from 0.13692\n",
      "359/359 [==============================] - 0s 704us/step - loss: 0.1436 - accuracy: 0.9560 - val_loss: 0.1373 - val_accuracy: 0.9587\n",
      "Epoch 355/400\n",
      "347/359 [===========================>..] - ETA: 0s - loss: 0.1431 - accuracy: 0.9556\n",
      "Epoch 355: val_loss did not improve from 0.13692\n",
      "359/359 [==============================] - 0s 730us/step - loss: 0.1426 - accuracy: 0.9558 - val_loss: 0.1399 - val_accuracy: 0.9560\n",
      "Epoch 356/400\n",
      "329/359 [==========================>...] - ETA: 0s - loss: 0.1420 - accuracy: 0.9562\n",
      "Epoch 356: val_loss did not improve from 0.13692\n",
      "359/359 [==============================] - 0s 764us/step - loss: 0.1430 - accuracy: 0.9560 - val_loss: 0.1390 - val_accuracy: 0.9553\n",
      "Epoch 357/400\n",
      "321/359 [=========================>....] - ETA: 0s - loss: 0.1426 - accuracy: 0.9570\n",
      "Epoch 357: val_loss did not improve from 0.13692\n",
      "359/359 [==============================] - 0s 773us/step - loss: 0.1427 - accuracy: 0.9567 - val_loss: 0.1383 - val_accuracy: 0.9520\n",
      "Epoch 358/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.1420 - accuracy: 0.9563\n",
      "Epoch 358: val_loss did not improve from 0.13692\n",
      "359/359 [==============================] - 0s 755us/step - loss: 0.1426 - accuracy: 0.9565 - val_loss: 0.1377 - val_accuracy: 0.9560\n",
      "Epoch 359/400\n",
      "346/359 [===========================>..] - ETA: 0s - loss: 0.1431 - accuracy: 0.9574\n",
      "Epoch 359: val_loss did not improve from 0.13692\n",
      "359/359 [==============================] - 0s 724us/step - loss: 0.1426 - accuracy: 0.9573 - val_loss: 0.1374 - val_accuracy: 0.9565\n",
      "Epoch 360/400\n",
      "306/359 [========================>.....] - ETA: 0s - loss: 0.1400 - accuracy: 0.9565\n",
      "Epoch 360: val_loss did not improve from 0.13692\n",
      "359/359 [==============================] - 0s 815us/step - loss: 0.1422 - accuracy: 0.9560 - val_loss: 0.1379 - val_accuracy: 0.9535\n",
      "Epoch 361/400\n",
      "304/359 [========================>.....] - ETA: 0s - loss: 0.1420 - accuracy: 0.9566\n",
      "Epoch 361: val_loss improved from 0.13692 to 0.13682, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 870us/step - loss: 0.1421 - accuracy: 0.9564 - val_loss: 0.1368 - val_accuracy: 0.9562\n",
      "Epoch 362/400\n",
      "314/359 [=========================>....] - ETA: 0s - loss: 0.1427 - accuracy: 0.9565\n",
      "Epoch 362: val_loss did not improve from 0.13682\n",
      "359/359 [==============================] - 0s 789us/step - loss: 0.1419 - accuracy: 0.9567 - val_loss: 0.1401 - val_accuracy: 0.9523\n",
      "Epoch 363/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/359 [==========================>...] - ETA: 0s - loss: 0.1426 - accuracy: 0.9558\n",
      "Epoch 363: val_loss did not improve from 0.13682\n",
      "359/359 [==============================] - 0s 764us/step - loss: 0.1423 - accuracy: 0.9560 - val_loss: 0.1370 - val_accuracy: 0.9580\n",
      "Epoch 364/400\n",
      "335/359 [==========================>...] - ETA: 0s - loss: 0.1433 - accuracy: 0.9562\n",
      "Epoch 364: val_loss improved from 0.13682 to 0.13645, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 795us/step - loss: 0.1421 - accuracy: 0.9567 - val_loss: 0.1364 - val_accuracy: 0.9570\n",
      "Epoch 365/400\n",
      "331/359 [==========================>...] - ETA: 0s - loss: 0.1416 - accuracy: 0.9560\n",
      "Epoch 365: val_loss did not improve from 0.13645\n",
      "359/359 [==============================] - 0s 764us/step - loss: 0.1415 - accuracy: 0.9563 - val_loss: 0.1365 - val_accuracy: 0.9575\n",
      "Epoch 366/400\n",
      "341/359 [===========================>..] - ETA: 0s - loss: 0.1430 - accuracy: 0.9566\n",
      "Epoch 366: val_loss did not improve from 0.13645\n",
      "359/359 [==============================] - 0s 731us/step - loss: 0.1417 - accuracy: 0.9571 - val_loss: 0.1396 - val_accuracy: 0.9577\n",
      "Epoch 367/400\n",
      "342/359 [===========================>..] - ETA: 0s - loss: 0.1400 - accuracy: 0.9572\n",
      "Epoch 367: val_loss did not improve from 0.13645\n",
      "359/359 [==============================] - 0s 767us/step - loss: 0.1415 - accuracy: 0.9567 - val_loss: 0.1378 - val_accuracy: 0.9528\n",
      "Epoch 368/400\n",
      "332/359 [==========================>...] - ETA: 0s - loss: 0.1431 - accuracy: 0.9562\n",
      "Epoch 368: val_loss did not improve from 0.13645\n",
      "359/359 [==============================] - 0s 744us/step - loss: 0.1420 - accuracy: 0.9565 - val_loss: 0.1396 - val_accuracy: 0.9515\n",
      "Epoch 369/400\n",
      "331/359 [==========================>...] - ETA: 0s - loss: 0.1430 - accuracy: 0.9562\n",
      "Epoch 369: val_loss improved from 0.13645 to 0.13609, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 795us/step - loss: 0.1430 - accuracy: 0.9562 - val_loss: 0.1361 - val_accuracy: 0.9590\n",
      "Epoch 370/400\n",
      "322/359 [=========================>....] - ETA: 0s - loss: 0.1416 - accuracy: 0.9576\n",
      "Epoch 370: val_loss did not improve from 0.13609\n",
      "359/359 [==============================] - 0s 783us/step - loss: 0.1420 - accuracy: 0.9575 - val_loss: 0.1366 - val_accuracy: 0.9557\n",
      "Epoch 371/400\n",
      "303/359 [========================>.....] - ETA: 0s - loss: 0.1414 - accuracy: 0.9578\n",
      "Epoch 371: val_loss did not improve from 0.13609\n",
      "359/359 [==============================] - 0s 817us/step - loss: 0.1415 - accuracy: 0.9575 - val_loss: 0.1368 - val_accuracy: 0.9553\n",
      "Epoch 372/400\n",
      "328/359 [==========================>...] - ETA: 0s - loss: 0.1406 - accuracy: 0.9561\n",
      "Epoch 372: val_loss improved from 0.13609 to 0.13583, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 797us/step - loss: 0.1407 - accuracy: 0.9564 - val_loss: 0.1358 - val_accuracy: 0.9577\n",
      "Epoch 373/400\n",
      "319/359 [=========================>....] - ETA: 0s - loss: 0.1417 - accuracy: 0.9575\n",
      "Epoch 373: val_loss did not improve from 0.13583\n",
      "359/359 [==============================] - 0s 768us/step - loss: 0.1407 - accuracy: 0.9579 - val_loss: 0.1366 - val_accuracy: 0.9515\n",
      "Epoch 374/400\n",
      "348/359 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9560\n",
      "Epoch 374: val_loss improved from 0.13583 to 0.13433, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 761us/step - loss: 0.1409 - accuracy: 0.9565 - val_loss: 0.1343 - val_accuracy: 0.9570\n",
      "Epoch 375/400\n",
      "306/359 [========================>.....] - ETA: 0s - loss: 0.1389 - accuracy: 0.9584\n",
      "Epoch 375: val_loss did not improve from 0.13433\n",
      "359/359 [==============================] - 0s 790us/step - loss: 0.1407 - accuracy: 0.9577 - val_loss: 0.1351 - val_accuracy: 0.9609\n",
      "Epoch 376/400\n",
      "315/359 [=========================>....] - ETA: 0s - loss: 0.1420 - accuracy: 0.9565\n",
      "Epoch 376: val_loss did not improve from 0.13433\n",
      "359/359 [==============================] - 0s 779us/step - loss: 0.1410 - accuracy: 0.9567 - val_loss: 0.1355 - val_accuracy: 0.9585\n",
      "Epoch 377/400\n",
      "342/359 [===========================>..] - ETA: 0s - loss: 0.1402 - accuracy: 0.9582\n",
      "Epoch 377: val_loss did not improve from 0.13433\n",
      "359/359 [==============================] - 0s 752us/step - loss: 0.1408 - accuracy: 0.9577 - val_loss: 0.1366 - val_accuracy: 0.9481\n",
      "Epoch 378/400\n",
      "305/359 [========================>.....] - ETA: 0s - loss: 0.1422 - accuracy: 0.9567\n",
      "Epoch 378: val_loss did not improve from 0.13433\n",
      "359/359 [==============================] - 0s 830us/step - loss: 0.1408 - accuracy: 0.9571 - val_loss: 0.1365 - val_accuracy: 0.9548\n",
      "Epoch 379/400\n",
      "319/359 [=========================>....] - ETA: 0s - loss: 0.1417 - accuracy: 0.9571\n",
      "Epoch 379: val_loss did not improve from 0.13433\n",
      "359/359 [==============================] - 0s 765us/step - loss: 0.1404 - accuracy: 0.9569 - val_loss: 0.1387 - val_accuracy: 0.9545\n",
      "Epoch 380/400\n",
      "351/359 [============================>.] - ETA: 0s - loss: 0.1402 - accuracy: 0.9570\n",
      "Epoch 380: val_loss did not improve from 0.13433\n",
      "359/359 [==============================] - 0s 720us/step - loss: 0.1401 - accuracy: 0.9571 - val_loss: 0.1355 - val_accuracy: 0.9530\n",
      "Epoch 381/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.1406 - accuracy: 0.9575\n",
      "Epoch 381: val_loss did not improve from 0.13433\n",
      "359/359 [==============================] - 0s 732us/step - loss: 0.1405 - accuracy: 0.9574 - val_loss: 0.1362 - val_accuracy: 0.9602\n",
      "Epoch 382/400\n",
      "345/359 [===========================>..] - ETA: 0s - loss: 0.1406 - accuracy: 0.9567\n",
      "Epoch 382: val_loss improved from 0.13433 to 0.13432, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 811us/step - loss: 0.1401 - accuracy: 0.9567 - val_loss: 0.1343 - val_accuracy: 0.9595\n",
      "Epoch 383/400\n",
      "329/359 [==========================>...] - ETA: 0s - loss: 0.1404 - accuracy: 0.9570\n",
      "Epoch 383: val_loss improved from 0.13432 to 0.13387, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 799us/step - loss: 0.1402 - accuracy: 0.9573 - val_loss: 0.1339 - val_accuracy: 0.9575\n",
      "Epoch 384/400\n",
      "291/359 [=======================>......] - ETA: 0s - loss: 0.1405 - accuracy: 0.9566\n",
      "Epoch 384: val_loss did not improve from 0.13387\n",
      "359/359 [==============================] - 0s 861us/step - loss: 0.1401 - accuracy: 0.9570 - val_loss: 0.1363 - val_accuracy: 0.9582\n",
      "Epoch 385/400\n",
      "358/359 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9573\n",
      "Epoch 385: val_loss did not improve from 0.13387\n",
      "359/359 [==============================] - 0s 870us/step - loss: 0.1399 - accuracy: 0.9573 - val_loss: 0.1394 - val_accuracy: 0.9562\n",
      "Epoch 386/400\n",
      "324/359 [==========================>...] - ETA: 0s - loss: 0.1398 - accuracy: 0.9567\n",
      "Epoch 386: val_loss improved from 0.13387 to 0.13356, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 838us/step - loss: 0.1404 - accuracy: 0.9566 - val_loss: 0.1336 - val_accuracy: 0.9587\n",
      "Epoch 387/400\n",
      "306/359 [========================>.....] - ETA: 0s - loss: 0.1387 - accuracy: 0.9572\n",
      "Epoch 387: val_loss did not improve from 0.13356\n",
      "359/359 [==============================] - 0s 818us/step - loss: 0.1401 - accuracy: 0.9570 - val_loss: 0.1340 - val_accuracy: 0.9612\n",
      "Epoch 388/400\n",
      "310/359 [========================>.....] - ETA: 0s - loss: 0.1401 - accuracy: 0.9581\n",
      "Epoch 388: val_loss did not improve from 0.13356\n",
      "359/359 [==============================] - 0s 792us/step - loss: 0.1397 - accuracy: 0.9576 - val_loss: 0.1342 - val_accuracy: 0.9585\n",
      "Epoch 389/400\n",
      "316/359 [=========================>....] - ETA: 0s - loss: 0.1393 - accuracy: 0.9569\n",
      "Epoch 389: val_loss did not improve from 0.13356\n",
      "359/359 [==============================] - 0s 844us/step - loss: 0.1399 - accuracy: 0.9571 - val_loss: 0.1359 - val_accuracy: 0.9590\n",
      "Epoch 390/400\n",
      "304/359 [========================>.....] - ETA: 0s - loss: 0.1406 - accuracy: 0.9564\n",
      "Epoch 390: val_loss did not improve from 0.13356\n",
      "359/359 [==============================] - 0s 823us/step - loss: 0.1399 - accuracy: 0.9573 - val_loss: 0.1339 - val_accuracy: 0.9575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/400\n",
      "331/359 [==========================>...] - ETA: 0s - loss: 0.1393 - accuracy: 0.9571\n",
      "Epoch 391: val_loss did not improve from 0.13356\n",
      "359/359 [==============================] - 0s 753us/step - loss: 0.1397 - accuracy: 0.9568 - val_loss: 0.1361 - val_accuracy: 0.9553\n",
      "Epoch 392/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.1398 - accuracy: 0.9575\n",
      "Epoch 392: val_loss did not improve from 0.13356\n",
      "359/359 [==============================] - 0s 728us/step - loss: 0.1395 - accuracy: 0.9575 - val_loss: 0.1344 - val_accuracy: 0.9617\n",
      "Epoch 393/400\n",
      "351/359 [============================>.] - ETA: 0s - loss: 0.1389 - accuracy: 0.9581\n",
      "Epoch 393: val_loss did not improve from 0.13356\n",
      "359/359 [==============================] - 0s 717us/step - loss: 0.1387 - accuracy: 0.9580 - val_loss: 0.1348 - val_accuracy: 0.9555\n",
      "Epoch 394/400\n",
      "351/359 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9571\n",
      "Epoch 394: val_loss did not improve from 0.13356\n",
      "359/359 [==============================] - 0s 722us/step - loss: 0.1392 - accuracy: 0.9573 - val_loss: 0.1348 - val_accuracy: 0.9545\n",
      "Epoch 395/400\n",
      "341/359 [===========================>..] - ETA: 0s - loss: 0.1386 - accuracy: 0.9571\n",
      "Epoch 395: val_loss improved from 0.13356 to 0.13247, saving model to ENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "359/359 [==============================] - 0s 769us/step - loss: 0.1392 - accuracy: 0.9571 - val_loss: 0.1325 - val_accuracy: 0.9582\n",
      "Epoch 396/400\n",
      "343/359 [===========================>..] - ETA: 0s - loss: 0.1397 - accuracy: 0.9575\n",
      "Epoch 396: val_loss did not improve from 0.13247\n",
      "359/359 [==============================] - 0s 737us/step - loss: 0.1386 - accuracy: 0.9576 - val_loss: 0.1326 - val_accuracy: 0.9577\n",
      "Epoch 397/400\n",
      "316/359 [=========================>....] - ETA: 0s - loss: 0.1394 - accuracy: 0.9579\n",
      "Epoch 397: val_loss did not improve from 0.13247\n",
      "359/359 [==============================] - 0s 783us/step - loss: 0.1393 - accuracy: 0.9578 - val_loss: 0.1330 - val_accuracy: 0.9585\n",
      "Epoch 398/400\n",
      "344/359 [===========================>..] - ETA: 0s - loss: 0.1393 - accuracy: 0.9573\n",
      "Epoch 398: val_loss did not improve from 0.13247\n",
      "359/359 [==============================] - 0s 727us/step - loss: 0.1386 - accuracy: 0.9572 - val_loss: 0.1332 - val_accuracy: 0.9560\n",
      "Epoch 399/400\n",
      "351/359 [============================>.] - ETA: 0s - loss: 0.1378 - accuracy: 0.9574\n",
      "Epoch 399: val_loss did not improve from 0.13247\n",
      "359/359 [==============================] - 0s 719us/step - loss: 0.1384 - accuracy: 0.9572 - val_loss: 0.1336 - val_accuracy: 0.9582\n",
      "Epoch 400/400\n",
      "338/359 [===========================>..] - ETA: 0s - loss: 0.1391 - accuracy: 0.9569\n",
      "Epoch 400: val_loss did not improve from 0.13247\n",
      "359/359 [==============================] - 0s 732us/step - loss: 0.1389 - accuracy: 0.9570 - val_loss: 0.1334 - val_accuracy: 0.9560\n",
      "name weight ENO3//model/trained_weights_Hn_7smoothdata.mat\n",
      "149/149 [==============================] - 0s 484us/step\n",
      "here\n",
      "Accuracy  : 0.9569146700294241\n",
      "Precision : 0.958615084010031\n",
      "f1Score : 0.9570968837310326\n",
      "[[ 546   61    0]\n",
      " [  55 3532   10]\n",
      " [  59   20  475]]\n",
      "train history is strored in ENO3/History/history-Hn_7smoothdata.dat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is nonsmoothdata\n",
      "Data file being used is: ENO3/train_input_nonsmoothdata.csv\n",
      "In load data (32500, 6) (32500,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 49        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73 (584.00 Byte)\n",
      "Trainable params: 73 (584.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "324/367 [=========================>....] - ETA: 0s - loss: 1.1213 - accuracy: 0.3347\n",
      "Epoch 1: val_loss improved from inf to 0.98502, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 1s 1ms/step - loss: 1.1075 - accuracy: 0.3407 - val_loss: 0.9850 - val_accuracy: 0.3986\n",
      "Epoch 2/400\n",
      "244/367 [==================>...........] - ETA: 0s - loss: 0.9258 - accuracy: 0.5854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\xai\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/367 [=========================>....] - ETA: 0s - loss: 0.9064 - accuracy: 0.6166\n",
      "Epoch 2: val_loss improved from 0.98502 to 0.81233, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 788us/step - loss: 0.8986 - accuracy: 0.6285 - val_loss: 0.8123 - val_accuracy: 0.7510\n",
      "Epoch 3/400\n",
      "338/367 [==========================>...] - ETA: 0s - loss: 0.7385 - accuracy: 0.7563\n",
      "Epoch 3: val_loss improved from 0.81233 to 0.65917, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 780us/step - loss: 0.7319 - accuracy: 0.7584 - val_loss: 0.6592 - val_accuracy: 0.7814\n",
      "Epoch 4/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.6132 - accuracy: 0.7902\n",
      "Epoch 4: val_loss improved from 0.65917 to 0.56905, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 782us/step - loss: 0.6074 - accuracy: 0.7937 - val_loss: 0.5691 - val_accuracy: 0.8265\n",
      "Epoch 5/400\n",
      "334/367 [==========================>...] - ETA: 0s - loss: 0.5374 - accuracy: 0.8333\n",
      "Epoch 5: val_loss improved from 0.56905 to 0.50711, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 779us/step - loss: 0.5335 - accuracy: 0.8357 - val_loss: 0.5071 - val_accuracy: 0.8540\n",
      "Epoch 6/400\n",
      "338/367 [==========================>...] - ETA: 0s - loss: 0.4805 - accuracy: 0.8575\n",
      "Epoch 6: val_loss improved from 0.50711 to 0.45692, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 790us/step - loss: 0.4783 - accuracy: 0.8576 - val_loss: 0.4569 - val_accuracy: 0.8641\n",
      "Epoch 7/400\n",
      "334/367 [==========================>...] - ETA: 0s - loss: 0.4314 - accuracy: 0.8725\n",
      "Epoch 7: val_loss improved from 0.45692 to 0.40571, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 797us/step - loss: 0.4285 - accuracy: 0.8742 - val_loss: 0.4057 - val_accuracy: 0.8875\n",
      "Epoch 8/400\n",
      "336/367 [==========================>...] - ETA: 0s - loss: 0.3837 - accuracy: 0.8977\n",
      "Epoch 8: val_loss improved from 0.40571 to 0.35716, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 818us/step - loss: 0.3821 - accuracy: 0.8980 - val_loss: 0.3572 - val_accuracy: 0.9117\n",
      "Epoch 9/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.3411 - accuracy: 0.9086\n",
      "Epoch 9: val_loss improved from 0.35716 to 0.32060, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 794us/step - loss: 0.3389 - accuracy: 0.9091 - val_loss: 0.3206 - val_accuracy: 0.9167\n",
      "Epoch 10/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9099\n",
      "Epoch 10: val_loss improved from 0.32060 to 0.29801, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 779us/step - loss: 0.3121 - accuracy: 0.9107 - val_loss: 0.2980 - val_accuracy: 0.9182\n",
      "Epoch 11/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.2942 - accuracy: 0.9137\n",
      "Epoch 11: val_loss improved from 0.29801 to 0.28195, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 756us/step - loss: 0.2948 - accuracy: 0.9132 - val_loss: 0.2820 - val_accuracy: 0.9172\n",
      "Epoch 12/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.2811 - accuracy: 0.9142\n",
      "Epoch 12: val_loss improved from 0.28195 to 0.26951, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 754us/step - loss: 0.2810 - accuracy: 0.9134 - val_loss: 0.2695 - val_accuracy: 0.9180\n",
      "Epoch 13/400\n",
      "359/367 [============================>.] - ETA: 0s - loss: 0.2703 - accuracy: 0.9157\n",
      "Epoch 13: val_loss improved from 0.26951 to 0.25926, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 732us/step - loss: 0.2701 - accuracy: 0.9159 - val_loss: 0.2593 - val_accuracy: 0.9192\n",
      "Epoch 14/400\n",
      "353/367 [===========================>..] - ETA: 0s - loss: 0.2598 - accuracy: 0.9173\n",
      "Epoch 14: val_loss improved from 0.25926 to 0.25082, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 747us/step - loss: 0.2606 - accuracy: 0.9167 - val_loss: 0.2508 - val_accuracy: 0.9213\n",
      "Epoch 15/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.2532 - accuracy: 0.9197\n",
      "Epoch 15: val_loss improved from 0.25082 to 0.24294, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 759us/step - loss: 0.2525 - accuracy: 0.9199 - val_loss: 0.2429 - val_accuracy: 0.9223\n",
      "Epoch 16/400\n",
      "303/367 [=======================>......] - ETA: 0s - loss: 0.2477 - accuracy: 0.9205\n",
      "Epoch 16: val_loss improved from 0.24294 to 0.23765, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 828us/step - loss: 0.2457 - accuracy: 0.9214 - val_loss: 0.2376 - val_accuracy: 0.9240\n",
      "Epoch 17/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.2407 - accuracy: 0.9221\n",
      "Epoch 17: val_loss improved from 0.23765 to 0.23196, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 776us/step - loss: 0.2397 - accuracy: 0.9229 - val_loss: 0.2320 - val_accuracy: 0.9252\n",
      "Epoch 18/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.2344 - accuracy: 0.9251\n",
      "Epoch 18: val_loss improved from 0.23196 to 0.22667, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 755us/step - loss: 0.2341 - accuracy: 0.9248 - val_loss: 0.2267 - val_accuracy: 0.9208\n",
      "Epoch 19/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.2305 - accuracy: 0.9262\n",
      "Epoch 19: val_loss improved from 0.22667 to 0.22203, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 764us/step - loss: 0.2295 - accuracy: 0.9264 - val_loss: 0.2220 - val_accuracy: 0.9283\n",
      "Epoch 20/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.2257 - accuracy: 0.9286\n",
      "Epoch 20: val_loss improved from 0.22203 to 0.21840, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 753us/step - loss: 0.2251 - accuracy: 0.9284 - val_loss: 0.2184 - val_accuracy: 0.9293\n",
      "Epoch 21/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.2189 - accuracy: 0.9317\n",
      "Epoch 21: val_loss improved from 0.21840 to 0.21447, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 767us/step - loss: 0.2210 - accuracy: 0.9309 - val_loss: 0.2145 - val_accuracy: 0.9276\n",
      "Epoch 22/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.2181 - accuracy: 0.9305\n",
      "Epoch 22: val_loss improved from 0.21447 to 0.20997, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 739us/step - loss: 0.2174 - accuracy: 0.9308 - val_loss: 0.2100 - val_accuracy: 0.9317\n",
      "Epoch 23/400\n",
      "329/367 [=========================>....] - ETA: 0s - loss: 0.2145 - accuracy: 0.9313\n",
      "Epoch 23: val_loss improved from 0.20997 to 0.20650, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 817us/step - loss: 0.2140 - accuracy: 0.9315 - val_loss: 0.2065 - val_accuracy: 0.9329\n",
      "Epoch 24/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.2123 - accuracy: 0.9320\n",
      "Epoch 24: val_loss improved from 0.20650 to 0.20290, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 769us/step - loss: 0.2110 - accuracy: 0.9325 - val_loss: 0.2029 - val_accuracy: 0.9315\n",
      "Epoch 25/400\n",
      "339/367 [==========================>...] - ETA: 0s - loss: 0.2080 - accuracy: 0.9331\n",
      "Epoch 25: val_loss improved from 0.20290 to 0.20059, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 770us/step - loss: 0.2083 - accuracy: 0.9323 - val_loss: 0.2006 - val_accuracy: 0.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/400\n",
      "353/367 [===========================>..] - ETA: 0s - loss: 0.2057 - accuracy: 0.9333\n",
      "Epoch 26: val_loss improved from 0.20059 to 0.19896, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 753us/step - loss: 0.2055 - accuracy: 0.9334 - val_loss: 0.1990 - val_accuracy: 0.9312\n",
      "Epoch 27/400\n",
      "354/367 [===========================>..] - ETA: 0s - loss: 0.2037 - accuracy: 0.9338\n",
      "Epoch 27: val_loss improved from 0.19896 to 0.19496, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 742us/step - loss: 0.2028 - accuracy: 0.9339 - val_loss: 0.1950 - val_accuracy: 0.9300\n",
      "Epoch 28/400\n",
      "338/367 [==========================>...] - ETA: 0s - loss: 0.2004 - accuracy: 0.9344\n",
      "Epoch 28: val_loss improved from 0.19496 to 0.19484, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 771us/step - loss: 0.2001 - accuracy: 0.9348 - val_loss: 0.1948 - val_accuracy: 0.9315\n",
      "Epoch 29/400\n",
      "324/367 [=========================>....] - ETA: 0s - loss: 0.1979 - accuracy: 0.9363\n",
      "Epoch 29: val_loss improved from 0.19484 to 0.19037, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 789us/step - loss: 0.1976 - accuracy: 0.9355 - val_loss: 0.1904 - val_accuracy: 0.9329\n",
      "Epoch 30/400\n",
      "339/367 [==========================>...] - ETA: 0s - loss: 0.1936 - accuracy: 0.9363\n",
      "Epoch 30: val_loss improved from 0.19037 to 0.18650, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 797us/step - loss: 0.1947 - accuracy: 0.9359 - val_loss: 0.1865 - val_accuracy: 0.9322\n",
      "Epoch 31/400\n",
      "317/367 [========================>.....] - ETA: 0s - loss: 0.1902 - accuracy: 0.9385\n",
      "Epoch 31: val_loss improved from 0.18650 to 0.18252, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 816us/step - loss: 0.1920 - accuracy: 0.9369 - val_loss: 0.1825 - val_accuracy: 0.9361\n",
      "Epoch 32/400\n",
      "348/367 [===========================>..] - ETA: 0s - loss: 0.1882 - accuracy: 0.9386\n",
      "Epoch 32: val_loss improved from 0.18252 to 0.17829, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 755us/step - loss: 0.1884 - accuracy: 0.9386 - val_loss: 0.1783 - val_accuracy: 0.9377\n",
      "Epoch 33/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.1837 - accuracy: 0.9376\n",
      "Epoch 33: val_loss improved from 0.17829 to 0.17450, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 760us/step - loss: 0.1838 - accuracy: 0.9376 - val_loss: 0.1745 - val_accuracy: 0.9380\n",
      "Epoch 34/400\n",
      "338/367 [==========================>...] - ETA: 0s - loss: 0.1803 - accuracy: 0.9387\n",
      "Epoch 34: val_loss improved from 0.17450 to 0.16906, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 777us/step - loss: 0.1795 - accuracy: 0.9392 - val_loss: 0.1691 - val_accuracy: 0.9389\n",
      "Epoch 35/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.1755 - accuracy: 0.9390\n",
      "Epoch 35: val_loss improved from 0.16906 to 0.16515, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 759us/step - loss: 0.1753 - accuracy: 0.9394 - val_loss: 0.1652 - val_accuracy: 0.9409\n",
      "Epoch 36/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.1714 - accuracy: 0.9409\n",
      "Epoch 36: val_loss improved from 0.16515 to 0.16121, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 754us/step - loss: 0.1711 - accuracy: 0.9408 - val_loss: 0.1612 - val_accuracy: 0.9428\n",
      "Epoch 37/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.1662 - accuracy: 0.9423\n",
      "Epoch 37: val_loss improved from 0.16121 to 0.15826, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 760us/step - loss: 0.1672 - accuracy: 0.9419 - val_loss: 0.1583 - val_accuracy: 0.9435\n",
      "Epoch 38/400\n",
      "294/367 [=======================>......] - ETA: 0s - loss: 0.1661 - accuracy: 0.9415\n",
      "Epoch 38: val_loss improved from 0.15826 to 0.15503, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 862us/step - loss: 0.1643 - accuracy: 0.9428 - val_loss: 0.1550 - val_accuracy: 0.9438\n",
      "Epoch 39/400\n",
      "331/367 [==========================>...] - ETA: 0s - loss: 0.1611 - accuracy: 0.9426\n",
      "Epoch 39: val_loss improved from 0.15503 to 0.15320, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 780us/step - loss: 0.1616 - accuracy: 0.9427 - val_loss: 0.1532 - val_accuracy: 0.9440\n",
      "Epoch 40/400\n",
      "315/367 [========================>.....] - ETA: 0s - loss: 0.1598 - accuracy: 0.9435\n",
      "Epoch 40: val_loss improved from 0.15320 to 0.15198, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 812us/step - loss: 0.1598 - accuracy: 0.9438 - val_loss: 0.1520 - val_accuracy: 0.9423\n",
      "Epoch 41/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.1582 - accuracy: 0.9444\n",
      "Epoch 41: val_loss improved from 0.15198 to 0.15082, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 753us/step - loss: 0.1580 - accuracy: 0.9446 - val_loss: 0.1508 - val_accuracy: 0.9440\n",
      "Epoch 42/400\n",
      "326/367 [=========================>....] - ETA: 0s - loss: 0.1568 - accuracy: 0.9452\n",
      "Epoch 42: val_loss improved from 0.15082 to 0.14900, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 808us/step - loss: 0.1566 - accuracy: 0.9454 - val_loss: 0.1490 - val_accuracy: 0.9447\n",
      "Epoch 43/400\n",
      "323/367 [=========================>....] - ETA: 0s - loss: 0.1539 - accuracy: 0.9462\n",
      "Epoch 43: val_loss improved from 0.14900 to 0.14650, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 793us/step - loss: 0.1549 - accuracy: 0.9453 - val_loss: 0.1465 - val_accuracy: 0.9459\n",
      "Epoch 44/400\n",
      "333/367 [==========================>...] - ETA: 0s - loss: 0.1536 - accuracy: 0.9461\n",
      "Epoch 44: val_loss improved from 0.14650 to 0.14572, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 774us/step - loss: 0.1542 - accuracy: 0.9459 - val_loss: 0.1457 - val_accuracy: 0.9457\n",
      "Epoch 45/400\n",
      "311/367 [========================>.....] - ETA: 0s - loss: 0.1537 - accuracy: 0.9456\n",
      "Epoch 45: val_loss improved from 0.14572 to 0.14492, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 830us/step - loss: 0.1531 - accuracy: 0.9463 - val_loss: 0.1449 - val_accuracy: 0.9469\n",
      "Epoch 46/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.1522 - accuracy: 0.9472\n",
      "Epoch 46: val_loss improved from 0.14492 to 0.14432, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 777us/step - loss: 0.1524 - accuracy: 0.9471 - val_loss: 0.1443 - val_accuracy: 0.9440\n",
      "Epoch 47/400\n",
      "334/367 [==========================>...] - ETA: 0s - loss: 0.1512 - accuracy: 0.9471\n",
      "Epoch 47: val_loss improved from 0.14432 to 0.14291, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 778us/step - loss: 0.1516 - accuracy: 0.9469 - val_loss: 0.1429 - val_accuracy: 0.9469\n",
      "Epoch 48/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.1501 - accuracy: 0.9479\n",
      "Epoch 48: val_loss did not improve from 0.14291\n",
      "367/367 [==============================] - 0s 722us/step - loss: 0.1509 - accuracy: 0.9475 - val_loss: 0.1429 - val_accuracy: 0.9472\n",
      "Epoch 49/400\n",
      "324/367 [=========================>....] - ETA: 0s - loss: 0.1488 - accuracy: 0.9483\n",
      "Epoch 49: val_loss improved from 0.14291 to 0.14120, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 802us/step - loss: 0.1502 - accuracy: 0.9476 - val_loss: 0.1412 - val_accuracy: 0.9469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/400\n",
      "326/367 [=========================>....] - ETA: 0s - loss: 0.1479 - accuracy: 0.9487\n",
      "Epoch 50: val_loss improved from 0.14120 to 0.14112, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 811us/step - loss: 0.1495 - accuracy: 0.9479 - val_loss: 0.1411 - val_accuracy: 0.9484\n",
      "Epoch 51/400\n",
      "339/367 [==========================>...] - ETA: 0s - loss: 0.1496 - accuracy: 0.9480\n",
      "Epoch 51: val_loss improved from 0.14112 to 0.14014, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 775us/step - loss: 0.1490 - accuracy: 0.9480 - val_loss: 0.1401 - val_accuracy: 0.9484\n",
      "Epoch 52/400\n",
      "326/367 [=========================>....] - ETA: 0s - loss: 0.1490 - accuracy: 0.9482\n",
      "Epoch 52: val_loss did not improve from 0.14014\n",
      "367/367 [==============================] - 0s 795us/step - loss: 0.1483 - accuracy: 0.9488 - val_loss: 0.1410 - val_accuracy: 0.9481\n",
      "Epoch 53/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.1464 - accuracy: 0.9498\n",
      "Epoch 53: val_loss improved from 0.14014 to 0.13966, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 748us/step - loss: 0.1478 - accuracy: 0.9493 - val_loss: 0.1397 - val_accuracy: 0.9488\n",
      "Epoch 54/400\n",
      "351/367 [===========================>..] - ETA: 0s - loss: 0.1478 - accuracy: 0.9493\n",
      "Epoch 54: val_loss improved from 0.13966 to 0.13818, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 749us/step - loss: 0.1471 - accuracy: 0.9494 - val_loss: 0.1382 - val_accuracy: 0.9493\n",
      "Epoch 55/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.1471 - accuracy: 0.9492\n",
      "Epoch 55: val_loss did not improve from 0.13818\n",
      "367/367 [==============================] - 0s 716us/step - loss: 0.1468 - accuracy: 0.9494 - val_loss: 0.1387 - val_accuracy: 0.9500\n",
      "Epoch 56/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.1450 - accuracy: 0.9510\n",
      "Epoch 56: val_loss improved from 0.13818 to 0.13785, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 763us/step - loss: 0.1462 - accuracy: 0.9504 - val_loss: 0.1378 - val_accuracy: 0.9513\n",
      "Epoch 57/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.1456 - accuracy: 0.9502\n",
      "Epoch 57: val_loss improved from 0.13785 to 0.13619, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 746us/step - loss: 0.1459 - accuracy: 0.9500 - val_loss: 0.1362 - val_accuracy: 0.9496\n",
      "Epoch 58/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.1451 - accuracy: 0.9505\n",
      "Epoch 58: val_loss did not improve from 0.13619\n",
      "367/367 [==============================] - 0s 712us/step - loss: 0.1452 - accuracy: 0.9508 - val_loss: 0.1373 - val_accuracy: 0.9481\n",
      "Epoch 59/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.1445 - accuracy: 0.9509\n",
      "Epoch 59: val_loss improved from 0.13619 to 0.13544, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 748us/step - loss: 0.1447 - accuracy: 0.9506 - val_loss: 0.1354 - val_accuracy: 0.9510\n",
      "Epoch 60/400\n",
      "362/367 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 0.9510\n",
      "Epoch 60: val_loss improved from 0.13544 to 0.13532, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 899us/step - loss: 0.1437 - accuracy: 0.9511 - val_loss: 0.1353 - val_accuracy: 0.9479\n",
      "Epoch 61/400\n",
      "321/367 [=========================>....] - ETA: 0s - loss: 0.1439 - accuracy: 0.9501\n",
      "Epoch 61: val_loss improved from 0.13532 to 0.13451, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 825us/step - loss: 0.1431 - accuracy: 0.9505 - val_loss: 0.1345 - val_accuracy: 0.9527\n",
      "Epoch 62/400\n",
      "335/367 [==========================>...] - ETA: 0s - loss: 0.1432 - accuracy: 0.9504\n",
      "Epoch 62: val_loss improved from 0.13451 to 0.13361, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 779us/step - loss: 0.1426 - accuracy: 0.9509 - val_loss: 0.1336 - val_accuracy: 0.9505\n",
      "Epoch 63/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.1410 - accuracy: 0.9522\n",
      "Epoch 63: val_loss did not improve from 0.13361\n",
      "367/367 [==============================] - 0s 746us/step - loss: 0.1420 - accuracy: 0.9517 - val_loss: 0.1339 - val_accuracy: 0.9500\n",
      "Epoch 64/400\n",
      "313/367 [========================>.....] - ETA: 0s - loss: 0.1406 - accuracy: 0.9511\n",
      "Epoch 64: val_loss improved from 0.13361 to 0.13209, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 863us/step - loss: 0.1415 - accuracy: 0.9506 - val_loss: 0.1321 - val_accuracy: 0.9525\n",
      "Epoch 65/400\n",
      "292/367 [======================>.......] - ETA: 0s - loss: 0.1409 - accuracy: 0.9524\n",
      "Epoch 65: val_loss did not improve from 0.13209\n",
      "367/367 [==============================] - 0s 819us/step - loss: 0.1411 - accuracy: 0.9520 - val_loss: 0.1324 - val_accuracy: 0.9539\n",
      "Epoch 66/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9518\n",
      "Epoch 66: val_loss did not improve from 0.13209\n",
      "367/367 [==============================] - 0s 714us/step - loss: 0.1405 - accuracy: 0.9517 - val_loss: 0.1321 - val_accuracy: 0.9529\n",
      "Epoch 67/400\n",
      "305/367 [=======================>......] - ETA: 0s - loss: 0.1413 - accuracy: 0.9508\n",
      "Epoch 67: val_loss improved from 0.13209 to 0.13152, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 817us/step - loss: 0.1401 - accuracy: 0.9519 - val_loss: 0.1315 - val_accuracy: 0.9522\n",
      "Epoch 68/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.1411 - accuracy: 0.9507\n",
      "Epoch 68: val_loss improved from 0.13152 to 0.13134, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 780us/step - loss: 0.1397 - accuracy: 0.9510 - val_loss: 0.1313 - val_accuracy: 0.9522\n",
      "Epoch 69/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.1385 - accuracy: 0.9529\n",
      "Epoch 69: val_loss improved from 0.13134 to 0.13107, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 761us/step - loss: 0.1395 - accuracy: 0.9526 - val_loss: 0.1311 - val_accuracy: 0.9529\n",
      "Epoch 70/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.1387 - accuracy: 0.9521\n",
      "Epoch 70: val_loss did not improve from 0.13107\n",
      "367/367 [==============================] - 0s 737us/step - loss: 0.1388 - accuracy: 0.9520 - val_loss: 0.1324 - val_accuracy: 0.9491\n",
      "Epoch 71/400\n",
      "308/367 [========================>.....] - ETA: 0s - loss: 0.1371 - accuracy: 0.9525\n",
      "Epoch 71: val_loss improved from 0.13107 to 0.13004, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 862us/step - loss: 0.1386 - accuracy: 0.9518 - val_loss: 0.1300 - val_accuracy: 0.9542\n",
      "Epoch 72/400\n",
      "318/367 [========================>.....] - ETA: 0s - loss: 0.1391 - accuracy: 0.9516\n",
      "Epoch 72: val_loss did not improve from 0.13004\n",
      "367/367 [==============================] - 0s 760us/step - loss: 0.1383 - accuracy: 0.9516 - val_loss: 0.1302 - val_accuracy: 0.9513\n",
      "Epoch 73/400\n",
      "358/367 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.9515\n",
      "Epoch 73: val_loss improved from 0.13004 to 0.12928, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 755us/step - loss: 0.1377 - accuracy: 0.9515 - val_loss: 0.1293 - val_accuracy: 0.9549\n",
      "Epoch 74/400\n",
      "299/367 [=======================>......] - ETA: 0s - loss: 0.1363 - accuracy: 0.9527\n",
      "Epoch 74: val_loss improved from 0.12928 to 0.12926, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 850us/step - loss: 0.1375 - accuracy: 0.9518 - val_loss: 0.1293 - val_accuracy: 0.9532\n",
      "Epoch 75/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/367 [==========================>...] - ETA: 0s - loss: 0.1374 - accuracy: 0.9528\n",
      "Epoch 75: val_loss improved from 0.12926 to 0.12886, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 935us/step - loss: 0.1371 - accuracy: 0.9525 - val_loss: 0.1289 - val_accuracy: 0.9508\n",
      "Epoch 76/400\n",
      "358/367 [============================>.] - ETA: 0s - loss: 0.1365 - accuracy: 0.9518\n",
      "Epoch 76: val_loss improved from 0.12886 to 0.12851, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 910us/step - loss: 0.1366 - accuracy: 0.9519 - val_loss: 0.1285 - val_accuracy: 0.9522\n",
      "Epoch 77/400\n",
      "308/367 [========================>.....] - ETA: 0s - loss: 0.1360 - accuracy: 0.9520\n",
      "Epoch 77: val_loss improved from 0.12851 to 0.12800, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 832us/step - loss: 0.1363 - accuracy: 0.9519 - val_loss: 0.1280 - val_accuracy: 0.9529\n",
      "Epoch 78/400\n",
      "336/367 [==========================>...] - ETA: 0s - loss: 0.1365 - accuracy: 0.9518\n",
      "Epoch 78: val_loss did not improve from 0.12800\n",
      "367/367 [==============================] - 0s 746us/step - loss: 0.1359 - accuracy: 0.9520 - val_loss: 0.1294 - val_accuracy: 0.9510\n",
      "Epoch 79/400\n",
      "331/367 [==========================>...] - ETA: 0s - loss: 0.1352 - accuracy: 0.9520\n",
      "Epoch 79: val_loss improved from 0.12800 to 0.12745, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 794us/step - loss: 0.1356 - accuracy: 0.9522 - val_loss: 0.1275 - val_accuracy: 0.9515\n",
      "Epoch 80/400\n",
      "318/367 [========================>.....] - ETA: 0s - loss: 0.1336 - accuracy: 0.9530\n",
      "Epoch 80: val_loss improved from 0.12745 to 0.12687, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 805us/step - loss: 0.1348 - accuracy: 0.9522 - val_loss: 0.1269 - val_accuracy: 0.9527\n",
      "Epoch 81/400\n",
      "300/367 [=======================>......] - ETA: 0s - loss: 0.1344 - accuracy: 0.9534\n",
      "Epoch 81: val_loss did not improve from 0.12687\n",
      "367/367 [==============================] - 0s 788us/step - loss: 0.1350 - accuracy: 0.9531 - val_loss: 0.1269 - val_accuracy: 0.9529\n",
      "Epoch 82/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.1336 - accuracy: 0.9533\n",
      "Epoch 82: val_loss improved from 0.12687 to 0.12572, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 755us/step - loss: 0.1344 - accuracy: 0.9529 - val_loss: 0.1257 - val_accuracy: 0.9527\n",
      "Epoch 83/400\n",
      "323/367 [=========================>....] - ETA: 0s - loss: 0.1329 - accuracy: 0.9536\n",
      "Epoch 83: val_loss did not improve from 0.12572\n",
      "367/367 [==============================] - 0s 771us/step - loss: 0.1340 - accuracy: 0.9532 - val_loss: 0.1263 - val_accuracy: 0.9539\n",
      "Epoch 84/400\n",
      "331/367 [==========================>...] - ETA: 0s - loss: 0.1337 - accuracy: 0.9530\n",
      "Epoch 84: val_loss did not improve from 0.12572\n",
      "367/367 [==============================] - 0s 745us/step - loss: 0.1338 - accuracy: 0.9528 - val_loss: 0.1263 - val_accuracy: 0.9522\n",
      "Epoch 85/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.1337 - accuracy: 0.9536\n",
      "Epoch 85: val_loss did not improve from 0.12572\n",
      "367/367 [==============================] - 0s 722us/step - loss: 0.1337 - accuracy: 0.9536 - val_loss: 0.1262 - val_accuracy: 0.9556\n",
      "Epoch 86/400\n",
      "354/367 [===========================>..] - ETA: 0s - loss: 0.1328 - accuracy: 0.9535\n",
      "Epoch 86: val_loss improved from 0.12572 to 0.12524, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 761us/step - loss: 0.1330 - accuracy: 0.9536 - val_loss: 0.1252 - val_accuracy: 0.9558\n",
      "Epoch 87/400\n",
      "340/367 [==========================>...] - ETA: 0s - loss: 0.1322 - accuracy: 0.9542\n",
      "Epoch 87: val_loss improved from 0.12524 to 0.12448, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 768us/step - loss: 0.1330 - accuracy: 0.9541 - val_loss: 0.1245 - val_accuracy: 0.9546\n",
      "Epoch 88/400\n",
      "351/367 [===========================>..] - ETA: 0s - loss: 0.1328 - accuracy: 0.9541\n",
      "Epoch 88: val_loss did not improve from 0.12448\n",
      "367/367 [==============================] - 0s 742us/step - loss: 0.1326 - accuracy: 0.9542 - val_loss: 0.1256 - val_accuracy: 0.9534\n",
      "Epoch 89/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.1318 - accuracy: 0.9543\n",
      "Epoch 89: val_loss did not improve from 0.12448\n",
      "367/367 [==============================] - 0s 727us/step - loss: 0.1324 - accuracy: 0.9539 - val_loss: 0.1259 - val_accuracy: 0.9549\n",
      "Epoch 90/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.1322 - accuracy: 0.9536\n",
      "Epoch 90: val_loss did not improve from 0.12448\n",
      "367/367 [==============================] - 0s 724us/step - loss: 0.1320 - accuracy: 0.9535 - val_loss: 0.1245 - val_accuracy: 0.9544\n",
      "Epoch 91/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.1319 - accuracy: 0.9545\n",
      "Epoch 91: val_loss improved from 0.12448 to 0.12309, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 765us/step - loss: 0.1322 - accuracy: 0.9542 - val_loss: 0.1231 - val_accuracy: 0.9583\n",
      "Epoch 92/400\n",
      "326/367 [=========================>....] - ETA: 0s - loss: 0.1320 - accuracy: 0.9546\n",
      "Epoch 92: val_loss did not improve from 0.12309\n",
      "367/367 [==============================] - 0s 758us/step - loss: 0.1317 - accuracy: 0.9544 - val_loss: 0.1240 - val_accuracy: 0.9554\n",
      "Epoch 93/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.1318 - accuracy: 0.9540\n",
      "Epoch 93: val_loss did not improve from 0.12309\n",
      "367/367 [==============================] - 0s 730us/step - loss: 0.1316 - accuracy: 0.9543 - val_loss: 0.1234 - val_accuracy: 0.9570\n",
      "Epoch 94/400\n",
      "329/367 [=========================>....] - ETA: 0s - loss: 0.1318 - accuracy: 0.9541\n",
      "Epoch 94: val_loss did not improve from 0.12309\n",
      "367/367 [==============================] - 0s 764us/step - loss: 0.1313 - accuracy: 0.9544 - val_loss: 0.1234 - val_accuracy: 0.9551\n",
      "Epoch 95/400\n",
      "324/367 [=========================>....] - ETA: 0s - loss: 0.1315 - accuracy: 0.9541\n",
      "Epoch 95: val_loss improved from 0.12309 to 0.12268, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 792us/step - loss: 0.1311 - accuracy: 0.9546 - val_loss: 0.1227 - val_accuracy: 0.9554\n",
      "Epoch 96/400\n",
      "304/367 [=======================>......] - ETA: 0s - loss: 0.1313 - accuracy: 0.9548\n",
      "Epoch 96: val_loss improved from 0.12268 to 0.12243, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 837us/step - loss: 0.1308 - accuracy: 0.9548 - val_loss: 0.1224 - val_accuracy: 0.9568\n",
      "Epoch 97/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.1294 - accuracy: 0.9560\n",
      "Epoch 97: val_loss improved from 0.12243 to 0.12202, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 803us/step - loss: 0.1307 - accuracy: 0.9553 - val_loss: 0.1220 - val_accuracy: 0.9578\n",
      "Epoch 98/400\n",
      "325/367 [=========================>....] - ETA: 0s - loss: 0.1298 - accuracy: 0.9545\n",
      "Epoch 98: val_loss did not improve from 0.12202\n",
      "367/367 [==============================] - 0s 779us/step - loss: 0.1300 - accuracy: 0.9548 - val_loss: 0.1222 - val_accuracy: 0.9568\n",
      "Epoch 99/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.1296 - accuracy: 0.9545\n",
      "Epoch 99: val_loss did not improve from 0.12202\n",
      "367/367 [==============================] - 0s 730us/step - loss: 0.1299 - accuracy: 0.9545 - val_loss: 0.1221 - val_accuracy: 0.9573\n",
      "Epoch 100/400\n",
      "331/367 [==========================>...] - ETA: 0s - loss: 0.1300 - accuracy: 0.9550\n",
      "Epoch 100: val_loss did not improve from 0.12202\n",
      "367/367 [==============================] - 0s 746us/step - loss: 0.1294 - accuracy: 0.9549 - val_loss: 0.1223 - val_accuracy: 0.9570\n",
      "Epoch 101/400\n",
      "327/367 [=========================>....] - ETA: 0s - loss: 0.1281 - accuracy: 0.9538\n",
      "Epoch 101: val_loss improved from 0.12202 to 0.12139, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 805us/step - loss: 0.1289 - accuracy: 0.9540 - val_loss: 0.1214 - val_accuracy: 0.9580\n",
      "Epoch 102/400\n",
      "316/367 [========================>.....] - ETA: 0s - loss: 0.1299 - accuracy: 0.9546\n",
      "Epoch 102: val_loss improved from 0.12139 to 0.12104, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 824us/step - loss: 0.1288 - accuracy: 0.9546 - val_loss: 0.1210 - val_accuracy: 0.9566\n",
      "Epoch 103/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.1290 - accuracy: 0.9549\n",
      "Epoch 103: val_loss improved from 0.12104 to 0.12053, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 805us/step - loss: 0.1285 - accuracy: 0.9550 - val_loss: 0.1205 - val_accuracy: 0.9592\n",
      "Epoch 104/400\n",
      "358/367 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.9543\n",
      "Epoch 104: val_loss did not improve from 0.12053\n",
      "367/367 [==============================] - 0s 698us/step - loss: 0.1281 - accuracy: 0.9547 - val_loss: 0.1209 - val_accuracy: 0.9590\n",
      "Epoch 105/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.1284 - accuracy: 0.9558\n",
      "Epoch 105: val_loss improved from 0.12053 to 0.11983, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 763us/step - loss: 0.1278 - accuracy: 0.9560 - val_loss: 0.1198 - val_accuracy: 0.9580\n",
      "Epoch 106/400\n",
      "337/367 [==========================>...] - ETA: 0s - loss: 0.1278 - accuracy: 0.9556\n",
      "Epoch 106: val_loss improved from 0.11983 to 0.11907, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 789us/step - loss: 0.1277 - accuracy: 0.9556 - val_loss: 0.1191 - val_accuracy: 0.9599\n",
      "Epoch 107/400\n",
      "315/367 [========================>.....] - ETA: 0s - loss: 0.1272 - accuracy: 0.9566\n",
      "Epoch 107: val_loss did not improve from 0.11907\n",
      "367/367 [==============================] - 0s 772us/step - loss: 0.1273 - accuracy: 0.9563 - val_loss: 0.1193 - val_accuracy: 0.9570\n",
      "Epoch 108/400\n",
      "325/367 [=========================>....] - ETA: 0s - loss: 0.1272 - accuracy: 0.9558\n",
      "Epoch 108: val_loss improved from 0.11907 to 0.11861, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 814us/step - loss: 0.1270 - accuracy: 0.9562 - val_loss: 0.1186 - val_accuracy: 0.9614\n",
      "Epoch 109/400\n",
      "333/367 [==========================>...] - ETA: 0s - loss: 0.1279 - accuracy: 0.9570\n",
      "Epoch 109: val_loss did not improve from 0.11861\n",
      "367/367 [==============================] - 0s 739us/step - loss: 0.1267 - accuracy: 0.9573 - val_loss: 0.1192 - val_accuracy: 0.9583\n",
      "Epoch 110/400\n",
      "358/367 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9560\n",
      "Epoch 110: val_loss did not improve from 0.11861\n",
      "367/367 [==============================] - 0s 725us/step - loss: 0.1266 - accuracy: 0.9560 - val_loss: 0.1190 - val_accuracy: 0.9580\n",
      "Epoch 111/400\n",
      "306/367 [========================>.....] - ETA: 0s - loss: 0.1253 - accuracy: 0.9571\n",
      "Epoch 111: val_loss improved from 0.11861 to 0.11857, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 851us/step - loss: 0.1264 - accuracy: 0.9565 - val_loss: 0.1186 - val_accuracy: 0.9595\n",
      "Epoch 112/400\n",
      "324/367 [=========================>....] - ETA: 0s - loss: 0.1261 - accuracy: 0.9568\n",
      "Epoch 112: val_loss did not improve from 0.11857\n",
      "367/367 [==============================] - 0s 778us/step - loss: 0.1261 - accuracy: 0.9569 - val_loss: 0.1189 - val_accuracy: 0.9604\n",
      "Epoch 113/400\n",
      "310/367 [========================>.....] - ETA: 0s - loss: 0.1250 - accuracy: 0.9579\n",
      "Epoch 113: val_loss improved from 0.11857 to 0.11840, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 829us/step - loss: 0.1256 - accuracy: 0.9574 - val_loss: 0.1184 - val_accuracy: 0.9570\n",
      "Epoch 114/400\n",
      "327/367 [=========================>....] - ETA: 0s - loss: 0.1236 - accuracy: 0.9572\n",
      "Epoch 114: val_loss improved from 0.11840 to 0.11762, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 788us/step - loss: 0.1251 - accuracy: 0.9572 - val_loss: 0.1176 - val_accuracy: 0.9616\n",
      "Epoch 115/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.1246 - accuracy: 0.9570\n",
      "Epoch 115: val_loss improved from 0.11762 to 0.11692, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 769us/step - loss: 0.1249 - accuracy: 0.9569 - val_loss: 0.1169 - val_accuracy: 0.9602\n",
      "Epoch 116/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.1239 - accuracy: 0.9571\n",
      "Epoch 116: val_loss improved from 0.11692 to 0.11619, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 791us/step - loss: 0.1246 - accuracy: 0.9567 - val_loss: 0.1162 - val_accuracy: 0.9590\n",
      "Epoch 117/400\n",
      "360/367 [============================>.] - ETA: 0s - loss: 0.1240 - accuracy: 0.9564\n",
      "Epoch 117: val_loss improved from 0.11619 to 0.11476, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 928us/step - loss: 0.1236 - accuracy: 0.9567 - val_loss: 0.1148 - val_accuracy: 0.9599\n",
      "Epoch 118/400\n",
      "288/367 [======================>.......] - ETA: 0s - loss: 0.1230 - accuracy: 0.9575\n",
      "Epoch 118: val_loss did not improve from 0.11476\n",
      "367/367 [==============================] - 0s 828us/step - loss: 0.1230 - accuracy: 0.9573 - val_loss: 0.1151 - val_accuracy: 0.9587\n",
      "Epoch 119/400\n",
      "329/367 [=========================>....] - ETA: 0s - loss: 0.1213 - accuracy: 0.9579\n",
      "Epoch 119: val_loss improved from 0.11476 to 0.11376, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 787us/step - loss: 0.1224 - accuracy: 0.9578 - val_loss: 0.1138 - val_accuracy: 0.9602\n",
      "Epoch 120/400\n",
      "359/367 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9584\n",
      "Epoch 120: val_loss improved from 0.11376 to 0.11369, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 732us/step - loss: 0.1218 - accuracy: 0.9585 - val_loss: 0.1137 - val_accuracy: 0.9587\n",
      "Epoch 121/400\n",
      "315/367 [========================>.....] - ETA: 0s - loss: 0.1218 - accuracy: 0.9578\n",
      "Epoch 121: val_loss improved from 0.11369 to 0.11263, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 838us/step - loss: 0.1212 - accuracy: 0.9582 - val_loss: 0.1126 - val_accuracy: 0.9587\n",
      "Epoch 122/400\n",
      "309/367 [========================>.....] - ETA: 0s - loss: 0.1206 - accuracy: 0.9587\n",
      "Epoch 122: val_loss improved from 0.11263 to 0.11199, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 839us/step - loss: 0.1210 - accuracy: 0.9592 - val_loss: 0.1120 - val_accuracy: 0.9609\n",
      "Epoch 123/400\n",
      "334/367 [==========================>...] - ETA: 0s - loss: 0.1204 - accuracy: 0.9601\n",
      "Epoch 123: val_loss improved from 0.11199 to 0.11101, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 778us/step - loss: 0.1202 - accuracy: 0.9600 - val_loss: 0.1110 - val_accuracy: 0.9604\n",
      "Epoch 124/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.1210 - accuracy: 0.9586\n",
      "Epoch 124: val_loss improved from 0.11101 to 0.11039, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 765us/step - loss: 0.1200 - accuracy: 0.9593 - val_loss: 0.1104 - val_accuracy: 0.9597\n",
      "Epoch 125/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9596\n",
      "Epoch 125: val_loss did not improve from 0.11039\n",
      "367/367 [==============================] - 0s 857us/step - loss: 0.1195 - accuracy: 0.9595 - val_loss: 0.1107 - val_accuracy: 0.9592\n",
      "Epoch 126/400\n",
      "343/367 [===========================>..] - ETA: 0s - loss: 0.1194 - accuracy: 0.9593\n",
      "Epoch 126: val_loss did not improve from 0.11039\n",
      "367/367 [==============================] - 0s 721us/step - loss: 0.1194 - accuracy: 0.9591 - val_loss: 0.1108 - val_accuracy: 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/400\n",
      "356/367 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9596\n",
      "Epoch 127: val_loss improved from 0.11039 to 0.10984, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 738us/step - loss: 0.1187 - accuracy: 0.9597 - val_loss: 0.1098 - val_accuracy: 0.9616\n",
      "Epoch 128/400\n",
      "320/367 [=========================>....] - ETA: 0s - loss: 0.1171 - accuracy: 0.9606\n",
      "Epoch 128: val_loss improved from 0.10984 to 0.10947, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 804us/step - loss: 0.1181 - accuracy: 0.9606 - val_loss: 0.1095 - val_accuracy: 0.9607\n",
      "Epoch 129/400\n",
      "348/367 [===========================>..] - ETA: 0s - loss: 0.1186 - accuracy: 0.9593\n",
      "Epoch 129: val_loss improved from 0.10947 to 0.10815, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 762us/step - loss: 0.1177 - accuracy: 0.9596 - val_loss: 0.1081 - val_accuracy: 0.9597\n",
      "Epoch 130/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.1170 - accuracy: 0.9605\n",
      "Epoch 130: val_loss did not improve from 0.10815\n",
      "367/367 [==============================] - 0s 727us/step - loss: 0.1170 - accuracy: 0.9604 - val_loss: 0.1090 - val_accuracy: 0.9607\n",
      "Epoch 131/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.1144 - accuracy: 0.9618\n",
      "Epoch 131: val_loss did not improve from 0.10815\n",
      "367/367 [==============================] - 0s 728us/step - loss: 0.1166 - accuracy: 0.9607 - val_loss: 0.1091 - val_accuracy: 0.9595\n",
      "Epoch 132/400\n",
      "330/367 [=========================>....] - ETA: 0s - loss: 0.1147 - accuracy: 0.9610\n",
      "Epoch 132: val_loss improved from 0.10815 to 0.10767, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 795us/step - loss: 0.1162 - accuracy: 0.9605 - val_loss: 0.1077 - val_accuracy: 0.9607\n",
      "Epoch 133/400\n",
      "348/367 [===========================>..] - ETA: 0s - loss: 0.1163 - accuracy: 0.9608\n",
      "Epoch 133: val_loss improved from 0.10767 to 0.10721, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 752us/step - loss: 0.1160 - accuracy: 0.9607 - val_loss: 0.1072 - val_accuracy: 0.9592\n",
      "Epoch 134/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.1154 - accuracy: 0.9613\n",
      "Epoch 134: val_loss did not improve from 0.10721\n",
      "367/367 [==============================] - 0s 752us/step - loss: 0.1154 - accuracy: 0.9613 - val_loss: 0.1075 - val_accuracy: 0.9602\n",
      "Epoch 135/400\n",
      "310/367 [========================>.....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9602\n",
      "Epoch 135: val_loss improved from 0.10721 to 0.10700, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 865us/step - loss: 0.1149 - accuracy: 0.9609 - val_loss: 0.1070 - val_accuracy: 0.9614\n",
      "Epoch 136/400\n",
      "302/367 [=======================>......] - ETA: 0s - loss: 0.1141 - accuracy: 0.9615\n",
      "Epoch 136: val_loss improved from 0.10700 to 0.10617, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 828us/step - loss: 0.1146 - accuracy: 0.9617 - val_loss: 0.1062 - val_accuracy: 0.9611\n",
      "Epoch 137/400\n",
      "333/367 [==========================>...] - ETA: 0s - loss: 0.1145 - accuracy: 0.9618\n",
      "Epoch 137: val_loss improved from 0.10617 to 0.10565, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 806us/step - loss: 0.1140 - accuracy: 0.9618 - val_loss: 0.1057 - val_accuracy: 0.9607\n",
      "Epoch 138/400\n",
      "303/367 [=======================>......] - ETA: 0s - loss: 0.1163 - accuracy: 0.9604\n",
      "Epoch 138: val_loss improved from 0.10565 to 0.10468, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 855us/step - loss: 0.1141 - accuracy: 0.9616 - val_loss: 0.1047 - val_accuracy: 0.9602\n",
      "Epoch 139/400\n",
      "314/367 [========================>.....] - ETA: 0s - loss: 0.1143 - accuracy: 0.9601\n",
      "Epoch 139: val_loss improved from 0.10468 to 0.10466, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 830us/step - loss: 0.1133 - accuracy: 0.9606 - val_loss: 0.1047 - val_accuracy: 0.9628\n",
      "Epoch 140/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.9626\n",
      "Epoch 140: val_loss did not improve from 0.10466\n",
      "367/367 [==============================] - 0s 716us/step - loss: 0.1130 - accuracy: 0.9625 - val_loss: 0.1054 - val_accuracy: 0.9611\n",
      "Epoch 141/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9617\n",
      "Epoch 141: val_loss improved from 0.10466 to 0.10461, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 736us/step - loss: 0.1128 - accuracy: 0.9621 - val_loss: 0.1046 - val_accuracy: 0.9614\n",
      "Epoch 142/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.1121 - accuracy: 0.9622\n",
      "Epoch 142: val_loss improved from 0.10461 to 0.10388, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 784us/step - loss: 0.1125 - accuracy: 0.9619 - val_loss: 0.1039 - val_accuracy: 0.9628\n",
      "Epoch 143/400\n",
      "299/367 [=======================>......] - ETA: 0s - loss: 0.1098 - accuracy: 0.9627\n",
      "Epoch 143: val_loss did not improve from 0.10388\n",
      "367/367 [==============================] - 0s 838us/step - loss: 0.1119 - accuracy: 0.9620 - val_loss: 0.1053 - val_accuracy: 0.9616\n",
      "Epoch 144/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.1115 - accuracy: 0.9620\n",
      "Epoch 144: val_loss did not improve from 0.10388\n",
      "367/367 [==============================] - 0s 714us/step - loss: 0.1116 - accuracy: 0.9621 - val_loss: 0.1044 - val_accuracy: 0.9616\n",
      "Epoch 145/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.1113 - accuracy: 0.9629\n",
      "Epoch 145: val_loss improved from 0.10388 to 0.10338, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 775us/step - loss: 0.1113 - accuracy: 0.9632 - val_loss: 0.1034 - val_accuracy: 0.9619\n",
      "Epoch 146/400\n",
      "353/367 [===========================>..] - ETA: 0s - loss: 0.1118 - accuracy: 0.9621\n",
      "Epoch 146: val_loss improved from 0.10338 to 0.10246, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 749us/step - loss: 0.1109 - accuracy: 0.9626 - val_loss: 0.1025 - val_accuracy: 0.9638\n",
      "Epoch 147/400\n",
      "309/367 [========================>.....] - ETA: 0s - loss: 0.1105 - accuracy: 0.9642\n",
      "Epoch 147: val_loss did not improve from 0.10246\n",
      "367/367 [==============================] - 0s 794us/step - loss: 0.1104 - accuracy: 0.9641 - val_loss: 0.1028 - val_accuracy: 0.9626\n",
      "Epoch 148/400\n",
      "338/367 [==========================>...] - ETA: 0s - loss: 0.1105 - accuracy: 0.9630\n",
      "Epoch 148: val_loss improved from 0.10246 to 0.10190, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 777us/step - loss: 0.1104 - accuracy: 0.9627 - val_loss: 0.1019 - val_accuracy: 0.9650\n",
      "Epoch 149/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.1099 - accuracy: 0.9635\n",
      "Epoch 149: val_loss improved from 0.10190 to 0.10102, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 801us/step - loss: 0.1100 - accuracy: 0.9633 - val_loss: 0.1010 - val_accuracy: 0.9631\n",
      "Epoch 150/400\n",
      "333/367 [==========================>...] - ETA: 0s - loss: 0.1083 - accuracy: 0.9640\n",
      "Epoch 150: val_loss did not improve from 0.10102\n",
      "367/367 [==============================] - 0s 740us/step - loss: 0.1096 - accuracy: 0.9637 - val_loss: 0.1023 - val_accuracy: 0.9616\n",
      "Epoch 151/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.1087 - accuracy: 0.9645\n",
      "Epoch 151: val_loss did not improve from 0.10102\n",
      "367/367 [==============================] - 0s 719us/step - loss: 0.1093 - accuracy: 0.9640 - val_loss: 0.1017 - val_accuracy: 0.9628\n",
      "Epoch 152/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/367 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9643\n",
      "Epoch 152: val_loss did not improve from 0.10102\n",
      "367/367 [==============================] - 0s 694us/step - loss: 0.1089 - accuracy: 0.9644 - val_loss: 0.1015 - val_accuracy: 0.9614\n",
      "Epoch 153/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.1091 - accuracy: 0.9633\n",
      "Epoch 153: val_loss did not improve from 0.10102\n",
      "367/367 [==============================] - 0s 753us/step - loss: 0.1086 - accuracy: 0.9634 - val_loss: 0.1018 - val_accuracy: 0.9616\n",
      "Epoch 154/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.1097 - accuracy: 0.9628\n",
      "Epoch 154: val_loss improved from 0.10102 to 0.10045, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 985us/step - loss: 0.1083 - accuracy: 0.9635 - val_loss: 0.1005 - val_accuracy: 0.9638\n",
      "Epoch 155/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.1079 - accuracy: 0.9650\n",
      "Epoch 155: val_loss did not improve from 0.10045\n",
      "367/367 [==============================] - 0s 747us/step - loss: 0.1078 - accuracy: 0.9647 - val_loss: 0.1019 - val_accuracy: 0.9631\n",
      "Epoch 156/400\n",
      "327/367 [=========================>....] - ETA: 0s - loss: 0.1083 - accuracy: 0.9636\n",
      "Epoch 156: val_loss improved from 0.10045 to 0.10000, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 799us/step - loss: 0.1076 - accuracy: 0.9642 - val_loss: 0.1000 - val_accuracy: 0.9624\n",
      "Epoch 157/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.1070 - accuracy: 0.9640\n",
      "Epoch 157: val_loss improved from 0.10000 to 0.09954, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 766us/step - loss: 0.1073 - accuracy: 0.9637 - val_loss: 0.0995 - val_accuracy: 0.9653\n",
      "Epoch 158/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.1070 - accuracy: 0.9657\n",
      "Epoch 158: val_loss did not improve from 0.09954\n",
      "367/367 [==============================] - 0s 746us/step - loss: 0.1071 - accuracy: 0.9654 - val_loss: 0.0996 - val_accuracy: 0.9640\n",
      "Epoch 159/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.1064 - accuracy: 0.9654\n",
      "Epoch 159: val_loss improved from 0.09954 to 0.09924, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 772us/step - loss: 0.1067 - accuracy: 0.9652 - val_loss: 0.0992 - val_accuracy: 0.9650\n",
      "Epoch 160/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.1069 - accuracy: 0.9656\n",
      "Epoch 160: val_loss did not improve from 0.09924\n",
      "367/367 [==============================] - 0s 721us/step - loss: 0.1063 - accuracy: 0.9660 - val_loss: 0.1006 - val_accuracy: 0.9631\n",
      "Epoch 161/400\n",
      "314/367 [========================>.....] - ETA: 0s - loss: 0.1036 - accuracy: 0.9669\n",
      "Epoch 161: val_loss did not improve from 0.09924\n",
      "367/367 [==============================] - 0s 825us/step - loss: 0.1060 - accuracy: 0.9658 - val_loss: 0.0997 - val_accuracy: 0.9657\n",
      "Epoch 162/400\n",
      "339/367 [==========================>...] - ETA: 0s - loss: 0.1067 - accuracy: 0.9650\n",
      "Epoch 162: val_loss improved from 0.09924 to 0.09875, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 796us/step - loss: 0.1058 - accuracy: 0.9652 - val_loss: 0.0988 - val_accuracy: 0.9631\n",
      "Epoch 163/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.1056 - accuracy: 0.9656\n",
      "Epoch 163: val_loss improved from 0.09875 to 0.09874, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 806us/step - loss: 0.1053 - accuracy: 0.9658 - val_loss: 0.0987 - val_accuracy: 0.9667\n",
      "Epoch 164/400\n",
      "343/367 [===========================>..] - ETA: 0s - loss: 0.1055 - accuracy: 0.9657\n",
      "Epoch 164: val_loss improved from 0.09874 to 0.09847, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 763us/step - loss: 0.1051 - accuracy: 0.9658 - val_loss: 0.0985 - val_accuracy: 0.9636\n",
      "Epoch 165/400\n",
      "348/367 [===========================>..] - ETA: 0s - loss: 0.1043 - accuracy: 0.9670\n",
      "Epoch 165: val_loss improved from 0.09847 to 0.09835, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 747us/step - loss: 0.1045 - accuracy: 0.9670 - val_loss: 0.0983 - val_accuracy: 0.9657\n",
      "Epoch 166/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.1046 - accuracy: 0.9663\n",
      "Epoch 166: val_loss improved from 0.09835 to 0.09745, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 768us/step - loss: 0.1046 - accuracy: 0.9664 - val_loss: 0.0974 - val_accuracy: 0.9672\n",
      "Epoch 167/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.1047 - accuracy: 0.9663\n",
      "Epoch 167: val_loss did not improve from 0.09745\n",
      "367/367 [==============================] - 0s 730us/step - loss: 0.1042 - accuracy: 0.9667 - val_loss: 0.0980 - val_accuracy: 0.9667\n",
      "Epoch 168/400\n",
      "331/367 [==========================>...] - ETA: 0s - loss: 0.1041 - accuracy: 0.9660\n",
      "Epoch 168: val_loss improved from 0.09745 to 0.09681, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 818us/step - loss: 0.1039 - accuracy: 0.9664 - val_loss: 0.0968 - val_accuracy: 0.9662\n",
      "Epoch 169/400\n",
      "300/367 [=======================>......] - ETA: 0s - loss: 0.1022 - accuracy: 0.9680\n",
      "Epoch 169: val_loss did not improve from 0.09681\n",
      "367/367 [==============================] - 0s 809us/step - loss: 0.1035 - accuracy: 0.9671 - val_loss: 0.0973 - val_accuracy: 0.9657\n",
      "Epoch 170/400\n",
      "323/367 [=========================>....] - ETA: 0s - loss: 0.1034 - accuracy: 0.9664\n",
      "Epoch 170: val_loss improved from 0.09681 to 0.09653, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 804us/step - loss: 0.1033 - accuracy: 0.9667 - val_loss: 0.0965 - val_accuracy: 0.9686\n",
      "Epoch 171/400\n",
      "338/367 [==========================>...] - ETA: 0s - loss: 0.1032 - accuracy: 0.9673\n",
      "Epoch 171: val_loss did not improve from 0.09653\n",
      "367/367 [==============================] - 0s 740us/step - loss: 0.1030 - accuracy: 0.9675 - val_loss: 0.0971 - val_accuracy: 0.9650\n",
      "Epoch 172/400\n",
      "323/367 [=========================>....] - ETA: 0s - loss: 0.1029 - accuracy: 0.9673\n",
      "Epoch 172: val_loss improved from 0.09653 to 0.09565, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 814us/step - loss: 0.1027 - accuracy: 0.9672 - val_loss: 0.0956 - val_accuracy: 0.9689\n",
      "Epoch 173/400\n",
      "340/367 [==========================>...] - ETA: 0s - loss: 0.1038 - accuracy: 0.9667\n",
      "Epoch 173: val_loss did not improve from 0.09565\n",
      "367/367 [==============================] - 0s 740us/step - loss: 0.1025 - accuracy: 0.9673 - val_loss: 0.0966 - val_accuracy: 0.9674\n",
      "Epoch 174/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.1024 - accuracy: 0.9671\n",
      "Epoch 174: val_loss improved from 0.09565 to 0.09537, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 754us/step - loss: 0.1020 - accuracy: 0.9673 - val_loss: 0.0954 - val_accuracy: 0.9698\n",
      "Epoch 175/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.1022 - accuracy: 0.9678\n",
      "Epoch 175: val_loss did not improve from 0.09537\n",
      "367/367 [==============================] - 0s 736us/step - loss: 0.1020 - accuracy: 0.9678 - val_loss: 0.0965 - val_accuracy: 0.9662\n",
      "Epoch 176/400\n",
      "324/367 [=========================>....] - ETA: 0s - loss: 0.1020 - accuracy: 0.9672\n",
      "Epoch 176: val_loss did not improve from 0.09537\n",
      "367/367 [==============================] - 0s 763us/step - loss: 0.1015 - accuracy: 0.9674 - val_loss: 0.0964 - val_accuracy: 0.9667\n",
      "Epoch 177/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.9688\n",
      "Epoch 177: val_loss improved from 0.09537 to 0.09523, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 735us/step - loss: 0.1013 - accuracy: 0.9689 - val_loss: 0.0952 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.1016 - accuracy: 0.9678\n",
      "Epoch 178: val_loss did not improve from 0.09523\n",
      "367/367 [==============================] - 0s 729us/step - loss: 0.1012 - accuracy: 0.9678 - val_loss: 0.0955 - val_accuracy: 0.9698\n",
      "Epoch 179/400\n",
      "326/367 [=========================>....] - ETA: 0s - loss: 0.1005 - accuracy: 0.9685\n",
      "Epoch 179: val_loss improved from 0.09523 to 0.09453, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 784us/step - loss: 0.1008 - accuracy: 0.9684 - val_loss: 0.0945 - val_accuracy: 0.9686\n",
      "Epoch 180/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0996 - accuracy: 0.9696\n",
      "Epoch 180: val_loss did not improve from 0.09453\n",
      "367/367 [==============================] - 0s 724us/step - loss: 0.1003 - accuracy: 0.9690 - val_loss: 0.0953 - val_accuracy: 0.9653\n",
      "Epoch 181/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.1013 - accuracy: 0.9684\n",
      "Epoch 181: val_loss did not improve from 0.09453\n",
      "367/367 [==============================] - 0s 736us/step - loss: 0.1003 - accuracy: 0.9686 - val_loss: 0.0961 - val_accuracy: 0.9674\n",
      "Epoch 182/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.0993 - accuracy: 0.9698\n",
      "Epoch 182: val_loss did not improve from 0.09453\n",
      "367/367 [==============================] - 0s 717us/step - loss: 0.1001 - accuracy: 0.9695 - val_loss: 0.0950 - val_accuracy: 0.9684\n",
      "Epoch 183/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.0999 - accuracy: 0.9688\n",
      "Epoch 183: val_loss improved from 0.09453 to 0.09435, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 771us/step - loss: 0.0998 - accuracy: 0.9688 - val_loss: 0.0943 - val_accuracy: 0.9684\n",
      "Epoch 184/400\n",
      "318/367 [========================>.....] - ETA: 0s - loss: 0.0996 - accuracy: 0.9693\n",
      "Epoch 184: val_loss did not improve from 0.09435\n",
      "367/367 [==============================] - 0s 764us/step - loss: 0.0995 - accuracy: 0.9695 - val_loss: 0.0951 - val_accuracy: 0.9679\n",
      "Epoch 185/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.0993 - accuracy: 0.9700\n",
      "Epoch 185: val_loss did not improve from 0.09435\n",
      "367/367 [==============================] - 0s 712us/step - loss: 0.0992 - accuracy: 0.9700 - val_loss: 0.0944 - val_accuracy: 0.9689\n",
      "Epoch 186/400\n",
      "357/367 [============================>.] - ETA: 0s - loss: 0.0989 - accuracy: 0.9691\n",
      "Epoch 186: val_loss did not improve from 0.09435\n",
      "367/367 [==============================] - 0s 714us/step - loss: 0.0992 - accuracy: 0.9692 - val_loss: 0.0944 - val_accuracy: 0.9689\n",
      "Epoch 187/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.0992 - accuracy: 0.9691\n",
      "Epoch 187: val_loss improved from 0.09435 to 0.09400, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 778us/step - loss: 0.0989 - accuracy: 0.9690 - val_loss: 0.0940 - val_accuracy: 0.9679\n",
      "Epoch 188/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.0990 - accuracy: 0.9692\n",
      "Epoch 188: val_loss did not improve from 0.09400\n",
      "367/367 [==============================] - 0s 729us/step - loss: 0.0986 - accuracy: 0.9694 - val_loss: 0.0940 - val_accuracy: 0.9672\n",
      "Epoch 189/400\n",
      "325/367 [=========================>....] - ETA: 0s - loss: 0.0980 - accuracy: 0.9702\n",
      "Epoch 189: val_loss improved from 0.09400 to 0.09307, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 791us/step - loss: 0.0983 - accuracy: 0.9701 - val_loss: 0.0931 - val_accuracy: 0.9686\n",
      "Epoch 190/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.0984 - accuracy: 0.9696\n",
      "Epoch 190: val_loss improved from 0.09307 to 0.09275, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 749us/step - loss: 0.0982 - accuracy: 0.9698 - val_loss: 0.0927 - val_accuracy: 0.9701\n",
      "Epoch 191/400\n",
      "313/367 [========================>.....] - ETA: 0s - loss: 0.0983 - accuracy: 0.9703\n",
      "Epoch 191: val_loss did not improve from 0.09275\n",
      "367/367 [==============================] - 0s 797us/step - loss: 0.0980 - accuracy: 0.9700 - val_loss: 0.0938 - val_accuracy: 0.9681\n",
      "Epoch 192/400\n",
      "353/367 [===========================>..] - ETA: 0s - loss: 0.0974 - accuracy: 0.9700\n",
      "Epoch 192: val_loss improved from 0.09275 to 0.09257, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 746us/step - loss: 0.0976 - accuracy: 0.9699 - val_loss: 0.0926 - val_accuracy: 0.9684\n",
      "Epoch 193/400\n",
      "340/367 [==========================>...] - ETA: 0s - loss: 0.0970 - accuracy: 0.9703\n",
      "Epoch 193: val_loss did not improve from 0.09257\n",
      "367/367 [==============================] - 0s 734us/step - loss: 0.0974 - accuracy: 0.9701 - val_loss: 0.0935 - val_accuracy: 0.9701\n",
      "Epoch 194/400\n",
      "343/367 [===========================>..] - ETA: 0s - loss: 0.0981 - accuracy: 0.9702\n",
      "Epoch 194: val_loss improved from 0.09257 to 0.09185, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 761us/step - loss: 0.0973 - accuracy: 0.9705 - val_loss: 0.0919 - val_accuracy: 0.9710\n",
      "Epoch 195/400\n",
      "353/367 [===========================>..] - ETA: 0s - loss: 0.0971 - accuracy: 0.9707\n",
      "Epoch 195: val_loss did not improve from 0.09185\n",
      "367/367 [==============================] - 0s 727us/step - loss: 0.0972 - accuracy: 0.9707 - val_loss: 0.0928 - val_accuracy: 0.9713\n",
      "Epoch 196/400\n",
      "333/367 [==========================>...] - ETA: 0s - loss: 0.0972 - accuracy: 0.9701\n",
      "Epoch 196: val_loss did not improve from 0.09185\n",
      "367/367 [==============================] - 0s 749us/step - loss: 0.0970 - accuracy: 0.9705 - val_loss: 0.0932 - val_accuracy: 0.9681\n",
      "Epoch 197/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0966 - accuracy: 0.9706\n",
      "Epoch 197: val_loss improved from 0.09185 to 0.09152, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 751us/step - loss: 0.0966 - accuracy: 0.9704 - val_loss: 0.0915 - val_accuracy: 0.9708\n",
      "Epoch 198/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.0966 - accuracy: 0.9704\n",
      "Epoch 198: val_loss improved from 0.09152 to 0.09103, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 744us/step - loss: 0.0966 - accuracy: 0.9705 - val_loss: 0.0910 - val_accuracy: 0.9708\n",
      "Epoch 199/400\n",
      "306/367 [========================>.....] - ETA: 0s - loss: 0.0953 - accuracy: 0.9715\n",
      "Epoch 199: val_loss did not improve from 0.09103\n",
      "367/367 [==============================] - 0s 797us/step - loss: 0.0964 - accuracy: 0.9713 - val_loss: 0.0929 - val_accuracy: 0.9689\n",
      "Epoch 200/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.0966 - accuracy: 0.9708\n",
      "Epoch 200: val_loss did not improve from 0.09103\n",
      "367/367 [==============================] - 0s 760us/step - loss: 0.0962 - accuracy: 0.9713 - val_loss: 0.0917 - val_accuracy: 0.9706\n",
      "Epoch 201/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.0961 - accuracy: 0.9709\n",
      "Epoch 201: val_loss did not improve from 0.09103\n",
      "367/367 [==============================] - 0s 750us/step - loss: 0.0960 - accuracy: 0.9708 - val_loss: 0.0924 - val_accuracy: 0.9696\n",
      "Epoch 202/400\n",
      "322/367 [=========================>....] - ETA: 0s - loss: 0.0952 - accuracy: 0.9712\n",
      "Epoch 202: val_loss improved from 0.09103 to 0.09099, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 813us/step - loss: 0.0959 - accuracy: 0.9709 - val_loss: 0.0910 - val_accuracy: 0.9722\n",
      "Epoch 203/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.0964 - accuracy: 0.9698\n",
      "Epoch 203: val_loss improved from 0.09099 to 0.09073, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 747us/step - loss: 0.0956 - accuracy: 0.9703 - val_loss: 0.0907 - val_accuracy: 0.9706\n",
      "Epoch 204/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.0956 - accuracy: 0.9713\n",
      "Epoch 204: val_loss did not improve from 0.09073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 726us/step - loss: 0.0954 - accuracy: 0.9715 - val_loss: 0.0914 - val_accuracy: 0.9703\n",
      "Epoch 205/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0948 - accuracy: 0.9717\n",
      "Epoch 205: val_loss did not improve from 0.09073\n",
      "367/367 [==============================] - 0s 716us/step - loss: 0.0953 - accuracy: 0.9716 - val_loss: 0.0915 - val_accuracy: 0.9696\n",
      "Epoch 206/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.0949 - accuracy: 0.9707\n",
      "Epoch 206: val_loss did not improve from 0.09073\n",
      "367/367 [==============================] - 0s 757us/step - loss: 0.0949 - accuracy: 0.9710 - val_loss: 0.0909 - val_accuracy: 0.9722\n",
      "Epoch 207/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.0942 - accuracy: 0.9716\n",
      "Epoch 207: val_loss improved from 0.09073 to 0.09043, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 776us/step - loss: 0.0948 - accuracy: 0.9715 - val_loss: 0.0904 - val_accuracy: 0.9727\n",
      "Epoch 208/400\n",
      "335/367 [==========================>...] - ETA: 0s - loss: 0.0945 - accuracy: 0.9718\n",
      "Epoch 208: val_loss did not improve from 0.09043\n",
      "367/367 [==============================] - 0s 752us/step - loss: 0.0946 - accuracy: 0.9716 - val_loss: 0.0906 - val_accuracy: 0.9701\n",
      "Epoch 209/400\n",
      "339/367 [==========================>...] - ETA: 0s - loss: 0.0940 - accuracy: 0.9716\n",
      "Epoch 209: val_loss did not improve from 0.09043\n",
      "367/367 [==============================] - 0s 735us/step - loss: 0.0943 - accuracy: 0.9716 - val_loss: 0.0906 - val_accuracy: 0.9718\n",
      "Epoch 210/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.0948 - accuracy: 0.9717\n",
      "Epoch 210: val_loss improved from 0.09043 to 0.09019, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 756us/step - loss: 0.0942 - accuracy: 0.9718 - val_loss: 0.0902 - val_accuracy: 0.9684\n",
      "Epoch 211/400\n",
      "351/367 [===========================>..] - ETA: 0s - loss: 0.0938 - accuracy: 0.9711\n",
      "Epoch 211: val_loss improved from 0.09019 to 0.08954, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 765us/step - loss: 0.0941 - accuracy: 0.9707 - val_loss: 0.0895 - val_accuracy: 0.9727\n",
      "Epoch 212/400\n",
      "331/367 [==========================>...] - ETA: 0s - loss: 0.0947 - accuracy: 0.9713\n",
      "Epoch 212: val_loss did not improve from 0.08954\n",
      "367/367 [==============================] - 0s 757us/step - loss: 0.0939 - accuracy: 0.9715 - val_loss: 0.0905 - val_accuracy: 0.9722\n",
      "Epoch 213/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.0938 - accuracy: 0.9717\n",
      "Epoch 213: val_loss did not improve from 0.08954\n",
      "367/367 [==============================] - 0s 732us/step - loss: 0.0938 - accuracy: 0.9714 - val_loss: 0.0898 - val_accuracy: 0.9701\n",
      "Epoch 214/400\n",
      "320/367 [=========================>....] - ETA: 0s - loss: 0.0941 - accuracy: 0.9711\n",
      "Epoch 214: val_loss improved from 0.08954 to 0.08902, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 795us/step - loss: 0.0936 - accuracy: 0.9716 - val_loss: 0.0890 - val_accuracy: 0.9722\n",
      "Epoch 215/400\n",
      "351/367 [===========================>..] - ETA: 0s - loss: 0.0934 - accuracy: 0.9722\n",
      "Epoch 215: val_loss improved from 0.08902 to 0.08859, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 764us/step - loss: 0.0933 - accuracy: 0.9721 - val_loss: 0.0886 - val_accuracy: 0.9710\n",
      "Epoch 216/400\n",
      "357/367 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9719\n",
      "Epoch 216: val_loss did not improve from 0.08859\n",
      "367/367 [==============================] - 0s 703us/step - loss: 0.0932 - accuracy: 0.9720 - val_loss: 0.0897 - val_accuracy: 0.9735\n",
      "Epoch 217/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.0933 - accuracy: 0.9725\n",
      "Epoch 217: val_loss improved from 0.08859 to 0.08855, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 778us/step - loss: 0.0928 - accuracy: 0.9726 - val_loss: 0.0886 - val_accuracy: 0.9722\n",
      "Epoch 218/400\n",
      "326/367 [=========================>....] - ETA: 0s - loss: 0.0919 - accuracy: 0.9718\n",
      "Epoch 218: val_loss did not improve from 0.08855\n",
      "367/367 [==============================] - 0s 757us/step - loss: 0.0927 - accuracy: 0.9716 - val_loss: 0.0889 - val_accuracy: 0.9708\n",
      "Epoch 219/400\n",
      "336/367 [==========================>...] - ETA: 0s - loss: 0.0920 - accuracy: 0.9735\n",
      "Epoch 219: val_loss did not improve from 0.08855\n",
      "367/367 [==============================] - 0s 738us/step - loss: 0.0924 - accuracy: 0.9729 - val_loss: 0.0889 - val_accuracy: 0.9718\n",
      "Epoch 220/400\n",
      "335/367 [==========================>...] - ETA: 0s - loss: 0.0924 - accuracy: 0.9719\n",
      "Epoch 220: val_loss did not improve from 0.08855\n",
      "367/367 [==============================] - 0s 741us/step - loss: 0.0925 - accuracy: 0.9718 - val_loss: 0.0911 - val_accuracy: 0.9737\n",
      "Epoch 221/400\n",
      "348/367 [===========================>..] - ETA: 0s - loss: 0.0919 - accuracy: 0.9727\n",
      "Epoch 221: val_loss did not improve from 0.08855\n",
      "367/367 [==============================] - 0s 725us/step - loss: 0.0921 - accuracy: 0.9725 - val_loss: 0.0904 - val_accuracy: 0.9684\n",
      "Epoch 222/400\n",
      "354/367 [===========================>..] - ETA: 0s - loss: 0.0920 - accuracy: 0.9719\n",
      "Epoch 222: val_loss did not improve from 0.08855\n",
      "367/367 [==============================] - 0s 712us/step - loss: 0.0920 - accuracy: 0.9719 - val_loss: 0.0889 - val_accuracy: 0.9706\n",
      "Epoch 223/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0911 - accuracy: 0.9722\n",
      "Epoch 223: val_loss did not improve from 0.08855\n",
      "367/367 [==============================] - 0s 719us/step - loss: 0.0918 - accuracy: 0.9719 - val_loss: 0.0889 - val_accuracy: 0.9708\n",
      "Epoch 224/400\n",
      "358/367 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9720\n",
      "Epoch 224: val_loss improved from 0.08855 to 0.08816, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 748us/step - loss: 0.0917 - accuracy: 0.9721 - val_loss: 0.0882 - val_accuracy: 0.9735\n",
      "Epoch 225/400\n",
      "357/367 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9722\n",
      "Epoch 225: val_loss improved from 0.08816 to 0.08649, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 752us/step - loss: 0.0915 - accuracy: 0.9721 - val_loss: 0.0865 - val_accuracy: 0.9718\n",
      "Epoch 226/400\n",
      "336/367 [==========================>...] - ETA: 0s - loss: 0.0924 - accuracy: 0.9723\n",
      "Epoch 226: val_loss did not improve from 0.08649\n",
      "367/367 [==============================] - 0s 737us/step - loss: 0.0912 - accuracy: 0.9727 - val_loss: 0.0878 - val_accuracy: 0.9742\n",
      "Epoch 227/400\n",
      "343/367 [===========================>..] - ETA: 0s - loss: 0.0902 - accuracy: 0.9736\n",
      "Epoch 227: val_loss did not improve from 0.08649\n",
      "367/367 [==============================] - 0s 731us/step - loss: 0.0910 - accuracy: 0.9730 - val_loss: 0.0875 - val_accuracy: 0.9751\n",
      "Epoch 228/400\n",
      "356/367 [============================>.] - ETA: 0s - loss: 0.0911 - accuracy: 0.9722\n",
      "Epoch 228: val_loss did not improve from 0.08649\n",
      "367/367 [==============================] - 0s 709us/step - loss: 0.0912 - accuracy: 0.9721 - val_loss: 0.0880 - val_accuracy: 0.9730\n",
      "Epoch 229/400\n",
      "312/367 [========================>.....] - ETA: 0s - loss: 0.0913 - accuracy: 0.9725\n",
      "Epoch 229: val_loss improved from 0.08649 to 0.08644, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 866us/step - loss: 0.0908 - accuracy: 0.9729 - val_loss: 0.0864 - val_accuracy: 0.9732\n",
      "Epoch 230/400\n",
      "331/367 [==========================>...] - ETA: 0s - loss: 0.0907 - accuracy: 0.9731\n",
      "Epoch 230: val_loss did not improve from 0.08644\n",
      "367/367 [==============================] - 0s 751us/step - loss: 0.0905 - accuracy: 0.9730 - val_loss: 0.0877 - val_accuracy: 0.9696\n",
      "Epoch 231/400\n",
      "335/367 [==========================>...] - ETA: 0s - loss: 0.0906 - accuracy: 0.9721\n",
      "Epoch 231: val_loss did not improve from 0.08644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 743us/step - loss: 0.0907 - accuracy: 0.9721 - val_loss: 0.0868 - val_accuracy: 0.9722\n",
      "Epoch 232/400\n",
      "327/367 [=========================>....] - ETA: 0s - loss: 0.0900 - accuracy: 0.9724\n",
      "Epoch 232: val_loss did not improve from 0.08644\n",
      "367/367 [==============================] - 0s 761us/step - loss: 0.0903 - accuracy: 0.9723 - val_loss: 0.0882 - val_accuracy: 0.9725\n",
      "Epoch 233/400\n",
      "340/367 [==========================>...] - ETA: 0s - loss: 0.0907 - accuracy: 0.9726\n",
      "Epoch 233: val_loss did not improve from 0.08644\n",
      "367/367 [==============================] - 0s 736us/step - loss: 0.0902 - accuracy: 0.9728 - val_loss: 0.0865 - val_accuracy: 0.9722\n",
      "Epoch 234/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.0895 - accuracy: 0.9727\n",
      "Epoch 234: val_loss improved from 0.08644 to 0.08619, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 759us/step - loss: 0.0900 - accuracy: 0.9727 - val_loss: 0.0862 - val_accuracy: 0.9725\n",
      "Epoch 235/400\n",
      "351/367 [===========================>..] - ETA: 0s - loss: 0.0907 - accuracy: 0.9719\n",
      "Epoch 235: val_loss did not improve from 0.08619\n",
      "367/367 [==============================] - 0s 722us/step - loss: 0.0898 - accuracy: 0.9722 - val_loss: 0.0877 - val_accuracy: 0.9694\n",
      "Epoch 236/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.0905 - accuracy: 0.9724\n",
      "Epoch 236: val_loss did not improve from 0.08619\n",
      "367/367 [==============================] - 0s 722us/step - loss: 0.0899 - accuracy: 0.9728 - val_loss: 0.0862 - val_accuracy: 0.9703\n",
      "Epoch 237/400\n",
      "336/367 [==========================>...] - ETA: 0s - loss: 0.0891 - accuracy: 0.9727\n",
      "Epoch 237: val_loss improved from 0.08619 to 0.08618, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 788us/step - loss: 0.0897 - accuracy: 0.9726 - val_loss: 0.0862 - val_accuracy: 0.9735\n",
      "Epoch 238/400\n",
      "343/367 [===========================>..] - ETA: 0s - loss: 0.0900 - accuracy: 0.9727\n",
      "Epoch 238: val_loss improved from 0.08618 to 0.08577, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 769us/step - loss: 0.0894 - accuracy: 0.9729 - val_loss: 0.0858 - val_accuracy: 0.9732\n",
      "Epoch 239/400\n",
      "323/367 [=========================>....] - ETA: 0s - loss: 0.0898 - accuracy: 0.9726\n",
      "Epoch 239: val_loss did not improve from 0.08577\n",
      "367/367 [==============================] - 0s 771us/step - loss: 0.0894 - accuracy: 0.9728 - val_loss: 0.0860 - val_accuracy: 0.9735\n",
      "Epoch 240/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.0889 - accuracy: 0.9736\n",
      "Epoch 240: val_loss did not improve from 0.08577\n",
      "367/367 [==============================] - 0s 728us/step - loss: 0.0892 - accuracy: 0.9731 - val_loss: 0.0861 - val_accuracy: 0.9696\n",
      "Epoch 241/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.0888 - accuracy: 0.9730\n",
      "Epoch 241: val_loss did not improve from 0.08577\n",
      "367/367 [==============================] - 0s 724us/step - loss: 0.0892 - accuracy: 0.9727 - val_loss: 0.0862 - val_accuracy: 0.9754\n",
      "Epoch 242/400\n",
      "351/367 [===========================>..] - ETA: 0s - loss: 0.0893 - accuracy: 0.9726\n",
      "Epoch 242: val_loss improved from 0.08577 to 0.08543, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 755us/step - loss: 0.0889 - accuracy: 0.9728 - val_loss: 0.0854 - val_accuracy: 0.9739\n",
      "Epoch 243/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.0894 - accuracy: 0.9726\n",
      "Epoch 243: val_loss did not improve from 0.08543\n",
      "367/367 [==============================] - 0s 723us/step - loss: 0.0886 - accuracy: 0.9730 - val_loss: 0.0864 - val_accuracy: 0.9732\n",
      "Epoch 244/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.0879 - accuracy: 0.9733\n",
      "Epoch 244: val_loss improved from 0.08543 to 0.08529, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 765us/step - loss: 0.0884 - accuracy: 0.9730 - val_loss: 0.0853 - val_accuracy: 0.9722\n",
      "Epoch 245/400\n",
      "330/367 [=========================>....] - ETA: 0s - loss: 0.0900 - accuracy: 0.9720\n",
      "Epoch 245: val_loss did not improve from 0.08529\n",
      "367/367 [==============================] - 0s 753us/step - loss: 0.0885 - accuracy: 0.9727 - val_loss: 0.0862 - val_accuracy: 0.9722\n",
      "Epoch 246/400\n",
      "336/367 [==========================>...] - ETA: 0s - loss: 0.0885 - accuracy: 0.9727\n",
      "Epoch 246: val_loss improved from 0.08529 to 0.08425, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 794us/step - loss: 0.0883 - accuracy: 0.9730 - val_loss: 0.0842 - val_accuracy: 0.9735\n",
      "Epoch 247/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.0874 - accuracy: 0.9733\n",
      "Epoch 247: val_loss did not improve from 0.08425\n",
      "367/367 [==============================] - 0s 714us/step - loss: 0.0885 - accuracy: 0.9731 - val_loss: 0.0851 - val_accuracy: 0.9727\n",
      "Epoch 248/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0869 - accuracy: 0.9731\n",
      "Epoch 248: val_loss did not improve from 0.08425\n",
      "367/367 [==============================] - 0s 720us/step - loss: 0.0878 - accuracy: 0.9728 - val_loss: 0.0845 - val_accuracy: 0.9737\n",
      "Epoch 249/400\n",
      "359/367 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9728\n",
      "Epoch 249: val_loss did not improve from 0.08425\n",
      "367/367 [==============================] - 0s 711us/step - loss: 0.0875 - accuracy: 0.9728 - val_loss: 0.0855 - val_accuracy: 0.9739\n",
      "Epoch 250/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.0875 - accuracy: 0.9732\n",
      "Epoch 250: val_loss improved from 0.08425 to 0.08416, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 777us/step - loss: 0.0880 - accuracy: 0.9731 - val_loss: 0.0842 - val_accuracy: 0.9730\n",
      "Epoch 251/400\n",
      "353/367 [===========================>..] - ETA: 0s - loss: 0.0878 - accuracy: 0.9733\n",
      "Epoch 251: val_loss improved from 0.08416 to 0.08376, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 760us/step - loss: 0.0878 - accuracy: 0.9732 - val_loss: 0.0838 - val_accuracy: 0.9747\n",
      "Epoch 252/400\n",
      "320/367 [=========================>....] - ETA: 0s - loss: 0.0878 - accuracy: 0.9732\n",
      "Epoch 252: val_loss did not improve from 0.08376\n",
      "367/367 [==============================] - 0s 766us/step - loss: 0.0876 - accuracy: 0.9735 - val_loss: 0.0844 - val_accuracy: 0.9742\n",
      "Epoch 253/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.0878 - accuracy: 0.9728\n",
      "Epoch 253: val_loss improved from 0.08376 to 0.08303, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 782us/step - loss: 0.0874 - accuracy: 0.9732 - val_loss: 0.0830 - val_accuracy: 0.9739\n",
      "Epoch 254/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.0877 - accuracy: 0.9737\n",
      "Epoch 254: val_loss did not improve from 0.08303\n",
      "367/367 [==============================] - 0s 721us/step - loss: 0.0872 - accuracy: 0.9738 - val_loss: 0.0846 - val_accuracy: 0.9737\n",
      "Epoch 255/400\n",
      "340/367 [==========================>...] - ETA: 0s - loss: 0.0877 - accuracy: 0.9729\n",
      "Epoch 255: val_loss improved from 0.08303 to 0.08276, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 782us/step - loss: 0.0873 - accuracy: 0.9732 - val_loss: 0.0828 - val_accuracy: 0.9744\n",
      "Epoch 256/400\n",
      "348/367 [===========================>..] - ETA: 0s - loss: 0.0875 - accuracy: 0.9732\n",
      "Epoch 256: val_loss did not improve from 0.08276\n",
      "367/367 [==============================] - 0s 728us/step - loss: 0.0870 - accuracy: 0.9737 - val_loss: 0.0836 - val_accuracy: 0.9725\n",
      "Epoch 257/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.0865 - accuracy: 0.9739\n",
      "Epoch 257: val_loss did not improve from 0.08276\n",
      "367/367 [==============================] - 0s 716us/step - loss: 0.0869 - accuracy: 0.9739 - val_loss: 0.0829 - val_accuracy: 0.9730\n",
      "Epoch 258/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/367 [==========================>...] - ETA: 0s - loss: 0.0868 - accuracy: 0.9736\n",
      "Epoch 258: val_loss did not improve from 0.08276\n",
      "367/367 [==============================] - 0s 741us/step - loss: 0.0867 - accuracy: 0.9736 - val_loss: 0.0832 - val_accuracy: 0.9756\n",
      "Epoch 259/400\n",
      "309/367 [========================>.....] - ETA: 0s - loss: 0.0862 - accuracy: 0.9741\n",
      "Epoch 259: val_loss did not improve from 0.08276\n",
      "367/367 [==============================] - 0s 808us/step - loss: 0.0866 - accuracy: 0.9734 - val_loss: 0.0833 - val_accuracy: 0.9744\n",
      "Epoch 260/400\n",
      "354/367 [===========================>..] - ETA: 0s - loss: 0.0867 - accuracy: 0.9735\n",
      "Epoch 260: val_loss improved from 0.08276 to 0.08237, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 756us/step - loss: 0.0864 - accuracy: 0.9736 - val_loss: 0.0824 - val_accuracy: 0.9737\n",
      "Epoch 261/400\n",
      "321/367 [=========================>....] - ETA: 0s - loss: 0.0860 - accuracy: 0.9736\n",
      "Epoch 261: val_loss improved from 0.08237 to 0.08219, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 820us/step - loss: 0.0863 - accuracy: 0.9736 - val_loss: 0.0822 - val_accuracy: 0.9751\n",
      "Epoch 262/400\n",
      "340/367 [==========================>...] - ETA: 0s - loss: 0.0864 - accuracy: 0.9744\n",
      "Epoch 262: val_loss did not improve from 0.08219\n",
      "367/367 [==============================] - 0s 738us/step - loss: 0.0864 - accuracy: 0.9743 - val_loss: 0.0824 - val_accuracy: 0.9732\n",
      "Epoch 263/400\n",
      "323/367 [=========================>....] - ETA: 0s - loss: 0.0865 - accuracy: 0.9735\n",
      "Epoch 263: val_loss did not improve from 0.08219\n",
      "367/367 [==============================] - 0s 764us/step - loss: 0.0862 - accuracy: 0.9737 - val_loss: 0.0830 - val_accuracy: 0.9737\n",
      "Epoch 264/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.0858 - accuracy: 0.9740\n",
      "Epoch 264: val_loss did not improve from 0.08219\n",
      "367/367 [==============================] - 0s 707us/step - loss: 0.0861 - accuracy: 0.9739 - val_loss: 0.0839 - val_accuracy: 0.9713\n",
      "Epoch 265/400\n",
      "333/367 [==========================>...] - ETA: 0s - loss: 0.0869 - accuracy: 0.9730\n",
      "Epoch 265: val_loss did not improve from 0.08219\n",
      "367/367 [==============================] - 0s 759us/step - loss: 0.0861 - accuracy: 0.9736 - val_loss: 0.0825 - val_accuracy: 0.9739\n",
      "Epoch 266/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.0865 - accuracy: 0.9732\n",
      "Epoch 266: val_loss did not improve from 0.08219\n",
      "367/367 [==============================] - 0s 750us/step - loss: 0.0859 - accuracy: 0.9736 - val_loss: 0.0836 - val_accuracy: 0.9737\n",
      "Epoch 267/400\n",
      "337/367 [==========================>...] - ETA: 0s - loss: 0.0853 - accuracy: 0.9740\n",
      "Epoch 267: val_loss did not improve from 0.08219\n",
      "367/367 [==============================] - 0s 737us/step - loss: 0.0857 - accuracy: 0.9737 - val_loss: 0.0839 - val_accuracy: 0.9747\n",
      "Epoch 268/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0854 - accuracy: 0.9743\n",
      "Epoch 268: val_loss did not improve from 0.08219\n",
      "367/367 [==============================] - 0s 712us/step - loss: 0.0854 - accuracy: 0.9742 - val_loss: 0.0839 - val_accuracy: 0.9754\n",
      "Epoch 269/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.0837 - accuracy: 0.9750\n",
      "Epoch 269: val_loss did not improve from 0.08219\n",
      "367/367 [==============================] - 0s 724us/step - loss: 0.0856 - accuracy: 0.9741 - val_loss: 0.0825 - val_accuracy: 0.9744\n",
      "Epoch 270/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.0851 - accuracy: 0.9738\n",
      "Epoch 270: val_loss did not improve from 0.08219\n",
      "367/367 [==============================] - 0s 728us/step - loss: 0.0852 - accuracy: 0.9739 - val_loss: 0.0834 - val_accuracy: 0.9696\n",
      "Epoch 271/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.0849 - accuracy: 0.9736\n",
      "Epoch 271: val_loss improved from 0.08219 to 0.08153, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 771us/step - loss: 0.0854 - accuracy: 0.9734 - val_loss: 0.0815 - val_accuracy: 0.9754\n",
      "Epoch 272/400\n",
      "331/367 [==========================>...] - ETA: 0s - loss: 0.0839 - accuracy: 0.9744\n",
      "Epoch 272: val_loss did not improve from 0.08153\n",
      "367/367 [==============================] - 0s 765us/step - loss: 0.0851 - accuracy: 0.9741 - val_loss: 0.0818 - val_accuracy: 0.9744\n",
      "Epoch 273/400\n",
      "326/367 [=========================>....] - ETA: 0s - loss: 0.0850 - accuracy: 0.9740\n",
      "Epoch 273: val_loss improved from 0.08153 to 0.08107, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 812us/step - loss: 0.0850 - accuracy: 0.9741 - val_loss: 0.0811 - val_accuracy: 0.9742\n",
      "Epoch 274/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0846 - accuracy: 0.9736\n",
      "Epoch 274: val_loss did not improve from 0.08107\n",
      "367/367 [==============================] - 0s 724us/step - loss: 0.0848 - accuracy: 0.9736 - val_loss: 0.0814 - val_accuracy: 0.9754\n",
      "Epoch 275/400\n",
      "335/367 [==========================>...] - ETA: 0s - loss: 0.0851 - accuracy: 0.9739\n",
      "Epoch 275: val_loss did not improve from 0.08107\n",
      "367/367 [==============================] - 0s 739us/step - loss: 0.0850 - accuracy: 0.9742 - val_loss: 0.0816 - val_accuracy: 0.9742\n",
      "Epoch 276/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.0840 - accuracy: 0.9749\n",
      "Epoch 276: val_loss did not improve from 0.08107\n",
      "367/367 [==============================] - 0s 722us/step - loss: 0.0845 - accuracy: 0.9745 - val_loss: 0.0830 - val_accuracy: 0.9751\n",
      "Epoch 277/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 0.9744\n",
      "Epoch 277: val_loss did not improve from 0.08107\n",
      "367/367 [==============================] - 0s 712us/step - loss: 0.0846 - accuracy: 0.9745 - val_loss: 0.0813 - val_accuracy: 0.9744\n",
      "Epoch 278/400\n",
      "335/367 [==========================>...] - ETA: 0s - loss: 0.0843 - accuracy: 0.9747\n",
      "Epoch 278: val_loss improved from 0.08107 to 0.08045, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 770us/step - loss: 0.0844 - accuracy: 0.9745 - val_loss: 0.0805 - val_accuracy: 0.9742\n",
      "Epoch 279/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.0846 - accuracy: 0.9748\n",
      "Epoch 279: val_loss did not improve from 0.08045\n",
      "367/367 [==============================] - 0s 749us/step - loss: 0.0843 - accuracy: 0.9745 - val_loss: 0.0827 - val_accuracy: 0.9720\n",
      "Epoch 280/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.0839 - accuracy: 0.9743\n",
      "Epoch 280: val_loss improved from 0.08045 to 0.08039, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 775us/step - loss: 0.0842 - accuracy: 0.9739 - val_loss: 0.0804 - val_accuracy: 0.9747\n",
      "Epoch 281/400\n",
      "339/367 [==========================>...] - ETA: 0s - loss: 0.0840 - accuracy: 0.9756\n",
      "Epoch 281: val_loss did not improve from 0.08039\n",
      "367/367 [==============================] - 0s 733us/step - loss: 0.0841 - accuracy: 0.9753 - val_loss: 0.0816 - val_accuracy: 0.9747\n",
      "Epoch 282/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.0838 - accuracy: 0.9742\n",
      "Epoch 282: val_loss did not improve from 0.08039\n",
      "367/367 [==============================] - 0s 750us/step - loss: 0.0841 - accuracy: 0.9743 - val_loss: 0.0806 - val_accuracy: 0.9754\n",
      "Epoch 283/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.0832 - accuracy: 0.9743\n",
      "Epoch 283: val_loss did not improve from 0.08039\n",
      "367/367 [==============================] - 0s 712us/step - loss: 0.0836 - accuracy: 0.9742 - val_loss: 0.0813 - val_accuracy: 0.9751\n",
      "Epoch 284/400\n",
      "348/367 [===========================>..] - ETA: 0s - loss: 0.0836 - accuracy: 0.9749\n",
      "Epoch 284: val_loss did not improve from 0.08039\n",
      "367/367 [==============================] - 0s 731us/step - loss: 0.0840 - accuracy: 0.9745 - val_loss: 0.0810 - val_accuracy: 0.9754\n",
      "Epoch 285/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.0848 - accuracy: 0.9744\n",
      "Epoch 285: val_loss did not improve from 0.08039\n",
      "367/367 [==============================] - 0s 756us/step - loss: 0.0836 - accuracy: 0.9746 - val_loss: 0.0813 - val_accuracy: 0.9749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/400\n",
      "339/367 [==========================>...] - ETA: 0s - loss: 0.0828 - accuracy: 0.9753\n",
      "Epoch 286: val_loss did not improve from 0.08039\n",
      "367/367 [==============================] - 0s 730us/step - loss: 0.0838 - accuracy: 0.9749 - val_loss: 0.0808 - val_accuracy: 0.9744\n",
      "Epoch 287/400\n",
      "341/367 [==========================>...] - ETA: 0s - loss: 0.0836 - accuracy: 0.9747\n",
      "Epoch 287: val_loss improved from 0.08039 to 0.07949, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 765us/step - loss: 0.0834 - accuracy: 0.9749 - val_loss: 0.0795 - val_accuracy: 0.9739\n",
      "Epoch 288/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.0827 - accuracy: 0.9752\n",
      "Epoch 288: val_loss did not improve from 0.07949\n",
      "367/367 [==============================] - 0s 729us/step - loss: 0.0834 - accuracy: 0.9749 - val_loss: 0.0805 - val_accuracy: 0.9732\n",
      "Epoch 289/400\n",
      "351/367 [===========================>..] - ETA: 0s - loss: 0.0840 - accuracy: 0.9743\n",
      "Epoch 289: val_loss did not improve from 0.07949\n",
      "367/367 [==============================] - 0s 718us/step - loss: 0.0834 - accuracy: 0.9747 - val_loss: 0.0796 - val_accuracy: 0.9725\n",
      "Epoch 290/400\n",
      "333/367 [==========================>...] - ETA: 0s - loss: 0.0846 - accuracy: 0.9747\n",
      "Epoch 290: val_loss did not improve from 0.07949\n",
      "367/367 [==============================] - 0s 744us/step - loss: 0.0832 - accuracy: 0.9752 - val_loss: 0.0795 - val_accuracy: 0.9737\n",
      "Epoch 291/400\n",
      "324/367 [=========================>....] - ETA: 0s - loss: 0.0827 - accuracy: 0.9753\n",
      "Epoch 291: val_loss did not improve from 0.07949\n",
      "367/367 [==============================] - 0s 763us/step - loss: 0.0833 - accuracy: 0.9750 - val_loss: 0.0799 - val_accuracy: 0.9751\n",
      "Epoch 292/400\n",
      "324/367 [=========================>....] - ETA: 0s - loss: 0.0827 - accuracy: 0.9744\n",
      "Epoch 292: val_loss improved from 0.07949 to 0.07949, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 799us/step - loss: 0.0831 - accuracy: 0.9745 - val_loss: 0.0795 - val_accuracy: 0.9739\n",
      "Epoch 293/400\n",
      "356/367 [============================>.] - ETA: 0s - loss: 0.0826 - accuracy: 0.9753\n",
      "Epoch 293: val_loss improved from 0.07949 to 0.07932, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 752us/step - loss: 0.0831 - accuracy: 0.9751 - val_loss: 0.0793 - val_accuracy: 0.9744\n",
      "Epoch 294/400\n",
      "356/367 [============================>.] - ETA: 0s - loss: 0.0826 - accuracy: 0.9755\n",
      "Epoch 294: val_loss did not improve from 0.07932\n",
      "367/367 [==============================] - 0s 708us/step - loss: 0.0829 - accuracy: 0.9752 - val_loss: 0.0798 - val_accuracy: 0.9739\n",
      "Epoch 295/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9746\n",
      "Epoch 295: val_loss did not improve from 0.07932\n",
      "367/367 [==============================] - 0s 718us/step - loss: 0.0827 - accuracy: 0.9746 - val_loss: 0.0799 - val_accuracy: 0.9749\n",
      "Epoch 296/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.0827 - accuracy: 0.9751\n",
      "Epoch 296: val_loss did not improve from 0.07932\n",
      "367/367 [==============================] - 0s 735us/step - loss: 0.0826 - accuracy: 0.9750 - val_loss: 0.0798 - val_accuracy: 0.9756\n",
      "Epoch 297/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.0833 - accuracy: 0.9746\n",
      "Epoch 297: val_loss improved from 0.07932 to 0.07899, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 811us/step - loss: 0.0827 - accuracy: 0.9750 - val_loss: 0.0790 - val_accuracy: 0.9749\n",
      "Epoch 298/400\n",
      "326/367 [=========================>....] - ETA: 0s - loss: 0.0835 - accuracy: 0.9747\n",
      "Epoch 298: val_loss did not improve from 0.07899\n",
      "367/367 [==============================] - 0s 763us/step - loss: 0.0825 - accuracy: 0.9749 - val_loss: 0.0815 - val_accuracy: 0.9706\n",
      "Epoch 299/400\n",
      "331/367 [==========================>...] - ETA: 0s - loss: 0.0818 - accuracy: 0.9755\n",
      "Epoch 299: val_loss did not improve from 0.07899\n",
      "367/367 [==============================] - 0s 752us/step - loss: 0.0823 - accuracy: 0.9752 - val_loss: 0.0797 - val_accuracy: 0.9754\n",
      "Epoch 300/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.0821 - accuracy: 0.9752\n",
      "Epoch 300: val_loss did not improve from 0.07899\n",
      "367/367 [==============================] - 0s 729us/step - loss: 0.0823 - accuracy: 0.9750 - val_loss: 0.0801 - val_accuracy: 0.9756\n",
      "Epoch 301/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.0827 - accuracy: 0.9750\n",
      "Epoch 301: val_loss improved from 0.07899 to 0.07854, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 765us/step - loss: 0.0821 - accuracy: 0.9752 - val_loss: 0.0785 - val_accuracy: 0.9751\n",
      "Epoch 302/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9749\n",
      "Epoch 302: val_loss did not improve from 0.07854\n",
      "367/367 [==============================] - 0s 710us/step - loss: 0.0821 - accuracy: 0.9750 - val_loss: 0.0792 - val_accuracy: 0.9744\n",
      "Epoch 303/400\n",
      "336/367 [==========================>...] - ETA: 0s - loss: 0.0816 - accuracy: 0.9751\n",
      "Epoch 303: val_loss did not improve from 0.07854\n",
      "367/367 [==============================] - 0s 737us/step - loss: 0.0820 - accuracy: 0.9749 - val_loss: 0.0796 - val_accuracy: 0.9747\n",
      "Epoch 304/400\n",
      "340/367 [==========================>...] - ETA: 0s - loss: 0.0827 - accuracy: 0.9757\n",
      "Epoch 304: val_loss did not improve from 0.07854\n",
      "367/367 [==============================] - 0s 739us/step - loss: 0.0818 - accuracy: 0.9759 - val_loss: 0.0794 - val_accuracy: 0.9749\n",
      "Epoch 305/400\n",
      "320/367 [=========================>....] - ETA: 0s - loss: 0.0816 - accuracy: 0.9754\n",
      "Epoch 305: val_loss improved from 0.07854 to 0.07814, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 817us/step - loss: 0.0816 - accuracy: 0.9757 - val_loss: 0.0781 - val_accuracy: 0.9754\n",
      "Epoch 306/400\n",
      "343/367 [===========================>..] - ETA: 0s - loss: 0.0812 - accuracy: 0.9761\n",
      "Epoch 306: val_loss did not improve from 0.07814\n",
      "367/367 [==============================] - 0s 740us/step - loss: 0.0818 - accuracy: 0.9755 - val_loss: 0.0800 - val_accuracy: 0.9715\n",
      "Epoch 307/400\n",
      "354/367 [===========================>..] - ETA: 0s - loss: 0.0815 - accuracy: 0.9755\n",
      "Epoch 307: val_loss did not improve from 0.07814\n",
      "367/367 [==============================] - 0s 706us/step - loss: 0.0816 - accuracy: 0.9756 - val_loss: 0.0787 - val_accuracy: 0.9751\n",
      "Epoch 308/400\n",
      "348/367 [===========================>..] - ETA: 0s - loss: 0.0819 - accuracy: 0.9752\n",
      "Epoch 308: val_loss did not improve from 0.07814\n",
      "367/367 [==============================] - 0s 729us/step - loss: 0.0815 - accuracy: 0.9752 - val_loss: 0.0789 - val_accuracy: 0.9756\n",
      "Epoch 309/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0814 - accuracy: 0.9762\n",
      "Epoch 309: val_loss did not improve from 0.07814\n",
      "367/367 [==============================] - 0s 716us/step - loss: 0.0813 - accuracy: 0.9763 - val_loss: 0.0801 - val_accuracy: 0.9751\n",
      "Epoch 310/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 0.9758\n",
      "Epoch 310: val_loss improved from 0.07814 to 0.07750, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 760us/step - loss: 0.0811 - accuracy: 0.9760 - val_loss: 0.0775 - val_accuracy: 0.9749\n",
      "Epoch 311/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.0808 - accuracy: 0.9763\n",
      "Epoch 311: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 755us/step - loss: 0.0813 - accuracy: 0.9761 - val_loss: 0.0789 - val_accuracy: 0.9744\n",
      "Epoch 312/400\n",
      "340/367 [==========================>...] - ETA: 0s - loss: 0.0820 - accuracy: 0.9756\n",
      "Epoch 312: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 745us/step - loss: 0.0813 - accuracy: 0.9759 - val_loss: 0.0782 - val_accuracy: 0.9749\n",
      "Epoch 313/400\n",
      "334/367 [==========================>...] - ETA: 0s - loss: 0.0814 - accuracy: 0.9757\n",
      "Epoch 313: val_loss improved from 0.07750 to 0.07750, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 768us/step - loss: 0.0810 - accuracy: 0.9758 - val_loss: 0.0775 - val_accuracy: 0.9751\n",
      "Epoch 314/400\n",
      "333/367 [==========================>...] - ETA: 0s - loss: 0.0798 - accuracy: 0.9759\n",
      "Epoch 314: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 749us/step - loss: 0.0807 - accuracy: 0.9756 - val_loss: 0.0795 - val_accuracy: 0.9737\n",
      "Epoch 315/400\n",
      "356/367 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9763\n",
      "Epoch 315: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 706us/step - loss: 0.0809 - accuracy: 0.9762 - val_loss: 0.0790 - val_accuracy: 0.9754\n",
      "Epoch 316/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.0810 - accuracy: 0.9765\n",
      "Epoch 316: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 710us/step - loss: 0.0807 - accuracy: 0.9764 - val_loss: 0.0779 - val_accuracy: 0.9754\n",
      "Epoch 317/400\n",
      "336/367 [==========================>...] - ETA: 0s - loss: 0.0799 - accuracy: 0.9751\n",
      "Epoch 317: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 741us/step - loss: 0.0808 - accuracy: 0.9750 - val_loss: 0.0780 - val_accuracy: 0.9756\n",
      "Epoch 318/400\n",
      "333/367 [==========================>...] - ETA: 0s - loss: 0.0796 - accuracy: 0.9764\n",
      "Epoch 318: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 748us/step - loss: 0.0806 - accuracy: 0.9759 - val_loss: 0.0796 - val_accuracy: 0.9747\n",
      "Epoch 319/400\n",
      "340/367 [==========================>...] - ETA: 0s - loss: 0.0797 - accuracy: 0.9765\n",
      "Epoch 319: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 741us/step - loss: 0.0803 - accuracy: 0.9764 - val_loss: 0.0786 - val_accuracy: 0.9766\n",
      "Epoch 320/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.0790 - accuracy: 0.9759\n",
      "Epoch 320: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 755us/step - loss: 0.0803 - accuracy: 0.9754 - val_loss: 0.0783 - val_accuracy: 0.9754\n",
      "Epoch 321/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.0799 - accuracy: 0.9758\n",
      "Epoch 321: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 719us/step - loss: 0.0804 - accuracy: 0.9757 - val_loss: 0.0783 - val_accuracy: 0.9756\n",
      "Epoch 322/400\n",
      "323/367 [=========================>....] - ETA: 0s - loss: 0.0792 - accuracy: 0.9762\n",
      "Epoch 322: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 761us/step - loss: 0.0803 - accuracy: 0.9761 - val_loss: 0.0778 - val_accuracy: 0.9768\n",
      "Epoch 323/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.0804 - accuracy: 0.9762\n",
      "Epoch 323: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 718us/step - loss: 0.0802 - accuracy: 0.9764 - val_loss: 0.0786 - val_accuracy: 0.9739\n",
      "Epoch 324/400\n",
      "336/367 [==========================>...] - ETA: 0s - loss: 0.0805 - accuracy: 0.9754\n",
      "Epoch 324: val_loss did not improve from 0.07750\n",
      "367/367 [==============================] - 0s 742us/step - loss: 0.0803 - accuracy: 0.9759 - val_loss: 0.0776 - val_accuracy: 0.9764\n",
      "Epoch 325/400\n",
      "334/367 [==========================>...] - ETA: 0s - loss: 0.0794 - accuracy: 0.9770\n",
      "Epoch 325: val_loss improved from 0.07750 to 0.07709, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 791us/step - loss: 0.0803 - accuracy: 0.9763 - val_loss: 0.0771 - val_accuracy: 0.9749\n",
      "Epoch 326/400\n",
      "353/367 [===========================>..] - ETA: 0s - loss: 0.0806 - accuracy: 0.9759\n",
      "Epoch 326: val_loss did not improve from 0.07709\n",
      "367/367 [==============================] - 0s 708us/step - loss: 0.0799 - accuracy: 0.9759 - val_loss: 0.0776 - val_accuracy: 0.9751\n",
      "Epoch 327/400\n",
      "354/367 [===========================>..] - ETA: 0s - loss: 0.0796 - accuracy: 0.9765\n",
      "Epoch 327: val_loss did not improve from 0.07709\n",
      "367/367 [==============================] - 0s 710us/step - loss: 0.0801 - accuracy: 0.9763 - val_loss: 0.0774 - val_accuracy: 0.9764\n",
      "Epoch 328/400\n",
      "337/367 [==========================>...] - ETA: 0s - loss: 0.0794 - accuracy: 0.9765\n",
      "Epoch 328: val_loss did not improve from 0.07709\n",
      "367/367 [==============================] - 0s 736us/step - loss: 0.0796 - accuracy: 0.9764 - val_loss: 0.0777 - val_accuracy: 0.9749\n",
      "Epoch 329/400\n",
      "343/367 [===========================>..] - ETA: 0s - loss: 0.0799 - accuracy: 0.9764\n",
      "Epoch 329: val_loss did not improve from 0.07709\n",
      "367/367 [==============================] - 0s 729us/step - loss: 0.0798 - accuracy: 0.9764 - val_loss: 0.0773 - val_accuracy: 0.9761\n",
      "Epoch 330/400\n",
      "353/367 [===========================>..] - ETA: 0s - loss: 0.0802 - accuracy: 0.9762\n",
      "Epoch 330: val_loss did not improve from 0.07709\n",
      "367/367 [==============================] - 0s 715us/step - loss: 0.0796 - accuracy: 0.9764 - val_loss: 0.0780 - val_accuracy: 0.9749\n",
      "Epoch 331/400\n",
      "343/367 [===========================>..] - ETA: 0s - loss: 0.0810 - accuracy: 0.9751\n",
      "Epoch 331: val_loss did not improve from 0.07709\n",
      "367/367 [==============================] - 0s 731us/step - loss: 0.0795 - accuracy: 0.9758 - val_loss: 0.0777 - val_accuracy: 0.9742\n",
      "Epoch 332/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.0798 - accuracy: 0.9764\n",
      "Epoch 332: val_loss improved from 0.07709 to 0.07697, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 753us/step - loss: 0.0795 - accuracy: 0.9765 - val_loss: 0.0770 - val_accuracy: 0.9756\n",
      "Epoch 333/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9766\n",
      "Epoch 333: val_loss did not improve from 0.07697\n",
      "367/367 [==============================] - 0s 706us/step - loss: 0.0794 - accuracy: 0.9765 - val_loss: 0.0781 - val_accuracy: 0.9759\n",
      "Epoch 334/400\n",
      "358/367 [============================>.] - ETA: 0s - loss: 0.0790 - accuracy: 0.9768\n",
      "Epoch 334: val_loss improved from 0.07697 to 0.07589, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 751us/step - loss: 0.0794 - accuracy: 0.9767 - val_loss: 0.0759 - val_accuracy: 0.9756\n",
      "Epoch 335/400\n",
      "355/367 [============================>.] - ETA: 0s - loss: 0.0797 - accuracy: 0.9765\n",
      "Epoch 335: val_loss did not improve from 0.07589\n",
      "367/367 [==============================] - 0s 718us/step - loss: 0.0793 - accuracy: 0.9765 - val_loss: 0.0762 - val_accuracy: 0.9754\n",
      "Epoch 336/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.0790 - accuracy: 0.9761\n",
      "Epoch 336: val_loss did not improve from 0.07589\n",
      "367/367 [==============================] - 0s 730us/step - loss: 0.0791 - accuracy: 0.9760 - val_loss: 0.0762 - val_accuracy: 0.9768\n",
      "Epoch 337/400\n",
      "321/367 [=========================>....] - ETA: 0s - loss: 0.0786 - accuracy: 0.9771\n",
      "Epoch 337: val_loss did not improve from 0.07589\n",
      "367/367 [==============================] - 0s 774us/step - loss: 0.0791 - accuracy: 0.9766 - val_loss: 0.0767 - val_accuracy: 0.9727\n",
      "Epoch 338/400\n",
      "338/367 [==========================>...] - ETA: 0s - loss: 0.0785 - accuracy: 0.9774\n",
      "Epoch 338: val_loss did not improve from 0.07589\n",
      "367/367 [==============================] - 0s 743us/step - loss: 0.0788 - accuracy: 0.9773 - val_loss: 0.0761 - val_accuracy: 0.9764\n",
      "Epoch 339/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.0791 - accuracy: 0.9764\n",
      "Epoch 339: val_loss did not improve from 0.07589\n",
      "367/367 [==============================] - 0s 722us/step - loss: 0.0788 - accuracy: 0.9764 - val_loss: 0.0759 - val_accuracy: 0.9756\n",
      "Epoch 340/400\n",
      "354/367 [===========================>..] - ETA: 0s - loss: 0.0788 - accuracy: 0.9769\n",
      "Epoch 340: val_loss did not improve from 0.07589\n",
      "367/367 [==============================] - 0s 711us/step - loss: 0.0788 - accuracy: 0.9770 - val_loss: 0.0776 - val_accuracy: 0.9735\n",
      "Epoch 341/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.0783 - accuracy: 0.9766\n",
      "Epoch 341: val_loss improved from 0.07589 to 0.07528, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 765us/step - loss: 0.0787 - accuracy: 0.9764 - val_loss: 0.0753 - val_accuracy: 0.9759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/400\n",
      "354/367 [===========================>..] - ETA: 0s - loss: 0.0788 - accuracy: 0.9759\n",
      "Epoch 342: val_loss did not improve from 0.07528\n",
      "367/367 [==============================] - 0s 710us/step - loss: 0.0787 - accuracy: 0.9760 - val_loss: 0.0755 - val_accuracy: 0.9768\n",
      "Epoch 343/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.0795 - accuracy: 0.9766\n",
      "Epoch 343: val_loss did not improve from 0.07528\n",
      "367/367 [==============================] - 0s 732us/step - loss: 0.0787 - accuracy: 0.9769 - val_loss: 0.0764 - val_accuracy: 0.9768\n",
      "Epoch 344/400\n",
      "327/367 [=========================>....] - ETA: 0s - loss: 0.0791 - accuracy: 0.9763\n",
      "Epoch 344: val_loss did not improve from 0.07528\n",
      "367/367 [==============================] - 0s 756us/step - loss: 0.0786 - accuracy: 0.9766 - val_loss: 0.0762 - val_accuracy: 0.9749\n",
      "Epoch 345/400\n",
      "333/367 [==========================>...] - ETA: 0s - loss: 0.0772 - accuracy: 0.9768\n",
      "Epoch 345: val_loss did not improve from 0.07528\n",
      "367/367 [==============================] - 0s 750us/step - loss: 0.0787 - accuracy: 0.9766 - val_loss: 0.0780 - val_accuracy: 0.9706\n",
      "Epoch 346/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.0786 - accuracy: 0.9772\n",
      "Epoch 346: val_loss did not improve from 0.07528\n",
      "367/367 [==============================] - 0s 728us/step - loss: 0.0784 - accuracy: 0.9770 - val_loss: 0.0764 - val_accuracy: 0.9742\n",
      "Epoch 347/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.0789 - accuracy: 0.9768\n",
      "Epoch 347: val_loss did not improve from 0.07528\n",
      "367/367 [==============================] - 0s 720us/step - loss: 0.0783 - accuracy: 0.9770 - val_loss: 0.0760 - val_accuracy: 0.9732\n",
      "Epoch 348/400\n",
      "343/367 [===========================>..] - ETA: 0s - loss: 0.0784 - accuracy: 0.9769\n",
      "Epoch 348: val_loss did not improve from 0.07528\n",
      "367/367 [==============================] - 0s 728us/step - loss: 0.0783 - accuracy: 0.9770 - val_loss: 0.0760 - val_accuracy: 0.9749\n",
      "Epoch 349/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.0781 - accuracy: 0.9776\n",
      "Epoch 349: val_loss did not improve from 0.07528\n",
      "367/367 [==============================] - 0s 721us/step - loss: 0.0782 - accuracy: 0.9775 - val_loss: 0.0764 - val_accuracy: 0.9744\n",
      "Epoch 350/400\n",
      "342/367 [==========================>...] - ETA: 0s - loss: 0.0773 - accuracy: 0.9773\n",
      "Epoch 350: val_loss did not improve from 0.07528\n",
      "367/367 [==============================] - 0s 731us/step - loss: 0.0779 - accuracy: 0.9770 - val_loss: 0.0758 - val_accuracy: 0.9771\n",
      "Epoch 351/400\n",
      "329/367 [=========================>....] - ETA: 0s - loss: 0.0796 - accuracy: 0.9759\n",
      "Epoch 351: val_loss improved from 0.07528 to 0.07470, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 808us/step - loss: 0.0781 - accuracy: 0.9767 - val_loss: 0.0747 - val_accuracy: 0.9759\n",
      "Epoch 352/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.0787 - accuracy: 0.9771\n",
      "Epoch 352: val_loss did not improve from 0.07470\n",
      "367/367 [==============================] - 0s 730us/step - loss: 0.0782 - accuracy: 0.9771 - val_loss: 0.0759 - val_accuracy: 0.9773\n",
      "Epoch 353/400\n",
      "338/367 [==========================>...] - ETA: 0s - loss: 0.0771 - accuracy: 0.9775\n",
      "Epoch 353: val_loss did not improve from 0.07470\n",
      "367/367 [==============================] - 0s 740us/step - loss: 0.0779 - accuracy: 0.9773 - val_loss: 0.0765 - val_accuracy: 0.9780\n",
      "Epoch 354/400\n",
      "343/367 [===========================>..] - ETA: 0s - loss: 0.0775 - accuracy: 0.9774\n",
      "Epoch 354: val_loss did not improve from 0.07470\n",
      "367/367 [==============================] - 0s 729us/step - loss: 0.0778 - accuracy: 0.9772 - val_loss: 0.0761 - val_accuracy: 0.9761\n",
      "Epoch 355/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0777 - accuracy: 0.9772\n",
      "Epoch 355: val_loss did not improve from 0.07470\n",
      "367/367 [==============================] - 0s 717us/step - loss: 0.0778 - accuracy: 0.9771 - val_loss: 0.0750 - val_accuracy: 0.9756\n",
      "Epoch 356/400\n",
      "361/367 [============================>.] - ETA: 0s - loss: 0.0777 - accuracy: 0.9771\n",
      "Epoch 356: val_loss did not improve from 0.07470\n",
      "367/367 [==============================] - 0s 701us/step - loss: 0.0777 - accuracy: 0.9770 - val_loss: 0.0751 - val_accuracy: 0.9754\n",
      "Epoch 357/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.0778 - accuracy: 0.9773\n",
      "Epoch 357: val_loss did not improve from 0.07470\n",
      "367/367 [==============================] - 0s 732us/step - loss: 0.0777 - accuracy: 0.9773 - val_loss: 0.0762 - val_accuracy: 0.9756\n",
      "Epoch 358/400\n",
      "337/367 [==========================>...] - ETA: 0s - loss: 0.0762 - accuracy: 0.9774\n",
      "Epoch 358: val_loss did not improve from 0.07470\n",
      "367/367 [==============================] - 0s 775us/step - loss: 0.0776 - accuracy: 0.9772 - val_loss: 0.0749 - val_accuracy: 0.9766\n",
      "Epoch 359/400\n",
      "344/367 [===========================>..] - ETA: 0s - loss: 0.0758 - accuracy: 0.9775\n",
      "Epoch 359: val_loss did not improve from 0.07470\n",
      "367/367 [==============================] - 0s 724us/step - loss: 0.0772 - accuracy: 0.9770 - val_loss: 0.0749 - val_accuracy: 0.9783\n",
      "Epoch 360/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.0767 - accuracy: 0.9780\n",
      "Epoch 360: val_loss did not improve from 0.07470\n",
      "367/367 [==============================] - 0s 717us/step - loss: 0.0775 - accuracy: 0.9777 - val_loss: 0.0766 - val_accuracy: 0.9759\n",
      "Epoch 361/400\n",
      "351/367 [===========================>..] - ETA: 0s - loss: 0.0773 - accuracy: 0.9773\n",
      "Epoch 361: val_loss improved from 0.07470 to 0.07461, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 758us/step - loss: 0.0770 - accuracy: 0.9773 - val_loss: 0.0746 - val_accuracy: 0.9759\n",
      "Epoch 362/400\n",
      "346/367 [===========================>..] - ETA: 0s - loss: 0.0760 - accuracy: 0.9770\n",
      "Epoch 362: val_loss did not improve from 0.07461\n",
      "367/367 [==============================] - 0s 729us/step - loss: 0.0772 - accuracy: 0.9767 - val_loss: 0.0751 - val_accuracy: 0.9766\n",
      "Epoch 363/400\n",
      "354/367 [===========================>..] - ETA: 0s - loss: 0.0772 - accuracy: 0.9773\n",
      "Epoch 363: val_loss did not improve from 0.07461\n",
      "367/367 [==============================] - 0s 713us/step - loss: 0.0771 - accuracy: 0.9774 - val_loss: 0.0750 - val_accuracy: 0.9761\n",
      "Epoch 364/400\n",
      "327/367 [=========================>....] - ETA: 0s - loss: 0.0765 - accuracy: 0.9775\n",
      "Epoch 364: val_loss did not improve from 0.07461\n",
      "367/367 [==============================] - 0s 764us/step - loss: 0.0770 - accuracy: 0.9775 - val_loss: 0.0755 - val_accuracy: 0.9751\n",
      "Epoch 365/400\n",
      "324/367 [=========================>....] - ETA: 0s - loss: 0.0776 - accuracy: 0.9773\n",
      "Epoch 365: val_loss improved from 0.07461 to 0.07458, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 784us/step - loss: 0.0772 - accuracy: 0.9774 - val_loss: 0.0746 - val_accuracy: 0.9761\n",
      "Epoch 366/400\n",
      "325/367 [=========================>....] - ETA: 0s - loss: 0.0779 - accuracy: 0.9766\n",
      "Epoch 366: val_loss did not improve from 0.07458\n",
      "367/367 [==============================] - 0s 766us/step - loss: 0.0770 - accuracy: 0.9770 - val_loss: 0.0751 - val_accuracy: 0.9747\n",
      "Epoch 367/400\n",
      "360/367 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 0.9767\n",
      "Epoch 367: val_loss improved from 0.07458 to 0.07430, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 733us/step - loss: 0.0770 - accuracy: 0.9768 - val_loss: 0.0743 - val_accuracy: 0.9759\n",
      "Epoch 368/400\n",
      "362/367 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.9772\n",
      "Epoch 368: val_loss did not improve from 0.07430\n",
      "367/367 [==============================] - 0s 701us/step - loss: 0.0769 - accuracy: 0.9773 - val_loss: 0.0745 - val_accuracy: 0.9771\n",
      "Epoch 369/400\n",
      "352/367 [===========================>..] - ETA: 0s - loss: 0.0774 - accuracy: 0.9778\n",
      "Epoch 369: val_loss did not improve from 0.07430\n",
      "367/367 [==============================] - 0s 714us/step - loss: 0.0767 - accuracy: 0.9781 - val_loss: 0.0761 - val_accuracy: 0.9732\n",
      "Epoch 370/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0768 - accuracy: 0.9766\n",
      "Epoch 370: val_loss did not improve from 0.07430\n",
      "367/367 [==============================] - 0s 723us/step - loss: 0.0767 - accuracy: 0.9767 - val_loss: 0.0756 - val_accuracy: 0.9730\n",
      "Epoch 371/400\n",
      "334/367 [==========================>...] - ETA: 0s - loss: 0.0758 - accuracy: 0.9778\n",
      "Epoch 371: val_loss improved from 0.07430 to 0.07388, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 794us/step - loss: 0.0766 - accuracy: 0.9776 - val_loss: 0.0739 - val_accuracy: 0.9778\n",
      "Epoch 372/400\n",
      "331/367 [==========================>...] - ETA: 0s - loss: 0.0757 - accuracy: 0.9782\n",
      "Epoch 372: val_loss did not improve from 0.07388\n",
      "367/367 [==============================] - 0s 761us/step - loss: 0.0766 - accuracy: 0.9779 - val_loss: 0.0748 - val_accuracy: 0.9761\n",
      "Epoch 373/400\n",
      "323/367 [=========================>....] - ETA: 0s - loss: 0.0759 - accuracy: 0.9781\n",
      "Epoch 373: val_loss did not improve from 0.07388\n",
      "367/367 [==============================] - 0s 765us/step - loss: 0.0764 - accuracy: 0.9778 - val_loss: 0.0741 - val_accuracy: 0.9771\n",
      "Epoch 374/400\n",
      "324/367 [=========================>....] - ETA: 0s - loss: 0.0776 - accuracy: 0.9775\n",
      "Epoch 374: val_loss improved from 0.07388 to 0.07373, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 807us/step - loss: 0.0766 - accuracy: 0.9778 - val_loss: 0.0737 - val_accuracy: 0.9771\n",
      "Epoch 375/400\n",
      "351/367 [===========================>..] - ETA: 0s - loss: 0.0760 - accuracy: 0.9773\n",
      "Epoch 375: val_loss did not improve from 0.07373\n",
      "367/367 [==============================] - 0s 716us/step - loss: 0.0763 - accuracy: 0.9773 - val_loss: 0.0741 - val_accuracy: 0.9759\n",
      "Epoch 376/400\n",
      "354/367 [===========================>..] - ETA: 0s - loss: 0.0766 - accuracy: 0.9771\n",
      "Epoch 376: val_loss did not improve from 0.07373\n",
      "367/367 [==============================] - 0s 711us/step - loss: 0.0764 - accuracy: 0.9773 - val_loss: 0.0747 - val_accuracy: 0.9761\n",
      "Epoch 377/400\n",
      "339/367 [==========================>...] - ETA: 0s - loss: 0.0757 - accuracy: 0.9780\n",
      "Epoch 377: val_loss did not improve from 0.07373\n",
      "367/367 [==============================] - 0s 742us/step - loss: 0.0763 - accuracy: 0.9778 - val_loss: 0.0752 - val_accuracy: 0.9739\n",
      "Epoch 378/400\n",
      "334/367 [==========================>...] - ETA: 0s - loss: 0.0749 - accuracy: 0.9781\n",
      "Epoch 378: val_loss did not improve from 0.07373\n",
      "367/367 [==============================] - 0s 743us/step - loss: 0.0761 - accuracy: 0.9775 - val_loss: 0.0741 - val_accuracy: 0.9778\n",
      "Epoch 379/400\n",
      "318/367 [========================>.....] - ETA: 0s - loss: 0.0762 - accuracy: 0.9776\n",
      "Epoch 379: val_loss improved from 0.07373 to 0.07349, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 865us/step - loss: 0.0763 - accuracy: 0.9777 - val_loss: 0.0735 - val_accuracy: 0.9766\n",
      "Epoch 380/400\n",
      "327/367 [=========================>....] - ETA: 0s - loss: 0.0767 - accuracy: 0.9775\n",
      "Epoch 380: val_loss did not improve from 0.07349\n",
      "367/367 [==============================] - 0s 770us/step - loss: 0.0762 - accuracy: 0.9777 - val_loss: 0.0737 - val_accuracy: 0.9771\n",
      "Epoch 381/400\n",
      "327/367 [=========================>....] - ETA: 0s - loss: 0.0758 - accuracy: 0.9776\n",
      "Epoch 381: val_loss did not improve from 0.07349\n",
      "367/367 [==============================] - 0s 763us/step - loss: 0.0761 - accuracy: 0.9776 - val_loss: 0.0736 - val_accuracy: 0.9771\n",
      "Epoch 382/400\n",
      "322/367 [=========================>....] - ETA: 0s - loss: 0.0764 - accuracy: 0.9779\n",
      "Epoch 382: val_loss improved from 0.07349 to 0.07309, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 817us/step - loss: 0.0759 - accuracy: 0.9780 - val_loss: 0.0731 - val_accuracy: 0.9766\n",
      "Epoch 383/400\n",
      "326/367 [=========================>....] - ETA: 0s - loss: 0.0767 - accuracy: 0.9771\n",
      "Epoch 383: val_loss improved from 0.07309 to 0.07308, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 791us/step - loss: 0.0759 - accuracy: 0.9775 - val_loss: 0.0731 - val_accuracy: 0.9768\n",
      "Epoch 384/400\n",
      "332/367 [==========================>...] - ETA: 0s - loss: 0.0749 - accuracy: 0.9783\n",
      "Epoch 384: val_loss did not improve from 0.07308\n",
      "367/367 [==============================] - 0s 775us/step - loss: 0.0757 - accuracy: 0.9778 - val_loss: 0.0750 - val_accuracy: 0.9730\n",
      "Epoch 385/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.0764 - accuracy: 0.9774\n",
      "Epoch 385: val_loss did not improve from 0.07308\n",
      "367/367 [==============================] - 0s 757us/step - loss: 0.0760 - accuracy: 0.9776 - val_loss: 0.0738 - val_accuracy: 0.9759\n",
      "Epoch 386/400\n",
      "330/367 [=========================>....] - ETA: 0s - loss: 0.0759 - accuracy: 0.9779\n",
      "Epoch 386: val_loss did not improve from 0.07308\n",
      "367/367 [==============================] - 0s 747us/step - loss: 0.0756 - accuracy: 0.9779 - val_loss: 0.0735 - val_accuracy: 0.9778\n",
      "Epoch 387/400\n",
      "349/367 [===========================>..] - ETA: 0s - loss: 0.0753 - accuracy: 0.9775\n",
      "Epoch 387: val_loss did not improve from 0.07308\n",
      "367/367 [==============================] - 0s 718us/step - loss: 0.0756 - accuracy: 0.9774 - val_loss: 0.0748 - val_accuracy: 0.9754\n",
      "Epoch 388/400\n",
      "345/367 [===========================>..] - ETA: 0s - loss: 0.0764 - accuracy: 0.9775\n",
      "Epoch 388: val_loss did not improve from 0.07308\n",
      "367/367 [==============================] - 0s 732us/step - loss: 0.0754 - accuracy: 0.9779 - val_loss: 0.0755 - val_accuracy: 0.9710\n",
      "Epoch 389/400\n",
      "347/367 [===========================>..] - ETA: 0s - loss: 0.0756 - accuracy: 0.9782\n",
      "Epoch 389: val_loss improved from 0.07308 to 0.07259, saving model to ENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "367/367 [==============================] - 0s 756us/step - loss: 0.0755 - accuracy: 0.9783 - val_loss: 0.0726 - val_accuracy: 0.9776\n",
      "Epoch 390/400\n",
      "335/367 [==========================>...] - ETA: 0s - loss: 0.0768 - accuracy: 0.9772\n",
      "Epoch 390: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 765us/step - loss: 0.0755 - accuracy: 0.9779 - val_loss: 0.0728 - val_accuracy: 0.9766\n",
      "Epoch 391/400\n",
      "312/367 [========================>.....] - ETA: 0s - loss: 0.0757 - accuracy: 0.9778\n",
      "Epoch 391: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 793us/step - loss: 0.0756 - accuracy: 0.9776 - val_loss: 0.0733 - val_accuracy: 0.9771\n",
      "Epoch 392/400\n",
      "328/367 [=========================>....] - ETA: 0s - loss: 0.0762 - accuracy: 0.9778\n",
      "Epoch 392: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 760us/step - loss: 0.0753 - accuracy: 0.9782 - val_loss: 0.0731 - val_accuracy: 0.9761\n",
      "Epoch 393/400\n",
      "351/367 [===========================>..] - ETA: 0s - loss: 0.0754 - accuracy: 0.9781\n",
      "Epoch 393: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 721us/step - loss: 0.0753 - accuracy: 0.9782 - val_loss: 0.0734 - val_accuracy: 0.9771\n",
      "Epoch 394/400\n",
      "318/367 [========================>.....] - ETA: 0s - loss: 0.0749 - accuracy: 0.9780\n",
      "Epoch 394: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 796us/step - loss: 0.0751 - accuracy: 0.9782 - val_loss: 0.0728 - val_accuracy: 0.9771\n",
      "Epoch 395/400\n",
      "291/367 [======================>.......] - ETA: 0s - loss: 0.0756 - accuracy: 0.9781\n",
      "Epoch 395: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 821us/step - loss: 0.0749 - accuracy: 0.9782 - val_loss: 0.0735 - val_accuracy: 0.9730\n",
      "Epoch 396/400\n",
      "357/367 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9782\n",
      "Epoch 396: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 867us/step - loss: 0.0752 - accuracy: 0.9780 - val_loss: 0.0749 - val_accuracy: 0.9708\n",
      "Epoch 397/400\n",
      "327/367 [=========================>....] - ETA: 0s - loss: 0.0751 - accuracy: 0.9778\n",
      "Epoch 397: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 775us/step - loss: 0.0750 - accuracy: 0.9781 - val_loss: 0.0730 - val_accuracy: 0.9761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/400\n",
      "319/367 [=========================>....] - ETA: 0s - loss: 0.0743 - accuracy: 0.9784\n",
      "Epoch 398: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 789us/step - loss: 0.0752 - accuracy: 0.9776 - val_loss: 0.0752 - val_accuracy: 0.9739\n",
      "Epoch 399/400\n",
      "306/367 [========================>.....] - ETA: 0s - loss: 0.0752 - accuracy: 0.9787\n",
      "Epoch 399: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 820us/step - loss: 0.0748 - accuracy: 0.9783 - val_loss: 0.0727 - val_accuracy: 0.9773\n",
      "Epoch 400/400\n",
      "350/367 [===========================>..] - ETA: 0s - loss: 0.0749 - accuracy: 0.9772\n",
      "Epoch 400: val_loss did not improve from 0.07259\n",
      "367/367 [==============================] - 0s 887us/step - loss: 0.0747 - accuracy: 0.9773 - val_loss: 0.0742 - val_accuracy: 0.9749\n",
      "name weight ENO3//model/trained_weights_Hn_7nonsmoothdata.mat\n",
      "153/153 [==============================] - 0s 525us/step\n",
      "here\n",
      "Accuracy  : 0.9757948717948718\n",
      "Precision : 0.9763762740111169\n",
      "f1Score : 0.9757979028365319\n",
      "[[1791    3    0]\n",
      " [  57 1511    2]\n",
      " [  25   31 1455]]\n",
      "train history is strored in ENO3/History/history-Hn_7nonsmoothdata.dat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/MAAAH/CAYAAAAboY3xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAADBAElEQVR4nOzdd3xUVfrH8c+dkkkvlCSUQGhSBAFBMCpWiqIoVlSUYltRVjC6KooUGzYQXXHZVUF2hQUbrr8FkYBGZEFRMAgoIDW0hBpC6kxm7u+PkNGYUDPJzITv+/WKMGfuPfM8A3jnmXPuOYZpmiYiIiIiIiIiEjQs/g5ARERERERERE6NinkRERERERGRIKNiXkRERERERCTIqJgXERERERERCTIq5kVERERERESCjIp5ERERERERkSCjYl5EREREREQkyKiYFxEREREREQkyKuZFREREREREgoyKeREREREREZEgo2JeRI7pvffewzAMfvjhB3+HIiIicsZ66623MAyD7t27+zsUEQkgKuZFRERERALYzJkzSU5OZsWKFWzatMnf4YhIgFAxLyIiIiISoLZu3cqyZcuYNGkS9evXZ+bMmf4OqVL5+fn+DkHkjKNiXkSq5Mcff+Sqq64iOjqayMhIrrjiCr799ttyx7hcLsaPH0+rVq0IDQ2lbt26XHTRRaSlpXmPycrKYujQoTRu3BiHw0GDBg247rrr2LZtWw1nJCIiEjhmzpxJXFwcV199NTfddFOlxXxOTg4PP/wwycnJOBwOGjduzKBBg9i/f7/3mKKiIsaNG8dZZ51FaGgoDRo04IYbbmDz5s0ApKenYxgG6enp5fretm0bhmHw3nvveduGDBlCZGQkmzdvpm/fvkRFRTFw4EAAvvnmG26++WaaNGmCw+EgKSmJhx9+mMLCwgpxr1+/nltuuYX69esTFhZG69ateeqppwD46quvMAyDuXPnVjhv1qxZGIbB8uXLT/n9FKlNbP4OQESC17p16+jRowfR0dE89thj2O12/v73v3PppZfy9ddfe+/tGzduHBMmTOCee+6hW7du5Obm8sMPP7Bq1Sp69eoFwI033si6dev485//THJyMnv37iUtLY3MzEySk5P9mKWIiIj/zJw5kxtuuIGQkBBuu+02/va3v/H9999z3nnnAZCXl0ePHj345ZdfuOuuuzj33HPZv38/n332GTt37qRevXq43W6uueYaFi9ezK233sqIESM4cuQIaWlprF27lhYtWpxyXCUlJfTp04eLLrqIV199lfDwcAA+/PBDCgoKGDZsGHXr1mXFihX89a9/ZefOnXz44Yfe83/66Sd69OiB3W7nvvvuIzk5mc2bN/N///d/PP/881x66aUkJSUxc+ZMrr/++grvSYsWLUhJSanCOytSC5giIscwffp0EzC///77Sp/v37+/GRISYm7evNnbtnv3bjMqKsq8+OKLvW0dO3Y0r7766mO+zqFDh0zAfOWVV3wXvIiISJD74YcfTMBMS0szTdM0PR6P2bhxY3PEiBHeY8aMGWMC5ieffFLhfI/HY5qmaU6bNs0EzEmTJh3zmK+++soEzK+++qrc81u3bjUBc/r06d62wYMHm4D5xBNPVOivoKCgQtuECRNMwzDM7du3e9suvvhiMyoqqlzb7+MxTdMcNWqU6XA4zJycHG/b3r17TZvNZo4dO7bC64icaTTNXkROi9vtZuHChfTv35/mzZt72xs0aMDtt9/O0qVLyc3NBSA2NpZ169bx66+/VtpXWFgYISEhpKenc+jQoRqJX0REJNDNnDmThIQELrvsMgAMw2DAgAHMnj0bt9sNwMcff0zHjh0rjF6XHV92TL169fjzn/98zGNOx7Bhwyq0hYWFeX+fn5/P/v37ueCCCzBNkx9//BGAffv2sWTJEu666y6aNGlyzHgGDRpEcXExH330kbdtzpw5lJSUcMcdd5x23CK1hYp5ETkt+/bto6CggNatW1d4rm3btng8Hnbs2AHAM888Q05ODmeddRYdOnTgL3/5Cz/99JP3eIfDwUsvvcTnn39OQkICF198MS+//DJZWVk1lo+IiEggcbvdzJ49m8suu4ytW7eyadMmNm3aRPfu3cnOzmbx4sUAbN68mfbt2x+3r82bN9O6dWtsNt/dYWuz2WjcuHGF9szMTIYMGUKdOnWIjIykfv36XHLJJQAcPnwYgC1btgCcMO42bdpw3nnnlVsnYObMmZx//vm0bNnSV6mIBC0V8yJS7S6++GI2b97MtGnTaN++Pe+88w7nnnsu77zzjveYkSNHsnHjRiZMmEBoaChPP/00bdu29X6LLyIicib58ssv2bNnD7Nnz6ZVq1ben1tuuQXA56vaH2uEvmwGwB85HA4sFkuFY3v16sW8efN4/PHH+fTTT0lLS/MunufxeE45rkGDBvH111+zc+dONm/ezLfffqtReZGjtACeiJyW+vXrEx4ezoYNGyo8t379eiwWC0lJSd62OnXqMHToUIYOHUpeXh4XX3wx48aN45577vEe06JFCx555BEeeeQRfv31Vzp16sTEiRN5//33ayQnERGRQDFz5kzi4+OZMmVKhec++eQT5s6dy9SpU2nRogVr1649bl8tWrTgu+++w+VyYbfbKz0mLi4OKF0Z//e2b99+0jGvWbOGjRs3MmPGDAYNGuRt//3uNYD39rwTxQ1w6623kpqayr///W8KCwux2+0MGDDgpGMSqc00Mi8ip8VqtdK7d2/+85//lNs+Ljs7m1mzZnHRRRcRHR0NwIEDB8qdGxkZScuWLSkuLgagoKCAoqKicse0aNGCqKgo7zEiIiJnisLCQj755BOuueYabrrppgo/w4cP58iRI3z22WfceOONrF69utIt3EzTBEp3jNm/fz9vvvnmMY9p2rQpVquVJUuWlHv+rbfeOum4rVZruT7Lfv/666+XO65+/fpcfPHFTJs2jczMzErjKVOvXj2uuuoq3n//fWbOnMmVV15JvXr1TjomkdpMI/MickLTpk1jwYIFFdrHjRtHWloaF110EQ888AA2m42///3vFBcX8/LLL3uPa9euHZdeeildunShTp06/PDDD3z00UcMHz4cgI0bN3LFFVdwyy230K5dO2w2G3PnziU7O5tbb721xvIUEREJBJ999hlHjhzh2muvrfT5888/n/r16zNz5kxmzZrFRx99xM0338xdd91Fly5dOHjwIJ999hlTp06lY8eODBo0iH/+85+kpqayYsUKevToQX5+PosWLeKBBx7guuuuIyYmhptvvpm//vWvGIZBixYt+O9//8vevXtPOu42bdrQokULHn30UXbt2kV0dDQff/xxpYvbvvHGG1x00UWce+653HfffTRr1oxt27Yxb948MjIyyh07aNAgbrrpJgCeffbZk38jRWo7fy6lLyKBrWxrumP97Nixw1y1apXZp08fMzIy0gwPDzcvu+wyc9myZeX6ee6558xu3bqZsbGxZlhYmNmmTRvz+eefN51Op2maprl//37zwQcfNNu0aWNGRESYMTExZvfu3c0PPvjAH2mLiIj4Vb9+/czQ0FAzPz//mMcMGTLEtNvt5v79+80DBw6Yw4cPNxs1amSGhISYjRs3NgcPHmzu37/fe3xBQYH51FNPmc2aNTPtdruZmJho3nTTTeW2l923b5954403muHh4WZcXJz5pz/9yVy7dm2lW9NFRERUGtfPP/9s9uzZ04yMjDTr1atn3nvvvebq1asr9GGaprl27Vrz+uuvN2NjY83Q0FCzdevW5tNPP12hz+LiYjMuLs6MiYkxCwsLT/JdFKn9DNP8w1wWERERERGRAFFSUkLDhg3p168f7777rr/DEQkYumdeREREREQC1qeffsq+ffvKLaonIqCReRERERERCTjfffcdP/30E88++yz16tVj1apV/g5JJKBoZF5ERERERALO3/72N4YNG0Z8fDz//Oc//R2OSMDRyLyIiIiIiIhIkNHIvIiIiIiIiEiQUTEvIiIiIiIiEmRs/g6gpnk8Hnbv3k1UVBSGYfg7HBEREZ8wTZMjR47QsGFDLJYz47t6XdNFRKQ2Otlr+hlXzO/evZukpCR/hyEiIlItduzYQePGjf0dRo3QNV1ERGqzE13Tz7hiPioqCih9Y6Kjo6vcn8vlYuHChfTu3Ru73V7l/vxFeQSW2pIH1J5clEdgUR4V5ebmkpSU5L3OnQl0Ta+c8ggsyiOw1JY8oPbkojwqOtlr+hlXzJdNw4uOjvbZhT88PJzo6Oig/8unPAJHbckDak8uyiOwKI9jO5Omm+uaXjnlEViUR2CpLXlA7clFeRzbia7pZ8ZNdSIiIiIiIiK1iIp5ERERERERkSCjYl5EREREREQkyJxx98yLiH+UlJTgdrv9HcZpc7lc2Gw2ioqKlEcAOBPzsFqt2Gy2M+qeeBERETk2FfMiUq1cLhd16tRh69atQV2EmKZJYmIiO3bsUB4B4EzNIzw8nAYNGhASElID0YmIiEggUzEvItXG4/GQmZlJXFwcDRs2xOFwBG3h5fF4yMvLIzIyEosleO9QUh6B5WTzME0Tp9PJvn372Lp1K61atQrqvEVERKTqVMyLSLVxOp14PB7q169PdHR0UBcfHo8Hp9NJaGio8ggAZ2IeYWFh2O12tm/f7j1HREREzlzB+wlIRIJGsI7GiwSaYP7iQkRERHxLnwpEREREREREgoyKeREREREREZEgo2JeRKSGJCcnM3nyZL/34Q/jxo2jU6dO/g5DREREpNZQMS8i8geGYVT4sVqtxMXFYbVaGTdu3Gn1+/3333Pffff5NtgqSE9PxzAMcnJy/B1Ktfrpp5/o0aMHoaGhJCUl8fLLL5/wnMzMTK6++mrCw8OJj4/nL3/5CyUlJd7nhwwZUunfk7PPPrvS/l588UUMw2DkyJHetm3btpX7e/X7fj788MMq5y0iIiK1m4p5EZE/2LNnj/dn8uTJREdHs2vXLtavX8+uXbt49NFHvceaplmuyDue+vXrEx4eXl1hSyVyc3Pp3bs3TZs2ZeXKlbzyyiuMGzeOf/zjH8c8x+12c/XVV+N0Olm2bBkzZszgvffeY8yYMd5jXn/99XJ/T3bs2EGdOnW4+eabK/T3/fff8/e//51zzjmnXHtSUlK5v1d79uxh/PjxREZGctVVV/nuTaghS5YsoV+/fjRs2BDDMPj0009PeE56ejrnnnsuDoeDli1b8t5771V7nCIiIrWFinkRkT9ITEz0/sTExGAYBomJiSQkJLB+/XqioqL4/PPP6dKlCw6Hg6VLl7J582auu+46EhISiIyM5LzzzmPRokXl+v3jFHnDMHjnnXe4/vrrCQ8Pp1WrVnz22WenFOukSZPo0KEDERERJCUl8cADD5CXl+d9fvv27fTr14+4uDgiIiLo0KEDCxcuZNu2bVx22WUAxMXFYRgGQ4YMqdB/bm4uYWFhfP755+Xa586dS1RUFAUFBQA8/vjjnHXWWYSHh9O8eXOefvppXC7XMeO+9NJLy41SA/Tv379cDMXFxTz66KM0atSIiIgIunfvTnp6+im9PzNnzsTpdDJt2jTOPvtsbr31Vh566CEmTZp0zHMWLlzIzz//zPvvv0+nTp246qqrePbZZ5kyZQpOpxOAmJiYcn9PfvjhBw4dOsTQoUPL9ZWXl8fAgQN5++23iYuLK/ec1Wr1/r0q62fu3LnccsstREZGnlKegSA/P5+OHTsyZcqUkzp+69atXH311Vx22WVkZGQwcuRI7rnnHr744otqjlRERKR20D7zIlLjCp1uNu/LO/GBPtaifiRhIVaf9PXEE0/w6quv0rx5c+Li4tixYwd9+/bl+eefx+Fw8M9//pN+/fqxYcMGmjRpcsx+xo8fz8svv8wrr7zCX//6VwYOHMj27dupU6fOScVhsVh44403aNasGVu2bOGBBx7gscce46233gLgwQcfxOl0smTJEiIiIli7di1Wq5WkpCQ+/vhjbrzxRjZs2EB0dDRhYWEV+o+Ojuaaa65h1qxZ5UaLZ86cSf/+/b0zDaKionjvvfdo2LAha9as4d577yUqKorHHnvsVN7WcoYPH87PP//M7NmzadiwIXPnzuXKK69kzZo1tGjRAigtiKdPn17pFxEAy5cv5+KLLyYkJMTb1qdPH1566SUOHTpUocAuO6dDhw4kJCSUO2fYsGGsW7eOzp07Vzjn3XffpWfPnjRt2rRc+4MPPsjVV19Nz549ee65546b78qVK8nIyDjpYjjQXHXVVac0o2Dq1Kk0a9aMiRMnAtC2bVuWLl3Ka6+9Rp8+faorTBERkVpDxXwVfbVhH+9vstDX34GIBJHN+/K45q9La/x1//vni2jfKMYnfT3zzDP06tXL+7hOnTp07NjR+/jZZ59l7ty5fPbZZwwfPvyY/QwZMoTbbrsNgBdeeIE33niDFStWcOWVV55UHL8f3U5OTua5557j/vvv9xbzmZmZ3HjjjXTo0MF7TG5uLlar1fuFQXx8PLGxscd8jYEDB3LnnXdSUFBAeHg4ubm5zJs3j7lz53qPGT16dLk4Hn30UWbPnn3axXxmZibTp08nMzOThg0bAvDoo4+yYMECpk+f7i2MW7duTUzMsf9Ms7KyaNasWbm2siI9Kyur0mI+KyurXCH/x3P+aPfu3Xz++efMmjWrXPvs2bNZtWoV33///YnSBUq/EGjbti0XXHDBSR0f7JYvX07Pnj3LtfXp06fCjI3fKy4upri42Ps4NzcXAJfLddyZICerrA9f9OVPyiOwKI/AUlvygNqTi/I4dl8nomK+irYfLGD1AcPfYYgElRb1I/nvny/yy+v6SteuXcs9zsvLY9y4ccybN489e/ZQUlJCYWEhmZmZx+3n9/dRR0REEB0dzd69e086jkWLFjFhwgTWr19Pbm4uJSUlFBUVeQvvhx56iGHDhrFw4UJ69uzJ9ddfT3Jy8inl2rdvX+x2O5999hm33norH3/8MdHR0eUKsTlz5vDGG2+wefNm8vLyKCkpITo6+pRe5/fWrFmD2+3mrLPOKtdeXFxM3bp1vY9//vlnLBb/3jE2Y8YMYmNj6d+/v7dtx44djBgxgrS0NEJDQ0/YR2FhIbNmzeLpp5+uxkgDy7G+NMnNzaWwsLDSmSITJkxg/PjxFdoXLlzo0/Uo0tLSfNaXPymPwKI8AkttyQNqTy7K4zdltzGeiIr5KrIaBh7T31GIBJewEKvPRsj9JSIiotzjRx99lLS0NF599VVatmxJWFgYN910k/ce62Ox2+3lHhuGgcfjOakYtm3bxjXXXMOwYcN4/vnnqVOnDkuXLuXuu+/G6XQSHh7OPffcQ58+fZg3bx4LFy5kwoQJPPfcc+UW8TuRkJAQbrrpJmbNmsWtt97KrFmzGDBgADZb6SVk+fLlDBw4kPHjx9OnTx9iYmKYPXu2d/p0ZSwWC6ZZ/n+ev/8WOi8vD6vVysqVK7Fay98acSr3kycmJpKdnV2urexxYmLiMc9ZsWLFSZ1jmibTpk3jzjvvLDeVf+XKlezdu5dzzz3X2+Z2u1myZAlvvvkmxcXF5fL66KOPKCgoYNCgQSed25lo1KhRpKameh/n5uaSlJRE7969q/TlURmXy0VaWhq9evWq8G8zmCiPwKI8AkttyQNqTy7Ko6KymWcnomK+iiwWg5P72C0itdn//vc/hgwZwvXXXw+UFqPbtm2r1tdcuXIlHo+HiRMnekenP/jggwrHJSUlcf/993P//ffzxBNPMGPGDB599FFv8el2u0/4WgMHDqRXr16sW7eOL7/8stz938uWLaNp06Y89dRT3rbt27cft7/69euzZ88e72O3283atWu9i/J17twZt9vN3r176dGjR4XzT/YLj5SUFJ566ilcLpf3wpqWlkbr1q0rnWJfds7zzz/P3r17iY+P954THR1Nu3btyh379ddfs2nTJu6+++5y7VdccQVr1qwp1zZ06FDatGnD448/XuELiunTp3PttddSv379k8qrNjjWFy3HWr8BwOFw4HA4KrTb7XaffgD0dX/+ojwCi/IILLUlD6g9uSiP8n2cDK1mX0U2i4HH1DR7kTNdq1at+OSTT8jIyGD16tXcfvvtJ11wnq6WLVvicrn461//ypYtW/jXv/7F1KlTyx0zcuRIvvjiC7Zu3cqqVatIT0+ndevWADRt2hTDMPjvf//Lvn37yq2C/0cXX3wxiYmJDBw4kGbNmtG9e3fvc61atSIzM5PZs2ezefNm3njjjXL301fm8ssvZ968ecybN4/169czbNiwcvvdn3XWWQwcOJBBgwbxySefsHXrVlasWMGECROYN2+e97h27dod97Vuv/12QkJCuPvuu1m3bh1z5szh9ddfLze6O3fuXNq0aeN93Lt3b9q1a8edd97J6tWr+eKLLxg9ejQPPvhghULy3XffpXv37rRv375ce1RUFO3bty/3ExERQd26dSscu2XLFpYsWcI999xz3PestklJSWHx4sXl2tLS0khJSfFTRCIiIsFFxXwVWYzSQt6jufYiZ7RJkyYRFxfHBRdcQL9+/ejTp0+5KdbVoWPHjkyaNImXXnqJ9u3bM3PmTCZMmFDuGLfbzYMPPkjbtm258soradWqFa+++ioAjRo1Yvz48TzxxBMkJCQcd6E+wzC47bbbWL16NQMHDiz33LXXXsvDDz/M8OHD6dSpE8uWLTvhvd933XUXgwcPZtCgQVxyySU0b97cOypfZvr06QwaNIhHHnmE1q1b079/f77//vtyuwNs2LCBw4cPH/N1YmJiWLhwIVu3bqVLly488sgjjBkzhvvuu897zOHDh9mwYYP3sdVq5b///S9Wq5WUlBTuuOMOBg0axDPPPFOu78OHD/Pxxx9XGJU/Ve+//z6NGzemd+/eVerH3/Ly8sjIyCAjIwMo3XouIyPDu27EqFGjyt1GcP/997NlyxYee+wx1q9fz1tvvcUHH3zAww8/7I/wRUREgo95hjl8+LAJmIcPH/ZJf7O/22o2ffy/Zn5hkU/68xen02l++umnptPp9HcoVaI8AkthYaG5bt06Mzs723S73f4Op0rcbrd56NAh5REgztQ8CgsLzZ9//tksLCys8Jyvr2+n6quvvjKBCj+DBw82TdM0Bw8ebF5yySUVzunUqZMZEhJiNm/e3Jw+ffopvaavc64t/+9VHoFFeQSW2pKHadaeXJRHRSd7fdM981VkPXqfqkbmRUTkTHbppZdWWNTw9957771Kz/nxxx+rMSoREZHaS8V8FVmP3i5fomJeRERERETk1JkmFByA6AQw/rAe2b6NeOKaY7Edu3Q1TZOs3CISokLB9JBbXLq4r91qIcJRel6Ry43DYlKCBYPS26X35xUTFxGC22Nit1o4UlBEdHgouUUuNu/LIyYshEaxYew8VECR67e1kMIdVjwek8SYULYfKKBZvQhC/HADu4r5KrJajt4zf5zRCBERERERqWbFeeA4+e1LKzBNOLgF6jQvLShNs2JhWXZcUQ6EHd0VpSgXQqPLx1DJuUXOEkKLD4DNAa5CiEwAy7ErQJfbg9tjEmoF9m8sjcvmoDhnNyEFeykIT8JjQoGzhJUbswk3nETH1gNnHpEFmfwv244RXo8wh41Qu5Uwm4HFYmXnjm248/ZxQfMYthREEPXLbKJbXYDpKsKxaT7fJtxGq8IMNkanEBURTsz2hWyL6EhM/jb2xHSiXmISedt/xFGQRZE1Egseuud9ydyIm4nemY6lXgtWcA6XW1aRUrSE3PwClta/jcywduzKKaDEbeI2TYoP7mS0MY2c8GS6HE7HnpHFElsKi0N7c8CWQEjRAfq7F3Cx638s8pzH0pAedA/NZEtxFMs8Z9PYzGJn5DlcEPIrnQ8uYEJhfyLjEvh7/kiWe9oSSSFhhpNvbV3Zb9RlZUECM0NeYL2ZhAcLIbjYadanBCtTSq7jHGMLz9jf412zJ5Od/fk0ZAy7zTpk4WGjmURLYxcOw8XzroH8ZLYgxbKO3WZdnre9ywuWS+je/4HT/7t3mlTMV1HZAnhu7U8nIiIiImca04SSYrCH/tb2x6LaVQhb0nE3uwyL3cHh/VnE7lkK7W8sLWZdRbB1CcQ1peS/j2Jkr8G4Ygy7I9pRWPdsWsZH4vGY7M0rpk64HbvVSnZOLpGZX5FX5MJjdZDvglZpgylodS0HzhpATnw36oWUYG5dQp69DvEHfsBw5nGAGLr9PJPcrHfIC2/CIaeF+u4svku4nUbZX9J99z/JiTqLnIjmNNz7NWmxN2PENGZTTAoXHf4vdnc+jfZ9Q53C7WwPa8f3jQdz469PsCe0OS4jlKaF69hlTybetZNt1mR22pqwIvRCbi6YTYRzH6FGjvdtOUIEa2jBT54WZJgt2OZOYJD1c661LGeN7WycLie5ZjgXWn+hDoc5bEbwmjmAJ40ZGIabcNNKG7MReT+mcgkHMDH4u/sahlq/INwopgmQY0aww6xPfeMwdcnle09rbrX+XBrAKmhqGpiAdetbpX90pp1bdnyKDQ9dTAOLUTpgeUnZHy12tngSaWvZUeGvQkMjjRgzF3bAdfamNHJtZ63ZjPo2Dw9ufZAJMWO4xviJYnsMXXO+IIIjmB4IOfwDK60dWdfgFnpkzeDivOXePnNCElhc/04uO/AhvUu+50BhPL3Nw/zZUwyAJ9fAgkmRJYJ/1z3ArzQh1G7hkpBd5Ec1x2kNZ9ieD7B6SjAdBvmhiSRF1cNlj6LEcNCseBeOI5u4ipcJK97HgXrnce/+/+OGhruoc3A39RskU+Cx0y13Jc46bbDl7+FD8z02X/AS7T5/Ho9hBQwuMtex63ArfqBuFf9BnRoV81Vks5QV86rmRURERCRweTwmlqOfXU3TpMjlIdTipti0YrUYFO5ai3tDGkUegx3JNxG7ewm57hCWuM4mrnAb9h3fk//Gs2S2uYf5h5JILNrMrVmvYHUXsaDOHcQW7WJraDsGHXiNg/ZEvo/pQ4fDX5HvttLKs5Vssy7pjku5rPgrYo2DjPhgDY7YBG4u+pjzSlbiwSDTk8BGsyVXznuYxsCMkl7E2n6gjplDBKHkYeMBz2PcYC5mgC2dqKO5HTQj2WHWxVj/P5ps/JS6pgMbHhyGC4AjZhhF2Glh5PKluxPugnySjK+pbxTiMq3csHshANPNa6ifs4+2h1eTbu3E1Qf/CQdLi1i3aSGHKJZaOrAnpj8Dc9/lul+fItOMZ6OnGVHk84kxiO62TH6K60W8ayed81Zy2eEv2Wprzo6mN/DfkqYUO104QsNoaW6nafEGOuUu4X7nXLBCkT2OzQ1uoNGBNVjqxBHqymFj2DUcSriA8ze9xri8aeREn8WX7Z4mIX8Dzs3/w5nQnJCmrYnYtpAHt31Gfv1OrOw4inZRBUTnbKbNwe24wupTgJUumz/H3fFZXI268eO2fbT1/ErkuTezYesWwiOiiK8Ti+2Lv1DS9R5sBftwGg5CWlwM25ZCQjscW9JpmbkCs/1zGEndoTgXig5D/j5iZt8OPR6FBufQaN4j0PMVzu52L4anBGb04+kdz5TOVvC4oc3VEJME3e/DFdmYrM8/p2/fvtit4+HIHsjJhNBoYuu35QqLBVyvQEkxdcNiwVkA25dBTGMsm7+EpO6EhkQQ+s4VdHFugatehu5/IrzsL76rCA7vwPjiSSIv/guRSd3K/8PYnQHv9IQuQ6l7zWswL5W6P0yDlr2IveMjYo8eFgKw9xeY2oN2iwZDXDKW+m3g/GGw5yfi2/WBJT9U07/eyqmYr6Ky/yG6NcteRERERKrTkWzMTYvIb5hCxLpZYHXgWT2b7X1nkm3U5+Dyf9Jz11tkxPfng7DbSHDvJmrPMsJDHWw65Kadcx2x0ZH8Enk+Kw44uKv4fS62/MRfS66npWUX11v/R77pIBon1mWvE390FLkF0cSRC8AOT33O+f5xzjka0pd0IyLEoN+BaXgw6JH/BUs97Ykxoc/+GWx0nE1dy2H+k/Qs7Q5/w43755GV2IPMvCwmFUzBmldCsSWML5qkEu/aRVanh3BE12PG5nVctW8ag7f/l62xKWxMvIx4Rwl1ti9gds4YDEx+6vI8JS370PjHV4nfOJvdFzxDTrNryc/7mZisb8l3QVGzK4goOcyeiDZgtZNrHmTbqg1cdtllRISGUD/KQe6RPMydX2HUbcHQhLNxlniwWw1aGEZp4bhnNY4vn4MrJxDe4ByuLfvzWBoHi8bR5NqnaNplMADn//HPLP8ArHqPZl3vollYHF0r+3M1TcjZDllrCW1+CWc7oso9Xa/sN9ubw/s3EnvtBK5s2ROXy8X8+WeVFsF2O+TfCAufJuKSx+hSp5n3fAtg9z4aDYAVSPntEFrHJf324I6PvUViSFnbOTeX/ppwNvaUB38XXYPffjv8B6jTonS2RdtrwTAwAKx26PsKvNsb+jwPne4AW8hv57lcv/3eYoGYRqU/v2cPK/0BCAmHVj1Lfx/f5rdjHl4HedlQ76w/nBsK9VrBwA+pVMNO8MgGCK9T+mXD5U9D1hq4aGTFY+Pbwu2zYe79cMVYaH9DaXvzS8vnUUNUzFeR1Tsyr2peRERERI5yFf5WfFTG48F5aAdr86IoKCpiw859NCteT0xsXWLXzmBu3BDO2vg2PTwr2GNrTKa9OS3zV9HS3E6hGUOkcRiAItOB+c/+WIihl7GJn82mdN/+DyJt/+PsknV4sECeiQWTg1HN8RTnc1X+pwDkRzYgK/YK/rLnA4pC6rCmw3PknXUjTTI/IfH7l8i6chYOnMStn0PJ2Tey9vslNL3lBbbvzaSJZydGXjaXd7ytNJ/dP2IpOABpY+l+20zsMQ1hz2rOatwVDIPrAHgIgKYAO1bAJ/dB7+dwtOxJn99P0wdomwjF3WDtJzTreCvNbI7S9rz74Nu3oFVvzmmaUtrWYhKsv4L2Z98AVhulk8IvKdddWd3qcsVR9+cNNI4LKy2AgZjoKGjnLdEJsf3uPvaQcGiaAkPnVfwzPP8BiEnCaHfdsf+cI+pCj0eO/TyUFpBxyaU/x9P0Anhsa/lbGsq9Vj24/m/H76M61Wv12+//uNZAYofjx+4LYbGlP6cj4nfT48PrwD2Ljn1sy57w6K+Vr6dQw1TMV5EWwBMRERE5g5Q4MQ9u4UB4M2JtLmxHdkG9s9h2oIDM1V9Rd9dXFBzcybm5X5HeLJUvLD3I2prNP7Yv58bE/STt/D8W5jbhytC1XFG0iMZmLNHk04B4Whi7yDNDiTSKGLF7PiUWB0si+lDXc4BORSsItbtZG3YZ7Q9/xZedX8cdEk1oiJ2OGyYTGd4QS8OriOzwEJ6fp3D20knQczyW7veXxl2UQ52oxNJR4KyfYP+vRLS5mgh7GJQUE2oNoUNZcdJ6OFwxjESLtfTxuddjulxs3xbC2WGhxLU8Gzi7/PtSNnW59VW/jQInnXfs9zGpG4zIOP577YiCoyPeXpH1oefY8m0hEXDOLcfvqzrYHNDhppp9zeoshqtbMMf+RwFQyIOK+SqzHv2D1NZ0IiIiItXM4wFXfunK3us+LZ3marXB4V2l02uLj8B3U0tHTJuklB5rDSnd8iqmMRzYjPvn/yMvshkxzc6FmMaYv/wf+cveZlt8T2KadWLXtk3stjehrnM3PxmtabTjM1oUrmNjcSzbaUBvywrOKVrJz+4OtLLsooFxkEwzHkyDC4x9uLFiNdykuztyxeYJXMwr2CkhM78VCT9vp9hw0IsjUARfxNzCOYlhFFucNM9cTEmbewjdMA/PpU9g//lT7FdPpE/dFuXegliPGw5t4/Lft1/Rj6NrqdMSIHE0dL+/tPAtY08s/dUwoEHH0p8yZaPev1dWyItIwFIxX0Vlu0l4VMyLiI9s27aNZs2a8eOPP9KpUyd/h3NKLr30Ujp16sTkyZP9HYqIBKrDO2HXqtJpzb/fvutIVmlRnti+dEGtw3uon7sG48f98MM7pYtlFedC1loIj4OcTEoOZWKz2WHNR5iGgTusHlbnEYwN88ERjenMp8QRh71oP1uiutAgfwM2TyExlO5BfZgIIihir6c+bXd8g3WVye/uHOYSoAQr622tudyyiTjnHlyGjfdDbqJX1A6OhF3CF1HnkZS3BkdYBAVNziK31Y0k2vM5i/qYuT9i2bqUVVv30SnqAJZ6N+C4KLX0y4XiXPrEt/3txUwTm2HANa+Wviddh1T+/lms8IcCvwLDKF/Ii0itpGK+iqyG7pkXqW2ME0ydGjt2LOPGjTvtvufOnUv//v1P6/zTMW7cOD799FMyMjJq7DX94cMPP+Tpp59m27ZttGrVipdeeom+ffse95z09HRSU1NZt24dSUlJjB49miFDhnifT05OZvv27RXOe+CBB5gyZUq5NtM06du3LwsWLCj3Z7x69WpefPFFli5dyv79+0lOTub+++9nxIgRVc5ZpEa5S0qL7IiT3Hrp8E74cWbp1NpOd5ROmc7dBR8OgT0Z0PBczCNZlFz8BK4tSwlb/xGG6cHEwMDEDlwAsBlym/ai5OB+3Pn7cVsTqZ+zmX/bbqDvz2mYVgfv2e/l/KL/0T3/F3o7X6SVNZuulq3sd4fTIC+LrUZjehWsZZ31QjZ1foyz61tw7sygXt5GXB4Dd8qfsYUVcGD7L5zVohkRuZvxRDbAkrUaW9t+tI86OqrtKsLhcXHH0QXKEjg6Ev47pSPk9Uq/FKhzIZ5G3diRO58OfftiOXqPduniXn9Y4Kvs2hMg03dFJPCpmK8iLYAnUvvs2bPH+/s5c+YwZswYfvnlF44cOUJUVBTR0dHHOVv8YdmyZdx2221MmDCBa665hlmzZtG/f39WrVpF+/btKz1n69atXH311dx///3MnDmTxYsXc88999CgQQP69OkDwPfff4/b7faes3btWnr16sXNN99cob/JkydX+kXQypUriY+P5/333ycpKYlly5Zx3333YbVaeeCBB3z0DoichsIcOLyjdGGq4iOY30zCs+cnjFa9MZMvIn//TnYfLqJJSH5poe2IhA0LOHLhKDLPupOW+asx3SUUNb2UooM7yVm7kL2HDhNbuIPQomzq5G0ioigbi1mCJ+15coiiAftxY2EhF9J51y9kmvF0m/cQOWY0L5fcwQYziWZGFvvMGFzYMC02GptZzNxwBWDQOC6MSPLp0fgIeXXacyjmSTJ25NAiPpL9de9hHXsYEXYWB/Kc5BS4iA2x0LZJHLc0jsFh++O08XMrvCVNkstK8/ZYAJr8YQsreyhQi+77FZGgpmK+irzFvBbAE6k1EhMTvb+PiYnBMAwSExMJDw8nOjqaadOmMXHiRLZu3UpycjIPPfSQtyhzOp2kpqby8ccfc+jQIRISErj//vsZNWoUycnJAFx//fUANG3alG3btp0wHrfbzX333ceXX35JVlYWTZo04YEHHig3spuens5jjz3GunXrsNvtnH322cyaNYuvvvqK8ePHA7/NOJgyZQr3339/uddYuHAh1157LVlZWcTGxnrbR4wYwZo1a/jyyy85cOAAw4cPZ8mSJRw6dIgWLVrw5JNPcttttx0z9spmIsTGxjJ58mTvCPiOHTt45JFHWLhwIRaLhR49evD6669736+T8frrr3PllVfyl7/8BYBnn32WtLQ03nzzTaZOnVrpOVOnTqVZs2ZMnDgRgLZt27J06VJee+01bzFfv375aaovvvgiLVq04JJLyq+SnJGRwcSJE/nhhx9o0KBBuefuuuuuco+bN2/O8uXL+eSTT1TMS7UyTZOi/FyMrenkrv4/8vIL+aHZnyjM2kjikbU0KNhA+7xl/CfiRtoXrqSxZzcZnuZ02TQKu+EmGogwDY4QTriRD0A6Xbl0yTgSvp6EwyjdqmybJ4nmxm4SDTctTQv5hFFghBHBEcY3mIIloh79iv9LTNEu5odcwGEzgpCWF7PHbsVht7DPyCMsqg6D42OIcFjZsi+fnAInhcUu0r7N4IKLBnJznUgcNgttG5zoy9TWdDzBESIitYWK+SqyHP1w7PH4ORCRYOIsKF28qKbVO6t0i5kqmDlzJmPGjOHNN9+kc+fO/Pjjj9x7771EREQwePBg3njjDT777DM++OADmjRpwo4dO9ixYwdQOsobHx/P9OnTufLKK7FaT25xIY/HQ+PGjfnwww+pW7eud2S3QYMG3HLLLZSUlNC/f3/uvfde/v3vf+N0OlmxYgWGYTBgwADWrl3LggULWLRoER6Pp9LR4yuuuILY2Fg+/vhj7r77bqD0S4Q5c+bw/PPPA1BUVESXLl14/PHHiY6OZt68edx55520aNGCbt26VejzZLhcLvr06UNKSgrffPMNNpuN5557jiuvvJKffvqJkJAQ0tPTueyyy7xfnlRm+fLlpKamlmvr06cPn3766TFfe/ny5fTs2bPCOSNHjqz0eKfTyfvvv09qamq597CgoIDbb7+dKVOmlPsi6HgOHz5MnTp1TupYkWPyeMgvLORAIRTu20zm3oNE7F1F3b3fEnbIyXc/TuY8cw0Ow0WupwFhRjH9di3AYkAIpfshf2c9lysL/kuhNYrx9d/gnC4XkFmUg2ffenI9YdyR9SLRB9ezpOOrePL3s7bBTdTN/4JG+78hvelgIgt30yD7a7bXHwIdb6dl4wRigBi3EwoP8WJ0w6PBXgZAu5NIKz6qdOTb5XJh2fkjvdsleLcQExGR36iYryKbRuZFTt3+jfCPS058nK/d9zU07FSlLsaPH8/EiRO54YYbAGjWrBk///wzf//73xk8eDCZmZm0atWKiy66CMMwaNq0qffcslHe2NjYky76AOx2u3d0vew1ly9fzgcffMAtt9xCbm4uhw8f5pprrqFFi9JFkdq2/W1RpcjISGw2G4mJiXg8HnJzcyu8htVq5dZbb2XWrFneYn7x4sXk5ORw4403AtCoUSMeffRR7zl//vOf+eKLL/jggw9Ou5ifM2cOHo+Hd955x1sgT58+ndjYWNLT0+nduzfh4eG0bt36uB/ms7KySEhIKNeWkJBAVlbWKZ+Tm5tLYWEhYWHl94f+9NNPycnJKXdPPcDDDz/MBRdcwHXXHWef4d9ZtmwZc+bMYd68SvYsFjmOAmcJyzPWEr52FrE564jO24zhdrLB05Re1lW0PnrcT7QiCTfh0XH8mjSSvQ0uI7JhGzol2rEsnYT9yC6Ibws7f6D7gPcBCMVkgnf18ibAOaW/PXIeHNjExckXAXApAK2A4Ud/D3BPxWAtYcffY11ERKpMxXwVWXTPvMipq3dWaWHtj9etgvz8fDZv3szdd9/Nvffe620vKSkhJiYGgCFDhtCrVy9at27NlVdeyTXXXEPv3r2r9LpQOjV+2rRpZGZmUlhYiNPp9K50X6dOHYYMGUKfPn3o1asXPXv25JZbbqkw3ftEBg4cyPnnn8/u3btp2LAhM2fO5Oqrr/ZOu3e73bzwwgt88MEH7Nq1C6fTSXFxMeHhpz/bYfXq1WzatImoqKhy7UVFRWzevBmAbt26sX79+tN+DV959913ueqqq2jYsKG37bPPPuPLL7/kxx9/PKk+1q5dy3XXXcfYsWPp3bs3Hk3rkmPZ+QOeb6dSkJmBtWAvh6x12FAUxxXGKooIYY21HQVR7WntXEfPogy2pLxIwxYdcETVpW1cS+bPn0/fvn1p+scvwXqPO7U4ohJLf0REJOComK8irWYvchpCwqs8Qu4P+fml94y+/fbbdO/evdxzZVPmzz33XLZu3crnn3/OokWLuOWWW+jZsycfffTRab/u7NmzefTRR5k4cSIpKSlERUXxyiuv8N1333mPmT59Og899BALFixgzpw5jB49mrS0NM4///yTfp3zzjuPFi1aMHv2bIYNG8bcuXN57733vM+/8sorvP7660yePJkOHToQERHByJEjcTqdx+zTMAzMP8xccrlc3t/n5eXRpUsXZs6cWeHcP96vfjyJiYlkZ2eXa8vOzj7uDIhjnRMdHV1hVH779u0sWrSITz75pFz7l19+yebNm8utMwBw44030qNHD9LT071tP//8M1dccQX33Xcfo0ePPunc5MzidrvJ/fI1Yv73AttJ5OuSs8mzd+UyM4Nuju0c6PEadbtez3lhcaUnHN4Fh3fSvMnv/p/0u39jIiJSe6mYr6KyBfA8mmYvUuvFx8fTsGFDtmzZwsCBA495XHR0NAMGDGDAgAHcdNNNXHnllRw8eJA6depgt9vLrY5+Mv73v/9xwQUXlFssrWzU+vc6d+5M586dGTVqFCkpKcyaNYvzzz+fkJCQk37NgQMHMnPmTBo3bozFYuHqq68uF8d1113HHXfcAZTey79x40batTv2XbD169cvtzvAr7/+SkFBgffxueeey5w5c4iPj6/SLgEpKSksXry43P3uaWlppKSkHPec+fPnl2s71jnTp08nPj6+3PsB8MQTT3DPPeWnGHfo0IHXXnuNfv36edvWrVvH5ZdfzuDBg71rEIiUySlw8vFHM2m0J402xWtI9mTyd/e1ZHd9lJu7NStd9M00weMmwvqHj24xjY5ucyYiImcaFfNVpK3pRM4sY8eOZeTIkcTExHDllVdSXFzMDz/8wKFDh0hNTWXSpEk0aNCAzp07Y7FY+PDDD0lMTPSO3CYnJ7N48WIuvPBCHA4HcXFxJ3zNVq1a8c9//pMvvviCZs2a8a9//Yvvv/+eZs2aAaVbrP3jH//g2muvpWHDhmzYsIFff/2VQYMGeV9z69atZGRk0LBhwwoj5b83cOBAxo0bx/PPP89NN92Ew+EoF8dHH33EsmXLiIuLY9KkSWRnZx+3mL/88st58803SUlJwe128/jjj5e7933gwIG88sorXHfddTzzzDM0btyY7du388knn/DYY4/RuHFjVqxYwaBBg1i8eDGNGlVetIwYMYJLLrmEiRMncvXVVzN79mx++OEH/vGPf3iPGTVqFLt27eKf//wnAPfffz9vvvkmjz32GHfddRdffvklH3zwQYV72T0eD9OnT2fw4MHYbOUvm4mJiZWO/jdp0sT757N27Vouv/xy+vTpQ2pqqvc+fqvVSt26J7lft9Qqbo9Jxo4cFv2STUZmDl12vsejln+zx9aYraGtONB9Atd2uoIGMb+bIWIY8MdCXkREzmi6KlSRinmRM8s999xDZGQkr7zyCn/5y1+IiIigQ4cO3hHhqKgoXn75ZX799VesVivnnXce8+fPx2KxADBx4kRSU1N5++23adSo0UltTfenP/2JH3/8kQEDBmAYBrfddhsPPPAAn3/+OQDh4eGsX7+eGTNmcODAARo0aMCDDz7In/70J6B0yvcnn3zCZZddRk5OTqVb05Vp2bIl3bp1Y8WKFUyePLncc6NHj2bLli306dOH8PBw7rvvPvr378/hw4ePGfvEiRMZOnQoPXr0oGHDhrz++uusXLnS+3x4eDhLlizh8ccf54YbbuDIkSM0atSIK664wjtSX1BQwIYNG8pNz/+jCy64gFmzZjF69GiefPJJWrVqxaefflpuj/k9e/aQmZnpfdysWTPmzZvHww8/zOuvv07jxo155513vNvSlVm0aBGZmZkVtpg7WR999BH79u3j/fff5/333/e2N23alC1btpxWnxJEivMo/u4dtu3czdd1bmZdjo3Fv+ylqLiIe8K+ZnjUHs63LqSg64M06Ps8DSrZbUJERKQyKuar6Ggtr9XsRWqpIUOGMGTIkHILld1+++3cfvvtlR5/7733llsc74/69etXbvp1ZZKTk8uNnjscDqZPn8706dPLHTdhwgSgdAX2uXPnHrM/h8PhvWf/WKvZ/97v78X/vTp16hx3qzeg3D3iAA0bNuSLL74o15aTk1PucWJiIjNmzDhmn5deeulxZxOUufnmm7n55puP+fzv7///fd8nWryud+/eJ/X6Zf547Lhx4xg3blylx2oBvNrLc3g3U9M30mn1M3R1r6YRNnoYadhDzue50MXYo8Nw5GViWJtA4y6E9xlXOvouIiJyklTMV5FNI/MiIiLyO4X/+zuOtCf4k2liNUzSOk2mc5NY2v7fENqyDyITIL4dXDITEtufuEMREZFKqJivIm1NJyIiIhQdhu/fZVtOCfaV7/ALXUk6O4XWdW30umIolBTDwmgozoXrPoYm3U/cp4iIyHGomK8ibU0nIiJyBnPmw5qP8Hz1AuTtJZnSWyccN7xJvXN6/3aczQFtr4Vt30Dj8/wUrIiI1CYq5qvI4t2azs+BiIiISM3aux4+GIS5fyPpRjde8Izm3zFvUs9zkHrtr6h4/FUvQvEROLogpoiISFWomK8i3TMvcmKnsniYiByb/i352f5NMP9RyMmEqAaY2/9HYVRTbvG8Sp3kc/jXjR2oz2VQeAgs1ornO6JKf0RERHxAxXwVWTTNXuSYyvYTdzqdfo5EpHYoKCgAfvu3JTXINOGTe6DgIGbyRTiPHGBG7EgmZnWkTeP6TL3jXMJDbEBjiGns72hFROQMoGK+irz7zGu0RKQCq9VKdHQ0+/btIzQ0lMjISIwg3XrJ4/HgdDopKiry7hkfjJRHYDnZPEzTpKCggL179xIbG4vVWsmor1SvjQtg9484B37KA8siWfTLXiJCrEwdei4Xt6rv/TwgIiJSU1TMV1HZtdujkXmRSsXHx7Nx40YcDgf79+/3dzinzTRNCgsLCQsLC9ovJEB5BJpTzSM2NpbExMQaiEwq+Pkziuu2o/88K1sP7OeF6zvQo1U9kuqE+zsyERE5Q6mYryLDMLBgUqJiXqRShmFw5MgRLrjgAn+HUiUul4slS5Zw8cUXB/UUZ+URWE4lD7vdrhF5f8rdyZrieI64S/jwTxfQoXGMvyMSEZEznF+L+SVLlvDKK6+wcuVK9uzZw9y5c+nfv/9xz0lPTyc1NZV169aRlJTE6NGjGTJkSI3EeyyGAR5Nsxc5LqvVGtRFl9VqpaSkhNDQUOURAJSH1DQzdw/r89tw3fkNVciLiEhA8OuNhvn5+XTs2JEpU6ac1PFbt27l6quv5rLLLiMjI4ORI0dyzz338MUXX1RzpMdnMbQAnoiISK1lmpi5u9jqjKZrch1/RyMiIgL4eWT+qquu4qqrrjrp46dOnUqzZs2YOHEiAG3btmXp0qW89tpr9OnTp7rCPCGLoX3mRUREaq2iw1hcBWRTl3ObxPk7GhERESDI7plfvnw5PXv2LNfWp08fRo4cecxziouLKS4u9j7Ozc0FSu9TdLlcVY7J5XJhAYpdJT7pz1/KYg/mHEB5BKLakovyCCzK49h9STXI3Q2ANaYRMWG6HUJERAJDUBXzWVlZJCQklGtLSEggNzfXuxrwH02YMIHx48dXaF+4cCHh4b5ZgdZiWNmwcSPz8zf4pD9/SktL83cIPqE8Ak9tyUV5BBbl8ZuyPeilGhwt5h11k/wciIiIyG+Cqpg/HaNGjSI1NdX7ODc3l6SkJHr37k10dHSV+3e5XIz+4Uuat2hJ38tbVbk/f3G5XKSlpdGrV6+gXoRJeQSe2pKL8ggsyqOisplnUg1yd+HBILROQ39HIiIi4hVUxXxiYiLZ2dnl2rKzs4mOjq50VB7A4XDgcDgqtNvtdp99ALQc/W8wf6As48v3xZ+UR+CpLbkoj8CiPMr3IdXkyB4OEEtCbJS/IxEREfHy62r2pyolJYXFixeXa0tLSyMlJcVPEZUyDHBrazoREZFaqSRnJ7s9cSRGh/o7FBERES+/FvN5eXlkZGSQkZEBlG49l5GRQWZmJlA6RX7QoEHe4++//362bNnCY489xvr163nrrbf44IMPePjhh/0RvpfFAI+WsxcREamVnAd3kmXWoUGMinkREQkcfi3mf/jhBzp37kznzp0BSE1NpXPnzowZMwaAPXv2eAt7gGbNmjFv3jzS0tLo2LEjEydO5J133vHrtnTGmg+YbozTyLyIiEhtlbuLPWYdElTMi4hIAPHrPfOXXnop5nGK4Pfee6/Sc3788cdqjOrUGEU5tGY7n2lkXkREpFay5WeRZZ6rafYiIhJQguqe+YBk2LDixq1iXkREpPZx5hPiyiXHXp8IR1CtGywiIrWcivkqMi1WrHhwq5YXERGpfXL3AOCKaODnQERERMpTMV9VFhsWTDzuEn9HIiIiIr6WuwsAR53Gfg5ERESkPBXzVWUpnXJnut1+DkRERER8Lnc3AHUSm/o5EBERkfJ081dVWaylv5oamRcREaltnId2kGdGkpxYz9+hiIiIlKOR+aryjsyrmBcREalt8rK3kGXWpUX9CH+HIiIiUo6K+ao6WszjUTEvIiJS29h3rSDD04Lm9SP9HYqIiEg5Kuar6ug0e90zLyIiUsscySLqyGbWOjoSE2b3dzQiIiLlqJivKkP3zIuIiNRK25YCsK9ONz8HIiIiUpGK+aoqu2de0+xFRERql8xv2WlNIrJeQ39HIiIiUoGK+ao6WswbWgBPRESkdsndzXYznoaxof6OREREpAIV81Xl3ZpO98yLiIjUJmZeNjtd0TSMDfN3KCIiIhWomK8q72r2KuZFRERqE3duFnvNGBXzIiISkFTMV5W2phMREal9TBNL/l72mTE0UjEvIiIBSMV8FZlHp9kbWs1eRESk9ijKweJxss+M1ci8iIgEJBXzVaWReRERkdonby8AhSF1iXTY/ByMiIhIRSrmq0r3zIuIiNQ+edkAGFEJfg5ERESkcirmq6psmr1G5kVERGqPoyPzRKqYFxGRwKRivqrK9pnX1nQiIiK1R142RUYoIeFR/o5ERESkUirmq6psmr0WwBMREak98rI5ZIkjOtTu70hEREQqpWK+qoyjI/NujcyLiIjUGvkHOEQ00WEq5kVEJDCpmK8qbU0nIiJS+xQf5rAnTCPzIiISsFTMV5XumRcREal9inI55A4lKlTb0omISGBSMV9VZcW8tqYTERGpNTzFR0pH5jXNXkREApSK+aryTrNXMS8iIlJbmIWHOUI40RqZFxGRAKVivqqOjsxbdM+8iIhIrWEW53LE1Mi8iIgELhXzVaV75kVERGodS/ERjhCue+ZFRCRgqZivKqP0LdRq9iIicqabMmUKycnJhIaG0r17d1asWHHc4ydPnkzr1q0JCwsjKSmJhx9+mKKiohqK9jjcLizuIvLQavYiIhK4VMxXlWHgxopFI/MiInIGmzNnDqmpqYwdO5ZVq1bRsWNH+vTpw969eys9ftasWTzxxBOMHTuWX375hXfffZc5c+bw5JNP1nDklSjOBeCIGa5p9iIiErA0d8wH3FhUzIuIyBlt0qRJ3HvvvQwdOhSAqVOnMm/ePKZNm8YTTzxR4fhly5Zx4YUXcvvttwOQnJzMbbfdxnfffXfM1yguLqa4uNj7ODe3tOh2uVy4XK4q51DWR0n+IezAEcIJtZg+6bsmlcUbbHH/kfIILMoj8NSWXJTHsfs6ERXzPuAxrNqaTkREzlhOp5OVK1cyatQob5vFYqFnz54sX7680nMuuOAC3n//fVasWEG3bt3YsmUL8+fP58477zzm60yYMIHx48dXaF+4cCHh4eFVT+So775eyKWA0xLKggWf+6zfmpaWlubvEHxCeQQW5RF4aksuyuM3BQUFJ3Wcinkf8GDRAngiInLG2r9/P263m4SEhHLtCQkJrF+/vtJzbr/9dvbv389FF12EaZqUlJRw//33H3ea/ahRo0hNTfU+zs3NJSkpid69exMdHV3lPFwuF2lpaZzf+WzYAJawOPr27VvlfmtaWR69evXCbg/e2wSUR2BRHoGntuSiPCoqm3l2IirmfcBjWLU1nYiIyClIT0/nhRde4K233qJ79+5s2rSJESNG8Oyzz/L0009Xeo7D4cDhcFRot9vtPv0AaHOXjogYYTFB/cHS1++LvyiPwKI8Ak9tyUV5lO/jZKiY9wGP7pkXEZEzWL169bBarWRnZ5drz87OJjExsdJznn76ae68807uueceADp06EB+fj733XcfTz31FBaLH9foLT4CgD08xn8xiIiInIBWs/cBj2HFigePx/R3KCIiIjUuJCSELl26sHjxYm+bx+Nh8eLFpKSkVHpOQUFBhYLdarUCYJr+vZ4axUdwYScyItKvcYiIiByPRuZ9wIMFCx7cpokFw9/hiIiI1LjU1FQGDx5M165d6datG5MnTyY/P9+7uv2gQYNo1KgREyZMAKBfv35MmjSJzp07e6fZP/300/Tr189b1PtNcS75Rjix4cE/3VNERGovFfM+YBpWbLhxe0zsfv78ISIi4g8DBgxg3759jBkzhqysLDp16sSCBQu8i+JlZmaWG4kfPXo0hmEwevRodu3aRf369enXrx/PP/+8v1L4TXEuRwgnNjzE35GIiIgck4p5H/BQOs2+RNPsRUTkDDZ8+HCGDx9e6XPp6enlHttsNsaOHcvYsWNrILJTVJTLETOUOI3Mi4hIANM98z7gMSylI/NuFfMiIiJBr+AA+92RmmYvIiIBTcW8D5hYseLG5fH4OxQRERGpIveRfewnRtPsRUQkoKmY94HSkXkPbk2zFxERCXpmwX4OmNHEqZgXEZEApmLeB0yjdGRe98yLiIgEP0vBgaPFvKbZi4hI4FIx7wOmYcFmeHTPvIiISJAzzBLszhwOEE2MinkREQlgKuZ9oOye+RLdMy8iIhLUQkryADhgRhMbpmn2IiISuFTM+4B3NXtNsxcREQlqDlcuAAX2OoTY9DFJREQCl65SPlB6z7z2mRcREQl2jpLSYr4ktK6fIxERETk+FfM+YGpkXkREpFYIOVrMe8JVzIuISGBTMe8DpffMa2ReREQk2DlKcik2QsEe7u9QREREjkvFvA+UjcyXuLUAnoiISDBzlBwhzxqL3aqPSCIiEth0pfIB7TMvIiJSO4SU5JFnjVYxLyIiAU9XKl8o22dexbyIiEhQM0w3JVixWQ1/hyIiInJcKuZ9QSPzIiIitYSJxzSwWfQRSUREApuuVD5Qes+8B7dH98yLiIgEMwMTDwZ2jcyLiEiAUzHvA6bl6Mi8WyPzIiIiwcwwTdwY2HTPvIiIBDhdqXzBOzKvYl5ERCS4mXhMC3aLRuZFRCSwqZj3Bd0zLyIiUisYeI6OzKuYFxGRwKZi3gfK9pnXyLyIiEiQM48ugKdp9iIiEuB0pfIFw4oVj0bmRUREglzpAngQomJeREQCnK5UvmBYsBluStxazV5ERCSYGZi4TQOb7pkXEZEAp2LeB0zDopF5ERGR2sA8WsxrZF5ERAKcrlQ+YBpW3TMvIiJSC2ifeRERCRYq5n3ApHRrOo3Mi4iIBDvP0Wn2+ogkIiKBTVcqH/AYVqyGG7dH98yLiIgEM8M7zV4j8yIiEthUzPtA2dZ0GpkXEREJdqXFvKbZi4hIoPN7MT9lyhSSk5MJDQ2le/furFix4rjHT548mdatWxMWFkZSUhIPP/wwRUVFNRRt5UzDhhUPbreKeRERkWBmmCZu0DR7EREJeH69Us2ZM4fU1FTGjh3LqlWr6NixI3369GHv3r2VHj9r1iyeeOIJxo4dyy+//MK7777LnDlzePLJJ2s48vI8GpkXERGpFQw8eDQyLyIiQcCvxfykSZO49957GTp0KO3atWPq1KmEh4czbdq0So9ftmwZF154IbfffjvJycn07t2b22677YSj+dXNNKxHR+bdfo1DREREqsgsm2avkXkREQlsNn+9sNPpZOXKlYwaNcrbZrFY6NmzJ8uXL6/0nAsuuID333+fFStW0K1bN7Zs2cL8+fO58847j/k6xcXFFBcXex/n5uYC4HK5cLlcVc7D5XJhYgWgxFXskz79oSzuYI2/jPIIPLUlF+URWJTHsfuSqirdmk77zIuISKDzWzG/f/9+3G43CQkJ5doTEhJYv359pefcfvvt7N+/n4suugjTNCkpKeH+++8/7jT7CRMmMH78+ArtCxcuJDw8vGpJHNXIKL3gb9m8ifnzt/ukT39JS0vzdwg+oTwCT23JRXkEFuXxm4KCAh9EIpjaZ15ERIKD34r505Gens4LL7zAW2+9Rffu3dm0aRMjRozg2Wef5emnn670nFGjRpGamup9nJubS1JSEr179yY6OrrKMblcLtZ9UDrNv2lSI/r27VrlPv3B5XKRlpZGr169sNvt/g7ntCmPwFNbclEegUV5VFQ280yqxsTEgwWHFsATEZEA57divl69elitVrKzs8u1Z2dnk5iYWOk5Tz/9NHfeeSf33HMPAB06dCA/P5/77ruPp556CkslF16Hw4HD4ajQbrfbffYB0Dw6Mm+YnqD+UAm+fV/8SXkEntqSi/IILMqjfB9SdYZpYqJ95kVEJPD57WvnkJAQunTpwuLFi71tHo+HxYsXk5KSUuk5BQUFFQp2q7X0fnXT9N9K8h7jaAzuEr/FICIiIr6g1exFRCQ4+HWafWpqKoMHD6Zr165069aNyZMnk5+fz9ChQwEYNGgQjRo1YsKECQD069ePSZMm0blzZ+80+6effpp+/fp5i3p/MI8W83icfotBREREfKBsZF7T7EVEJMD5tZgfMGAA+/btY8yYMWRlZdGpUycWLFjgXRQvMzOz3Ej86NGjMQyD0aNHs2vXLurXr0+/fv14/vnn/ZUC8NvIvEcj8yIiIsHNLFvNXiPzIiIS2Py+AN7w4cMZPnx4pc+lp6eXe2yz2Rg7dixjx46tgchOXtnWdIZHxbyIiEhwK1vNXiPzIiIS2HSl8gGNzIuIiNQSpgcTCzaLRuZFRCSwqZj3Ae9q9m6XnyMRERGRqtLIvIiIBANdqXygbAE8U9PsRUREgpvpUTEvIiJBQVcqH/B4V7PXyLyIiEgwMzDxYNECeCIiEvBUzPvAb1vTuf0biIiIiFTN0a3p7NqaTkREApyuVD7gLeZ1z7yIiEiQO7rPvEbmRUQkwKmY94Gyafbamk5ERCS4GdpnXkREgoSKeR8wy95G3TMvIiIS5I4ugKdp9iIiEuB0pfIB0zsyr3vmRUREgpmBWbrPvEbmRUQkwKmY9wHvNHtT0+xFRESC2tFp9tqaTkREAp2uVD7w22r2KuZFRESCWenWdCrmRUQk8OlK5QO/jcxrmr2IiEhwK13N3mrRNHsREQlsKuZ9wDRK30ZDW9OJiIgENcM0wdDHIxERCXy6WvmAydFp9hqZFxERCWoGHixayV5ERIKArla+YBh4sGLVAngiIiJBzUAj8yIiEhx0tfIRj8WmBfBERESCnKbZi4hIsNDVykc8hkbmRUREgp8HQ8W8iIgEAV2tfMRj2LSavYiISJCzYGLonnkREQkCulr5iGlYsWiavYiISNDTyLyIiAQDXa18xGPRyLyIiEiwM/BoZF5ERIKCrlY+Yho2LKYL0zT9HYqIiIicJsM0MQyrv8MQERE5IRXzPmJabFjx4PaomBcREQlWBiYWi+HvMERERE5IxbyvGFZsuClRMS8iIhK0tM+8iIgEC12tfMS02LDhxun2+DsUEREROU0WPCrmRUQkKOhq5StHi/kSt0bmRUREglXpyLym2YuISOBTMe8jZSPzLo3Mi4iIBC0DE1Mj8yIiEgR0tfIVix0rHhXzIiIiQczARB+PREQkGOhq5SsWKzajBJem2YuIiAQtLYAnIiLBQlcrX7HaseGhRCPzIiIiwck0sWiavYiIBAldrXzEsNiwUaLV7EVE5Iw1ZcoUkpOTCQ0NpXv37qxYseK4x+fk5PDggw/SoEEDHA4HZ511FvPnz6+haCtTOrvOogXwREQkCNj8HUCtYbVjo1Cr2YuIyBlpzpw5pKamMnXqVLp3787kyZPp06cPGzZsID4+vsLxTqeTXr16ER8fz0cffUSjRo3Yvn07sbGxNR98GbP0C3mNzIuISDBQMe8jhsWq1exFROSMNWnSJO69916GDh0KwNSpU5k3bx7Tpk3jiSeeqHD8tGnTOHjwIMuWLcNutwOQnJxckyFXdLSY19Z0IiISDFTM+4hhtR8t5jUyLyIiZxan08nKlSsZNWqUt81isdCzZ0+WL19e6TmfffYZKSkpPPjgg/znP/+hfv363H777Tz++ONYrdZKzykuLqa4uNj7ODc3FwCXy4XL5apyHi5nMXbAxPBJf/5SFnsw5wDKI9Aoj8BTW3JRHsfu60RUzPuIYdU+8yIicmbav38/brebhISEcu0JCQmsX7++0nO2bNnCl19+ycCBA5k/fz6bNm3igQcewOVyMXbs2ErPmTBhAuPHj6/QvnDhQsLDw6uch9VTzDVA7pE8P9+77xtpaWn+DsEnlEdgUR6Bp7bkojx+U1BQcFLHqZj3EcNqx2a4KVIxLyIickIej4f4+Hj+8Y9/YLVa6dKlC7t27eKVV145ZjE/atQoUlNTvY9zc3NJSkqid+/eREdHVzkmV/5hWA0xMbH07du3yv35i8vlIi0tjV69enlvYQhGyiOwKI/AU1tyUR4Vlc08OxEV8z7y28i8ptmLiMiZpV69elitVrKzs8u1Z2dnk5iYWOk5DRo0wG63l5tS37ZtW7KysnA6nYSEhFQ4x+Fw4HA4KrTb7XbffAC0lS58Z1isQf2BsozP3hc/Ux6BRXkEntqSi/Io38fJ0HKtPmJYQ7Bqmr2IiJyBQkJC6NKlC4sXL/a2eTweFi9eTEpKSqXnXHjhhWzatAmP57fr5saNG2nQoEGlhXyNMI9+Ia/V7EVEJAjoauUjFqsNO25KPCrmRUTkzJOamsrbb7/NjBkz+OWXXxg2bBj5+fne1e0HDRpUboG8YcOGcfDgQUaMGMHGjRuZN28eL7zwAg8++KC/UtBq9iIiElQ0zd5HLFYbVjy4SjTNXkREzjwDBgxg3759jBkzhqysLDp16sSCBQu8i+JlZmZisfw2hpCUlMQXX3zBww8/zDnnnEOjRo0YMWIEjz/+uL9S8BbzhkbmRUQkCKiY9xHDasdOCS6NzIuIyBlq+PDhDB8+vNLn0tPTK7SlpKTw7bffVnNUp6BsZN6iYl5ERAKfrla+YrFhMzy4SlTMi4iIBCXvNHt9PBIRkcCnq5WvWOzY8FDi0TR7ERGRoKRiXkREgoiuVr5isWI3SnBqNXsREZHgdHQ1e90zLyIiwUBXK1+x2rHioUT7zIuISJBITk7mmWeeITMz09+hBAhtTSciIsFDVytfsVixa595EREJIiNHjuSTTz6hefPm9OrVi9mzZ1NcXOzvsPxH0+xFRCSI6GrlKxY7NkpwaWReRESCxMiRI8nIyGDFihW0bduWP//5zzRo0IDhw4ezatUqf4dX88q2prNon3kREQl8KuZ9xRpytJjXyLyIiASXc889lzfeeIPdu3czduxY3nnnHc477zw6derEtGnTMM0z5Itq7TMvIiJBRPvM+4hpcxBCCe6SEn+HIiIickpcLhdz585l+vTppKWlcf7553P33Xezc+dOnnzySRYtWsSsWbP8HWb10zR7EREJIirmfcUaAoC7xOnnQERERE7OqlWrmD59Ov/+97+xWCwMGjSI1157jTZt2niPuf766znvvPP8GGUN0si8iIgEERXzvmILLf21pMi/cYiIiJyk8847j169evG3v/2N/v37Y7fbKxzTrFkzbr31Vj9E5wemVrMXEZHgoWLeV2wOAMySM3gVYBERCSpbtmyhadOmxz0mIiKC6dOn11BEfqaReRERCSK6WvmKtbSYN9wq5kVEJDjs3buX7777rkL7d999xw8//OCHiPytdGTesOjjkYiIBD5drXzl6Mg8LhXzIiISHB588EF27NhRoX3Xrl08+OCDfojIz8oWwFMxLyIiQUBXK18pG5n3aAE8EREJDj///DPnnntuhfbOnTvz888/+yEiP/NOs9c+8yIiEvhUzPuIeXRk3tACeCIiEiQcDgfZ2dkV2vfs2YPNdgYuq6Ot6UREJIjoauUrNt0zLyIiwaV3796MGjWKw4cPe9tycnJ48skn6dWrlx8j85OjxbzFsPo5EBERkRM7A792rybeYl7T7EVEJDi8+uqrXHzxxTRt2pTOnTsDkJGRQUJCAv/617/8HF3NMzTNXkREgoiKeV85es+8VSPzIiISJBo1asRPP/3EzJkzWb16NWFhYQwdOpTbbrut0j3na72yfeYtGpkXEZHAp2LeV2xaAE9ERIJPREQE9913n7/DCAze1ew1Mi8iIoFPxbyv2DQyLyIiwennn38mMzMTp7P8F9LXXnutnyLyl9KRed0zLyIiweC0ivkdO3ZgGAaNGzcGYMWKFcyaNYt27dqdud/ul02z18i8iIgEiS1btnD99dezZs0aDMPAPDrNvOyecbfb7c/wap72mRcRkSByWler22+/na+++gqArKwsevXqxYoVK3jqqad45plnfBpg0DAMSgw7FhXzIiISJEaMGEGzZs3Yu3cv4eHhrFu3jiVLltC1a1fS09P9HV7N0wJ4IiISRE6rmF+7di3dunUD4IMPPqB9+/YsW7aMmTNn8t577/kyvqDitoRoZF5ERILG8uXLeeaZZ6hXrx4WiwWLxcJFF13EhAkTeOihh/wdXs0r25pOI/MiIhIETutq5XK5cDhKp5UvWrTIe09dmzZt2LNnj++iCzJuSwh2U8W8iIgEB7fbTVRUFAD16tVj9+7dADRt2pQNGzb4MzT/KJtmr3vmRUQkCJxWMX/22WczdepUvvnmG9LS0rjyyisB2L17N3Xr1j2lvqZMmUJycjKhoaF0796dFStWHPf4nJwcHnzwQRo0aIDD4eCss85i/vz5p5OGz3ksDo3Mi4hI0Gjfvj2rV68GoHv37rz88sv873//45lnnqF58+Z+js4PytYM0Mi8iIgEgdNaAO+ll17i+uuv55VXXmHw4MF07NgRgM8++8w7/f5kzJkzh9TUVKZOnUr37t2ZPHkyffr0YcOGDcTHx1c43ul00qtXL+Lj4/noo49o1KgR27dvJzY29nTS8DmPxY5VI/MiIhIkRo8eTX5+PgDPPPMM11xzDT169KBu3brMmTPHz9H5Qdk0e0PFvIiIBL7TKuYvvfRS9u/fT25uLnFxcd72++67j/Dw8JPuZ9KkSdx7770MHToUgKlTpzJv3jymTZvGE088UeH4adOmcfDgQZYtW4bdbgcgOTn5dFKoFh6rA5vHicdjYtEetSIiEuD69Onj/X3Lli1Zv349Bw8eJC4u7oxcBM70HF2936Jp9iIiEvhOq5gvLCzENE1vIb99+3bmzp1L27Zty30wOB6n08nKlSsZNWqUt81isdCzZ0+WL19e6TmfffYZKSkpPPjgg/znP/+hfv363H777Tz++ONYrZVfeIuLiyku/m3v99zcXKD0vn+Xy3VSsR5PWR8ulwuP1YEDF3mFxYSFBNcHgd/nEcyUR+CpLbkoj8CiPI7d16kcHxYWRkZGBu3bt/e216lTp8qxBCuPR6vZi4hI8DitYv66667jhhtu4P777ycnJ4fu3btjt9vZv38/kyZNYtiwYSfsY//+/bjdbhISEsq1JyQksH79+krP2bJlC19++SUDBw5k/vz5bNq0iQceeACXy8XYsWMrPWfChAmMHz++QvvChQtPaRbBiaSlpdG5yIXDcPHfz78gwu6zrmtUWlqav0PwCeUReGpLLsojsCiP3xQUFJzS8Xa7nSZNmpx5e8kfh3n0nnmLRuZFRCQInFYxv2rVKl577TUAPvroIxISEvjxxx/5+OOPGTNmzEkV86fD4/EQHx/PP/7xD6xWK126dGHXrl288sorxyzmR40aRWpqqvdxbm4uSUlJ9O7dm+jo6CrH5HK5SEtLo1evXhTt+hshBS7Ou/RyGsSEVrnvmvT7PMpuYQhGyiPw1JZclEdgUR4Vlc08OxVPPfUUTz75JP/617/O6BH5MmXT7A3dKiciIkHgtIr5goIC71Y2Cxcu5IYbbsBisXD++eezffv2k+qjXr16WK1WsrOzy7VnZ2eTmJhY6TkNGjTAbreXm1Lftm1bsrKycDqdhISEVDjH4XB4t9H7Pbvd7tMPgHa7nWK7AwdHKDGNoP1w6ev3xV+UR+CpLbkoj8CiPMr3carefPNNNm3aRMOGDWnatCkRERHlnl+1alWVYgo2pneavRbAExGRwHdaxXzLli359NNPuf766/niiy94+OGHAdi7d+9Jj3aHhITQpUsXFi9eTP/+/YHSkffFixczfPjwSs+58MILmTVrFh6PB8vRbWM2btxIgwYNKi3ka5phDyWEQxS5PP4ORURE5ITKrr9SynN0NXtD0+xFRCQInFYxP2bMGG6//XYefvhhLr/8clJSUoDSUfrOnTufdD+pqakMHjyYrl270q1bNyZPnkx+fr53dftBgwbRqFEjJkyYAMCwYcN48803GTFiBH/+85/59ddfeeGFF3jooYdOJw2fs9hCceCi0KX7D0VEJPAd6xa1M1XZNHuLFsATEZEgcFrF/E033cRFF13Enj17vHvMA1xxxRVcf/31J93PgAED2LdvH2PGjCErK4tOnTqxYMEC76J4mZmZ3hF4gKSkJO9MgHPOOYdGjRoxYsQIHn/88dNJw+csdgcOw0mRinkREZGgU7YAnkbmRUQkGJxWMQ+QmJhIYmIiO3fuBKBx48Z069btlPsZPnz4MafVp6enV2hLSUnh22+/PeXXqQmWkDBCKCGnRMW8iIgEPovFctxt2M60le49R/M1DBXzIiIS+E6rmPd4PDz33HNMnDiRvLw8AKKionjkkUd46qmnyo2mn0ms9tJ95nXPvIiIBIO5c+eWe+xyufjxxx+ZMWNGpdu61npH75m3WDXNXkREAt9pFfNPPfUU7777Li+++CIXXnghAEuXLmXcuHEUFRXx/PPP+zTIYGENCcOBk0LnmTWSISIiwem6666r0HbTTTdx9tlnM2fOHO6++24/ROU/mmYvIiLB5LSK+RkzZvDOO+9w7bXXetvK7mF/4IEHztxi3u4gxCihSNPsRUQkiJ1//vncd999/g6jxnm0AJ6IiASR05oPf/DgQdq0aVOhvU2bNhw8eLDKQQUrwxZKqKbZi4hIECssLOSNN96gUaNG/g6l5pWNzGufeRERCQKnNTLfsWNH3nzzTd54441y7W+++SbnnHOOTwILSrZQHIZLq9mLiEhQiIuLK7cAnmmaHDlyhPDwcN5//30/RuYf3q3prJpmLyIige+0ivmXX36Zq6++mkWLFnn3mF++fDk7duxg/vz5Pg0wqNjDCKOYIqfL35GIiIic0GuvvVaumLdYLNSvX5/u3bsTFxfnx8j8wzy6AJ5xhi7kKyIiweW0ivlLLrmEjRs3MmXKFNavXw/ADTfcwH333cdzzz1Hjx49fBpk0AiJAMBdXODnQERERE5syJAh/g4hoJieo6vZa5q9iIgEgdPeZ75hw4YVFrpbvXo17777Lv/4xz+qHFhQsocD4FExLyIiQWD69OlERkZy8803l2v/8MMPKSgoYPDgwX6KzD9MjwePaZyxW+yKiEhw0dXKl0KOFvPOPD8HIiIicmITJkygXr16Fdrj4+N54YUX/BCRf5mmBw8GFi1mLyIiQUDFvC+FRAJgOjUyLyIigS8zM5NmzZpVaG/atCmZmZl+iMi/TE9ZMa9qXkREAp+KeV86Os0eFfMiIhIE4uPj+emnnyq0r169mrp16/ohIv8yTQ8mBhYNzYuISBA4pXvmb7jhhuM+n5OTU5VYgt/RafaWknw/ByIiInJit912Gw899BBRUVFcfPHFAHz99deMGDGCW2+91c/R1TxvMa9aXkREgsApFfMxMTEnfH7QoEFVCiio2UtXszdcGpkXEZHA9+yzz7Jt2zauuOIKbLbSjwQej4dBgwadmffMezx4sGiavYiIBIVTKuanT59eXXHUDt6ReRXzIiIS+EJCQpgzZw7PPfccGRkZhIWF0aFDB5o2berv0Pzj6AJ4quVFRCQYnPbWdFIJe1kxX+jnQERERE5eq1ataNWqlb/D8Luy1eytquZFRCQIaAE8X7JYcRkObG4V8yIiEvhuvPFGXnrppQrtL7/8coW9588EpqfsnnkV8yIiEvhUzPtYiTUUm7vI32GIiIic0JIlS+jbt2+F9quuuoolS5b4ISI/M914sGiavYiIBAUV8z5WYgvDrpF5EREJAnl5eYSEhFRot9vt5Obm+iEi/zI9Zuk0ey1nLyIiQUDFvI95rOHY3YWYpunvUERERI6rQ4cOzJkzp0L77NmzadeunR8i8i8TTbMXEZHgoQXwfMxjDyeUIgpdbsJD9PaKiEjgevrpp7nhhhvYvHkzl19+OQCLFy9m1qxZfPTRR36Ozg+O3jOvWl5ERIKBqk1fs4cTbhSTV1yiYl5ERAJav379+PTTT3nhhRf46KOPCAsLo2PHjnz55ZfUqVPH3+HVOO9q9ppmLyIiQUDT7H0tJIJwiskvdvs7EhERkRO6+uqr+d///kd+fj5btmzhlltu4dFHH6Vjx47+Dq3mmR48WDTNXkREgoKKeR8zQiIIo5j84hJ/hyIiInJSlixZwuDBg2nYsCETJ07k8ssv59tvv/V3WDXO9JSOzKuWFxGRYKB54D5mdUQQYRSRp2JeREQCWFZWFu+99x7vvvsuubm53HLLLRQXF/Ppp5+ekYvfAWBqATwREQkeGpn3MWuoRuZFRCSw9evXj9atW/PTTz8xefJkdu/ezV//+ld/h+V3punBYxpYVcuLiEgQ0Mi8j9lCIwmnWCPzIiISsD7//HMeeughhg0bRqtWrfwdTuAwTTxYMDQyLyIiQUAj8z5mD40k3NACeCIiEriWLl3KkSNH6NKlC927d+fNN99k//79/g7L70zTgwmaZi8iIkFBxbyPGd7V7DUyLyIigen888/n7bffZs+ePfzpT39i9uzZNGzYEI/HQ1paGkeOHPF3iP5xdDV7qz4diYhIENDlytcckaUL4BU5/R2JiIjIcUVERHDXXXexdOlS1qxZwyOPPMKLL75IfHw81157rb/Dq3keExND0+xFRCQoqJj3NUcUAK7CM3RUQ0REglLr1q15+eWX2blzJ//+97/9HY5fmKYbDwYW1fIiIhIEVMz7miMaAHdRrp8DEREROXVWq5X+/fvz2Wef+TuUmnd0ATyrRuZFRCQIqJj3tZBIANwamRcREQkuR/eZ1zR7EREJBirmfe3oNHuPRuZFROQMM2XKFJKTkwkNDaV79+6sWLHipM6bPXs2hmHQv3//6g3wREyPptmLiEjQUDHva0eLeaNYI/MiInLmmDNnDqmpqYwdO5ZVq1bRsWNH+vTpw969e4973rZt23j00Ufp0aNHDUV6HN5iXtW8iIgEPpu/A6h1yop5Z56fAxEREak5kyZN4t5772Xo0KEATJ06lXnz5jFt2jSeeOKJSs9xu90MHDiQ8ePH880335CTk3Pc1yguLqa4uNj7ODe3dBacy+XC5XJVOQfT48bEwO0uweUK3oK+7L3wxXviT8ojsCiPwFNbclEex+7rRFTM+9rRYt7iUjEvIiJnBqfTycqVKxk1apS3zWKx0LNnT5YvX37M85555hni4+O5++67+eabb074OhMmTGD8+PEV2hcuXEh4ePjpBf87iYcOEopBWlpalfsKBMojsCiPwFJb8oDak4vy+E1BQcFJHadi3tesdkosDuwlKuZFROTMsH//ftxuNwkJCeXaExISWL9+faXnLF26lHfffZeMjIyTfp1Ro0aRmprqfZybm0tSUhK9e/cmOjr6tGL/ve8KN/Ld2nXc06sXdru9yv35i8vlIi0tjV7KIyAoj8BSW/KA2pOL8qiobObZiaiYrwYuWwS2onx/hyEiIhKQjhw5wp133snbb79NvXr1Tvo8h8OBw+Go0G63233yAfDXxjfwxuq2DPNRf/7mq/fF35RHYFEegae25KI8yvdxMlTMV4MSWwRhngJK3B5sVq0xKCIitVu9evWwWq1kZ2eXa8/OziYxMbHC8Zs3b2bbtm3069fP2+bxeACw2Wxs2LCBFi1aVG/QlfCYoLXvREQkWKjSrAYeexQRFJLvdPs7FBERkWoXEhJCly5dWLx4sbfN4/GwePFiUlJSKhzfpk0b1qxZQ0ZGhvfn2muv5bLLLiMjI4OkpKSaDN/L7TFRLS8iIsFCI/PVwHREEmkUkl9cQkxY8E8VEREROZHU1FQGDx5M165d6datG5MnTyY/P9+7uv2gQYNo1KgREyZMIDQ0lPbt25c7PzY2FqBCe00yTVN7zIuISNBQMV8dQiKJJIf84hJ/RyIiIlIjBgwYwL59+xgzZgxZWVl06tSJBQsWeBfFy8zMxGIJ7AmBHhONzIuISNBQMV8NjNBoIskiT8W8iIicQYYPH87w4cMrfS49Pf2457733nu+D+gUuT2m7pkXEZGgEdhfkQcpa1g0kUYB+cW6Z15ERCRYmKapD0YiIhI0dM2qBtawGCIp1Mi8iIhIENFq9iIiEkxUzFcDe1iUdwE8ERERCQ4eU6vZi4hI8FAxXw1sYTFEUkS+U8W8iIhIsPCYumdeRESCh4r56uCIIsxwUlBY6O9IRERE5CR5TH0wEhGR4KFrVnVwRALgLMj1cyAiIiJysjQyLyIiwUTFfHVwRAFQUnjEz4GIiIjIyfJ4tM+8iIgEDxXz1cERDYC7UCPzIiIiwcJjmlhUzYuISJBQMV8dQkqn2VOkkXkREZFgodXsRUQkmKiYrw5Hp9mbThXzIiIiwUL7zIuISDBRMV8djhbzhop5ERGRoOExTX0wEhGRoKFrVnU4Os3e6srzcyAiIiJysjQyLyIiwUTFfHWwWHBawrGpmBcREQkapu6ZFxGRIKJivpo4bRHYSgr8HYaIiIicJLdH+8yLiEjwUDFfTdz2SELceZim6e9QRERE5CR4TH0wEhGR4KFrVjXx2COJMAspdLn9HYqIiIicBNPUyLyIiAQPm78DqK1MRxSRRiFHikoID9HbLCIiEuie6tuazy3b/R2GiIjISdHIfDUxHFFEUkhuocvfoYiIiMhJCA+xEabv30VEJEiomK8mltDSkfncohJ/hyIiIiIiIiK1jIr5amINiyaSQo4UaWReREREREREfEvFfDUJiYghkiKNzIuIiIiIiIjPBUQxP2XKFJKTkwkNDaV79+6sWLHipM6bPXs2hmHQv3//6g3wNNjDYo4ugKeReREREREREfEtvxfzc+bMITU1lbFjx7Jq1So6duxInz592Lt373HP27ZtG48++ig9evSooUhPjeGILC3mtQCeiIiIiIiI+Jjfi/lJkyZx7733MnToUNq1a8fUqVMJDw9n2rRpxzzH7XYzcOBAxo8fT/PmzWsw2lPgiMaOm4LCfH9HIiIiIiIiIrWMXzdgcTqdrFy5klGjRnnbLBYLPXv2ZPny5cc875lnniE+Pp67776bb7755rivUVxcTHFxsfdxbm4uAC6XC5er6qPmZX38sS/DFoYNKDqS45PXqW7HyiPYKI/AU1tyUR6BRXkcuy8RERE5M/i1mN+/fz9ut5uEhIRy7QkJCaxfv77Sc5YuXcq7775LRkbGSb3GhAkTGD9+fIX2hQsXEh4efsoxH0taWlq5x/WO/MyFwK5tG5k/P8dnr1Pd/phHsFIegae25KI8Aovy+E1BQYEPIhEREZFg4ddi/lQdOXKEO++8k7fffpt69eqd1DmjRo0iNTXV+zg3N5ekpCR69+5NdHR0lWNyuVykpaXRq1cv7Hb7b0/saQibXqReTDh9+/at8utUt2PmEWSUR+CpLbkoj8CiPCoqm3kmIiIiZwa/FvP16tXDarWSnZ1drj07O5vExMQKx2/evJlt27bRr18/b5vH4wHAZrOxYcMGWrRoUe4ch8OBw+Go0JfdbvfpB8AK/UXUKf21OC+oPmj6+n3xF+UReGpLLsojsCiP8n2IiIjImcOvC+CFhITQpUsXFi9e7G3zeDwsXryYlJSUCse3adOGNWvWkJGR4f259tprueyyy8jIyCApKakmwz++kMjSX4uP+DcOERERERERqXX8Ps0+NTWVwYMH07VrV7p168bkyZPJz89n6NChAAwaNIhGjRoxYcIEQkNDad++fbnzY2NjASq0+50jCgCLU8W8iIiIiIiI+Jbfi/kBAwawb98+xowZQ1ZWFp06dWLBggXeRfEyMzOxWPy+g96ps4fhMawYrjx/RyIiIiIiIiK1jN+LeYDhw4czfPjwSp9LT08/7rnvvfee7wPyBcPAZYsgpDAfj8fEYjH8HZGIiIiIiIjUEkE45B083LYIIigkz1ni71BERERERESkFlExX408IVFEUsiRIhXzIiIiIiIi4jsq5quTo6yYd/k7EhEREREREalFVMxXI8MRRaRRSG6hRuZFRERERETEd1TMVyNrWLRG5kVERERERMTnVMxXI1tYNJFGke6ZFxEREREREZ9SMV+NrKFRRBkamRcRERERERHfUjFfjYzQaKKMQnI1Mi8iIiIiIiI+pGK+Oh1dzT5XI/MiIiIiIiLiQyrmq1NoDBEUkl9Y5O9IREREREREpBZRMV+dwuoA4M7P8W8cIiIiIiIiUquomK9O4aXFvFlwwM+BiIiIiIiISG2iYr46HR2ZtxQe9HMgIiIiIiIiUpuomK9OYXEA2Ipz/BuHiIiIiIiI1Coq5qtTWTHvzPFvHCIiIiIiIlKrqJivTrYQnNYIHK7D/o5EREREREREahEV89XM5Ygl0pNLfnGJv0MRERERERGRWkLFfDUzQ+OII4+9R4r9HYqIiIiIiIjUEirmq5klog4xRh7ZuUX+DkVERERERERqCRXz1cweWY84VMyLiIiIiIiI76iYr2b2yLrUteSxT9PsRURERERExEdUzFe3sDjqWPI1Mi8iIiIiIiI+o2K+uoXXJcbMJfuwinkRERERERHxDRXz1S26ISG4KDyc7e9IREREREREpJZQMV/dYpMAsOTu8nMgIiIiIiIiUluomK9uMaXFfEj+bkzT9HMwIiIiIiIiUhuomK9u4XVxW0Op796rFe1FRERERETEJ1TMVzfDwB3ViIbGfjbvy/d3NCIiIiIiIlILqJivAba4JjSyHGDL/jx/hyIiIiIiIiK1gIr5GmCJbUwz2yE279XIvIiIiIiIiFSdivmaEJNEQ/ZpZF5ERERERER8QsV8TajTnGhPDtl7tde8iIiIiIiIVJ2K+ZpQvzUAYYc3kV9c4udgREREREREJNipmK8J9c7CNCy0Mnbxy55cf0cjIiIiIiIiQU7FfE2wh0JcM9pYdrJ212F/RyMiIlItpkyZQnJyMqGhoXTv3p0VK1Yc89i3336bHj16EBcXR1xcHD179jzu8SIiIlKeivkaYtRvQ8fQbNbu1si8iIjUPnPmzCE1NZWxY8eyatUqOnbsSJ8+fdi7d2+lx6enp3Pbbbfx1VdfsXz5cpKSkujduze7du2q4chFRESCk4r5mhLfhhbs0Mi8iIjUSpMmTeLee+9l6NChtGvXjqlTpxIeHs60adMqPX7mzJk88MADdOrUiTZt2vDOO+/g8XhYvHhxDUcuIiISnGz+DuCMkdCeGNc+Du7dSX5xCREOvfUiIlI7OJ1OVq5cyahRo7xtFouFnj17snz58pPqo6CgAJfLRZ06dY55THFxMcXFxd7Hubmls91cLhcul+s0o/9NWR++6MuflEdgUR6BpbbkAbUnF+Vx7L5ORBVlTWncFYBz2MSqzEP0aFXfzwGJiIj4xv79+3G73SQkJJRrT0hIYP369SfVx+OPP07Dhg3p2bPnMY+ZMGEC48ePr9C+cOFCwsPDTy3o40hLS/NZX/6kPAKL8ggstSUPqD25KI/fFBQUnNRxKuZrSkwSZkQ8KcZWVmw9qGJeRETkqBdffJHZs2eTnp5OaGjoMY8bNWoUqamp3se5ubnee+2jo6OrHIfL5SItLY1evXpht9ur3J+/KI/AojwCS23JA2pPLsqjorKZZyeiYr6mGAZG465cmLmNMVsO+jsaERERn6lXrx5Wq5Xs7Oxy7dnZ2SQmJh733FdffZUXX3yRRYsWcc455xz3WIfDgcPhqNBut9t9+gHQ1/35i/IILMojsNSWPKD25KI8yvdxMrQAXk1q3JXmzg2s2XGAAmeJv6MRERHxiZCQELp06VJu8bqyxexSUlKOed7LL7/Ms88+y4IFC+jatWtNhCoiIlJrqJivSU0vIsSdz1mezXy75YC/oxEREfGZ1NRU3n77bWbMmMEvv/zCsGHDyM/PZ+jQoQAMGjSo3AJ5L730Ek8//TTTpk0jOTmZrKwssrKyyMvL81cKIiIiQUXT7GtSo3MxQyLpa9/I1xv2cXmbhBOfIyIiEgQGDBjAvn37GDNmDFlZWXTq1IkFCxZ4F8XLzMzEYvltDOFvf/sbTqeTm266qVw/Y8eOZdy4cTUZuoiISFBSMV+TrHaMphdwxZ713L1xH6ZpYhiGv6MSERHxieHDhzN8+PBKn0tPTy/3eNu2bdUfkIiISC2mafY1rfmlNCtcw74DB9mYramEIiIiIiIicupUzNe01n2xuou5KnQN89bs8Xc0IiIiIiIiEoRUzNe0Os2gQUfuiM5g/po9mKbp74hEREREREQkyKiY94d213FOwXfs3HuAVZmH/B2NiIiIiIiIBBkV8/7Q9jqsJQXcHLOefy7f7u9oREREREREJMiomPeHei0hoT2DY1czf80e9h0p9ndEIiIiIiIiEkRUzPtLu+tocfAb6ljymfN9pr+jERERERERkSCiYt5fugzBwGRC4te8/20mzhKPvyMSERERERGRIKFi3l8i46HbvVx66GOcuXv5NGOXvyMSERERERGRIKFi3p8uGIHFYmFCwpf8LX0zLrdG50VEREREROTEVMz7U0RdOP8BeuV9Rv6BXcxYts3fEYmIiIiIiEgQUDHvbykPYrE7mNzoK15f9Ct7jxT5OyIREREREREJcCrm/S0sFlL+TMqhz2hoOciLn6/3d0QiIiIiIiIS4FTMB4Lz78cIieDNpK/4ZNUuvtqw198RiYiIiIiISABTMR8IHFFw0Uha7vyYIU0P8thHP3Eo3+nvqERERERERCRAqZgPFOc/gJHYgdHFk7CWFPDk3DWYpunvqERERERERCQAqZgPFFY73PAOtvwsPkz+jM/XZvG3rzf7OyoREREREREJQCrmA0m9ltDneZK2fshLXY/w8oINLFib5e+oREREREREJMComA805w6BRl25Ze/rXHd2XUbO+ZHlmw/4OyoREREREREJIAFRzE+ZMoXk5GRCQ0Pp3r07K1asOOaxb7/9Nj169CAuLo64uDh69ux53OODjsUC/SZjHNjMxNgPOC+5DnfP+J4VWw/6OzIREREREREJEH4v5ufMmUNqaipjx45l1apVdOzYkT59+rB3b+Xbs6Wnp3Pbbbfx1VdfsXz5cpKSkujduze7du2q4cirUWIHuHICtpXv8m6XTDolxTJ0+gpWbldBLyIiIiIiIgFQzE+aNIl7772XoUOH0q5dO6ZOnUp4eDjTpk2r9PiZM2fywAMP0KlTJ9q0acM777yDx+Nh8eLFNRx5Net6F7S/iZB5DzE9ZR/tG8UweNr3rMo85O/IRERERERExM9s/nxxp9PJypUrGTVqlLfNYrHQs2dPli9fflJ9FBQU4HK5qFOnTqXPFxcXU1xc7H2cm5sLgMvlwuVyVSF6vP38/lef6jsJq6sIx0d38M9z7uAO960MencFM4Z04ZzGMT59qWrNowYpj8BTW3JRHoFFeRy7LxERETkz+LWY379/P263m4SEhHLtCQkJrF+//qT6ePzxx2nYsCE9e/as9PkJEyYwfvz4Cu0LFy4kPDz81IM+hrS0NJ/1VU7YTSQ3rkPHn/7JU4kuHrf14Y53vuXBdm6SIn3/ctWWRw1THoGntuSiPAKL8vhNQUGBDyIRERGRYOHXYr6qXnzxRWbPnk16ejqhoaGVHjNq1ChSU1O9j3Nzc7332UdHR1c5BpfLRVpaGr169cJut1e5v8pdg3uBjU4rp/F52CLujn6NtzeF8s+hXWnXoOo5QE3lUf2UR+CpLbkoj8CiPCoqm3kmIiIiZwa/FvP16tXDarWSnZ1drj07O5vExMTjnvvqq6/y4osvsmjRIs4555xjHudwOHA4HBXa7Xa7Tz8A+rq/Cq5+Fc7uj+Wju/h74qfcZL2boTNW8d8/X0TD2DCfvUy151FDlEfgqS25KI/AojzK9yEiIiJnDr8ugBcSEkKXLl3KLV5XtphdSkrKMc97+eWXefbZZ1mwYAFdu3atiVD9z2KF5pdA72cJ+eUTZl6cQ6jNwojZP+L2mP6OTkRERERERGqQ31ezT01N5e2332bGjBn88ssvDBs2jPz8fIYOHQrAoEGDyi2Q99JLL/H0008zbdo0kpOTycrKIisri7y8PH+lULM63gYtexG18BHe6J/M99sOMef7Hf6OSkRERERERGqQ34v5AQMG8OqrrzJmzBg6depERkYGCxYs8C6Kl5mZyZ49e7zH/+1vf8PpdHLTTTfRoEED78+rr77qrxRqlmHAtW+Aq5Cuv7zETV0a8/IX6zmY7/R3ZCIiIiIiIlJDAmIBvOHDhzN8+PBKn0tPTy/3eNu2bdUfUKCLbghXvQSf3s+Y665i4bpwXvp8PS/ddOy1A0RERERERKT28PvIvJymjrdC675EL/oLoy9PYM4PO/huywF/RyUiIiIiIiI1QMV8sDIMuGYyeEq4OWsyXZvG8cQnayhyuf0dmYiIiIiIiFQzFfPBLCoBrnwR4+e5TL7Iya6cQl5L2+jvqERERERERKSaqZgPdh1ugfptaLz6r4zs2Yq3v9nC6h05/o5KREREREREqpGK+WBnscClT8CmRfyp3jraNYzmLx+t5kiRy9+RiYiIiIiISDVRMV8btOsPba7BOj+Vydc0Zs/hIu5673sKnCX+jkxERERERESqQUBsTSdVVLYY3lvdafndaGYM/St3vruCu9/7gTdu60z9KIe/IxQREfEbt9uNy3XiGWsulwubzUZRURFud/AuKKs8AkttyMNut/s7BBGphIr52iKyPvR7A+YM5NzEc5g25B6GzVxF79e+Zvx17el3TgMMw/B3lCIiIjXGNE2ysrLIyck56eMTExPZsWNHUF8zlUdgqS15REVF+TsEEfkDFfO1Sdtr4IoxsPgZuvdvQtrDNzDmP+t46N8/Muf7TMZcczatE/U/YhEROTOUFfLx8fGEh4efsJDyeDzk5eURGRmJxRK8dyIqj8AS7HmYpklBQQHZ2dkq6EUCjIr52uaiVDi0Df7zAHVT1jGl/0hu6tKY8f+3jj6Tl9CifgQ3dmnMxa3q07ZBNFZL8H5DLCIicixut9tbyNetW/ekzvF4PDidTkJDQ4Oy6CqjPAJLbcgjLCwMj8dDfn4+brdb0+5FAoSK+dqm7P75uGT4+hX47h9c1nkgF9w/mq+2O1mwNos3Fv/Kyws2EB1qo3vzuqQ0r8t5TWPwmP4OXkRExDfK7pEPDw/3cyQitUN4eDgWi4WSEi2wLBIoVMzXRhYr9HgEugyFH6bB/97AsfELrrzjY668tTPFJW4yMnNYvuUAyzcf4MXP1+N0e4iwWZl/OIOOSbGc3SiG9g1jtHieiIgEtWC+R1kkkJT9WzJNjf6IBAoV87VZeB24+FHoeBvMugX+cRk064Gj+WV0b9Wb7j3PYmRPKHK5WbFlH+8v/J7DRS7+vmQLR4pKv3VNiHbQvmEMZzeKoXNSLBe2rEeILTiniImIiIiIiNQWKubPBDGNYMg8WPkebP4SFo2DL0ZBi8uhTnNCezxCSvP6HGrioW/f87DZbOw4WMja3YdZu+sw63bnMvPb7byx+FeiQ210TIrlnMYxdGgUS4fGMTSMCdXIh4iISIBKTk5m5MiRjBw50q99+MO4ceP49NNPycjI8HcoIiI+pyHWM0VYLFw0EgZ/Bo9vK93GDuDn/8CkttgmtuDCX1/ANvV8jO/foUmMlb6tY3jsyjbMuKsbP4z+//buOzyqKn/8+PtOn0xmUkiHUAKhSBMCYlhRkEhTBEUXhR+Cy4IoRUVdRQVhVxdXBRV1VQRx3VWwRv1KL6IikY70UCSEFnp6m3J+f4wZGJJARDSZ8Hk9z31m5t5z7z2fuQMn595TUlj0UBf+2iUBs0HHx+sPMep/G/jT8yto+cxibp7xPWPnbuKVZbv56qcjbD+SQ1FpYM6lKoQQQlQHTdMuuEyePPmSjrtu3TpGjhx5eTP7G6xcuRJN06o8ZWCg2rJlC126dCEoKIiWLVvy4osvXnSf5cuX07lzZ+x2OzExMTz++ON+fdQnT55c4W/DZrP50nTt2rXCNDfffLPfcZo3b47NZiMsLIyUlBTWrFlzeb8AIcTvTp7MX4lMQZA01LsUnYHdi/EcT8e1dQUqqgHagsdg0ROgPNDoBmj3/9AKT9H86sE0757oO8yx3GK2Hc7h5xMF/Hwyn33HC0jbd5KT+aW+NHEhFhpHBZMQYSMhMphGETbiQq3EhVoIMsnPTwghhChz9OhR3/uPPvqISZMmkZ6e7lsXHBzse6+Uwu12YzBcvCyNjIy8vBkVF5Wbm0uPHj1ISUnh3//+N2vXrmXs2LGEhYVVemPlp59+ok+fPjz11FO8//77HD58mFGjRuF2u3nppZcAePTRRxk1apTfft27d6djx46+z59//jmlpWf/Fjt16hRt27blzjvv9K1r2rQpr7/+OgkJCRQVFfHyyy/To0cP9u7dK78XIQKIPJm/0lnDoO1deLo+yZrG43HfPhseSIOUydD7Bcg7Cp8Nh4WPw6ttYHYP7yj5B9KILtxD9xbRjLg+gam3t+HjUcmsf/omfprUg88f6MxLd7alf7u6BJn0rN53iufm7+Sed9eSMv1brpq0mI7PLeP+/21g3C9P9L/ecoTVe0+y51geHhlaXwghxBUmJibGt4SEhKBpmu/zrl27sNvtLFy4kKSkJMxmM6tWrWLfvn3069eP6OhogoOD6dixI8uWLfM7bsOGDXnllVd8nzVNY9asWdx2220EBQWRmJjIV1999avyOn36dFq3bo3NZiM+Pp4HHniA/Px83/YDBw7Qt29fwsLCsNlstGzZkgULFpCRkUG3bt0ACAsLQ9M0hg0bVu74ubm52Gw2li5d6rc+NTUVu91OYWEhAI8//jhNmzYlKCiIhIQEJk6c6JvJoCJdu3Yt11Wgf//+fnkoKSnh0UcfpW7duthsNjp16sTKlSt/1ffzwQcfUFpayrvvvkvLli0ZMGAAY8eOZfr06ZXu89FHH9GmTRsmTZpEkyZNuOGGG3jhhRd44403yMvLA7w3dM79nRw7dowdO3YwfPhw33HCw8P90ixdupSgoCC/yvygQYNISUkhISGBli1bMn36dHJzc9myZcuvilMIUb3k0agoL6qFdwFoPxSyD4Cmg03/g9P74IdX4Jtnvdsb3QDGIHDEQWg8hNYnpCSP9plraH/T3yGpnu+wLreHI9nFHMkp4mhOEbuy8thyMAe3R7Fq70lOF5y9i2w26LAY9cSGWIgLtRIRbAKgfngQ4TYzYUFGwm0m4sODiHZY0Oukz74QQoiLKyp1s+9EfoXbyubRtuWpyzofeOPIYKwm/WU51hNPPMFLL71EQkICYWFhHDx4kD59+vDcc89hNpt5//336devH2vXrqVly5aVHmfKlCm88MILvPjii7z22msMHjyYAwcOEB4eXqV86HQ6ZsyYQaNGjfj555954IEH+Nvf/sa///1vAEaPHk1paSnfffcdNpuNHTt2EBwcTHx8PJ999hkDBgwgPT0dh8OB1Wotd3yHw8HNN9/Mp59+yoABA3zrP/jgA/r37++bctBut/Pee+8RFxfH1q1bGTFiBHa7nb/97W+/5mv1M2bMGHbs2MG8efOIi4sjNTWVXr16sXXrVhITvS0UNU1jzpw5Fd6IAEhLS+P666/HZDLh8XgA6NGjBy+88AJnzpwhLCys3D4lJSVYLBa/dVarleLiYjZs2EDXrl3L7TNr1iyaNm1Kly5dKo1n9uzZ3HXXXX5N8c9VWlrKzJkzCQkJoW3btpUeRwhR80hlXlyYwQQRvzStT3nG++oshlN7IGsr/DQXPC44uAa2fgIlud40Jjvsmg/BUdDwOrCGYajTmPoRTalPEeStg67Dweq9aaCUIrfIRXZRKYfPFLEzK49ip5tjucUcyS4i/Vg+SimW7jhGdpGTc2dFMel11AuzEh8eRHyYhaJjGmzNIiokiJgQCzEOy2X7I0oIIURg23cin1teW/WHnvPrsdfRqm7IZTnW3//+d2666Sbf5/DwcL8K2D/+8Q9SU1NZuHDhBSvzw4YN4+677wbgn//8JzNmzGDt2rX06tWrSvk49+l2w4YNefbZZxk1apSvMp+ZmcmAAQNo3bo1AAkJCX55BoiKiiI0NLTScwwaNIihQ4dSWFhIcHAwubm5zJ8/n9TUVF+ap59+2i8fjz76KPPmzbvkynxmZiZz5swhMzOTuLg4wNu0fdGiRcyZM4d//vOfADRr1oyQkMqvaVZWFo0aNfJbFx0d7dtWUWW+Z8+evPLKK8ydO5c///nPZGVl8fe//x3w74JRpri4mA8++IAnnnii0nysXbuWbdu2MXv27HLbvv76a+666y4KCwuJjY1l6dKlREREVHosIUTNI5V58esZLRDT2rtcPch/W1E2OIvA44QN/4HCk96Kfkke5BwCfqmFazpY8xbEdwJLCFriTYQUnCQEaGB20PnqbhBUx3vDwKODup3hlxHz3R5FXrGTk/klHDxdRObpQt/y48+n2X9Sx2cZ/s3EQoOMxDgsxIZYiHZYCLOZCAsyEhFspmm0nabRdplyTwghrgCNI4P5eux1FW7zPZm32S77k/nLpUOHDn6f8/PzmTx5MvPnz+fo0aO4XC6Kioo4dOjQBY/Tpk0b33ubzYbD4eD48eNVzseyZcuYOnUqu3btIjc3F5fLRXFxMYWFhQQFBTFu3Djuv/9+lixZQkpKCgMGDPA7Z1X06dMHg8HAV199xaBBg/jss89wOBykpKT40nz00UfMmDGDffv2kZ+fj8vlwuFw/KrznGvr1q243W6aNm3qt76kpIQ6der4Pu/ateuSz1GZHj168OKLLzJq1CiGDBmC2Wxm4sSJfP/99xX+HlNTU8nLy2Po0KGVHnP27Nm0bt2aa665pty2bt26sXnzZk6ePMk777zDn//8Z9asWUNUVNRljUsI8fuRyry4vKyh3gWg+0T/baWF3mb6JXkQUg9+fAtO7IQTu2DzB6AzAJr3RgAa2CKg4IR337pJ0G4IZGeiD2tIqNlOaPw1NGkSBYazhY7T6WT+/AVc3/0msos9ZOUWk5VTzNGcs6/bj+SSXVRKdoGTvBLvCLE6DaLsFuqFWflTkwi6NY+iZZwDo14q+EIIUZtYTfpKn5J7PB5yczUcDsdlrcxfTuc3lX700UdZunQpL730Ek2aNMFqtXLHHXdcsN84gNFo9PusaZqvOfjFZGRkcMstt3D//ffz3HPPER4ezqpVqxg+fDilpaUEBQXx17/+lZ49ezJ//nyWLFnC1KlTmTZtGmPHjq1yrCaTiX79+jF37lwGDRrEhx9+yMCBA32D/qWlpTF48GCmTJlCz549CQkJYd68eUybNq3SY+p0OpTyH5fn3O8qPz8fvV7Phg0b0Ov9W/WdOwDhxZT1Zz9X2eeYmJhK9xs/fjwPP/wwR48eJSwsjIyMDCZMmODXsqHMrFmzuOWWW3xP/M9XUFDAvHnzfE/3z2ez2WjSpAlNmjTh2muvJTExkdmzZzNhwoSqhimEqGZSmRd/HFOQ92l+mV7epmp4PJB3BOxxoNNBwSnYvRCO7YBmvcFVAt8+D18/BLbIsxX8Mnqz99geDwa9kfaWZoRsySQ8NJ4EZyE06QaOJhVmqaDExa6sXNKz8snKKWLfiQLm/LCfV5fvwWLU0bpuCG3qhRIfZiWpQTj16wThsBjQNOmjL4QQovr98MMPDBs2jNtuuw3wVkYzMjJITk7+3c65YcMGPB4P06ZN8930+Pjjj8uli4+PZ9SoUYwaNYoJEybwzjvvMHbsWEwm7zg4bvfFp7C98847ue2229i+fTsrVqzg2Wef9W1bvXo1DRo04KmnnvKtO3DgwAWPFxkZ6ddk3e12s23bNt+gfO3atcPtdnP8+PEL9kO/mOTkZJ566imcTqfvpsCyZcto1qxZhU3sz6Vpmq+J/9y5c4mPj6d9+/Z+afbv388333xzwYELP/nkE0pKSvh//+//VSnPHo+HkpKSKqUVQtQMUpkX1U+n8z6pL2OrA+3OK3iadIfC095tbpd3Sr1D66A4x9tPv7QAdAY8BSdxbEpF982z4Cr+ZWcNYtuApoc6jSHnMJiDwRqOLSicpOAokhpcBx3bg06Py+3hp0M5bMo8w6aD2SzfeYwjOcWUurxPLIJMeuqGWmlTL5T2DUJpEesgMSoYu8X/KYcQQgjxe0tMTOTzzz+nb9++aJrGxIkTq/yE/VI1adIEp9PJa6+9Rt++ffnhhx946623/NI89NBD9O7dm6ZNm3LmzBm++eYbWrTwjpPToEEDNE3j66+/pk+fPlit1kqfenfu3JmYmBgGDx5Mo0aN6NSpk29bYmIimZmZzJs3j44dO5brT1+RG2+8kfHjxzN//nwaN27M9OnT/ea7b9q0KYMHD+aee+5h2rRptGvXjhMnTrB8+XLatGnjm6u9efPmTJ061XcT5XyDBg1iypQpDB8+nMcee4x169YxY8YMXn75ZV+a1NRUJkyY4Ndk/8UXX6RXr17odDo+//xznn/+eT7++ONyrQTeffddYmNj6d27d6Wxzp49m/79+/t1DwDvE/vnnnuOW2+9ldjYWE6ePMkbb7zB4cOH/Ua8F0LUfFKZF4FB07wVeQC9AYIjoXmfcsk8TiffFiXRp1dPjK4C737pCyDjB1AeOLUXwhqCsxDOZMCRjZB7BEongyUEmqRg6DCcJGsoSddd5eunX+x0s+NoLkezizmaU8SBU4VsOniGLzYfxv3LNHp1Q600i7GTGB1Ms1/64TeJCsZilMH3hBBC/D6mT5/OX/7yFzp37kxERASPP/44ubm5v+s527Zty/Tp0/nXv/7FhAkTuP7665k6dSr33HOPL43b7Wb06NEcOnQIh8NBr169fBXZunXrMmXKFJ544gnuvfde7rnnHt57770Kz6VpGnfddRcvvvgikyZN8tt266238vDDDzNmzBhKSkq4+eabmThxIpMnT64073/5y1/46aefuOeeezAYDDz88MO+p/Jl5syZw7PPPssjjzzC4cOHiYiI4Nprr+WWW27xpUlPTycnJ6fS84SEhLBkyRJGjx5Nx44dqVOnDhMnTvSbYz4nJ4f09HS//RYuXMhzzz1HSUkJbdu25csvvyxXYfd4PLz33nsMGzasXCX/3PytWrWKJUuWlNum1+vZtWsX//nPfzh58iR16tShY8eOfP/99xccNFEIUfNo6vyOQ7Vcbm4uISEh5OTk/KYBUso4nU4WLFhAnz59yvU/CyRXdBxuFxzeAPuWe0fkP/2zd31kcwhvDFfdCo1v9I7Mf55ip5u9x/PZfSyP9GN57M7KY/exfA5nFwHevvhxoVYsRj3t4kNJiAwmPtxKfFgQ8eFBhAUZK2yyX1uuB9SeWCSOmkXiKO9yl2+B4EIxFxcXs3//fho1alRuuq/KePvM59boPvNVIXHULLUljsLCQnbu3EnTpk2x2+3VnZ1LVlvKD6g9sUgc5VW1TJcn80LoDVC/k3e5/jE4vNHbjH/Hl96Kfep9gAYN/gT1OnhH63eXQuNuWOLa0apu/XKDKeUVO9l9LJ89x/LIOFVIQYmLTQfPsGh7FnnFLl86m0lPfHgQ9cKCfNPr1QuzEms3Ueii3CA9QgghhBBCCAFSmRfCn97ordQDNPtlrt3co96n9jv/D7Z9BmY7eFywYY53e2xbOL0flIL290C9DthdJSRFJJKUdLX3ZsE5cgqdZJ4u5OCZQg7+8nroTBHf7znBoTNFlLjK+joaeHbLCuqGWokLtZZ/DbMSbTdjkBH3hRBCCCGEuOJIZV6Ii3HEegfkO39QvpxDsP97b5/8Fn29U+5t+A/8+MbZNJYQaNwdEm7w9tk/vpOQuh1oHZ5A61PLoUFn6PIn0Hn7vCmlOJFfQsaJPBZ8k0Z0QlOycks4nF3Mpsxs5m89Snbh2Sl0dBrEOCzUDbPSJMpOpN1M0+hggkx6ouwW4kKtlTblF0IIIYQQQgQuqcwLcalC6sHVd3uXMilTvE30DWbv1Hp7l8GexfB/nwMahNaHtTO9afVmWDkVgmOgaQ8AtEY3EBXXjjonVqAMB2nfpB5GTUF0K2+//vrdyXcqjmYXcTi7iCPZxRzOLiTzdBFbDmVzLLeEk/n+08pYjDrfE/3YEAuRdjMRwWYi7WbqhQVRN9SK3WKQgfqEEEIIIYQIIFKZF+Jy0jQICve+j+/oXbpNAOcv0+QZLZCXBcd3ep/KH93iHXRv/3fe7RvfB0CHRicUzH7Vu95gBVcR1E8muGkvEvUmEpUb0hd5uwV07QeOFmC2k10CxS7F8bxijmQXcTjb+3oku4j0Y/n8sPcUJ/NLzmnO7xUbYiEh0obdbPQ+2XdYqBtqITbEW9m3mQ2E20zUCTZhNkjFXwghhBBCiOoklXkh/gjGc0ZStsd4Fzhb4S9zJgMOb8DV4AaWL55PSodmGDwl8PM33tH1186E76eB2wmuYmjUBdbN8q77RajBCvU6EFOcQ5vGN3r798c1g/BcaNoT8o+hYpIoyNjAsSIde42J5JUo9p/MZ/+JfHRFpziYb2PdgdMczS7G5Sk/CJ/dYiAsyESjCBsRwWYcVgMOixGH1YjDYiDEWvbeSJARimUwPyGEEEIIIS4rqcwLUZOENfQuTiclxlBU3SQwGr197gHa3uV9VQpcJd6bBK5SOLweCk9DaT7kHoGDa8EWCRve8w7Yl3MQdAZY8hQAGhrBKIKBxrZIMFgg7mo4+RNkZ3oH9Wt1LerUXopCEig2hFBgiSbHbeJnW3uOlZgwnthGWqGFUyeOsrXUSm6Ri9yiEgqdFVXaDTy5YRkhViOhv1T0Q4O870OsRkKCTIT+si7knNcQq4kQqxGTQQb5E0IIIYQQ4lxSmRciEGna2af9BpO3yf6FlBaAxw17lkBIPBxaBw2v806zt3uR90n/wTWQ2NNbqd+9GPYuRQtPIChjOUHFuYQXniQeaIUGRis4CxlmDAJnIdTvDBwC1xHcHYdQHNoE48Z3ya/TCk9RDt8WN8PYtBvW7B04i/LJ1NVjp2rAqTOKzKMlHCkykl1USrHTDZQfrC/IpCfUauQqUxYeWxRGWxihVhMhvkp/2c0Bk++9w2rEbjag08ngf0IIIYQQovaRyrwQVwKTzfva+g7va9n0ewANksunP3/kfvC2ACg6452mL/+Y9+l95hrvGAHbv4DmfcASgv7Ht7CV5ECTFMJzduMx2Rhw+m348W3vcTSdd2T/cwVHQ3RD1JHNuEMbkh+VRG5wI8xH1pEVcjU5ykr4qY20Ov5/ePJ0fG/rwS4tgc3uRnxS3IC84lJcSoeFEoox+w4bqeXgtNQhNMiE3WLE6fbgsBiJtJuxmvRYjDqsRj3hNjNRdu+ggJoGLrdCoWgR6yDGYSG70InyuKigx4EQQgghhBDVQirzQoiqMZjAHg1XDzq7rvGN3tdO951dd8Pj3ib/wZEAuJ1Olqe+R7cOLTDEtQZTMJzcDce2n93nxC44uQeta08M2ZmEZq4hdOdciGlF9M5l3sq/NQx6PY/O7eSG1a9xQ+Ey73gAMW1QJ3aBpkdzFVEQ0wlj9s+UmEKx5+7hiKMdB60taHpqOfvtHflZJXDwdBhOpxOjqwDNXczGkkjqOzPYrhoSTi6rPK3IxQZoROtzOea24+2coGfiphU4LAbsFiN2i+GXxeh7DTbrcboVVpPe20VAr8No0BFhMxFpN+PyKOoEm/B4wGrUY7dI6wEhRM2QkZFBo0aN2LRpE1dffXV1Z+dX6dq1K1dffTWvvPJKdWdFCCH+MFKZF0JcXjq9ryJfptAchYrv5O3/DxDVwrtciNsFegOUFoLe6F3K/Gmct2vA7sWw9m2068Z7xwbQGbBtT4U2t2EqPA1xw4jbnkrcmSXQvBthB9Jon7ME3KVnj6XpATfKpEP7pcWAxxKO5iygxOjAUnyC3IhmnAxrT1FWOvkxnYjI2cqu4E4UOd0cLIklLx+0kjzWuBPILHVg07lo7txGc9cu1nma0VDLIkY7TRAlfOO5GgulrPc0JZdgNA3sZgMlLg+t7AW4gyIxGIyEGt2Yg2zYzd4bBlaTgZzCUkKDTHiUItxmIsikR6dp6DQNvU4jyKT3di+weAcktJr0mA06zAY9Rr2GpslNAyFqsov9G33mmWeYPHnyJR87NTWV/v37X9L+l2Ly5Ml88cUXbN68+Q87Z3X45JNPmDhxIhkZGSQmJvKvf/2LPn36XHCfN954g9dff52MjAzq16/PU089xT333OPb3rVrV7799tty+/Xp04f58+eXWz9q1CjefvttXn75ZR566CHf+o0bN/L444+zbt069Ho9AwYMYPr06QQHB196wEKIGkMq80KImkn/y39PpqBKthuhxS3e5VzXjvL/3HmM/2eloOCEd3+T3bvuxE608ARvawGTDd36d8ERh6XwNEQk4ti7DPuJjZzWewjPeAutTmMaH5yGt3//eW3vjUHesQhQKIsVzfUpSmfAHRSFx+NhROECAEqs0eQHN+C0pT6lLg/hRQeIzd7AUdWYLcHX0e34XNZb/kSBx0CGisHiyiXWYERzFXJCi+D94g7YPTkcVJGcwUEQxRRjwoMOAy70ePCgQ4+bhw2f8qNqyT5dI/L04Xjceqalf0+I1URokJHS0lL0egN2q5FoQyF6WzhoGm6PwmzQYTMbCP5lMRl06HUaNpOBYIsBvU5DKdDrQKdpeJQiyu4dzyHSbkav09BrmrQ+EKIKjh496nv/0UcfMWnSJNLT033rpAJW86xevZq7776bqVOncsstt/Dhhx/Sv39/Nm7cSKtWrSrc580332TChAm88847dOzYkbVr1zJixAjCwsLo27cvAJ9//jmlpWdvPJ86dYq2bdty5513ljteamoqP/74I3FxcX7rjxw5QkpKCgMHDuT1118nNzeXhx56iGHDhvHpp59exm9BCFFdpDIvhLiyaBoER/mvi2ntfY2/xvt68zT/7UnDcDmdrFqwgD4p12MMCoXTP3unGMw57G2NYLBAZpp3PAGTDep1RItsDplpaJHNMdgiwOOBAz+AyYZ53WzMzgLqnNjhvbEQGQ2dXyJ2x5fEZrwPjW+kc8YqcMRC7rfePGua92ZBzkrGGt/3ZU8ZrGiuIpSmx22tg77oFJpyA1BqCsFYmst9eJ/kHLc1o6DESXTpaVylevYUt6RN4Y8cN9bjjC6Uq4o3scqQTI7OQb4uhH3UpU/x55QqHYtd7ckmmHv0SzmqwlmjEilUZk6oEBrpstjniSPNcxV2rRCFRpiWT4GyUF93HJ3BzH59IxI5yF59AgXGcMwGHRajd+wCi1FPNKcpMoWj6Y0YdBomg45mRT+RZ2uA0xaN2aDHZNBhNujQa4otWRpFGw8TYbdiMeox6DUMOg2DXkdEsAmXWxFmM1F2H8Fq1FPq9qChYTbo5AbD7+CNN97gxRdfJCsri7Zt2/Laa69xzTXXVJr+Up5o1mYxMTG+9yEhIWia5rdu1qxZTJs2jf3799OwYUPGjRvHAw88AEBpaSnjx4/ns88+48yZM0RGRnL//ffz5JNP0rBhQwBuu+02ABo0aEBGRsZF8+N2uxk5ciQrVqwgKyuL+vXr88ADD/Dggw/60qxcuZK//e1vbN++HaPRSMuWLfnwww/55ptvmDJlCnC2xcGcOXMYNmyY3zmWLFnCrbfeSlZWFqGhob71Dz74IFu3buXzzz/n1KlTjBs3ju+++44zZ87QuHFjnnzySe6+++5K815RS4TQ0FBeeeUVXx4OHjzII488wpIlS9DpdHTp0oVXX33V931VxauvvkqvXr147LHHAPjHP/7B0qVLef3113nrrbcq3Oe///0v9913HwMHDgQgISGBdevW8a9//ctXmQ8PD/fbZ968eQQFBZWrzB8+fJixY8eyePFibr75Zr9tX3/9NUajkTfeeAOdzjsrzFtvvUWbNm3Yu3cvTZo0qXKcQoiaSSrzQgjxa5iCvZXqOo29nyObnt1WNsDguRped/a9TgeNunjf121f8fGvGeEdbNBg8r7qjd6ZCPTn/Hddkg87v4LQ+pBzGK3wFNgi0ErzMeRleW8ymILBWYTp+E5ocycUZUPRGSI2fUDJmSLMbe4iyFVI0s7/g2Z3U7foDHVdJRA1juvT3gBrFLhLoPAU1E2C8ARa7pqP5izE1bgHDZxFdD75A5qrCH1pLm5zKPqS7At/d7+Me5hviOSQpTW4SwnLP0SuPow8nZ22+avYZ27Bj5YutCzehN2dTVNXOoVYSdO3p8hjJEKdIssTxhJ3O5prmTQ8/E8KlZmlnrZkqii66TazT8WxV8UxUj+fTz3NSPNchUlzUU87wQFPNE4MHFF10AxG7tUvxqhTrDB2pdAQCkYLbmMwZoOeUF0hTdw/c8Yazxl9JE63B6NeR5BZj81koI6WS55Lj9kWQowhj/icDZwJb4crOA6jQcOo12HU6zDpdTisBkrzTuLUB2HIOYA1LBZHaDjBes8Fv7JA8tFHHzF+/HjeeustOnXqxCuvvELPnj1JT08nKiqqXPpLeaJ5WZQWesftqIhS6AvyoeCXf+eXS0TTylsZVdEHH3zApEmTeP3112nXrh2bNm1ixIgR2Gw2hg4dyowZM/jqq6/4+OOPqVevHrt27eL06dMArFu3jqioKObMmUOvXr3Q6/VVOqfH46FevXp88skn1KlTh9WrVzNy5EhiY2P585//jMvlon///owYMYK5c+dSWlrK2rVr0TSNgQMHsm3bNhYtWsSyZcsA7w2K83Xv3p3Q0FA+++wzhg8fDnhvInz00Uf84x//AKC4uJikpCQef/xxHA4H8+fPZ8iQITRu3PiCN4suxOl00rNnT5KTk/n+++8xGAw8++yz9OrViy1btmAymVi5ciXdunXz3TypSFpaGuPHj/db17NnT7744otKz11SUoLFYvFbZ7VaWbt2rXc8F6Ox3D6zZ8/mrrvuwmaz+dZ5PB6GDBnCY489RsuWLSs8j8lk8lXky84DsGrVKqnMC1ELSGVeCCFqGoPJ/1V/3n/V5mD/gQh/BXfzfmxcsICY6/qgNxrhpinlE11zH9giQWeA7AMQUg/0RjS3EzxuDEb/P0IpyUNvtEHeUTiyCayhgOZ9LcmH0HjvYIWH1oM9huC0N2hemg/6IAhNITovC/KPQ9txNP1pHk3zZkP9a8HaDJo+SNCpvXQ/tA5chWBvCKd+pv/xV3HqLGiJN+Euyadb5gdoHhcuWzT6whVoyk2xrS7XF3yKdn5XiHOU6m24dGaGlX6FrtTbmuGEKR5NeYhwHvZ+Z+j42dQct86IR2kc1UVT6DHQs2QxLozs0hJopdIx4eKoCuc1122EUEColkcoBZzEQax2mr66NI4TShTZHFF1KMZEet2bIKbbJV3Lmmb69OmMGDGCe++9F/A+AZw/fz7vvvsuTzzxRLn0l/JEs6SkhJKSEt/n3NxcwFsxczqdfmmdTidKKTweDx7POTdNTqSje6drhcfXAfaqBvwreEas9M4A8mv2+SXPZa/PPPMML774ou9Jc4MGDdi+fTtvv/02Q4YM4cCBAyQmJtK5s3eq0rCwMOx2Ox6Phzp16gDgcDh8N1b8vpMKzunxeNDr9TzzzDO+7Q0aNGD16tV89NFH3HHHHWRnZ5OTk0OfPn1o1KgRAM2aNfOlt9lsGAwGv5s555+3rOL/4Ycf+n47S5cuJTs7m9tvvx2AuLg4vwrz6NGjWbRoER999BEdOnTwrS+73uee6/zzla2bO3cuHo+HmTNn+loOzJ49m/DwcFasWEGPHj2wWCw0a9YMvV5f4fcFkJWVRWRkpN/2qKgosrKyfOuUUn7569GjB7NmzeLWW2+lffv2bNiwgVmzZuF0Ojl+/DixsbF+51i7di3btm3jnXfe8TvP888/j16vZ8yYMX7nKnvftWtXxo8fzwsvvMC4ceMoKCjg8ccfB7xN8CuLqTJlcbhcrnL/3gJJWd4DOYYytSUWiaPyY12MVOaFEEL4C6l79n14o7Pvzx+IsIzZfna/c/c9X2h972uDzpWn6T7JO33hRZ6KOrN2sGT1T/Toewdmo9E7bWJJHgZHXe+YCIWnsEQ0hdP7vS0MjEHeKRBP7PJ2izi9HzxuTAldMVkcsPF9bxpNI/LoT944o66C2LboD64hMeMHysZHuOrkbijJg/ajMJkdtD++HeLuhCY3EfvJUJ479S5YQ1GWMNzmUHR5u3CZQyhs+gh1Dq3GWSeRmAPfU2IOJ6jz7Zz5+cwFYw0EpaWlbNiwgQkTJvjW6XQ6UlJSSEtLq3CfS3miOXXqVF/T7XMtWbKEoCD/J98Gg4GYmBjy8/P9+h5jikE/6OsqRHX5uE0x8MuNh6oqLi5GKUVubi4FBQXs27ePESNGcN99Z2cPcblcOBwOcnNzueOOO7jtttto1qwZ3bt3p2fPntx4441+xywqKvLdAKlIfn4+AAUFBb5077zzDh988AGHDh2iuLiY0tJSWrduTW5uLgaDgUGDBtG7d2+6du1K165d6d+/v69rQElJCW63+4LnBOjXrx+vv/466enpxMbG8p///IcePXr4WhBkZ2czffp0UlNTOXr0KE6n0/fUuezYLpeL0tJSv3OdH69SiuLiYnJzc1m3bh179+4t11qguLiY7du3c+2119K8eXN+/PFHgAvGcP55ioqKfNfuXHl5eQCMGzeOgwcP0rlzZ5RSREVFMXDgQGbMmOH33Zd56623uOqqq2jevLlv2+bNm3n11VdZuXKl77gej8cXH0B8fDz//ve/efrpp3nyySfR6/WMHDmSqKioct9VVZT9O1q9ejUul+tX7VsTLV26tLqzcNnUllgkjrMKCwurlE4q80IIIWoOXdWa/1InEZd+z9nP1jDvAt5uBvZf+hmf2w0CoN4vT/Hi2vmvv2bE2ffnt3qIbgkd/lK1fI1e520JoNOj4X3SC6AHzOemUwqzpmF1OuHnBVU7dg128uRJ3G430dHRfuujo6PZtWtXhftkZWVVmD4rK6vS80yYMMHvBkBubi7x8fH06NEDh8Phl7a4uJiDBw8SHBx8XpNmB9TxP28ZpRR5eXnY7fZqn/3BYrGgaRoOh4OioiIA3n77bTp16uSXTq/X43A46NKlCz///DMLFy5k+fLl3HvvvaSkpPDJJ5/40lqt1nLf07nKBtiz2Ww4HA7mzZvHpEmTeOmll7j22mux2+289NJLrF271nec//73v4wfP57Fixfz1Vdf8dxzz7F48WKuvfZazGazL38X0rVrVxo3bsyCBQsYNWqUr0WH3W4nLy+Pt99+m7fffpvp06fTunVrbDYbDz/8MB6Px3dsg8GAyWTyfdY0DYvF4ndul8vlW+d0OklKSuK///1vufxERkZeNM9lYmJiyMvL80ufm5tLbGysb935vyuHw8H777/P7NmzOXbsGLGxscycORO73U5CQoJfs/iCggJSU1OZMmWK3zk2bdrEiRMnaN26tW+d2+3m6aef5u233+bnn38GYPjw4QwfPpxjx45hs9nQNI1///vftGjRosoxlin7HXbu3DmgB2N0Op0sXbqUm266qcIuDYGktsQicZRX1ZttUpkXQgghLpdz/gi/IJkm8JKYzWbMZnO59UajsdwfTm63G03T0Ol0fpWjCylrdly2X3UqO79OpyM2Npa4uDgyMjIYMmRIpfuEhoZy9913M3DgQHr37u1rCh8eHo7RaEQpdcG4zj2nTqcjLS2Nzp07M3r0aF+askriucdJSkoiKSmJJ598kuTkZObNm0fnzp0xm8243e4qfZeDBw/mww8/JD4+Hp1OR9++fX03VFavXk2/fv18U7d5PB727NnDVVdd5Xfsc69bZGQkx44d833es2cPhYWFvtiSkpL4+OOPiYmJ+dWV2nMlJyezYsUKHn74Yd+6ZcuWkZyc7Dt3Zb8rs9lM/freFksff/wxt9xyCwaD/5/mn332GSUlJQwZMsRv33vuuYebbrrJL23Pnj0ZMmQI9957b7nvvKzp/rvvvovFYqFnz56/+jdedj0MBkNAV7jKVPT/RqCqLbFIHP7HqIrqLamEEEIIEfAiIiLQ6/UcO3bMb/2xY8f8RmM/V0xMzK9Kf6WbMmUKU6dOZcaMGezevZutW7cyZ84cpk+fDnjHLJg7dy67du1i9+7dfPnll8TExPhGiG/YsCHLly8nKyuLM2eq1rUjMTGR9evXs3jxYnbv3s3EiRNZt26db/v+/fuZMGECaWlpHDhwgCVLlrBnzx5atGjhO+f+/fvZvHkzJ0+e9Bvv4HyDBw9m48aNPPfcc9xxxx1+N20SExNZunQpq1evZufOndx3333lfjvnu/HGG3n99dfZtGkT69evZ9SoUX5/HA8ePJiIiAj69evH999/z/79+1m5ciXjxo3j0KFDgLevevPmzTl8+HCl53nwwQdZtGgR06ZNY9euXUyePJn169czZszZaVGffPJJRo06O23q7t27+d///seePXtYu3Ytd911F9u2beOf//xnuePPnj2b/v37+8Y9KFOnTh1atWrltxiNRmJiYvzGLXj99dfZuHEju3fv5o033mDMmDFMnTrVb+YAIUTgksq8EEIIIX4Tk8lEUlISy5cv963zeDwsX76c5OTkCvdJTk72Sw/efoaVpb/S/fWvf2XWrFnMmTOH1q1bc8MNN/Dee+/5Bp6z2+288MILdOjQgU6dOpGZmcnXX3/te/o6bdo0li5dSnx8PO3atbvQqXzuu+8+br/9dgYOHEinTp04deqUbyo8gKCgIHbt2sWAAQNo2rQpI0eOZPTo0b5+/QMGDKBXr15069aNyMhI5s6dW+m5mjRpwjXXXMOWLVsYPHiw37annnqK9u3b07NnT7p27UpMTIzflHMVmTZtGvHx8XTp0oVBgwbx6KOP+o2rEBQUxHfffUf9+vW5/fbbadGiBcOHD6e4uNj3pL6wsJD09PQLDkTVuXNnPvzwQ2bOnEnbtm359NNP+eKLL/xmZDh69KjvBgF4W41MmzaNtm3bctNNN1FcXMzq1avLjZifnp7OqlWrfKP8X4q1a9dy00030bp1a2bOnMnbb7/NuHHjLvl4QoiaRZrZCyGEEOI3Gz9+PEOHDqVDhw5cc801vPLKKxQUFPhGKL/nnnuoW7cuU6dOBbxPNG+44QamTZvGzTffzLx581i/fj0zZ86szjBqjGHDhpWbk33QoEEMGlTxTBYjRoxgxAjv2A8ej4fc3Fy/5uN9+/b1zWFemYYNG/pGLAdvM/A5c+YwZ84cv3Rl1zA6OprU1NRKj2c2m/n0008veM5zrVmzpsL14eHhFxwYEbzz3Z8rLi6OxYsX+63Lzs72+xwTE8N//vOfSo/ZtWtXv++jMnfeeWe5+d/PNWfOHL/+ry1atGDTpk0XPW6zZs2qdP4yGRkZ5da9//77Vd5fCBF4pDIvhBBCiN9s4MCBnDhxgkmTJpGVlcXVV1/NokWLfIPcZWZm+vXRLXuiWTbSdmJiYrknmkIIIYSonFTmhRBCCHFZjBkzxq+v8LnOf3IKF3+iKYQQQojKSZ95IYQQQgghhBAiwEhlXgghhBBCCCGECDBSmRdCCCFErfVrBhATQlSu7N9S2XzzQojqJ5V5IYQQQtQ6ZXOKFxYWVnNOhKgdCgsL8Xg8GAwy5JYQNYX8axRCCCFEraPX6wkNDeX48eOAd17xiz1R9Hg8lJaWUlxc7DfyfqCROGqWQI9DKUVhYSEnTpwgLy8PvV5f3VkSQvxCKvNCCCGEqJViYmIAfBX6i1FKUVRUhNVqDeimxBJHzVJb4nA4HOzZs6e6syGEOIdU5oUQQghRK2maRmxsLFFRUTidzoumdzqdfPfdd1x//fW+ZvqBSOKoWWpDHEajEY/HU93ZEEKcRyrzQgghhKjV9Hp9lZoG6/V6XC4XFoslYCtdIHHUNLUlDqnMC1HzBF7HHSGEEEIIIYQQ4gonlXkhhBBCCCGEECLASGVeCCGEEEIIIYQIMFdcn3mlFAC5ubmX5XhOp5PCwkJyc3MDuh+UxFGz1JY4oPbEInHULBJHeWXlWlk5dyWQMr1iEkfNInHULLUlDqg9sUgc5VW1TL/iKvN5eXkAxMfHV3NOhBBCiMsvLy+PkJCQ6s7GH0LKdCGEELXZxcp0TV1Jt/DxjsR55MgR7Hb7ZZnrMzc3l/j4eA4ePIjD4bgMOaweEkfNUlvigNoTi8RRs0gc5SmlyMvLIy4uDp3uyuhFJ2V6xSSOmkXiqFlqSxxQe2KROMqrapl+xT2Z1+l01KtX77If1+FwBPSPr4zEUbPUljig9sQicdQsEoe/K+WJfBkp0y9M4qhZJI6apbbEAbUnFonDX1XK9Cvj1r0QQgghhBBCCFGLSGVeCCGEEEIIIYQIMFKZ/43MZjPPPPMMZrO5urPym0gcNUttiQNqTywSR80icYjfQ225HhJHzSJx1Cy1JQ6oPbFIHJfuihsATwghhBBCCCGECHTyZF4IIYQQQgghhAgwUpkXQgghhBBCCCECjFTmhRBCCCGEEEKIACOVeSGEEEIIIYQQIsBIZf43euONN2jYsCEWi4VOnTqxdu3a6s7SBU2ePBlN0/yW5s2b+7YXFxczevRo6tSpQ3BwMAMGDODYsWPVmGOv7777jr59+xIXF4emaXzxxRd+25VSTJo0idjYWKxWKykpKezZs8cvzenTpxk8eDAOh4PQ0FCGDx9Ofn7+HxjFxeMYNmxYuevTq1cvvzTVHcfUqVPp2LEjdrudqKgo+vfvT3p6ul+aqvyOMjMzufnmmwkKCiIqKorHHnsMl8v1h8UBVYula9eu5a7JqFGj/NJUdyxvvvkmbdq0weFw4HA4SE5OZuHChb7tgXI9LhZHIFyL8z3//PNomsZDDz3kWxco1+NKFEhleqCW5yBl+rmqO47aUqZLeV5zYigjZfpZv2scSlyyefPmKZPJpN599121fft2NWLECBUaGqqOHTtW3Vmr1DPPPKNatmypjh496ltOnDjh2z5q1CgVHx+vli9frtavX6+uvfZa1blz52rMsdeCBQvUU089pT7//HMFqNTUVL/tzz//vAoJCVFffPGF+umnn9Stt96qGjVqpIqKinxpevXqpdq2bat+/PFH9f3336smTZqou+++u0bFMXToUNWrVy+/63P69Gm/NNUdR8+ePdWcOXPUtm3b1ObNm1WfPn1U/fr1VX5+vi/NxX5HLpdLtWrVSqWkpKhNmzapBQsWqIiICDVhwoQ/LI6qxnLDDTeoESNG+F2TnJycGhXLV199pebPn692796t0tPT1ZNPPqmMRqPatm2bUipwrsfF4giEa3GutWvXqoYNG6o2bdqoBx980Lc+UK7HlSbQyvRALc+VkjL9XNUdR20p06U8rzkxVDWWQLge56qpZbpU5n+Da665Ro0ePdr32e12q7i4ODV16tRqzNWFPfPMM6pt27YVbsvOzlZGo1F98sknvnU7d+5UgEpLS/uDcnhx5xeYHo9HxcTEqBdffNG3Ljs7W5nNZjV37lyllFI7duxQgFq3bp0vzcKFC5Wmaerw4cN/WN7PVVnB369fv0r3qYlxHD9+XAHq22+/VUpV7Xe0YMECpdPpVFZWli/Nm2++qRwOhyopKfljAzjH+bEo5S1szv1P+3w1NZawsDA1a9asgL4eSp2NQ6nAuhZ5eXkqMTFRLV261C/fgX49arNAK9NrQ3mulJTpNS2O2lKmS3les2IoI2X65Y9DmtlfotLSUjZs2EBKSopvnU6nIyUlhbS0tGrM2cXt2bOHuLg4EhISGDx4MJmZmQBs2LABp9PpF1Pz5s2pX79+jY5p//79ZGVl+eU7JCSETp06+fKdlpZGaGgoHTp08KVJSUlBp9OxZs2aPzzPF7Jy5UqioqJo1qwZ999/P6dOnfJtq4lx5OTkABAeHg5U7XeUlpZG69atiY6O9qXp2bMnubm5bN++/Q/Mvb/zYynzwQcfEBERQatWrZgwYQKFhYW+bTUtFrfbzbx58ygoKCA5OTlgr8f5cZQJlGsxevRobr75Zr/vHQL730dtFqhlem0rz0HK9OqOo7aU6VKe14wYykiZ/vvFYfjNR7hCnTx5Erfb7XdhAKKjo9m1a1c15eriOnXqxHvvvUezZs04evQoU6ZMoUuXLmzbto2srCxMJhOhoaF++0RHR5OVlVU9Ga6CsrxVdC3KtmVlZREVFeW33WAwEB4eXqNi69WrF7fffjuNGjVi3759PPnkk/Tu3Zu0tDT0en2Ni8Pj8fDQQw/xpz/9iVatWgFU6XeUlZVV4fUq21YdKooFYNCgQTRo0IC4uDi2bNnC448/Tnp6Op9//rkvvzUhlq1bt5KcnExxcTHBwcGkpqZy1VVXsXnz5oC6HpXFAYFzLebNm8fGjRtZt25duW2B+u+jtgvEMr02lucgZbqU6b+dlOfVH0MZKdN//zikMn+F6d27t+99mzZt6NSpEw0aNODjjz/GarVWY84EwF133eV737p1a9q0aUPjxo1ZuXIl3bt3r8acVWz06NFs27aNVatWVXdWfrPKYhk5cqTvfevWrYmNjaV79+7s27ePxo0b/9HZrFSzZs3YvHkzOTk5fPrppwwdOpRvv/22urP1q1UWx1VXXRUQ1+LgwYM8+OCDLF26FIvFUt3ZEbWYlOc1n5Tp1UPK85pDyvTfnzSzv0QRERHo9fpyoxUeO3aMmJiYasrVrxcaGkrTpk3Zu3cvMTExlJaWkp2d7ZempsdUlrcLXYuYmBiOHz/ut93lcnH69OkaHVtCQgIRERHs3bsXqFlxjBkzhq+//ppvvvmGevXq+dZX5XcUExNT4fUq2/ZHqyyWinTq1AnA75rUhFhMJhNNmjQhKSmJqVOn0rZtW1599dWAux6VxVGRmngtNmzYwPHjx2nfvj0GgwGDwcC3337LjBkzMBgMREdHB9T1uFLUhjK9NpTnIGW6lOm/jZTnNSOGMlKm//5xSGX+EplMJpKSkli+fLlvncfjYfny5X59QWq6/Px89u3bR2xsLElJSRiNRr+Y0tPTyczMrNExNWrUiJiYGL985+bmsmbNGl++k5OTyc7OZsOGDb40K1aswOPx+P7zqIkOHTrEqVOniI2NBWpGHEopxowZQ2pqKitWrKBRo0Z+26vyO0pOTmbr1q1+f8QsXboUh8Pha371R7hYLBXZvHkzgN81qQmxnM/j8VBSUhJQ16MiZXFUpCZei+7du7N161Y2b97sWzp06MDgwYN97wP5etRWtaFMrw3lOUiZLmX67xNHRWpiGVKR2lKeg5Tpv0scv3kIvSvYvHnzlNlsVu+9957asWOHGjlypAoNDfUbrbCmeeSRR9TKlSvV/v371Q8//KBSUlJURESEOn78uFLKO71C/fr11YoVK9T69etVcnKySk5OruZce0eR3LRpk9q0aZMC1PTp09WmTZvUgQMHlFLeaWxCQ0PVl19+qbZs2aL69etX4TQ27dq1U2vWrFGrVq1SiYmJf/g0NheKIy8vTz366KMqLS1N7d+/Xy1btky1b99eJSYmquLi4hoTx/33369CQkLUypUr/aYTKSws9KW52O+obJqOHj16qM2bN6tFixapyMjIP3y6kYvFsnfvXvX3v/9drV+/Xu3fv199+eWXKiEhQV1//fU1KpYnnnhCffvtt2r//v1qy5Yt6oknnlCapqklS5YopQLnelwojkC5FhU5f8TeQLkeV5pAK9MDtTxXSsp0KdP/+DgCpQypLeX5xWIJlOtRkZpWpktl/jd67bXXVP369ZXJZFLXXHON+vHHH6s7Sxc0cOBAFRsbq0wmk6pbt64aOHCg2rt3r297UVGReuCBB1RYWJgKCgpSt912mzp69Gg15tjrm2++UUC5ZejQoUop71Q2EydOVNHR0cpsNqvu3bur9PR0v2OcOnVK3X333So4OFg5HA517733qry8vBoTR2FhoerRo4eKjIxURqNRNWjQQI0YMaLcH5LVHUdF+QfUnDlzfGmq8jvKyMhQvXv3VlarVUVERKhHHnlEOZ3OPyyOqsSSmZmprr/+ehUeHq7MZrNq0qSJeuyxx/zmQa0JsfzlL39RDRo0UCaTSUVGRqru3bv7Cn6lAud6XCiOQLkWFTm/4A+U63ElCqQyPVDLc6WkTK9JcdSWMl3K85oTQxkp08/6PePQlFLqtz/fF0IIIYQQQgghxB9F+swLIYQQQgghhBABRirzQgghhBBCCCFEgJHKvBBCCCGEEEIIEWCkMi+EEEIIIYQQQgQYqcwLIYQQQgghhBABRirzQgghhBBCCCFEgJHKvBBCCCGEEEIIEWCkMi+EEEIIIYQQQgQYqcwLIWoETdP44osvqjsbQgghhPgNpDwX4o8jlXkhBMOGDUPTtHJLr169qjtrQgghhKgiKc+FuLIYqjsDQoiaoVevXsyZM8dvndlsrqbcCCGEEOJSSHkuxJVDnswLIQBvQR8TE+O3hIWFAd4mc2+++Sa9e/fGarWSkJDAp59+6rf/1q1bufHGG7FardSpU4eRI0eSn5/vl+bdd9+lZcuWmM1mYmNjGTNmjN/2kydPcttttxEUFERiYiJfffWVb9uZM2cYPHgwkZGRWK1WEhMTy/2xIoQQQlzppDwX4sohlXkhRJVMnDiRAQMG8NNPPzF48GDuuusudu7cCUBBQQE9e/YkLCyMdevW8cknn7Bs2TK/wv3NN99k9OjRjBw5kq1bt/LVV1/RpEkTv3NMmTKFP//5z2zZsoU+ffowePBgTp8+7Tv/jh07WLhwITt37uTNN98kIiLij/sChBBCiFpAynMhahElhLjiDR06VOn1emWz2fyW5557TimlFKBGjRrlt0+nTp3U/fffr5RSaubMmSosLEzl5+f7ts+fP1/pdDqVlZWllFIqLi5OPfXUU5XmAVBPP/2073N+fr4C1MKFC5VSSvXt21fde++9lydgIYQQohaS8lyIK4v0mRdCANCtWzfefPNNv3Xh4eG+98nJyX7bkpOT2bx5MwA7d+6kbdu22Gw23/Y//elPeDwe0tPT0TSNI0eO0L179wvmoU2bNr73NpsNh8PB8ePHAbj//vsZMGAAGzdupEePHvTv35/OnTtfUqxCCCFEbSXluRBXDqnMCyEAb2F7fjO5y8VqtVYpndFo9PusaRoejweA3r17c+DAARYsWMDSpUvp3r07o0eP5qWXXrrs+RVCCCEClZTnQlw5pM+8EKJKfvzxx3KfW7RoAUCLFi346aefKCgo8G3/4Ycf0Ol0NGvWDLvdTsOGDVm+fPlvykNkZCRDhw7lf//7H6+88gozZ878TccTQgghrjRSngtRe8iTeSEEACUlJWRlZfmtMxgMvkFpPvnkEzp06MB1113HBx98wNq1a5k9ezYAgwcP5plnnmHo0KFMnjyZEydOMHbsWIYMGUJ0dDQAkydPZtSoUURFRdG7d2/y8vL44YcfGDt2bJXyN2nSJJKSkmjZsiUlJSV8/fXXvj8+hBBCCOEl5bkQVw6pzAshAFi0aBGxsbF+65o1a8auXbsA78i08+bN44EHHiA2Npa5c+dy1VVXARAUFMTixYt58MEH6dixI0FBQQwYMIDp06f7jjV06FCKi4t5+eWXefTRR4mIiOCOO+6ocv5MJhMTJkwgIyMDq9VKly5dmDdv3mWIXAghhKg9pDwX4sqhKaVUdWdCCFGzaZpGamoq/fv3r+6sCCGEEOISSXkuRO0ifeaFEEIIIYQQQogAI5V5IYQQQgghhBAiwEgzeyGEEEIIIYQQIsDIk3khhBBCCCGEECLASGVeCCGEEEIIIYQIMFKZF0IIIYQQQgghAoxU5oUQQgghhBBCiAAjlXkhhBBCCCGEECLASGVeCCGEEEIIIYQIMFKZF0IIIYQQQgghAoxU5oUQQgghhBBCiADz/wFfTEZAUq0uMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is union_data\n",
      "Data file being used is: ENO3/train_input_union_data.csv\n",
      "In load data (64220, 6) (64220,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 49        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73 (584.00 Byte)\n",
      "Trainable params: 73 (584.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "649/725 [=========================>....] - ETA: 0s - loss: 0.9450 - accuracy: 0.5679\n",
      "Epoch 1: val_loss improved from inf to 0.86042, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 880us/step - loss: 0.9356 - accuracy: 0.5712 - val_loss: 0.8604 - val_accuracy: 0.5921\n",
      "Epoch 2/400\n",
      "251/725 [=========>....................] - ETA: 0s - loss: 0.8358 - accuracy: 0.6044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\xai\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671/725 [==========================>...] - ETA: 0s - loss: 0.8050 - accuracy: 0.6398\n",
      "Epoch 2: val_loss improved from 0.86042 to 0.73834, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 734us/step - loss: 0.7988 - accuracy: 0.6450 - val_loss: 0.7383 - val_accuracy: 0.6935\n",
      "Epoch 3/400\n",
      "716/725 [============================>.] - ETA: 0s - loss: 0.6780 - accuracy: 0.7301\n",
      "Epoch 3: val_loss improved from 0.73834 to 0.64938, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 764us/step - loss: 0.6776 - accuracy: 0.7304 - val_loss: 0.6494 - val_accuracy: 0.7571\n",
      "Epoch 4/400\n",
      "654/725 [==========================>...] - ETA: 0s - loss: 0.6211 - accuracy: 0.7711\n",
      "Epoch 4: val_loss improved from 0.64938 to 0.60954, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 739us/step - loss: 0.6192 - accuracy: 0.7712 - val_loss: 0.6095 - val_accuracy: 0.7665\n",
      "Epoch 5/400\n",
      "651/725 [=========================>....] - ETA: 0s - loss: 0.5864 - accuracy: 0.7787\n",
      "Epoch 5: val_loss improved from 0.60954 to 0.57989, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 754us/step - loss: 0.5845 - accuracy: 0.7794 - val_loss: 0.5799 - val_accuracy: 0.7730\n",
      "Epoch 6/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.5598 - accuracy: 0.7946\n",
      "Epoch 6: val_loss improved from 0.57989 to 0.55844, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 747us/step - loss: 0.5579 - accuracy: 0.7960 - val_loss: 0.5584 - val_accuracy: 0.7933\n",
      "Epoch 7/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.5389 - accuracy: 0.8114\n",
      "Epoch 7: val_loss improved from 0.55844 to 0.54216, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 747us/step - loss: 0.5389 - accuracy: 0.8115 - val_loss: 0.5422 - val_accuracy: 0.8042\n",
      "Epoch 8/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.5251 - accuracy: 0.8207\n",
      "Epoch 8: val_loss improved from 0.54216 to 0.52824, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 738us/step - loss: 0.5238 - accuracy: 0.8217 - val_loss: 0.5282 - val_accuracy: 0.8141\n",
      "Epoch 9/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.5104 - accuracy: 0.8259\n",
      "Epoch 9: val_loss improved from 0.52824 to 0.51738, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 731us/step - loss: 0.5116 - accuracy: 0.8258 - val_loss: 0.5174 - val_accuracy: 0.8200\n",
      "Epoch 10/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.4999 - accuracy: 0.8271\n",
      "Epoch 10: val_loss improved from 0.51738 to 0.50767, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 739us/step - loss: 0.5003 - accuracy: 0.8271 - val_loss: 0.5077 - val_accuracy: 0.8217\n",
      "Epoch 11/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.4907 - accuracy: 0.8295\n",
      "Epoch 11: val_loss improved from 0.50767 to 0.49809, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 735us/step - loss: 0.4894 - accuracy: 0.8298 - val_loss: 0.4981 - val_accuracy: 0.8207\n",
      "Epoch 12/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.4800 - accuracy: 0.8340\n",
      "Epoch 12: val_loss improved from 0.49809 to 0.48938, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.4798 - accuracy: 0.8336 - val_loss: 0.4894 - val_accuracy: 0.8277\n",
      "Epoch 13/400\n",
      "684/725 [===========================>..] - ETA: 0s - loss: 0.4705 - accuracy: 0.8389\n",
      "Epoch 13: val_loss improved from 0.48938 to 0.48158, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 723us/step - loss: 0.4711 - accuracy: 0.8382 - val_loss: 0.4816 - val_accuracy: 0.8332\n",
      "Epoch 14/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.4628 - accuracy: 0.8414\n",
      "Epoch 14: val_loss improved from 0.48158 to 0.47524, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 729us/step - loss: 0.4628 - accuracy: 0.8414 - val_loss: 0.4752 - val_accuracy: 0.8328\n",
      "Epoch 15/400\n",
      "681/725 [===========================>..] - ETA: 0s - loss: 0.4571 - accuracy: 0.8428\n",
      "Epoch 15: val_loss improved from 0.47524 to 0.46854, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 741us/step - loss: 0.4561 - accuracy: 0.8433 - val_loss: 0.4685 - val_accuracy: 0.8359\n",
      "Epoch 16/400\n",
      "702/725 [============================>.] - ETA: 0s - loss: 0.4489 - accuracy: 0.8476\n",
      "Epoch 16: val_loss improved from 0.46854 to 0.46074, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 773us/step - loss: 0.4489 - accuracy: 0.8476 - val_loss: 0.4607 - val_accuracy: 0.8421\n",
      "Epoch 17/400\n",
      "682/725 [===========================>..] - ETA: 0s - loss: 0.4419 - accuracy: 0.8531\n",
      "Epoch 17: val_loss improved from 0.46074 to 0.45238, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 727us/step - loss: 0.4403 - accuracy: 0.8537 - val_loss: 0.4524 - val_accuracy: 0.8430\n",
      "Epoch 18/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.4328 - accuracy: 0.8544\n",
      "Epoch 18: val_loss improved from 0.45238 to 0.44470, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 734us/step - loss: 0.4331 - accuracy: 0.8547 - val_loss: 0.4447 - val_accuracy: 0.8469\n",
      "Epoch 19/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.4281 - accuracy: 0.8587\n",
      "Epoch 19: val_loss improved from 0.44470 to 0.43974, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 728us/step - loss: 0.4273 - accuracy: 0.8587 - val_loss: 0.4397 - val_accuracy: 0.8455\n",
      "Epoch 20/400\n",
      "669/725 [==========================>...] - ETA: 0s - loss: 0.4210 - accuracy: 0.8604\n",
      "Epoch 20: val_loss improved from 0.43974 to 0.43340, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 725us/step - loss: 0.4213 - accuracy: 0.8601 - val_loss: 0.4334 - val_accuracy: 0.8493\n",
      "Epoch 21/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.4161 - accuracy: 0.8570\n",
      "Epoch 21: val_loss improved from 0.43340 to 0.42670, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 737us/step - loss: 0.4150 - accuracy: 0.8575 - val_loss: 0.4267 - val_accuracy: 0.8475\n",
      "Epoch 22/400\n",
      "662/725 [==========================>...] - ETA: 0s - loss: 0.4091 - accuracy: 0.8453\n",
      "Epoch 22: val_loss improved from 0.42670 to 0.41912, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 733us/step - loss: 0.4083 - accuracy: 0.8441 - val_loss: 0.4191 - val_accuracy: 0.8091\n",
      "Epoch 23/400\n",
      "667/725 [==========================>...] - ETA: 0s - loss: 0.4015 - accuracy: 0.8207\n",
      "Epoch 23: val_loss improved from 0.41912 to 0.41225, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 739us/step - loss: 0.4016 - accuracy: 0.8208 - val_loss: 0.4122 - val_accuracy: 0.8102\n",
      "Epoch 24/400\n",
      "658/725 [==========================>...] - ETA: 0s - loss: 0.3958 - accuracy: 0.8219\n",
      "Epoch 24: val_loss improved from 0.41225 to 0.40730, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 748us/step - loss: 0.3961 - accuracy: 0.8222 - val_loss: 0.4073 - val_accuracy: 0.8381\n",
      "Epoch 25/400\n",
      "716/725 [============================>.] - ETA: 0s - loss: 0.3916 - accuracy: 0.8282\n",
      "Epoch 25: val_loss improved from 0.40730 to 0.40254, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 771us/step - loss: 0.3917 - accuracy: 0.8283 - val_loss: 0.4025 - val_accuracy: 0.8121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/400\n",
      "683/725 [===========================>..] - ETA: 0s - loss: 0.3887 - accuracy: 0.8279\n",
      "Epoch 26: val_loss improved from 0.40254 to 0.39972, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 714us/step - loss: 0.3879 - accuracy: 0.8298 - val_loss: 0.3997 - val_accuracy: 0.8157\n",
      "Epoch 27/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.3862 - accuracy: 0.8357\n",
      "Epoch 27: val_loss improved from 0.39972 to 0.39734, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 739us/step - loss: 0.3846 - accuracy: 0.8361 - val_loss: 0.3973 - val_accuracy: 0.8133\n",
      "Epoch 28/400\n",
      "672/725 [==========================>...] - ETA: 0s - loss: 0.3817 - accuracy: 0.8360\n",
      "Epoch 28: val_loss improved from 0.39734 to 0.39355, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 761us/step - loss: 0.3819 - accuracy: 0.8378 - val_loss: 0.3936 - val_accuracy: 0.8454\n",
      "Epoch 29/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.3803 - accuracy: 0.8461\n",
      "Epoch 29: val_loss improved from 0.39355 to 0.39228, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 732us/step - loss: 0.3794 - accuracy: 0.8475 - val_loss: 0.3923 - val_accuracy: 0.8466\n",
      "Epoch 30/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.3781 - accuracy: 0.8520\n",
      "Epoch 30: val_loss improved from 0.39228 to 0.39047, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 742us/step - loss: 0.3771 - accuracy: 0.8534 - val_loss: 0.3905 - val_accuracy: 0.8522\n",
      "Epoch 31/400\n",
      "647/725 [=========================>....] - ETA: 0s - loss: 0.3726 - accuracy: 0.8534\n",
      "Epoch 31: val_loss improved from 0.39047 to 0.38710, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 754us/step - loss: 0.3748 - accuracy: 0.8537 - val_loss: 0.3871 - val_accuracy: 0.8566\n",
      "Epoch 32/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.3738 - accuracy: 0.8591\n",
      "Epoch 32: val_loss improved from 0.38710 to 0.38524, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 731us/step - loss: 0.3731 - accuracy: 0.8592 - val_loss: 0.3852 - val_accuracy: 0.8536\n",
      "Epoch 33/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.3709 - accuracy: 0.8631\n",
      "Epoch 33: val_loss improved from 0.38524 to 0.38284, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 732us/step - loss: 0.3711 - accuracy: 0.8634 - val_loss: 0.3828 - val_accuracy: 0.8532\n",
      "Epoch 34/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.3694 - accuracy: 0.8648\n",
      "Epoch 34: val_loss improved from 0.38284 to 0.38041, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 733us/step - loss: 0.3693 - accuracy: 0.8646 - val_loss: 0.3804 - val_accuracy: 0.8546\n",
      "Epoch 35/400\n",
      "649/725 [=========================>....] - ETA: 0s - loss: 0.3663 - accuracy: 0.8650\n",
      "Epoch 35: val_loss did not improve from 0.38041\n",
      "725/725 [==============================] - 1s 728us/step - loss: 0.3677 - accuracy: 0.8648 - val_loss: 0.3805 - val_accuracy: 0.8570\n",
      "Epoch 36/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.3672 - accuracy: 0.8654\n",
      "Epoch 36: val_loss improved from 0.38041 to 0.37948, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 730us/step - loss: 0.3661 - accuracy: 0.8657 - val_loss: 0.3795 - val_accuracy: 0.8575\n",
      "Epoch 37/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.3624 - accuracy: 0.8681\n",
      "Epoch 37: val_loss improved from 0.37948 to 0.37742, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 727us/step - loss: 0.3645 - accuracy: 0.8676 - val_loss: 0.3774 - val_accuracy: 0.8576\n",
      "Epoch 38/400\n",
      "662/725 [==========================>...] - ETA: 0s - loss: 0.3628 - accuracy: 0.8688\n",
      "Epoch 38: val_loss improved from 0.37742 to 0.37538, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 738us/step - loss: 0.3631 - accuracy: 0.8689 - val_loss: 0.3754 - val_accuracy: 0.8579\n",
      "Epoch 39/400\n",
      "653/725 [==========================>...] - ETA: 0s - loss: 0.3616 - accuracy: 0.8676\n",
      "Epoch 39: val_loss improved from 0.37538 to 0.37467, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 742us/step - loss: 0.3617 - accuracy: 0.8681 - val_loss: 0.3747 - val_accuracy: 0.8613\n",
      "Epoch 40/400\n",
      "678/725 [===========================>..] - ETA: 0s - loss: 0.3616 - accuracy: 0.8692\n",
      "Epoch 40: val_loss improved from 0.37467 to 0.37193, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 726us/step - loss: 0.3605 - accuracy: 0.8692 - val_loss: 0.3719 - val_accuracy: 0.8579\n",
      "Epoch 41/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.3587 - accuracy: 0.8689\n",
      "Epoch 41: val_loss improved from 0.37193 to 0.37177, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 739us/step - loss: 0.3593 - accuracy: 0.8691 - val_loss: 0.3718 - val_accuracy: 0.8596\n",
      "Epoch 42/400\n",
      "669/725 [==========================>...] - ETA: 0s - loss: 0.3585 - accuracy: 0.8707\n",
      "Epoch 42: val_loss improved from 0.37177 to 0.36954, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 737us/step - loss: 0.3580 - accuracy: 0.8706 - val_loss: 0.3695 - val_accuracy: 0.8547\n",
      "Epoch 43/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.3555 - accuracy: 0.8700\n",
      "Epoch 43: val_loss improved from 0.36954 to 0.36817, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 743us/step - loss: 0.3570 - accuracy: 0.8696 - val_loss: 0.3682 - val_accuracy: 0.8607\n",
      "Epoch 44/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.3552 - accuracy: 0.8707\n",
      "Epoch 44: val_loss improved from 0.36817 to 0.36786, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 727us/step - loss: 0.3555 - accuracy: 0.8704 - val_loss: 0.3679 - val_accuracy: 0.8618\n",
      "Epoch 45/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.3556 - accuracy: 0.8700\n",
      "Epoch 45: val_loss improved from 0.36786 to 0.36644, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 744us/step - loss: 0.3548 - accuracy: 0.8706 - val_loss: 0.3664 - val_accuracy: 0.8603\n",
      "Epoch 46/400\n",
      "652/725 [=========================>....] - ETA: 0s - loss: 0.3543 - accuracy: 0.8709\n",
      "Epoch 46: val_loss improved from 0.36644 to 0.36547, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 756us/step - loss: 0.3536 - accuracy: 0.8714 - val_loss: 0.3655 - val_accuracy: 0.8605\n",
      "Epoch 47/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.3519 - accuracy: 0.8725\n",
      "Epoch 47: val_loss improved from 0.36547 to 0.36331, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 727us/step - loss: 0.3527 - accuracy: 0.8718 - val_loss: 0.3633 - val_accuracy: 0.8627\n",
      "Epoch 48/400\n",
      "697/725 [===========================>..] - ETA: 0s - loss: 0.3525 - accuracy: 0.8720\n",
      "Epoch 48: val_loss did not improve from 0.36331\n",
      "725/725 [==============================] - 1s 777us/step - loss: 0.3514 - accuracy: 0.8725 - val_loss: 0.3647 - val_accuracy: 0.8620\n",
      "Epoch 49/400\n",
      "676/725 [==========================>...] - ETA: 0s - loss: 0.3506 - accuracy: 0.8719\n",
      "Epoch 49: val_loss improved from 0.36331 to 0.36280, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 721us/step - loss: 0.3506 - accuracy: 0.8720 - val_loss: 0.3628 - val_accuracy: 0.8631\n",
      "Epoch 50/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/725 [==========================>...] - ETA: 0s - loss: 0.3510 - accuracy: 0.8722\n",
      "Epoch 50: val_loss improved from 0.36280 to 0.36092, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 738us/step - loss: 0.3497 - accuracy: 0.8727 - val_loss: 0.3609 - val_accuracy: 0.8621\n",
      "Epoch 51/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.3483 - accuracy: 0.8733\n",
      "Epoch 51: val_loss improved from 0.36092 to 0.36044, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 748us/step - loss: 0.3489 - accuracy: 0.8727 - val_loss: 0.3604 - val_accuracy: 0.8631\n",
      "Epoch 52/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.3479 - accuracy: 0.8726\n",
      "Epoch 52: val_loss improved from 0.36044 to 0.35889, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 732us/step - loss: 0.3480 - accuracy: 0.8728 - val_loss: 0.3589 - val_accuracy: 0.8638\n",
      "Epoch 53/400\n",
      "660/725 [==========================>...] - ETA: 0s - loss: 0.3481 - accuracy: 0.8725\n",
      "Epoch 53: val_loss improved from 0.35889 to 0.35861, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.3471 - accuracy: 0.8729 - val_loss: 0.3586 - val_accuracy: 0.8635\n",
      "Epoch 54/400\n",
      "690/725 [===========================>..] - ETA: 0s - loss: 0.3455 - accuracy: 0.8736\n",
      "Epoch 54: val_loss improved from 0.35861 to 0.35712, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 787us/step - loss: 0.3466 - accuracy: 0.8732 - val_loss: 0.3571 - val_accuracy: 0.8642\n",
      "Epoch 55/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.3459 - accuracy: 0.8726\n",
      "Epoch 55: val_loss improved from 0.35712 to 0.35654, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 746us/step - loss: 0.3457 - accuracy: 0.8731 - val_loss: 0.3565 - val_accuracy: 0.8652\n",
      "Epoch 56/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.3453 - accuracy: 0.8738\n",
      "Epoch 56: val_loss improved from 0.35654 to 0.35647, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 825us/step - loss: 0.3446 - accuracy: 0.8740 - val_loss: 0.3565 - val_accuracy: 0.8643\n",
      "Epoch 57/400\n",
      "657/725 [==========================>...] - ETA: 0s - loss: 0.3444 - accuracy: 0.8744\n",
      "Epoch 57: val_loss improved from 0.35647 to 0.35586, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 805us/step - loss: 0.3440 - accuracy: 0.8743 - val_loss: 0.3559 - val_accuracy: 0.8638\n",
      "Epoch 58/400\n",
      "650/725 [=========================>....] - ETA: 0s - loss: 0.3436 - accuracy: 0.8740\n",
      "Epoch 58: val_loss improved from 0.35586 to 0.35444, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 750us/step - loss: 0.3433 - accuracy: 0.8738 - val_loss: 0.3544 - val_accuracy: 0.8669\n",
      "Epoch 59/400\n",
      "675/725 [==========================>...] - ETA: 0s - loss: 0.3419 - accuracy: 0.8741\n",
      "Epoch 59: val_loss improved from 0.35444 to 0.35371, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 728us/step - loss: 0.3424 - accuracy: 0.8750 - val_loss: 0.3537 - val_accuracy: 0.8629\n",
      "Epoch 60/400\n",
      "675/725 [==========================>...] - ETA: 0s - loss: 0.3422 - accuracy: 0.8744\n",
      "Epoch 60: val_loss improved from 0.35371 to 0.35290, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 725us/step - loss: 0.3421 - accuracy: 0.8743 - val_loss: 0.3529 - val_accuracy: 0.8658\n",
      "Epoch 61/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.3411 - accuracy: 0.8751\n",
      "Epoch 61: val_loss improved from 0.35290 to 0.35230, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.3412 - accuracy: 0.8748 - val_loss: 0.3523 - val_accuracy: 0.8669\n",
      "Epoch 62/400\n",
      "718/725 [============================>.] - ETA: 0s - loss: 0.3411 - accuracy: 0.8749\n",
      "Epoch 62: val_loss improved from 0.35230 to 0.35187, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 779us/step - loss: 0.3408 - accuracy: 0.8750 - val_loss: 0.3519 - val_accuracy: 0.8662\n",
      "Epoch 63/400\n",
      "678/725 [===========================>..] - ETA: 0s - loss: 0.3400 - accuracy: 0.8741\n",
      "Epoch 63: val_loss did not improve from 0.35187\n",
      "725/725 [==============================] - 1s 792us/step - loss: 0.3398 - accuracy: 0.8746 - val_loss: 0.3544 - val_accuracy: 0.8662\n",
      "Epoch 64/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.3391 - accuracy: 0.8749\n",
      "Epoch 64: val_loss improved from 0.35187 to 0.35022, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 847us/step - loss: 0.3393 - accuracy: 0.8747 - val_loss: 0.3502 - val_accuracy: 0.8675\n",
      "Epoch 65/400\n",
      "672/725 [==========================>...] - ETA: 0s - loss: 0.3394 - accuracy: 0.8748\n",
      "Epoch 65: val_loss improved from 0.35022 to 0.34961, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 749us/step - loss: 0.3389 - accuracy: 0.8752 - val_loss: 0.3496 - val_accuracy: 0.8667\n",
      "Epoch 66/400\n",
      "680/725 [===========================>..] - ETA: 0s - loss: 0.3379 - accuracy: 0.8752\n",
      "Epoch 66: val_loss improved from 0.34961 to 0.34869, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 830us/step - loss: 0.3381 - accuracy: 0.8751 - val_loss: 0.3487 - val_accuracy: 0.8669\n",
      "Epoch 67/400\n",
      "720/725 [============================>.] - ETA: 0s - loss: 0.3377 - accuracy: 0.8763\n",
      "Epoch 67: val_loss did not improve from 0.34869\n",
      "725/725 [==============================] - 1s 752us/step - loss: 0.3375 - accuracy: 0.8764 - val_loss: 0.3489 - val_accuracy: 0.8707\n",
      "Epoch 68/400\n",
      "720/725 [============================>.] - ETA: 0s - loss: 0.3372 - accuracy: 0.8749\n",
      "Epoch 68: val_loss improved from 0.34869 to 0.34793, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 767us/step - loss: 0.3369 - accuracy: 0.8752 - val_loss: 0.3479 - val_accuracy: 0.8668\n",
      "Epoch 69/400\n",
      "710/725 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.8750\n",
      "Epoch 69: val_loss improved from 0.34793 to 0.34760, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 778us/step - loss: 0.3366 - accuracy: 0.8751 - val_loss: 0.3476 - val_accuracy: 0.8668\n",
      "Epoch 70/400\n",
      "648/725 [=========================>....] - ETA: 0s - loss: 0.3349 - accuracy: 0.8759\n",
      "Epoch 70: val_loss improved from 0.34760 to 0.34609, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 752us/step - loss: 0.3357 - accuracy: 0.8756 - val_loss: 0.3461 - val_accuracy: 0.8677\n",
      "Epoch 71/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.3363 - accuracy: 0.8746\n",
      "Epoch 71: val_loss improved from 0.34609 to 0.34584, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 722us/step - loss: 0.3352 - accuracy: 0.8750 - val_loss: 0.3458 - val_accuracy: 0.8675\n",
      "Epoch 72/400\n",
      "725/725 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.8763\n",
      "Epoch 72: val_loss did not improve from 0.34584\n",
      "725/725 [==============================] - 1s 740us/step - loss: 0.3344 - accuracy: 0.8763 - val_loss: 0.3465 - val_accuracy: 0.8675\n",
      "Epoch 73/400\n",
      "692/725 [===========================>..] - ETA: 0s - loss: 0.3339 - accuracy: 0.8761\n",
      "Epoch 73: val_loss improved from 0.34584 to 0.34530, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 791us/step - loss: 0.3338 - accuracy: 0.8763 - val_loss: 0.3453 - val_accuracy: 0.8676\n",
      "Epoch 74/400\n",
      "673/725 [==========================>...] - ETA: 0s - loss: 0.3328 - accuracy: 0.8769\n",
      "Epoch 74: val_loss improved from 0.34530 to 0.34387, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725/725 [==============================] - 1s 758us/step - loss: 0.3331 - accuracy: 0.8759 - val_loss: 0.3439 - val_accuracy: 0.8707\n",
      "Epoch 75/400\n",
      "656/725 [==========================>...] - ETA: 0s - loss: 0.3329 - accuracy: 0.8767\n",
      "Epoch 75: val_loss improved from 0.34387 to 0.34371, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 825us/step - loss: 0.3328 - accuracy: 0.8763 - val_loss: 0.3437 - val_accuracy: 0.8677\n",
      "Epoch 76/400\n",
      "672/725 [==========================>...] - ETA: 0s - loss: 0.3312 - accuracy: 0.8758\n",
      "Epoch 76: val_loss improved from 0.34371 to 0.34229, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 736us/step - loss: 0.3320 - accuracy: 0.8759 - val_loss: 0.3423 - val_accuracy: 0.8676\n",
      "Epoch 77/400\n",
      "689/725 [===========================>..] - ETA: 0s - loss: 0.3315 - accuracy: 0.8762\n",
      "Epoch 77: val_loss did not improve from 0.34229\n",
      "725/725 [==============================] - 1s 771us/step - loss: 0.3315 - accuracy: 0.8762 - val_loss: 0.3433 - val_accuracy: 0.8676\n",
      "Epoch 78/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.3303 - accuracy: 0.8772\n",
      "Epoch 78: val_loss improved from 0.34229 to 0.34115, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 760us/step - loss: 0.3311 - accuracy: 0.8765 - val_loss: 0.3411 - val_accuracy: 0.8681\n",
      "Epoch 79/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.8765\n",
      "Epoch 79: val_loss improved from 0.34115 to 0.34060, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 757us/step - loss: 0.3308 - accuracy: 0.8764 - val_loss: 0.3406 - val_accuracy: 0.8681\n",
      "Epoch 80/400\n",
      "686/725 [===========================>..] - ETA: 0s - loss: 0.3293 - accuracy: 0.8773\n",
      "Epoch 80: val_loss improved from 0.34060 to 0.33996, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 821us/step - loss: 0.3302 - accuracy: 0.8769 - val_loss: 0.3400 - val_accuracy: 0.8708\n",
      "Epoch 81/400\n",
      "715/725 [============================>.] - ETA: 0s - loss: 0.3298 - accuracy: 0.8769\n",
      "Epoch 81: val_loss improved from 0.33996 to 0.33934, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 781us/step - loss: 0.3297 - accuracy: 0.8770 - val_loss: 0.3393 - val_accuracy: 0.8697\n",
      "Epoch 82/400\n",
      "646/725 [=========================>....] - ETA: 0s - loss: 0.3291 - accuracy: 0.8778\n",
      "Epoch 82: val_loss did not improve from 0.33934\n",
      "725/725 [==============================] - 1s 737us/step - loss: 0.3292 - accuracy: 0.8774 - val_loss: 0.3394 - val_accuracy: 0.8692\n",
      "Epoch 83/400\n",
      "723/725 [============================>.] - ETA: 0s - loss: 0.3289 - accuracy: 0.8774\n",
      "Epoch 83: val_loss did not improve from 0.33934\n",
      "725/725 [==============================] - 1s 769us/step - loss: 0.3287 - accuracy: 0.8775 - val_loss: 0.3415 - val_accuracy: 0.8692\n",
      "Epoch 84/400\n",
      "697/725 [===========================>..] - ETA: 0s - loss: 0.3285 - accuracy: 0.8779\n",
      "Epoch 84: val_loss improved from 0.33934 to 0.33922, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 789us/step - loss: 0.3287 - accuracy: 0.8778 - val_loss: 0.3392 - val_accuracy: 0.8695\n",
      "Epoch 85/400\n",
      "660/725 [==========================>...] - ETA: 0s - loss: 0.3275 - accuracy: 0.8779\n",
      "Epoch 85: val_loss improved from 0.33922 to 0.33821, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.3280 - accuracy: 0.8777 - val_loss: 0.3382 - val_accuracy: 0.8703\n",
      "Epoch 86/400\n",
      "664/725 [==========================>...] - ETA: 0s - loss: 0.3281 - accuracy: 0.8776\n",
      "Epoch 86: val_loss did not improve from 0.33821\n",
      "725/725 [==============================] - 1s 723us/step - loss: 0.3276 - accuracy: 0.8778 - val_loss: 0.3383 - val_accuracy: 0.8687\n",
      "Epoch 87/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.3266 - accuracy: 0.8784\n",
      "Epoch 87: val_loss improved from 0.33821 to 0.33738, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 751us/step - loss: 0.3271 - accuracy: 0.8781 - val_loss: 0.3374 - val_accuracy: 0.8702\n",
      "Epoch 88/400\n",
      "724/725 [============================>.] - ETA: 0s - loss: 0.3268 - accuracy: 0.8780\n",
      "Epoch 88: val_loss improved from 0.33738 to 0.33654, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 756us/step - loss: 0.3268 - accuracy: 0.8781 - val_loss: 0.3365 - val_accuracy: 0.8703\n",
      "Epoch 89/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.3262 - accuracy: 0.8790\n",
      "Epoch 89: val_loss did not improve from 0.33654\n",
      "725/725 [==============================] - 1s 712us/step - loss: 0.3263 - accuracy: 0.8790 - val_loss: 0.3388 - val_accuracy: 0.8757\n",
      "Epoch 90/400\n",
      "676/725 [==========================>...] - ETA: 0s - loss: 0.3261 - accuracy: 0.8792\n",
      "Epoch 90: val_loss improved from 0.33654 to 0.33586, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 740us/step - loss: 0.3259 - accuracy: 0.8794 - val_loss: 0.3359 - val_accuracy: 0.8708\n",
      "Epoch 91/400\n",
      "695/725 [===========================>..] - ETA: 0s - loss: 0.3254 - accuracy: 0.8794\n",
      "Epoch 91: val_loss improved from 0.33586 to 0.33488, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 791us/step - loss: 0.3256 - accuracy: 0.8794 - val_loss: 0.3349 - val_accuracy: 0.8721\n",
      "Epoch 92/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.3253 - accuracy: 0.8791\n",
      "Epoch 92: val_loss did not improve from 0.33488\n",
      "725/725 [==============================] - 1s 728us/step - loss: 0.3252 - accuracy: 0.8790 - val_loss: 0.3355 - val_accuracy: 0.8664\n",
      "Epoch 93/400\n",
      "653/725 [==========================>...] - ETA: 0s - loss: 0.3258 - accuracy: 0.8796\n",
      "Epoch 93: val_loss did not improve from 0.33488\n",
      "725/725 [==============================] - 1s 732us/step - loss: 0.3246 - accuracy: 0.8798 - val_loss: 0.3361 - val_accuracy: 0.8698\n",
      "Epoch 94/400\n",
      "660/725 [==========================>...] - ETA: 0s - loss: 0.3242 - accuracy: 0.8797\n",
      "Epoch 94: val_loss improved from 0.33488 to 0.33405, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 741us/step - loss: 0.3244 - accuracy: 0.8796 - val_loss: 0.3341 - val_accuracy: 0.8710\n",
      "Epoch 95/400\n",
      "658/725 [==========================>...] - ETA: 0s - loss: 0.3242 - accuracy: 0.8803\n",
      "Epoch 95: val_loss improved from 0.33405 to 0.33315, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 748us/step - loss: 0.3241 - accuracy: 0.8801 - val_loss: 0.3331 - val_accuracy: 0.8763\n",
      "Epoch 96/400\n",
      "725/725 [==============================] - ETA: 0s - loss: 0.3238 - accuracy: 0.8811\n",
      "Epoch 96: val_loss improved from 0.33315 to 0.33275, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 760us/step - loss: 0.3238 - accuracy: 0.8811 - val_loss: 0.3327 - val_accuracy: 0.8721\n",
      "Epoch 97/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.3238 - accuracy: 0.8810\n",
      "Epoch 97: val_loss did not improve from 0.33275\n",
      "725/725 [==============================] - 1s 720us/step - loss: 0.3234 - accuracy: 0.8813 - val_loss: 0.3329 - val_accuracy: 0.8743\n",
      "Epoch 98/400\n",
      "656/725 [==========================>...] - ETA: 0s - loss: 0.3222 - accuracy: 0.8810\n",
      "Epoch 98: val_loss did not improve from 0.33275\n",
      "725/725 [==============================] - 1s 722us/step - loss: 0.3231 - accuracy: 0.8810 - val_loss: 0.3328 - val_accuracy: 0.8763\n",
      "Epoch 99/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.3232 - accuracy: 0.8810\n",
      "Epoch 99: val_loss improved from 0.33275 to 0.33175, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 740us/step - loss: 0.3228 - accuracy: 0.8815 - val_loss: 0.3317 - val_accuracy: 0.8712\n",
      "Epoch 100/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654/725 [==========================>...] - ETA: 0s - loss: 0.3240 - accuracy: 0.8796\n",
      "Epoch 100: val_loss improved from 0.33175 to 0.33145, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 774us/step - loss: 0.3224 - accuracy: 0.8802 - val_loss: 0.3315 - val_accuracy: 0.8761\n",
      "Epoch 101/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.3219 - accuracy: 0.8810\n",
      "Epoch 101: val_loss did not improve from 0.33145\n",
      "725/725 [==============================] - 1s 720us/step - loss: 0.3217 - accuracy: 0.8811 - val_loss: 0.3323 - val_accuracy: 0.8737\n",
      "Epoch 102/400\n",
      "676/725 [==========================>...] - ETA: 0s - loss: 0.3214 - accuracy: 0.8827\n",
      "Epoch 102: val_loss improved from 0.33145 to 0.33128, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 734us/step - loss: 0.3216 - accuracy: 0.8824 - val_loss: 0.3313 - val_accuracy: 0.8730\n",
      "Epoch 103/400\n",
      "721/725 [============================>.] - ETA: 0s - loss: 0.3217 - accuracy: 0.8810\n",
      "Epoch 103: val_loss improved from 0.33128 to 0.33112, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 790us/step - loss: 0.3215 - accuracy: 0.8811 - val_loss: 0.3311 - val_accuracy: 0.8764\n",
      "Epoch 104/400\n",
      "677/725 [===========================>..] - ETA: 0s - loss: 0.3213 - accuracy: 0.8820\n",
      "Epoch 104: val_loss did not improve from 0.33112\n",
      "725/725 [==============================] - 1s 879us/step - loss: 0.3209 - accuracy: 0.8825 - val_loss: 0.3321 - val_accuracy: 0.8719\n",
      "Epoch 105/400\n",
      "656/725 [==========================>...] - ETA: 0s - loss: 0.3211 - accuracy: 0.8811\n",
      "Epoch 105: val_loss improved from 0.33112 to 0.33052, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 746us/step - loss: 0.3207 - accuracy: 0.8818 - val_loss: 0.3305 - val_accuracy: 0.8792\n",
      "Epoch 106/400\n",
      "658/725 [==========================>...] - ETA: 0s - loss: 0.3204 - accuracy: 0.8829\n",
      "Epoch 106: val_loss did not improve from 0.33052\n",
      "725/725 [==============================] - 1s 726us/step - loss: 0.3204 - accuracy: 0.8830 - val_loss: 0.3315 - val_accuracy: 0.8730\n",
      "Epoch 107/400\n",
      "658/725 [==========================>...] - ETA: 0s - loss: 0.3210 - accuracy: 0.8818\n",
      "Epoch 107: val_loss improved from 0.33052 to 0.32950, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 740us/step - loss: 0.3200 - accuracy: 0.8825 - val_loss: 0.3295 - val_accuracy: 0.8703\n",
      "Epoch 108/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.3210 - accuracy: 0.8821\n",
      "Epoch 108: val_loss did not improve from 0.32950\n",
      "725/725 [==============================] - 1s 724us/step - loss: 0.3195 - accuracy: 0.8826 - val_loss: 0.3303 - val_accuracy: 0.8723\n",
      "Epoch 109/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.3190 - accuracy: 0.8819\n",
      "Epoch 109: val_loss improved from 0.32950 to 0.32807, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.3195 - accuracy: 0.8819 - val_loss: 0.3281 - val_accuracy: 0.8758\n",
      "Epoch 110/400\n",
      "658/725 [==========================>...] - ETA: 0s - loss: 0.3194 - accuracy: 0.8832\n",
      "Epoch 110: val_loss did not improve from 0.32807\n",
      "725/725 [==============================] - 1s 724us/step - loss: 0.3193 - accuracy: 0.8834 - val_loss: 0.3286 - val_accuracy: 0.8754\n",
      "Epoch 111/400\n",
      "657/725 [==========================>...] - ETA: 0s - loss: 0.3199 - accuracy: 0.8819\n",
      "Epoch 111: val_loss did not improve from 0.32807\n",
      "725/725 [==============================] - 1s 721us/step - loss: 0.3187 - accuracy: 0.8825 - val_loss: 0.3283 - val_accuracy: 0.8731\n",
      "Epoch 112/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.3191 - accuracy: 0.8834\n",
      "Epoch 112: val_loss improved from 0.32807 to 0.32763, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 746us/step - loss: 0.3186 - accuracy: 0.8837 - val_loss: 0.3276 - val_accuracy: 0.8780\n",
      "Epoch 113/400\n",
      "663/725 [==========================>...] - ETA: 0s - loss: 0.3193 - accuracy: 0.8832\n",
      "Epoch 113: val_loss did not improve from 0.32763\n",
      "725/725 [==============================] - 1s 715us/step - loss: 0.3181 - accuracy: 0.8831 - val_loss: 0.3277 - val_accuracy: 0.8759\n",
      "Epoch 114/400\n",
      "660/725 [==========================>...] - ETA: 0s - loss: 0.3168 - accuracy: 0.8842\n",
      "Epoch 114: val_loss improved from 0.32763 to 0.32744, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 741us/step - loss: 0.3179 - accuracy: 0.8838 - val_loss: 0.3274 - val_accuracy: 0.8786\n",
      "Epoch 115/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.3169 - accuracy: 0.8847\n",
      "Epoch 115: val_loss improved from 0.32744 to 0.32689, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 747us/step - loss: 0.3176 - accuracy: 0.8841 - val_loss: 0.3269 - val_accuracy: 0.8736\n",
      "Epoch 116/400\n",
      "667/725 [==========================>...] - ETA: 0s - loss: 0.3170 - accuracy: 0.8829\n",
      "Epoch 116: val_loss did not improve from 0.32689\n",
      "725/725 [==============================] - 1s 719us/step - loss: 0.3170 - accuracy: 0.8834 - val_loss: 0.3281 - val_accuracy: 0.8707\n",
      "Epoch 117/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.3174 - accuracy: 0.8841\n",
      "Epoch 117: val_loss improved from 0.32689 to 0.32588, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 742us/step - loss: 0.3166 - accuracy: 0.8847 - val_loss: 0.3259 - val_accuracy: 0.8748\n",
      "Epoch 118/400\n",
      "664/725 [==========================>...] - ETA: 0s - loss: 0.3169 - accuracy: 0.8840\n",
      "Epoch 118: val_loss did not improve from 0.32588\n",
      "725/725 [==============================] - 1s 729us/step - loss: 0.3171 - accuracy: 0.8841 - val_loss: 0.3260 - val_accuracy: 0.8756\n",
      "Epoch 119/400\n",
      "657/725 [==========================>...] - ETA: 0s - loss: 0.3172 - accuracy: 0.8845\n",
      "Epoch 119: val_loss did not improve from 0.32588\n",
      "725/725 [==============================] - 1s 726us/step - loss: 0.3163 - accuracy: 0.8847 - val_loss: 0.3260 - val_accuracy: 0.8743\n",
      "Epoch 120/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.3151 - accuracy: 0.8848\n",
      "Epoch 120: val_loss did not improve from 0.32588\n",
      "725/725 [==============================] - 1s 714us/step - loss: 0.3163 - accuracy: 0.8845 - val_loss: 0.3265 - val_accuracy: 0.8796\n",
      "Epoch 121/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.3163 - accuracy: 0.8839\n",
      "Epoch 121: val_loss improved from 0.32588 to 0.32489, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 731us/step - loss: 0.3161 - accuracy: 0.8840 - val_loss: 0.3249 - val_accuracy: 0.8789\n",
      "Epoch 122/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.3160 - accuracy: 0.8849\n",
      "Epoch 122: val_loss did not improve from 0.32489\n",
      "725/725 [==============================] - 1s 718us/step - loss: 0.3157 - accuracy: 0.8848 - val_loss: 0.3284 - val_accuracy: 0.8702\n",
      "Epoch 123/400\n",
      "663/725 [==========================>...] - ETA: 0s - loss: 0.3158 - accuracy: 0.8854\n",
      "Epoch 123: val_loss did not improve from 0.32489\n",
      "725/725 [==============================] - 1s 718us/step - loss: 0.3154 - accuracy: 0.8854 - val_loss: 0.3284 - val_accuracy: 0.8756\n",
      "Epoch 124/400\n",
      "667/725 [==========================>...] - ETA: 0s - loss: 0.3135 - accuracy: 0.8851\n",
      "Epoch 124: val_loss did not improve from 0.32489\n",
      "725/725 [==============================] - 1s 717us/step - loss: 0.3153 - accuracy: 0.8844 - val_loss: 0.3254 - val_accuracy: 0.8781\n",
      "Epoch 125/400\n",
      "678/725 [===========================>..] - ETA: 0s - loss: 0.3137 - accuracy: 0.8860\n",
      "Epoch 125: val_loss did not improve from 0.32489\n",
      "725/725 [==============================] - 1s 706us/step - loss: 0.3149 - accuracy: 0.8856 - val_loss: 0.3257 - val_accuracy: 0.8757\n",
      "Epoch 126/400\n",
      "678/725 [===========================>..] - ETA: 0s - loss: 0.3155 - accuracy: 0.8861\n",
      "Epoch 126: val_loss improved from 0.32489 to 0.32419, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725/725 [==============================] - 1s 726us/step - loss: 0.3144 - accuracy: 0.8862 - val_loss: 0.3242 - val_accuracy: 0.8758\n",
      "Epoch 127/400\n",
      "725/725 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.8858\n",
      "Epoch 127: val_loss improved from 0.32419 to 0.32299, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 757us/step - loss: 0.3140 - accuracy: 0.8858 - val_loss: 0.3230 - val_accuracy: 0.8783\n",
      "Epoch 128/400\n",
      "677/725 [===========================>..] - ETA: 0s - loss: 0.3131 - accuracy: 0.8867\n",
      "Epoch 128: val_loss did not improve from 0.32299\n",
      "725/725 [==============================] - 1s 709us/step - loss: 0.3141 - accuracy: 0.8864 - val_loss: 0.3230 - val_accuracy: 0.8802\n",
      "Epoch 129/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.3141 - accuracy: 0.8868\n",
      "Epoch 129: val_loss did not improve from 0.32299\n",
      "725/725 [==============================] - 1s 715us/step - loss: 0.3137 - accuracy: 0.8869 - val_loss: 0.3231 - val_accuracy: 0.8715\n",
      "Epoch 130/400\n",
      "677/725 [===========================>..] - ETA: 0s - loss: 0.3131 - accuracy: 0.8860\n",
      "Epoch 130: val_loss improved from 0.32299 to 0.32262, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 730us/step - loss: 0.3135 - accuracy: 0.8860 - val_loss: 0.3226 - val_accuracy: 0.8784\n",
      "Epoch 131/400\n",
      "644/725 [=========================>....] - ETA: 0s - loss: 0.3144 - accuracy: 0.8859\n",
      "Epoch 131: val_loss improved from 0.32262 to 0.32190, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 755us/step - loss: 0.3134 - accuracy: 0.8858 - val_loss: 0.3219 - val_accuracy: 0.8745\n",
      "Epoch 132/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.3112 - accuracy: 0.8868\n",
      "Epoch 132: val_loss did not improve from 0.32190\n",
      "725/725 [==============================] - 1s 714us/step - loss: 0.3129 - accuracy: 0.8862 - val_loss: 0.3228 - val_accuracy: 0.8757\n",
      "Epoch 133/400\n",
      "672/725 [==========================>...] - ETA: 0s - loss: 0.3128 - accuracy: 0.8873\n",
      "Epoch 133: val_loss improved from 0.32190 to 0.32183, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 731us/step - loss: 0.3127 - accuracy: 0.8876 - val_loss: 0.3218 - val_accuracy: 0.8798\n",
      "Epoch 134/400\n",
      "655/725 [==========================>...] - ETA: 0s - loss: 0.3125 - accuracy: 0.8867\n",
      "Epoch 134: val_loss did not improve from 0.32183\n",
      "725/725 [==============================] - 1s 726us/step - loss: 0.3125 - accuracy: 0.8870 - val_loss: 0.3233 - val_accuracy: 0.8817\n",
      "Epoch 135/400\n",
      "653/725 [==========================>...] - ETA: 0s - loss: 0.3118 - accuracy: 0.8873\n",
      "Epoch 135: val_loss improved from 0.32183 to 0.32169, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 758us/step - loss: 0.3123 - accuracy: 0.8873 - val_loss: 0.3217 - val_accuracy: 0.8801\n",
      "Epoch 136/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.3132 - accuracy: 0.8874\n",
      "Epoch 136: val_loss improved from 0.32169 to 0.32133, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 741us/step - loss: 0.3121 - accuracy: 0.8880 - val_loss: 0.3213 - val_accuracy: 0.8758\n",
      "Epoch 137/400\n",
      "672/725 [==========================>...] - ETA: 0s - loss: 0.3104 - accuracy: 0.8872\n",
      "Epoch 137: val_loss did not improve from 0.32133\n",
      "725/725 [==============================] - 1s 718us/step - loss: 0.3118 - accuracy: 0.8872 - val_loss: 0.3217 - val_accuracy: 0.8813\n",
      "Epoch 138/400\n",
      "667/725 [==========================>...] - ETA: 0s - loss: 0.3114 - accuracy: 0.8893\n",
      "Epoch 138: val_loss improved from 0.32133 to 0.31973, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 748us/step - loss: 0.3117 - accuracy: 0.8886 - val_loss: 0.3197 - val_accuracy: 0.8791\n",
      "Epoch 139/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.3125 - accuracy: 0.8877\n",
      "Epoch 139: val_loss did not improve from 0.31973\n",
      "725/725 [==============================] - 1s 727us/step - loss: 0.3114 - accuracy: 0.8878 - val_loss: 0.3202 - val_accuracy: 0.8798\n",
      "Epoch 140/400\n",
      "660/725 [==========================>...] - ETA: 0s - loss: 0.3121 - accuracy: 0.8879\n",
      "Epoch 140: val_loss did not improve from 0.31973\n",
      "725/725 [==============================] - 1s 723us/step - loss: 0.3110 - accuracy: 0.8883 - val_loss: 0.3207 - val_accuracy: 0.8803\n",
      "Epoch 141/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.3102 - accuracy: 0.8887\n",
      "Epoch 141: val_loss did not improve from 0.31973\n",
      "725/725 [==============================] - 1s 717us/step - loss: 0.3105 - accuracy: 0.8886 - val_loss: 0.3203 - val_accuracy: 0.8826\n",
      "Epoch 142/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.3111 - accuracy: 0.8889\n",
      "Epoch 142: val_loss did not improve from 0.31973\n",
      "725/725 [==============================] - 1s 714us/step - loss: 0.3102 - accuracy: 0.8890 - val_loss: 0.3216 - val_accuracy: 0.8729\n",
      "Epoch 143/400\n",
      "672/725 [==========================>...] - ETA: 0s - loss: 0.3102 - accuracy: 0.8884\n",
      "Epoch 143: val_loss improved from 0.31973 to 0.31929, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 742us/step - loss: 0.3106 - accuracy: 0.8885 - val_loss: 0.3193 - val_accuracy: 0.8798\n",
      "Epoch 144/400\n",
      "652/725 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.8887\n",
      "Epoch 144: val_loss did not improve from 0.31929\n",
      "725/725 [==============================] - 1s 727us/step - loss: 0.3100 - accuracy: 0.8888 - val_loss: 0.3199 - val_accuracy: 0.8835\n",
      "Epoch 145/400\n",
      "682/725 [===========================>..] - ETA: 0s - loss: 0.3105 - accuracy: 0.8894\n",
      "Epoch 145: val_loss did not improve from 0.31929\n",
      "725/725 [==============================] - 1s 784us/step - loss: 0.3099 - accuracy: 0.8897 - val_loss: 0.3206 - val_accuracy: 0.8798\n",
      "Epoch 146/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.3097 - accuracy: 0.8896\n",
      "Epoch 146: val_loss improved from 0.31929 to 0.31745, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 746us/step - loss: 0.3096 - accuracy: 0.8898 - val_loss: 0.3175 - val_accuracy: 0.8822\n",
      "Epoch 147/400\n",
      "722/725 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.8889\n",
      "Epoch 147: val_loss did not improve from 0.31745\n",
      "725/725 [==============================] - 1s 735us/step - loss: 0.3094 - accuracy: 0.8890 - val_loss: 0.3209 - val_accuracy: 0.8853\n",
      "Epoch 148/400\n",
      "667/725 [==========================>...] - ETA: 0s - loss: 0.3088 - accuracy: 0.8888\n",
      "Epoch 148: val_loss did not improve from 0.31745\n",
      "725/725 [==============================] - 1s 719us/step - loss: 0.3094 - accuracy: 0.8888 - val_loss: 0.3182 - val_accuracy: 0.8841\n",
      "Epoch 149/400\n",
      "655/725 [==========================>...] - ETA: 0s - loss: 0.3090 - accuracy: 0.8903\n",
      "Epoch 149: val_loss did not improve from 0.31745\n",
      "725/725 [==============================] - 1s 722us/step - loss: 0.3091 - accuracy: 0.8899 - val_loss: 0.3186 - val_accuracy: 0.8786\n",
      "Epoch 150/400\n",
      "679/725 [===========================>..] - ETA: 0s - loss: 0.3098 - accuracy: 0.8884\n",
      "Epoch 150: val_loss did not improve from 0.31745\n",
      "725/725 [==============================] - 1s 708us/step - loss: 0.3090 - accuracy: 0.8879 - val_loss: 0.3187 - val_accuracy: 0.8829\n",
      "Epoch 151/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.3078 - accuracy: 0.8906\n",
      "Epoch 151: val_loss improved from 0.31745 to 0.31733, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 731us/step - loss: 0.3087 - accuracy: 0.8897 - val_loss: 0.3173 - val_accuracy: 0.8824\n",
      "Epoch 152/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.3077 - accuracy: 0.8897\n",
      "Epoch 152: val_loss did not improve from 0.31733\n",
      "725/725 [==============================] - 1s 805us/step - loss: 0.3085 - accuracy: 0.8898 - val_loss: 0.3182 - val_accuracy: 0.8818\n",
      "Epoch 153/400\n",
      "663/725 [==========================>...] - ETA: 0s - loss: 0.3073 - accuracy: 0.8899\n",
      "Epoch 153: val_loss improved from 0.31733 to 0.31634, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725/725 [==============================] - 1s 742us/step - loss: 0.3084 - accuracy: 0.8895 - val_loss: 0.3163 - val_accuracy: 0.8835\n",
      "Epoch 154/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.3080 - accuracy: 0.8903\n",
      "Epoch 154: val_loss did not improve from 0.31634\n",
      "725/725 [==============================] - 1s 731us/step - loss: 0.3081 - accuracy: 0.8899 - val_loss: 0.3167 - val_accuracy: 0.8848\n",
      "Epoch 155/400\n",
      "680/725 [===========================>..] - ETA: 0s - loss: 0.3078 - accuracy: 0.8900\n",
      "Epoch 155: val_loss did not improve from 0.31634\n",
      "725/725 [==============================] - 1s 705us/step - loss: 0.3079 - accuracy: 0.8899 - val_loss: 0.3168 - val_accuracy: 0.8867\n",
      "Epoch 156/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.3074 - accuracy: 0.8903\n",
      "Epoch 156: val_loss did not improve from 0.31634\n",
      "725/725 [==============================] - 1s 718us/step - loss: 0.3079 - accuracy: 0.8899 - val_loss: 0.3164 - val_accuracy: 0.8828\n",
      "Epoch 157/400\n",
      "689/725 [===========================>..] - ETA: 0s - loss: 0.3069 - accuracy: 0.8900\n",
      "Epoch 157: val_loss did not improve from 0.31634\n",
      "725/725 [==============================] - 1s 699us/step - loss: 0.3077 - accuracy: 0.8897 - val_loss: 0.3186 - val_accuracy: 0.8814\n",
      "Epoch 158/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.3072 - accuracy: 0.8900\n",
      "Epoch 158: val_loss improved from 0.31634 to 0.31557, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 743us/step - loss: 0.3075 - accuracy: 0.8901 - val_loss: 0.3156 - val_accuracy: 0.8826\n",
      "Epoch 159/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.3082 - accuracy: 0.8898\n",
      "Epoch 159: val_loss did not improve from 0.31557\n",
      "725/725 [==============================] - 1s 708us/step - loss: 0.3072 - accuracy: 0.8900 - val_loss: 0.3157 - val_accuracy: 0.8811\n",
      "Epoch 160/400\n",
      "678/725 [===========================>..] - ETA: 0s - loss: 0.3083 - accuracy: 0.8895\n",
      "Epoch 160: val_loss did not improve from 0.31557\n",
      "725/725 [==============================] - 1s 708us/step - loss: 0.3071 - accuracy: 0.8902 - val_loss: 0.3159 - val_accuracy: 0.8826\n",
      "Epoch 161/400\n",
      "687/725 [===========================>..] - ETA: 0s - loss: 0.3070 - accuracy: 0.8904\n",
      "Epoch 161: val_loss did not improve from 0.31557\n",
      "725/725 [==============================] - 1s 697us/step - loss: 0.3067 - accuracy: 0.8902 - val_loss: 0.3166 - val_accuracy: 0.8824\n",
      "Epoch 162/400\n",
      "721/725 [============================>.] - ETA: 0s - loss: 0.3071 - accuracy: 0.8906\n",
      "Epoch 162: val_loss improved from 0.31557 to 0.31414, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 768us/step - loss: 0.3068 - accuracy: 0.8907 - val_loss: 0.3141 - val_accuracy: 0.8846\n",
      "Epoch 163/400\n",
      "682/725 [===========================>..] - ETA: 0s - loss: 0.3056 - accuracy: 0.8906\n",
      "Epoch 163: val_loss did not improve from 0.31414\n",
      "725/725 [==============================] - 1s 708us/step - loss: 0.3064 - accuracy: 0.8901 - val_loss: 0.3160 - val_accuracy: 0.8841\n",
      "Epoch 164/400\n",
      "679/725 [===========================>..] - ETA: 0s - loss: 0.3047 - accuracy: 0.8915\n",
      "Epoch 164: val_loss did not improve from 0.31414\n",
      "725/725 [==============================] - 1s 707us/step - loss: 0.3065 - accuracy: 0.8908 - val_loss: 0.3165 - val_accuracy: 0.8847\n",
      "Epoch 165/400\n",
      "673/725 [==========================>...] - ETA: 0s - loss: 0.3073 - accuracy: 0.8895\n",
      "Epoch 165: val_loss did not improve from 0.31414\n",
      "725/725 [==============================] - 1s 710us/step - loss: 0.3062 - accuracy: 0.8901 - val_loss: 0.3152 - val_accuracy: 0.8813\n",
      "Epoch 166/400\n",
      "682/725 [===========================>..] - ETA: 0s - loss: 0.3062 - accuracy: 0.8901\n",
      "Epoch 166: val_loss did not improve from 0.31414\n",
      "725/725 [==============================] - 1s 776us/step - loss: 0.3060 - accuracy: 0.8899 - val_loss: 0.3143 - val_accuracy: 0.8833\n",
      "Epoch 167/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.3058 - accuracy: 0.8902\n",
      "Epoch 167: val_loss did not improve from 0.31414\n",
      "725/725 [==============================] - 1s 711us/step - loss: 0.3060 - accuracy: 0.8904 - val_loss: 0.3157 - val_accuracy: 0.8784\n",
      "Epoch 168/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.3059 - accuracy: 0.8915\n",
      "Epoch 168: val_loss did not improve from 0.31414\n",
      "725/725 [==============================] - 1s 712us/step - loss: 0.3056 - accuracy: 0.8915 - val_loss: 0.3161 - val_accuracy: 0.8824\n",
      "Epoch 169/400\n",
      "684/725 [===========================>..] - ETA: 0s - loss: 0.3046 - accuracy: 0.8888\n",
      "Epoch 169: val_loss improved from 0.31414 to 0.31367, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 724us/step - loss: 0.3054 - accuracy: 0.8894 - val_loss: 0.3137 - val_accuracy: 0.8850\n",
      "Epoch 170/400\n",
      "720/725 [============================>.] - ETA: 0s - loss: 0.3056 - accuracy: 0.8915\n",
      "Epoch 170: val_loss did not improve from 0.31367\n",
      "725/725 [==============================] - 1s 738us/step - loss: 0.3055 - accuracy: 0.8916 - val_loss: 0.3143 - val_accuracy: 0.8826\n",
      "Epoch 171/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.3058 - accuracy: 0.8912\n",
      "Epoch 171: val_loss did not improve from 0.31367\n",
      "725/725 [==============================] - 1s 718us/step - loss: 0.3052 - accuracy: 0.8913 - val_loss: 0.3139 - val_accuracy: 0.8844\n",
      "Epoch 172/400\n",
      "654/725 [==========================>...] - ETA: 0s - loss: 0.3049 - accuracy: 0.8909\n",
      "Epoch 172: val_loss did not improve from 0.31367\n",
      "725/725 [==============================] - 1s 736us/step - loss: 0.3049 - accuracy: 0.8909 - val_loss: 0.3142 - val_accuracy: 0.8877\n",
      "Epoch 173/400\n",
      "657/725 [==========================>...] - ETA: 0s - loss: 0.3036 - accuracy: 0.8911\n",
      "Epoch 173: val_loss improved from 0.31367 to 0.31270, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 748us/step - loss: 0.3048 - accuracy: 0.8905 - val_loss: 0.3127 - val_accuracy: 0.8875\n",
      "Epoch 174/400\n",
      "658/725 [==========================>...] - ETA: 0s - loss: 0.3038 - accuracy: 0.8920\n",
      "Epoch 174: val_loss did not improve from 0.31270\n",
      "725/725 [==============================] - 1s 724us/step - loss: 0.3050 - accuracy: 0.8914 - val_loss: 0.3145 - val_accuracy: 0.8834\n",
      "Epoch 175/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.3059 - accuracy: 0.8911\n",
      "Epoch 175: val_loss did not improve from 0.31270\n",
      "725/725 [==============================] - 1s 716us/step - loss: 0.3046 - accuracy: 0.8911 - val_loss: 0.3140 - val_accuracy: 0.8856\n",
      "Epoch 176/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.3051 - accuracy: 0.8912\n",
      "Epoch 176: val_loss did not improve from 0.31270\n",
      "725/725 [==============================] - 1s 827us/step - loss: 0.3044 - accuracy: 0.8919 - val_loss: 0.3133 - val_accuracy: 0.8868\n",
      "Epoch 177/400\n",
      "669/725 [==========================>...] - ETA: 0s - loss: 0.3058 - accuracy: 0.8920\n",
      "Epoch 177: val_loss improved from 0.31270 to 0.31243, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 825us/step - loss: 0.3040 - accuracy: 0.8922 - val_loss: 0.3124 - val_accuracy: 0.8863\n",
      "Epoch 178/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.3032 - accuracy: 0.8931\n",
      "Epoch 178: val_loss improved from 0.31243 to 0.31185, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 773us/step - loss: 0.3034 - accuracy: 0.8930 - val_loss: 0.3118 - val_accuracy: 0.8841\n",
      "Epoch 179/400\n",
      "650/725 [=========================>....] - ETA: 0s - loss: 0.3018 - accuracy: 0.8937\n",
      "Epoch 179: val_loss did not improve from 0.31185\n",
      "725/725 [==============================] - 1s 737us/step - loss: 0.3031 - accuracy: 0.8931 - val_loss: 0.3121 - val_accuracy: 0.8905\n",
      "Epoch 180/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.3016 - accuracy: 0.8946\n",
      "Epoch 180: val_loss did not improve from 0.31185\n",
      "725/725 [==============================] - 1s 712us/step - loss: 0.3028 - accuracy: 0.8943 - val_loss: 0.3121 - val_accuracy: 0.8878\n",
      "Epoch 181/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/725 [==========================>...] - ETA: 0s - loss: 0.3019 - accuracy: 0.8929\n",
      "Epoch 181: val_loss improved from 0.31185 to 0.31094, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 741us/step - loss: 0.3028 - accuracy: 0.8930 - val_loss: 0.3109 - val_accuracy: 0.8880\n",
      "Epoch 182/400\n",
      "650/725 [=========================>....] - ETA: 0s - loss: 0.3025 - accuracy: 0.8938\n",
      "Epoch 182: val_loss improved from 0.31094 to 0.31077, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 757us/step - loss: 0.3024 - accuracy: 0.8941 - val_loss: 0.3108 - val_accuracy: 0.8891\n",
      "Epoch 183/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.3047 - accuracy: 0.8929\n",
      "Epoch 183: val_loss did not improve from 0.31077\n",
      "725/725 [==============================] - 1s 717us/step - loss: 0.3024 - accuracy: 0.8936 - val_loss: 0.3114 - val_accuracy: 0.8857\n",
      "Epoch 184/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.3027 - accuracy: 0.8930\n",
      "Epoch 184: val_loss improved from 0.31077 to 0.30962, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 737us/step - loss: 0.3024 - accuracy: 0.8932 - val_loss: 0.3096 - val_accuracy: 0.8880\n",
      "Epoch 185/400\n",
      "663/725 [==========================>...] - ETA: 0s - loss: 0.3022 - accuracy: 0.8929\n",
      "Epoch 185: val_loss did not improve from 0.30962\n",
      "725/725 [==============================] - 1s 721us/step - loss: 0.3018 - accuracy: 0.8930 - val_loss: 0.3100 - val_accuracy: 0.8857\n",
      "Epoch 186/400\n",
      "687/725 [===========================>..] - ETA: 0s - loss: 0.3022 - accuracy: 0.8937\n",
      "Epoch 186: val_loss did not improve from 0.30962\n",
      "725/725 [==============================] - 1s 775us/step - loss: 0.3017 - accuracy: 0.8937 - val_loss: 0.3099 - val_accuracy: 0.8867\n",
      "Epoch 187/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.3011 - accuracy: 0.8939\n",
      "Epoch 187: val_loss did not improve from 0.30962\n",
      "725/725 [==============================] - 1s 717us/step - loss: 0.3010 - accuracy: 0.8942 - val_loss: 0.3096 - val_accuracy: 0.8889\n",
      "Epoch 188/400\n",
      "664/725 [==========================>...] - ETA: 0s - loss: 0.3021 - accuracy: 0.8937\n",
      "Epoch 188: val_loss improved from 0.30962 to 0.30850, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.3013 - accuracy: 0.8939 - val_loss: 0.3085 - val_accuracy: 0.8863\n",
      "Epoch 189/400\n",
      "669/725 [==========================>...] - ETA: 0s - loss: 0.3008 - accuracy: 0.8937\n",
      "Epoch 189: val_loss did not improve from 0.30850\n",
      "725/725 [==============================] - 1s 723us/step - loss: 0.3011 - accuracy: 0.8942 - val_loss: 0.3099 - val_accuracy: 0.8880\n",
      "Epoch 190/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.3006 - accuracy: 0.8934\n",
      "Epoch 190: val_loss did not improve from 0.30850\n",
      "725/725 [==============================] - 1s 709us/step - loss: 0.3011 - accuracy: 0.8935 - val_loss: 0.3094 - val_accuracy: 0.8874\n",
      "Epoch 191/400\n",
      "696/725 [===========================>..] - ETA: 0s - loss: 0.3015 - accuracy: 0.8936\n",
      "Epoch 191: val_loss did not improve from 0.30850\n",
      "725/725 [==============================] - 1s 696us/step - loss: 0.3008 - accuracy: 0.8938 - val_loss: 0.3086 - val_accuracy: 0.8853\n",
      "Epoch 192/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.3012 - accuracy: 0.8933\n",
      "Epoch 192: val_loss did not improve from 0.30850\n",
      "725/725 [==============================] - 1s 708us/step - loss: 0.3007 - accuracy: 0.8937 - val_loss: 0.3093 - val_accuracy: 0.8880\n",
      "Epoch 193/400\n",
      "678/725 [===========================>..] - ETA: 0s - loss: 0.3012 - accuracy: 0.8933\n",
      "Epoch 193: val_loss improved from 0.30850 to 0.30765, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 721us/step - loss: 0.3005 - accuracy: 0.8937 - val_loss: 0.3077 - val_accuracy: 0.8899\n",
      "Epoch 194/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.3007 - accuracy: 0.8932\n",
      "Epoch 194: val_loss improved from 0.30765 to 0.30713, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 729us/step - loss: 0.3005 - accuracy: 0.8937 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 195/400\n",
      "688/725 [===========================>..] - ETA: 0s - loss: 0.3009 - accuracy: 0.8932\n",
      "Epoch 195: val_loss did not improve from 0.30713\n",
      "725/725 [==============================] - 1s 709us/step - loss: 0.2999 - accuracy: 0.8936 - val_loss: 0.3103 - val_accuracy: 0.8826\n",
      "Epoch 196/400\n",
      "717/725 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8934\n",
      "Epoch 196: val_loss did not improve from 0.30713\n",
      "725/725 [==============================] - 1s 754us/step - loss: 0.2999 - accuracy: 0.8936 - val_loss: 0.3087 - val_accuracy: 0.8846\n",
      "Epoch 197/400\n",
      "689/725 [===========================>..] - ETA: 0s - loss: 0.3000 - accuracy: 0.8942\n",
      "Epoch 197: val_loss did not improve from 0.30713\n",
      "725/725 [==============================] - 1s 695us/step - loss: 0.2999 - accuracy: 0.8939 - val_loss: 0.3089 - val_accuracy: 0.8852\n",
      "Epoch 198/400\n",
      "672/725 [==========================>...] - ETA: 0s - loss: 0.3000 - accuracy: 0.8928\n",
      "Epoch 198: val_loss did not improve from 0.30713\n",
      "725/725 [==============================] - 1s 713us/step - loss: 0.2997 - accuracy: 0.8931 - val_loss: 0.3074 - val_accuracy: 0.8916\n",
      "Epoch 199/400\n",
      "648/725 [=========================>....] - ETA: 0s - loss: 0.2992 - accuracy: 0.8947\n",
      "Epoch 199: val_loss did not improve from 0.30713\n",
      "725/725 [==============================] - 1s 747us/step - loss: 0.2997 - accuracy: 0.8944 - val_loss: 0.3079 - val_accuracy: 0.8900\n",
      "Epoch 200/400\n",
      "651/725 [=========================>....] - ETA: 0s - loss: 0.3001 - accuracy: 0.8933\n",
      "Epoch 200: val_loss did not improve from 0.30713\n",
      "725/725 [==============================] - 1s 753us/step - loss: 0.2995 - accuracy: 0.8939 - val_loss: 0.3076 - val_accuracy: 0.8880\n",
      "Epoch 201/400\n",
      "669/725 [==========================>...] - ETA: 0s - loss: 0.2993 - accuracy: 0.8942\n",
      "Epoch 201: val_loss did not improve from 0.30713\n",
      "725/725 [==============================] - 1s 815us/step - loss: 0.2991 - accuracy: 0.8945 - val_loss: 0.3083 - val_accuracy: 0.8857\n",
      "Epoch 202/400\n",
      "724/725 [============================>.] - ETA: 0s - loss: 0.2991 - accuracy: 0.8942\n",
      "Epoch 202: val_loss did not improve from 0.30713\n",
      "725/725 [==============================] - 1s 740us/step - loss: 0.2991 - accuracy: 0.8941 - val_loss: 0.3075 - val_accuracy: 0.8886\n",
      "Epoch 203/400\n",
      "713/725 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.8945\n",
      "Epoch 203: val_loss did not improve from 0.30713\n",
      "725/725 [==============================] - 1s 775us/step - loss: 0.2988 - accuracy: 0.8947 - val_loss: 0.3074 - val_accuracy: 0.8919\n",
      "Epoch 204/400\n",
      "651/725 [=========================>....] - ETA: 0s - loss: 0.2977 - accuracy: 0.8935\n",
      "Epoch 204: val_loss improved from 0.30713 to 0.30697, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 863us/step - loss: 0.2985 - accuracy: 0.8940 - val_loss: 0.3070 - val_accuracy: 0.8905\n",
      "Epoch 205/400\n",
      "718/725 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.8937\n",
      "Epoch 205: val_loss improved from 0.30697 to 0.30685, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 830us/step - loss: 0.2986 - accuracy: 0.8939 - val_loss: 0.3069 - val_accuracy: 0.8881\n",
      "Epoch 206/400\n",
      "678/725 [===========================>..] - ETA: 0s - loss: 0.2975 - accuracy: 0.8945\n",
      "Epoch 206: val_loss improved from 0.30685 to 0.30607, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 730us/step - loss: 0.2986 - accuracy: 0.8943 - val_loss: 0.3061 - val_accuracy: 0.8890\n",
      "Epoch 207/400\n",
      "662/725 [==========================>...] - ETA: 0s - loss: 0.2991 - accuracy: 0.8940\n",
      "Epoch 207: val_loss improved from 0.30607 to 0.30589, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 750us/step - loss: 0.2983 - accuracy: 0.8943 - val_loss: 0.3059 - val_accuracy: 0.8863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/400\n",
      "654/725 [==========================>...] - ETA: 0s - loss: 0.2985 - accuracy: 0.8948\n",
      "Epoch 208: val_loss did not improve from 0.30589\n",
      "725/725 [==============================] - 1s 732us/step - loss: 0.2982 - accuracy: 0.8950 - val_loss: 0.3059 - val_accuracy: 0.8866\n",
      "Epoch 209/400\n",
      "652/725 [=========================>....] - ETA: 0s - loss: 0.2975 - accuracy: 0.8943\n",
      "Epoch 209: val_loss did not improve from 0.30589\n",
      "725/725 [==============================] - 1s 728us/step - loss: 0.2980 - accuracy: 0.8942 - val_loss: 0.3078 - val_accuracy: 0.8891\n",
      "Epoch 210/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.2988 - accuracy: 0.8939\n",
      "Epoch 210: val_loss improved from 0.30589 to 0.30546, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 737us/step - loss: 0.2978 - accuracy: 0.8944 - val_loss: 0.3055 - val_accuracy: 0.8874\n",
      "Epoch 211/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.2986 - accuracy: 0.8944\n",
      "Epoch 211: val_loss did not improve from 0.30546\n",
      "725/725 [==============================] - 1s 797us/step - loss: 0.2976 - accuracy: 0.8949 - val_loss: 0.3061 - val_accuracy: 0.8900\n",
      "Epoch 212/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.2973 - accuracy: 0.8953\n",
      "Epoch 212: val_loss did not improve from 0.30546\n",
      "725/725 [==============================] - 1s 807us/step - loss: 0.2979 - accuracy: 0.8951 - val_loss: 0.3068 - val_accuracy: 0.8895\n",
      "Epoch 213/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.2968 - accuracy: 0.8957\n",
      "Epoch 213: val_loss improved from 0.30546 to 0.30435, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 832us/step - loss: 0.2976 - accuracy: 0.8954 - val_loss: 0.3043 - val_accuracy: 0.8894\n",
      "Epoch 214/400\n",
      "691/725 [===========================>..] - ETA: 0s - loss: 0.2971 - accuracy: 0.8946\n",
      "Epoch 214: val_loss did not improve from 0.30435\n",
      "725/725 [==============================] - 1s 780us/step - loss: 0.2973 - accuracy: 0.8946 - val_loss: 0.3054 - val_accuracy: 0.8886\n",
      "Epoch 215/400\n",
      "687/725 [===========================>..] - ETA: 0s - loss: 0.2968 - accuracy: 0.8958\n",
      "Epoch 215: val_loss did not improve from 0.30435\n",
      "725/725 [==============================] - 1s 785us/step - loss: 0.2971 - accuracy: 0.8955 - val_loss: 0.3048 - val_accuracy: 0.8884\n",
      "Epoch 216/400\n",
      "689/725 [===========================>..] - ETA: 0s - loss: 0.2956 - accuracy: 0.8963\n",
      "Epoch 216: val_loss did not improve from 0.30435\n",
      "725/725 [==============================] - 1s 795us/step - loss: 0.2971 - accuracy: 0.8955 - val_loss: 0.3051 - val_accuracy: 0.8870\n",
      "Epoch 217/400\n",
      "687/725 [===========================>..] - ETA: 0s - loss: 0.2966 - accuracy: 0.8952\n",
      "Epoch 217: val_loss did not improve from 0.30435\n",
      "725/725 [==============================] - 1s 791us/step - loss: 0.2972 - accuracy: 0.8952 - val_loss: 0.3047 - val_accuracy: 0.8884\n",
      "Epoch 218/400\n",
      "697/725 [===========================>..] - ETA: 0s - loss: 0.2966 - accuracy: 0.8951\n",
      "Epoch 218: val_loss did not improve from 0.30435\n",
      "725/725 [==============================] - 1s 776us/step - loss: 0.2966 - accuracy: 0.8954 - val_loss: 0.3050 - val_accuracy: 0.8868\n",
      "Epoch 219/400\n",
      "697/725 [===========================>..] - ETA: 0s - loss: 0.2969 - accuracy: 0.8948\n",
      "Epoch 219: val_loss improved from 0.30435 to 0.30363, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 799us/step - loss: 0.2968 - accuracy: 0.8951 - val_loss: 0.3036 - val_accuracy: 0.8890\n",
      "Epoch 220/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.2965 - accuracy: 0.8950\n",
      "Epoch 220: val_loss did not improve from 0.30363\n",
      "725/725 [==============================] - 1s 811us/step - loss: 0.2966 - accuracy: 0.8951 - val_loss: 0.3071 - val_accuracy: 0.8902\n",
      "Epoch 221/400\n",
      "689/725 [===========================>..] - ETA: 0s - loss: 0.2970 - accuracy: 0.8951\n",
      "Epoch 221: val_loss did not improve from 0.30363\n",
      "725/725 [==============================] - 1s 780us/step - loss: 0.2968 - accuracy: 0.8951 - val_loss: 0.3050 - val_accuracy: 0.8922\n",
      "Epoch 222/400\n",
      "708/725 [============================>.] - ETA: 0s - loss: 0.2958 - accuracy: 0.8961\n",
      "Epoch 222: val_loss improved from 0.30363 to 0.30317, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 788us/step - loss: 0.2964 - accuracy: 0.8959 - val_loss: 0.3032 - val_accuracy: 0.8922\n",
      "Epoch 223/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.2961 - accuracy: 0.8950\n",
      "Epoch 223: val_loss did not improve from 0.30317\n",
      "725/725 [==============================] - 1s 754us/step - loss: 0.2963 - accuracy: 0.8950 - val_loss: 0.3043 - val_accuracy: 0.8894\n",
      "Epoch 224/400\n",
      "697/725 [===========================>..] - ETA: 0s - loss: 0.2963 - accuracy: 0.8958\n",
      "Epoch 224: val_loss did not improve from 0.30317\n",
      "725/725 [==============================] - 1s 778us/step - loss: 0.2960 - accuracy: 0.8960 - val_loss: 0.3053 - val_accuracy: 0.8910\n",
      "Epoch 225/400\n",
      "674/725 [==========================>...] - ETA: 0s - loss: 0.2955 - accuracy: 0.8959\n",
      "Epoch 225: val_loss did not improve from 0.30317\n",
      "725/725 [==============================] - 1s 795us/step - loss: 0.2960 - accuracy: 0.8962 - val_loss: 0.3041 - val_accuracy: 0.8907\n",
      "Epoch 226/400\n",
      "720/725 [============================>.] - ETA: 0s - loss: 0.2958 - accuracy: 0.8962\n",
      "Epoch 226: val_loss did not improve from 0.30317\n",
      "725/725 [==============================] - 1s 753us/step - loss: 0.2962 - accuracy: 0.8962 - val_loss: 0.3044 - val_accuracy: 0.8899\n",
      "Epoch 227/400\n",
      "690/725 [===========================>..] - ETA: 0s - loss: 0.2959 - accuracy: 0.8956\n",
      "Epoch 227: val_loss did not improve from 0.30317\n",
      "725/725 [==============================] - 1s 784us/step - loss: 0.2956 - accuracy: 0.8956 - val_loss: 0.3032 - val_accuracy: 0.8944\n",
      "Epoch 228/400\n",
      "700/725 [===========================>..] - ETA: 0s - loss: 0.2953 - accuracy: 0.8967\n",
      "Epoch 228: val_loss did not improve from 0.30317\n",
      "725/725 [==============================] - 1s 769us/step - loss: 0.2955 - accuracy: 0.8965 - val_loss: 0.3065 - val_accuracy: 0.8896\n",
      "Epoch 229/400\n",
      "651/725 [=========================>....] - ETA: 0s - loss: 0.2965 - accuracy: 0.8955\n",
      "Epoch 229: val_loss did not improve from 0.30317\n",
      "725/725 [==============================] - 1s 744us/step - loss: 0.2955 - accuracy: 0.8954 - val_loss: 0.3064 - val_accuracy: 0.8914\n",
      "Epoch 230/400\n",
      "649/725 [=========================>....] - ETA: 0s - loss: 0.2943 - accuracy: 0.8964\n",
      "Epoch 230: val_loss did not improve from 0.30317\n",
      "725/725 [==============================] - 1s 752us/step - loss: 0.2951 - accuracy: 0.8964 - val_loss: 0.3034 - val_accuracy: 0.8864\n",
      "Epoch 231/400\n",
      "711/725 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.8959\n",
      "Epoch 231: val_loss improved from 0.30317 to 0.30238, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 790us/step - loss: 0.2954 - accuracy: 0.8957 - val_loss: 0.3024 - val_accuracy: 0.8885\n",
      "Epoch 232/400\n",
      "722/725 [============================>.] - ETA: 0s - loss: 0.2952 - accuracy: 0.8967\n",
      "Epoch 232: val_loss did not improve from 0.30238\n",
      "725/725 [==============================] - 1s 760us/step - loss: 0.2952 - accuracy: 0.8966 - val_loss: 0.3034 - val_accuracy: 0.8907\n",
      "Epoch 233/400\n",
      "685/725 [===========================>..] - ETA: 0s - loss: 0.2937 - accuracy: 0.8979\n",
      "Epoch 233: val_loss did not improve from 0.30238\n",
      "725/725 [==============================] - 1s 861us/step - loss: 0.2950 - accuracy: 0.8970 - val_loss: 0.3035 - val_accuracy: 0.8884\n",
      "Epoch 234/400\n",
      "720/725 [============================>.] - ETA: 0s - loss: 0.2954 - accuracy: 0.8961\n",
      "Epoch 234: val_loss improved from 0.30238 to 0.30214, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 766us/step - loss: 0.2952 - accuracy: 0.8963 - val_loss: 0.3021 - val_accuracy: 0.8919\n",
      "Epoch 235/400\n",
      "698/725 [===========================>..] - ETA: 0s - loss: 0.2951 - accuracy: 0.8965\n",
      "Epoch 235: val_loss improved from 0.30214 to 0.30173, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 802us/step - loss: 0.2949 - accuracy: 0.8966 - val_loss: 0.3017 - val_accuracy: 0.8922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/400\n",
      "710/725 [============================>.] - ETA: 0s - loss: 0.2946 - accuracy: 0.8967\n",
      "Epoch 236: val_loss improved from 0.30173 to 0.30139, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 777us/step - loss: 0.2945 - accuracy: 0.8966 - val_loss: 0.3014 - val_accuracy: 0.8917\n",
      "Epoch 237/400\n",
      "716/725 [============================>.] - ETA: 0s - loss: 0.2943 - accuracy: 0.8958\n",
      "Epoch 237: val_loss improved from 0.30139 to 0.30136, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 773us/step - loss: 0.2949 - accuracy: 0.8956 - val_loss: 0.3014 - val_accuracy: 0.8894\n",
      "Epoch 238/400\n",
      "708/725 [============================>.] - ETA: 0s - loss: 0.2947 - accuracy: 0.8962\n",
      "Epoch 238: val_loss improved from 0.30136 to 0.30065, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 788us/step - loss: 0.2942 - accuracy: 0.8964 - val_loss: 0.3006 - val_accuracy: 0.8905\n",
      "Epoch 239/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.2949 - accuracy: 0.8951\n",
      "Epoch 239: val_loss did not improve from 0.30065\n",
      "725/725 [==============================] - 1s 802us/step - loss: 0.2943 - accuracy: 0.8956 - val_loss: 0.3021 - val_accuracy: 0.8869\n",
      "Epoch 240/400\n",
      "721/725 [============================>.] - ETA: 0s - loss: 0.2944 - accuracy: 0.8955\n",
      "Epoch 240: val_loss did not improve from 0.30065\n",
      "725/725 [==============================] - 1s 755us/step - loss: 0.2941 - accuracy: 0.8956 - val_loss: 0.3028 - val_accuracy: 0.8951\n",
      "Epoch 241/400\n",
      "707/725 [============================>.] - ETA: 0s - loss: 0.2940 - accuracy: 0.8955\n",
      "Epoch 241: val_loss did not improve from 0.30065\n",
      "725/725 [==============================] - 1s 765us/step - loss: 0.2942 - accuracy: 0.8956 - val_loss: 0.3010 - val_accuracy: 0.8912\n",
      "Epoch 242/400\n",
      "696/725 [===========================>..] - ETA: 0s - loss: 0.2950 - accuracy: 0.8955\n",
      "Epoch 242: val_loss did not improve from 0.30065\n",
      "725/725 [==============================] - 1s 787us/step - loss: 0.2942 - accuracy: 0.8959 - val_loss: 0.3008 - val_accuracy: 0.8878\n",
      "Epoch 243/400\n",
      "712/725 [============================>.] - ETA: 0s - loss: 0.2933 - accuracy: 0.8950\n",
      "Epoch 243: val_loss did not improve from 0.30065\n",
      "725/725 [==============================] - 1s 758us/step - loss: 0.2938 - accuracy: 0.8947 - val_loss: 0.3008 - val_accuracy: 0.8953\n",
      "Epoch 244/400\n",
      "716/725 [============================>.] - ETA: 0s - loss: 0.2934 - accuracy: 0.8963\n",
      "Epoch 244: val_loss did not improve from 0.30065\n",
      "725/725 [==============================] - 1s 761us/step - loss: 0.2937 - accuracy: 0.8961 - val_loss: 0.3030 - val_accuracy: 0.8890\n",
      "Epoch 245/400\n",
      "722/725 [============================>.] - ETA: 0s - loss: 0.2937 - accuracy: 0.8956\n",
      "Epoch 245: val_loss improved from 0.30065 to 0.30031, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 772us/step - loss: 0.2936 - accuracy: 0.8956 - val_loss: 0.3003 - val_accuracy: 0.8911\n",
      "Epoch 246/400\n",
      "691/725 [===========================>..] - ETA: 0s - loss: 0.2937 - accuracy: 0.8955\n",
      "Epoch 246: val_loss did not improve from 0.30031\n",
      "725/725 [==============================] - 1s 796us/step - loss: 0.2931 - accuracy: 0.8954 - val_loss: 0.3005 - val_accuracy: 0.8877\n",
      "Epoch 247/400\n",
      "699/725 [===========================>..] - ETA: 0s - loss: 0.2940 - accuracy: 0.8949\n",
      "Epoch 247: val_loss improved from 0.30031 to 0.29931, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 811us/step - loss: 0.2933 - accuracy: 0.8951 - val_loss: 0.2993 - val_accuracy: 0.8929\n",
      "Epoch 248/400\n",
      "706/725 [============================>.] - ETA: 0s - loss: 0.2924 - accuracy: 0.8956\n",
      "Epoch 248: val_loss did not improve from 0.29931\n",
      "725/725 [==============================] - 1s 764us/step - loss: 0.2931 - accuracy: 0.8955 - val_loss: 0.3009 - val_accuracy: 0.8891\n",
      "Epoch 249/400\n",
      "673/725 [==========================>...] - ETA: 0s - loss: 0.2938 - accuracy: 0.8957\n",
      "Epoch 249: val_loss did not improve from 0.29931\n",
      "725/725 [==============================] - 1s 795us/step - loss: 0.2931 - accuracy: 0.8956 - val_loss: 0.2994 - val_accuracy: 0.8864\n",
      "Epoch 250/400\n",
      "654/725 [==========================>...] - ETA: 0s - loss: 0.2928 - accuracy: 0.8967\n",
      "Epoch 250: val_loss did not improve from 0.29931\n",
      "725/725 [==============================] - 1s 800us/step - loss: 0.2929 - accuracy: 0.8962 - val_loss: 0.3011 - val_accuracy: 0.8886\n",
      "Epoch 251/400\n",
      "662/725 [==========================>...] - ETA: 0s - loss: 0.2933 - accuracy: 0.8954\n",
      "Epoch 251: val_loss did not improve from 0.29931\n",
      "725/725 [==============================] - 1s 723us/step - loss: 0.2929 - accuracy: 0.8957 - val_loss: 0.2994 - val_accuracy: 0.8934\n",
      "Epoch 252/400\n",
      "648/725 [=========================>....] - ETA: 0s - loss: 0.2941 - accuracy: 0.8957\n",
      "Epoch 252: val_loss did not improve from 0.29931\n",
      "725/725 [==============================] - 1s 738us/step - loss: 0.2928 - accuracy: 0.8959 - val_loss: 0.2999 - val_accuracy: 0.8908\n",
      "Epoch 253/400\n",
      "658/725 [==========================>...] - ETA: 0s - loss: 0.2929 - accuracy: 0.8961\n",
      "Epoch 253: val_loss improved from 0.29931 to 0.29912, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 753us/step - loss: 0.2928 - accuracy: 0.8960 - val_loss: 0.2991 - val_accuracy: 0.8924\n",
      "Epoch 254/400\n",
      "717/725 [============================>.] - ETA: 0s - loss: 0.2928 - accuracy: 0.8961\n",
      "Epoch 254: val_loss improved from 0.29912 to 0.29838, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 774us/step - loss: 0.2922 - accuracy: 0.8963 - val_loss: 0.2984 - val_accuracy: 0.8933\n",
      "Epoch 255/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.2913 - accuracy: 0.8965\n",
      "Epoch 255: val_loss improved from 0.29838 to 0.29790, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 759us/step - loss: 0.2927 - accuracy: 0.8959 - val_loss: 0.2979 - val_accuracy: 0.8929\n",
      "Epoch 256/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.2917 - accuracy: 0.8964\n",
      "Epoch 256: val_loss improved from 0.29790 to 0.29762, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 825us/step - loss: 0.2922 - accuracy: 0.8959 - val_loss: 0.2976 - val_accuracy: 0.8936\n",
      "Epoch 257/400\n",
      "724/725 [============================>.] - ETA: 0s - loss: 0.2924 - accuracy: 0.8965\n",
      "Epoch 257: val_loss did not improve from 0.29762\n",
      "725/725 [==============================] - 1s 755us/step - loss: 0.2923 - accuracy: 0.8966 - val_loss: 0.2979 - val_accuracy: 0.8886\n",
      "Epoch 258/400\n",
      "673/725 [==========================>...] - ETA: 0s - loss: 0.2918 - accuracy: 0.8966\n",
      "Epoch 258: val_loss did not improve from 0.29762\n",
      "725/725 [==============================] - 1s 722us/step - loss: 0.2921 - accuracy: 0.8966 - val_loss: 0.2980 - val_accuracy: 0.8910\n",
      "Epoch 259/400\n",
      "656/725 [==========================>...] - ETA: 0s - loss: 0.2917 - accuracy: 0.8966\n",
      "Epoch 259: val_loss improved from 0.29762 to 0.29760, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 760us/step - loss: 0.2920 - accuracy: 0.8960 - val_loss: 0.2976 - val_accuracy: 0.8907\n",
      "Epoch 260/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.2912 - accuracy: 0.8963\n",
      "Epoch 260: val_loss did not improve from 0.29760\n",
      "725/725 [==============================] - 1s 728us/step - loss: 0.2918 - accuracy: 0.8961 - val_loss: 0.2982 - val_accuracy: 0.8884\n",
      "Epoch 261/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.2918 - accuracy: 0.8956\n",
      "Epoch 261: val_loss did not improve from 0.29760\n",
      "725/725 [==============================] - 1s 742us/step - loss: 0.2917 - accuracy: 0.8957 - val_loss: 0.2983 - val_accuracy: 0.8939\n",
      "Epoch 262/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.2923 - accuracy: 0.8963\n",
      "Epoch 262: val_loss did not improve from 0.29760\n",
      "725/725 [==============================] - 1s 721us/step - loss: 0.2916 - accuracy: 0.8964 - val_loss: 0.2980 - val_accuracy: 0.8901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263/400\n",
      "654/725 [==========================>...] - ETA: 0s - loss: 0.2909 - accuracy: 0.8966\n",
      "Epoch 263: val_loss improved from 0.29760 to 0.29730, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.2917 - accuracy: 0.8963 - val_loss: 0.2973 - val_accuracy: 0.8921\n",
      "Epoch 264/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.2923 - accuracy: 0.8958\n",
      "Epoch 264: val_loss did not improve from 0.29730\n",
      "725/725 [==============================] - 1s 720us/step - loss: 0.2914 - accuracy: 0.8964 - val_loss: 0.2974 - val_accuracy: 0.8923\n",
      "Epoch 265/400\n",
      "713/725 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.8964\n",
      "Epoch 265: val_loss did not improve from 0.29730\n",
      "725/725 [==============================] - 1s 752us/step - loss: 0.2913 - accuracy: 0.8962 - val_loss: 0.3009 - val_accuracy: 0.8903\n",
      "Epoch 266/400\n",
      "664/725 [==========================>...] - ETA: 0s - loss: 0.2929 - accuracy: 0.8968\n",
      "Epoch 266: val_loss did not improve from 0.29730\n",
      "725/725 [==============================] - 1s 725us/step - loss: 0.2914 - accuracy: 0.8966 - val_loss: 0.2981 - val_accuracy: 0.8872\n",
      "Epoch 267/400\n",
      "656/725 [==========================>...] - ETA: 0s - loss: 0.2902 - accuracy: 0.8976\n",
      "Epoch 267: val_loss improved from 0.29730 to 0.29642, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 756us/step - loss: 0.2912 - accuracy: 0.8968 - val_loss: 0.2964 - val_accuracy: 0.8897\n",
      "Epoch 268/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.2900 - accuracy: 0.8960\n",
      "Epoch 268: val_loss improved from 0.29642 to 0.29596, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 748us/step - loss: 0.2910 - accuracy: 0.8958 - val_loss: 0.2960 - val_accuracy: 0.8916\n",
      "Epoch 269/400\n",
      "718/725 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.8970\n",
      "Epoch 269: val_loss did not improve from 0.29596\n",
      "725/725 [==============================] - 1s 747us/step - loss: 0.2910 - accuracy: 0.8969 - val_loss: 0.2965 - val_accuracy: 0.8927\n",
      "Epoch 270/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.2888 - accuracy: 0.8967\n",
      "Epoch 270: val_loss did not improve from 0.29596\n",
      "725/725 [==============================] - 1s 729us/step - loss: 0.2909 - accuracy: 0.8966 - val_loss: 0.2992 - val_accuracy: 0.8927\n",
      "Epoch 271/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.2904 - accuracy: 0.8968\n",
      "Epoch 271: val_loss improved from 0.29596 to 0.29556, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.2909 - accuracy: 0.8964 - val_loss: 0.2956 - val_accuracy: 0.8888\n",
      "Epoch 272/400\n",
      "648/725 [=========================>....] - ETA: 0s - loss: 0.2897 - accuracy: 0.8967\n",
      "Epoch 272: val_loss improved from 0.29556 to 0.29548, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 764us/step - loss: 0.2908 - accuracy: 0.8960 - val_loss: 0.2955 - val_accuracy: 0.8906\n",
      "Epoch 273/400\n",
      "709/725 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.8956\n",
      "Epoch 273: val_loss did not improve from 0.29548\n",
      "725/725 [==============================] - 1s 760us/step - loss: 0.2905 - accuracy: 0.8957 - val_loss: 0.2966 - val_accuracy: 0.8912\n",
      "Epoch 274/400\n",
      "655/725 [==========================>...] - ETA: 0s - loss: 0.2914 - accuracy: 0.8971\n",
      "Epoch 274: val_loss improved from 0.29548 to 0.29484, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 748us/step - loss: 0.2903 - accuracy: 0.8971 - val_loss: 0.2948 - val_accuracy: 0.8931\n",
      "Epoch 275/400\n",
      "679/725 [===========================>..] - ETA: 0s - loss: 0.2912 - accuracy: 0.8969\n",
      "Epoch 275: val_loss did not improve from 0.29484\n",
      "725/725 [==============================] - 1s 712us/step - loss: 0.2902 - accuracy: 0.8971 - val_loss: 0.2952 - val_accuracy: 0.8896\n",
      "Epoch 276/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.8961\n",
      "Epoch 276: val_loss did not improve from 0.29484\n",
      "725/725 [==============================] - 1s 752us/step - loss: 0.2902 - accuracy: 0.8957 - val_loss: 0.2988 - val_accuracy: 0.8930\n",
      "Epoch 277/400\n",
      "645/725 [=========================>....] - ETA: 0s - loss: 0.2891 - accuracy: 0.8966\n",
      "Epoch 277: val_loss did not improve from 0.29484\n",
      "725/725 [==============================] - 1s 742us/step - loss: 0.2900 - accuracy: 0.8960 - val_loss: 0.2956 - val_accuracy: 0.8934\n",
      "Epoch 278/400\n",
      "652/725 [=========================>....] - ETA: 0s - loss: 0.2895 - accuracy: 0.8973\n",
      "Epoch 278: val_loss did not improve from 0.29484\n",
      "725/725 [==============================] - 1s 731us/step - loss: 0.2895 - accuracy: 0.8974 - val_loss: 0.2961 - val_accuracy: 0.8929\n",
      "Epoch 279/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.2890 - accuracy: 0.8971\n",
      "Epoch 279: val_loss did not improve from 0.29484\n",
      "725/725 [==============================] - 1s 729us/step - loss: 0.2902 - accuracy: 0.8964 - val_loss: 0.2966 - val_accuracy: 0.8916\n",
      "Epoch 280/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.2893 - accuracy: 0.8968\n",
      "Epoch 280: val_loss did not improve from 0.29484\n",
      "725/725 [==============================] - 1s 730us/step - loss: 0.2897 - accuracy: 0.8967 - val_loss: 0.2969 - val_accuracy: 0.8924\n",
      "Epoch 281/400\n",
      "651/725 [=========================>....] - ETA: 0s - loss: 0.2898 - accuracy: 0.8965\n",
      "Epoch 281: val_loss did not improve from 0.29484\n",
      "725/725 [==============================] - 1s 736us/step - loss: 0.2898 - accuracy: 0.8969 - val_loss: 0.2958 - val_accuracy: 0.8878\n",
      "Epoch 282/400\n",
      "660/725 [==========================>...] - ETA: 0s - loss: 0.2903 - accuracy: 0.8964\n",
      "Epoch 282: val_loss did not improve from 0.29484\n",
      "725/725 [==============================] - 1s 727us/step - loss: 0.2893 - accuracy: 0.8970 - val_loss: 0.2980 - val_accuracy: 0.8899\n",
      "Epoch 283/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.2909 - accuracy: 0.8965\n",
      "Epoch 283: val_loss did not improve from 0.29484\n",
      "725/725 [==============================] - 1s 721us/step - loss: 0.2897 - accuracy: 0.8964 - val_loss: 0.2965 - val_accuracy: 0.8910\n",
      "Epoch 284/400\n",
      "654/725 [==========================>...] - ETA: 0s - loss: 0.2885 - accuracy: 0.8961\n",
      "Epoch 284: val_loss improved from 0.29484 to 0.29457, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 771us/step - loss: 0.2896 - accuracy: 0.8964 - val_loss: 0.2946 - val_accuracy: 0.8916\n",
      "Epoch 285/400\n",
      "647/725 [=========================>....] - ETA: 0s - loss: 0.2888 - accuracy: 0.8961\n",
      "Epoch 285: val_loss did not improve from 0.29457\n",
      "725/725 [==============================] - 1s 740us/step - loss: 0.2894 - accuracy: 0.8965 - val_loss: 0.2962 - val_accuracy: 0.8930\n",
      "Epoch 286/400\n",
      "652/725 [=========================>....] - ETA: 0s - loss: 0.2891 - accuracy: 0.8975\n",
      "Epoch 286: val_loss did not improve from 0.29457\n",
      "725/725 [==============================] - 1s 731us/step - loss: 0.2891 - accuracy: 0.8969 - val_loss: 0.2950 - val_accuracy: 0.8899\n",
      "Epoch 287/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.2893 - accuracy: 0.8965\n",
      "Epoch 287: val_loss did not improve from 0.29457\n",
      "725/725 [==============================] - 1s 727us/step - loss: 0.2895 - accuracy: 0.8961 - val_loss: 0.2952 - val_accuracy: 0.8945\n",
      "Epoch 288/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.2896 - accuracy: 0.8972\n",
      "Epoch 288: val_loss did not improve from 0.29457\n",
      "725/725 [==============================] - 1s 742us/step - loss: 0.2892 - accuracy: 0.8976 - val_loss: 0.2947 - val_accuracy: 0.8901\n",
      "Epoch 289/400\n",
      "700/725 [===========================>..] - ETA: 0s - loss: 0.2889 - accuracy: 0.8957\n",
      "Epoch 289: val_loss did not improve from 0.29457\n",
      "725/725 [==============================] - 1s 768us/step - loss: 0.2889 - accuracy: 0.8961 - val_loss: 0.2951 - val_accuracy: 0.8918\n",
      "Epoch 290/400\n",
      "672/725 [==========================>...] - ETA: 0s - loss: 0.2885 - accuracy: 0.8972\n",
      "Epoch 290: val_loss did not improve from 0.29457\n",
      "725/725 [==============================] - 1s 716us/step - loss: 0.2891 - accuracy: 0.8968 - val_loss: 0.2951 - val_accuracy: 0.8945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/400\n",
      "664/725 [==========================>...] - ETA: 0s - loss: 0.2890 - accuracy: 0.8968\n",
      "Epoch 291: val_loss did not improve from 0.29457\n",
      "725/725 [==============================] - 1s 725us/step - loss: 0.2889 - accuracy: 0.8969 - val_loss: 0.2974 - val_accuracy: 0.8900\n",
      "Epoch 292/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.2883 - accuracy: 0.8980\n",
      "Epoch 292: val_loss did not improve from 0.29457\n",
      "725/725 [==============================] - 1s 739us/step - loss: 0.2888 - accuracy: 0.8976 - val_loss: 0.2947 - val_accuracy: 0.8906\n",
      "Epoch 293/400\n",
      "644/725 [=========================>....] - ETA: 0s - loss: 0.2887 - accuracy: 0.8964\n",
      "Epoch 293: val_loss improved from 0.29457 to 0.29364, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 766us/step - loss: 0.2886 - accuracy: 0.8970 - val_loss: 0.2936 - val_accuracy: 0.8950\n",
      "Epoch 294/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.2885 - accuracy: 0.8976\n",
      "Epoch 294: val_loss did not improve from 0.29364\n",
      "725/725 [==============================] - 1s 727us/step - loss: 0.2887 - accuracy: 0.8973 - val_loss: 0.2955 - val_accuracy: 0.8918\n",
      "Epoch 295/400\n",
      "657/725 [==========================>...] - ETA: 0s - loss: 0.2880 - accuracy: 0.8974\n",
      "Epoch 295: val_loss did not improve from 0.29364\n",
      "725/725 [==============================] - 1s 730us/step - loss: 0.2886 - accuracy: 0.8972 - val_loss: 0.2938 - val_accuracy: 0.8902\n",
      "Epoch 296/400\n",
      "682/725 [===========================>..] - ETA: 0s - loss: 0.2873 - accuracy: 0.8976\n",
      "Epoch 296: val_loss improved from 0.29364 to 0.29335, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 800us/step - loss: 0.2884 - accuracy: 0.8974 - val_loss: 0.2933 - val_accuracy: 0.8962\n",
      "Epoch 297/400\n",
      "712/725 [============================>.] - ETA: 0s - loss: 0.2876 - accuracy: 0.8974\n",
      "Epoch 297: val_loss did not improve from 0.29335\n",
      "725/725 [==============================] - 1s 756us/step - loss: 0.2883 - accuracy: 0.8973 - val_loss: 0.2938 - val_accuracy: 0.8934\n",
      "Epoch 298/400\n",
      "669/725 [==========================>...] - ETA: 0s - loss: 0.2889 - accuracy: 0.8968\n",
      "Epoch 298: val_loss improved from 0.29335 to 0.29313, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 748us/step - loss: 0.2882 - accuracy: 0.8970 - val_loss: 0.2931 - val_accuracy: 0.8901\n",
      "Epoch 299/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.2885 - accuracy: 0.8966\n",
      "Epoch 299: val_loss did not improve from 0.29313\n",
      "725/725 [==============================] - 1s 718us/step - loss: 0.2884 - accuracy: 0.8966 - val_loss: 0.2946 - val_accuracy: 0.8945\n",
      "Epoch 300/400\n",
      "701/725 [============================>.] - ETA: 0s - loss: 0.2891 - accuracy: 0.8975\n",
      "Epoch 300: val_loss did not improve from 0.29313\n",
      "725/725 [==============================] - 1s 766us/step - loss: 0.2881 - accuracy: 0.8981 - val_loss: 0.2947 - val_accuracy: 0.8908\n",
      "Epoch 301/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.2880 - accuracy: 0.8974\n",
      "Epoch 301: val_loss did not improve from 0.29313\n",
      "725/725 [==============================] - 1s 722us/step - loss: 0.2881 - accuracy: 0.8973 - val_loss: 0.2937 - val_accuracy: 0.8901\n",
      "Epoch 302/400\n",
      "651/725 [=========================>....] - ETA: 0s - loss: 0.2881 - accuracy: 0.8972\n",
      "Epoch 302: val_loss did not improve from 0.29313\n",
      "725/725 [==============================] - 1s 748us/step - loss: 0.2874 - accuracy: 0.8970 - val_loss: 0.2945 - val_accuracy: 0.8908\n",
      "Epoch 303/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.2880 - accuracy: 0.8965\n",
      "Epoch 303: val_loss did not improve from 0.29313\n",
      "725/725 [==============================] - 1s 736us/step - loss: 0.2879 - accuracy: 0.8967 - val_loss: 0.2951 - val_accuracy: 0.8892\n",
      "Epoch 304/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.2874 - accuracy: 0.8967\n",
      "Epoch 304: val_loss did not improve from 0.29313\n",
      "725/725 [==============================] - 1s 757us/step - loss: 0.2876 - accuracy: 0.8966 - val_loss: 0.2940 - val_accuracy: 0.8938\n",
      "Epoch 305/400\n",
      "663/725 [==========================>...] - ETA: 0s - loss: 0.2864 - accuracy: 0.8980\n",
      "Epoch 305: val_loss improved from 0.29313 to 0.29187, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 742us/step - loss: 0.2879 - accuracy: 0.8973 - val_loss: 0.2919 - val_accuracy: 0.8905\n",
      "Epoch 306/400\n",
      "655/725 [==========================>...] - ETA: 0s - loss: 0.2880 - accuracy: 0.8963\n",
      "Epoch 306: val_loss did not improve from 0.29187\n",
      "725/725 [==============================] - 1s 729us/step - loss: 0.2870 - accuracy: 0.8966 - val_loss: 0.2924 - val_accuracy: 0.8914\n",
      "Epoch 307/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.2872 - accuracy: 0.8966\n",
      "Epoch 307: val_loss improved from 0.29187 to 0.29168, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 756us/step - loss: 0.2875 - accuracy: 0.8964 - val_loss: 0.2917 - val_accuracy: 0.8911\n",
      "Epoch 308/400\n",
      "707/725 [============================>.] - ETA: 0s - loss: 0.2875 - accuracy: 0.8965\n",
      "Epoch 308: val_loss did not improve from 0.29168\n",
      "725/725 [==============================] - 1s 761us/step - loss: 0.2870 - accuracy: 0.8966 - val_loss: 0.2941 - val_accuracy: 0.8907\n",
      "Epoch 309/400\n",
      "658/725 [==========================>...] - ETA: 0s - loss: 0.2864 - accuracy: 0.8970\n",
      "Epoch 309: val_loss did not improve from 0.29168\n",
      "725/725 [==============================] - 1s 731us/step - loss: 0.2871 - accuracy: 0.8968 - val_loss: 0.2920 - val_accuracy: 0.8921\n",
      "Epoch 310/400\n",
      "655/725 [==========================>...] - ETA: 0s - loss: 0.2861 - accuracy: 0.8972\n",
      "Epoch 310: val_loss did not improve from 0.29168\n",
      "725/725 [==============================] - 1s 735us/step - loss: 0.2870 - accuracy: 0.8968 - val_loss: 0.2928 - val_accuracy: 0.8892\n",
      "Epoch 311/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.2881 - accuracy: 0.8961\n",
      "Epoch 311: val_loss improved from 0.29168 to 0.29100, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 742us/step - loss: 0.2869 - accuracy: 0.8965 - val_loss: 0.2910 - val_accuracy: 0.8910\n",
      "Epoch 312/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.2867 - accuracy: 0.8994\n",
      "Epoch 312: val_loss improved from 0.29100 to 0.28663, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 771us/step - loss: 0.2866 - accuracy: 0.8996 - val_loss: 0.2866 - val_accuracy: 0.9071\n",
      "Epoch 313/400\n",
      "667/725 [==========================>...] - ETA: 0s - loss: 0.2816 - accuracy: 0.9128\n",
      "Epoch 313: val_loss improved from 0.28663 to 0.28556, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 753us/step - loss: 0.2822 - accuracy: 0.9129 - val_loss: 0.2856 - val_accuracy: 0.9115\n",
      "Epoch 314/400\n",
      "653/725 [==========================>...] - ETA: 0s - loss: 0.2808 - accuracy: 0.9138\n",
      "Epoch 314: val_loss did not improve from 0.28556\n",
      "725/725 [==============================] - 1s 732us/step - loss: 0.2808 - accuracy: 0.9136 - val_loss: 0.2871 - val_accuracy: 0.9085\n",
      "Epoch 315/400\n",
      "658/725 [==========================>...] - ETA: 0s - loss: 0.2810 - accuracy: 0.9145\n",
      "Epoch 315: val_loss improved from 0.28556 to 0.28207, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 750us/step - loss: 0.2803 - accuracy: 0.9146 - val_loss: 0.2821 - val_accuracy: 0.9073\n",
      "Epoch 316/400\n",
      "654/725 [==========================>...] - ETA: 0s - loss: 0.2793 - accuracy: 0.9132\n",
      "Epoch 316: val_loss did not improve from 0.28207\n",
      "725/725 [==============================] - 1s 738us/step - loss: 0.2797 - accuracy: 0.9137 - val_loss: 0.2862 - val_accuracy: 0.9116\n",
      "Epoch 317/400\n",
      "655/725 [==========================>...] - ETA: 0s - loss: 0.2792 - accuracy: 0.9150\n",
      "Epoch 317: val_loss did not improve from 0.28207\n",
      "725/725 [==============================] - 1s 739us/step - loss: 0.2796 - accuracy: 0.9145 - val_loss: 0.2835 - val_accuracy: 0.9028\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/725 [==========================>...] - ETA: 0s - loss: 0.2795 - accuracy: 0.9137\n",
      "Epoch 318: val_loss did not improve from 0.28207\n",
      "725/725 [==============================] - 1s 725us/step - loss: 0.2791 - accuracy: 0.9142 - val_loss: 0.2833 - val_accuracy: 0.9085\n",
      "Epoch 319/400\n",
      "648/725 [=========================>....] - ETA: 0s - loss: 0.2784 - accuracy: 0.9136\n",
      "Epoch 319: val_loss improved from 0.28207 to 0.28138, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 783us/step - loss: 0.2789 - accuracy: 0.9137 - val_loss: 0.2814 - val_accuracy: 0.9122\n",
      "Epoch 320/400\n",
      "647/725 [=========================>....] - ETA: 0s - loss: 0.2780 - accuracy: 0.9145\n",
      "Epoch 320: val_loss did not improve from 0.28138\n",
      "725/725 [==============================] - 1s 738us/step - loss: 0.2786 - accuracy: 0.9134 - val_loss: 0.2818 - val_accuracy: 0.9111\n",
      "Epoch 321/400\n",
      "647/725 [=========================>....] - ETA: 0s - loss: 0.2796 - accuracy: 0.9129\n",
      "Epoch 321: val_loss improved from 0.28138 to 0.28078, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 752us/step - loss: 0.2779 - accuracy: 0.9138 - val_loss: 0.2808 - val_accuracy: 0.9124\n",
      "Epoch 322/400\n",
      "662/725 [==========================>...] - ETA: 0s - loss: 0.2787 - accuracy: 0.9139\n",
      "Epoch 322: val_loss did not improve from 0.28078\n",
      "725/725 [==============================] - 1s 725us/step - loss: 0.2784 - accuracy: 0.9140 - val_loss: 0.2819 - val_accuracy: 0.9043\n",
      "Epoch 323/400\n",
      "718/725 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.9141\n",
      "Epoch 323: val_loss did not improve from 0.28078\n",
      "725/725 [==============================] - 1s 754us/step - loss: 0.2778 - accuracy: 0.9141 - val_loss: 0.2813 - val_accuracy: 0.9039\n",
      "Epoch 324/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.2780 - accuracy: 0.9139\n",
      "Epoch 324: val_loss improved from 0.28078 to 0.27877, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 753us/step - loss: 0.2778 - accuracy: 0.9141 - val_loss: 0.2788 - val_accuracy: 0.9083\n",
      "Epoch 325/400\n",
      "662/725 [==========================>...] - ETA: 0s - loss: 0.2778 - accuracy: 0.9136\n",
      "Epoch 325: val_loss did not improve from 0.27877\n",
      "725/725 [==============================] - 1s 726us/step - loss: 0.2775 - accuracy: 0.9138 - val_loss: 0.2804 - val_accuracy: 0.9120\n",
      "Epoch 326/400\n",
      "655/725 [==========================>...] - ETA: 0s - loss: 0.2768 - accuracy: 0.9137\n",
      "Epoch 326: val_loss did not improve from 0.27877\n",
      "725/725 [==============================] - 1s 736us/step - loss: 0.2773 - accuracy: 0.9132 - val_loss: 0.2806 - val_accuracy: 0.9113\n",
      "Epoch 327/400\n",
      "718/725 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.9145\n",
      "Epoch 327: val_loss did not improve from 0.27877\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.2774 - accuracy: 0.9144 - val_loss: 0.2788 - val_accuracy: 0.9107\n",
      "Epoch 328/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.2768 - accuracy: 0.9144\n",
      "Epoch 328: val_loss did not improve from 0.27877\n",
      "725/725 [==============================] - 1s 747us/step - loss: 0.2769 - accuracy: 0.9144 - val_loss: 0.2789 - val_accuracy: 0.9168\n",
      "Epoch 329/400\n",
      "668/725 [==========================>...] - ETA: 0s - loss: 0.2769 - accuracy: 0.9153\n",
      "Epoch 329: val_loss improved from 0.27877 to 0.27805, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 744us/step - loss: 0.2764 - accuracy: 0.9156 - val_loss: 0.2781 - val_accuracy: 0.9116\n",
      "Epoch 330/400\n",
      "671/725 [==========================>...] - ETA: 0s - loss: 0.2761 - accuracy: 0.9143\n",
      "Epoch 330: val_loss improved from 0.27805 to 0.27785, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 746us/step - loss: 0.2765 - accuracy: 0.9140 - val_loss: 0.2779 - val_accuracy: 0.9122\n",
      "Epoch 331/400\n",
      "641/725 [=========================>....] - ETA: 0s - loss: 0.2763 - accuracy: 0.9144\n",
      "Epoch 331: val_loss did not improve from 0.27785\n",
      "725/725 [==============================] - 1s 746us/step - loss: 0.2761 - accuracy: 0.9143 - val_loss: 0.2795 - val_accuracy: 0.9116\n",
      "Epoch 332/400\n",
      "651/725 [=========================>....] - ETA: 0s - loss: 0.2752 - accuracy: 0.9153\n",
      "Epoch 332: val_loss improved from 0.27785 to 0.27694, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 762us/step - loss: 0.2761 - accuracy: 0.9151 - val_loss: 0.2769 - val_accuracy: 0.9116\n",
      "Epoch 333/400\n",
      "665/725 [==========================>...] - ETA: 0s - loss: 0.2750 - accuracy: 0.9162\n",
      "Epoch 333: val_loss improved from 0.27694 to 0.27643, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 741us/step - loss: 0.2759 - accuracy: 0.9159 - val_loss: 0.2764 - val_accuracy: 0.9134\n",
      "Epoch 334/400\n",
      "663/725 [==========================>...] - ETA: 0s - loss: 0.2737 - accuracy: 0.9164\n",
      "Epoch 334: val_loss did not improve from 0.27643\n",
      "725/725 [==============================] - 1s 726us/step - loss: 0.2751 - accuracy: 0.9158 - val_loss: 0.2799 - val_accuracy: 0.9101\n",
      "Epoch 335/400\n",
      "711/725 [============================>.] - ETA: 0s - loss: 0.2754 - accuracy: 0.9150\n",
      "Epoch 335: val_loss improved from 0.27643 to 0.27626, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 787us/step - loss: 0.2753 - accuracy: 0.9153 - val_loss: 0.2763 - val_accuracy: 0.9128\n",
      "Epoch 336/400\n",
      "648/725 [=========================>....] - ETA: 0s - loss: 0.2759 - accuracy: 0.9152\n",
      "Epoch 336: val_loss did not improve from 0.27626\n",
      "725/725 [==============================] - 1s 738us/step - loss: 0.2752 - accuracy: 0.9155 - val_loss: 0.2770 - val_accuracy: 0.9117\n",
      "Epoch 337/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.2751 - accuracy: 0.9155\n",
      "Epoch 337: val_loss did not improve from 0.27626\n",
      "725/725 [==============================] - 1s 732us/step - loss: 0.2750 - accuracy: 0.9155 - val_loss: 0.2790 - val_accuracy: 0.9088\n",
      "Epoch 338/400\n",
      "673/725 [==========================>...] - ETA: 0s - loss: 0.2756 - accuracy: 0.9166\n",
      "Epoch 338: val_loss improved from 0.27626 to 0.27625, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 734us/step - loss: 0.2743 - accuracy: 0.9171 - val_loss: 0.2763 - val_accuracy: 0.9083\n",
      "Epoch 339/400\n",
      "645/725 [=========================>....] - ETA: 0s - loss: 0.2715 - accuracy: 0.9175\n",
      "Epoch 339: val_loss did not improve from 0.27625\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.2737 - accuracy: 0.9168 - val_loss: 0.2771 - val_accuracy: 0.9116\n",
      "Epoch 340/400\n",
      "662/725 [==========================>...] - ETA: 0s - loss: 0.2735 - accuracy: 0.9165\n",
      "Epoch 340: val_loss improved from 0.27625 to 0.27445, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 744us/step - loss: 0.2737 - accuracy: 0.9166 - val_loss: 0.2744 - val_accuracy: 0.9150\n",
      "Epoch 341/400\n",
      "654/725 [==========================>...] - ETA: 0s - loss: 0.2724 - accuracy: 0.9172\n",
      "Epoch 341: val_loss did not improve from 0.27445\n",
      "725/725 [==============================] - 1s 734us/step - loss: 0.2722 - accuracy: 0.9178 - val_loss: 0.2754 - val_accuracy: 0.9077\n",
      "Epoch 342/400\n",
      "649/725 [=========================>....] - ETA: 0s - loss: 0.2736 - accuracy: 0.9162\n",
      "Epoch 342: val_loss did not improve from 0.27445\n",
      "725/725 [==============================] - 1s 733us/step - loss: 0.2718 - accuracy: 0.9167 - val_loss: 0.2756 - val_accuracy: 0.9095\n",
      "Epoch 343/400\n",
      "722/725 [============================>.] - ETA: 0s - loss: 0.2714 - accuracy: 0.9166\n",
      "Epoch 343: val_loss did not improve from 0.27445\n",
      "725/725 [==============================] - 1s 748us/step - loss: 0.2713 - accuracy: 0.9167 - val_loss: 0.2752 - val_accuracy: 0.9079\n",
      "Epoch 344/400\n",
      "669/725 [==========================>...] - ETA: 0s - loss: 0.2709 - accuracy: 0.9165\n",
      "Epoch 344: val_loss improved from 0.27445 to 0.27364, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 746us/step - loss: 0.2710 - accuracy: 0.9169 - val_loss: 0.2736 - val_accuracy: 0.9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.2707 - accuracy: 0.9170\n",
      "Epoch 345: val_loss improved from 0.27364 to 0.27359, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 757us/step - loss: 0.2709 - accuracy: 0.9169 - val_loss: 0.2736 - val_accuracy: 0.9091\n",
      "Epoch 346/400\n",
      "666/725 [==========================>...] - ETA: 0s - loss: 0.2696 - accuracy: 0.9168\n",
      "Epoch 346: val_loss improved from 0.27359 to 0.27209, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 746us/step - loss: 0.2703 - accuracy: 0.9166 - val_loss: 0.2721 - val_accuracy: 0.9115\n",
      "Epoch 347/400\n",
      "669/725 [==========================>...] - ETA: 0s - loss: 0.2709 - accuracy: 0.9163\n",
      "Epoch 347: val_loss did not improve from 0.27209\n",
      "725/725 [==============================] - 1s 818us/step - loss: 0.2703 - accuracy: 0.9164 - val_loss: 0.2749 - val_accuracy: 0.9107\n",
      "Epoch 348/400\n",
      "689/725 [===========================>..] - ETA: 0s - loss: 0.2707 - accuracy: 0.9164\n",
      "Epoch 348: val_loss improved from 0.27209 to 0.27201, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 811us/step - loss: 0.2701 - accuracy: 0.9165 - val_loss: 0.2720 - val_accuracy: 0.9115\n",
      "Epoch 349/400\n",
      "717/725 [============================>.] - ETA: 0s - loss: 0.2699 - accuracy: 0.9174\n",
      "Epoch 349: val_loss improved from 0.27201 to 0.27158, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 773us/step - loss: 0.2699 - accuracy: 0.9172 - val_loss: 0.2716 - val_accuracy: 0.9116\n",
      "Epoch 350/400\n",
      "703/725 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9169\n",
      "Epoch 350: val_loss improved from 0.27158 to 0.27097, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 825us/step - loss: 0.2697 - accuracy: 0.9170 - val_loss: 0.2710 - val_accuracy: 0.9177\n",
      "Epoch 351/400\n",
      "705/725 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.9165\n",
      "Epoch 351: val_loss did not improve from 0.27097\n",
      "725/725 [==============================] - 1s 764us/step - loss: 0.2694 - accuracy: 0.9165 - val_loss: 0.2712 - val_accuracy: 0.9120\n",
      "Epoch 352/400\n",
      "720/725 [============================>.] - ETA: 0s - loss: 0.2690 - accuracy: 0.9171\n",
      "Epoch 352: val_loss did not improve from 0.27097\n",
      "725/725 [==============================] - 1s 763us/step - loss: 0.2693 - accuracy: 0.9170 - val_loss: 0.2732 - val_accuracy: 0.9104\n",
      "Epoch 353/400\n",
      "652/725 [=========================>....] - ETA: 0s - loss: 0.2698 - accuracy: 0.9172\n",
      "Epoch 353: val_loss improved from 0.27097 to 0.26964, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 763us/step - loss: 0.2690 - accuracy: 0.9171 - val_loss: 0.2696 - val_accuracy: 0.9134\n",
      "Epoch 354/400\n",
      "683/725 [===========================>..] - ETA: 0s - loss: 0.2692 - accuracy: 0.9178\n",
      "Epoch 354: val_loss did not improve from 0.26964\n",
      "725/725 [==============================] - 1s 785us/step - loss: 0.2687 - accuracy: 0.9175 - val_loss: 0.2720 - val_accuracy: 0.9154\n",
      "Epoch 355/400\n",
      "670/725 [==========================>...] - ETA: 0s - loss: 0.2688 - accuracy: 0.9178\n",
      "Epoch 355: val_loss did not improve from 0.26964\n",
      "725/725 [==============================] - 1s 795us/step - loss: 0.2687 - accuracy: 0.9180 - val_loss: 0.2703 - val_accuracy: 0.9101\n",
      "Epoch 356/400\n",
      "706/725 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.9174\n",
      "Epoch 356: val_loss improved from 0.26964 to 0.26935, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 790us/step - loss: 0.2687 - accuracy: 0.9177 - val_loss: 0.2693 - val_accuracy: 0.9118\n",
      "Epoch 357/400\n",
      "647/725 [=========================>....] - ETA: 0s - loss: 0.2692 - accuracy: 0.9177\n",
      "Epoch 357: val_loss did not improve from 0.26935\n",
      "725/725 [==============================] - 1s 751us/step - loss: 0.2684 - accuracy: 0.9182 - val_loss: 0.2709 - val_accuracy: 0.9132\n",
      "Epoch 358/400\n",
      "696/725 [===========================>..] - ETA: 0s - loss: 0.2685 - accuracy: 0.9175\n",
      "Epoch 358: val_loss did not improve from 0.26935\n",
      "725/725 [==============================] - 1s 774us/step - loss: 0.2684 - accuracy: 0.9177 - val_loss: 0.2703 - val_accuracy: 0.9131\n",
      "Epoch 359/400\n",
      "715/725 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9174\n",
      "Epoch 359: val_loss improved from 0.26935 to 0.26899, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 772us/step - loss: 0.2679 - accuracy: 0.9174 - val_loss: 0.2690 - val_accuracy: 0.9156\n",
      "Epoch 360/400\n",
      "724/725 [============================>.] - ETA: 0s - loss: 0.2678 - accuracy: 0.9190\n",
      "Epoch 360: val_loss did not improve from 0.26899\n",
      "725/725 [==============================] - 1s 750us/step - loss: 0.2677 - accuracy: 0.9190 - val_loss: 0.2695 - val_accuracy: 0.9090\n",
      "Epoch 361/400\n",
      "722/725 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9186\n",
      "Epoch 361: val_loss improved from 0.26899 to 0.26852, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 799us/step - loss: 0.2676 - accuracy: 0.9184 - val_loss: 0.2685 - val_accuracy: 0.9160\n",
      "Epoch 362/400\n",
      "644/725 [=========================>....] - ETA: 0s - loss: 0.2675 - accuracy: 0.9189\n",
      "Epoch 362: val_loss did not improve from 0.26852\n",
      "725/725 [==============================] - 1s 749us/step - loss: 0.2673 - accuracy: 0.9190 - val_loss: 0.2713 - val_accuracy: 0.9151\n",
      "Epoch 363/400\n",
      "711/725 [============================>.] - ETA: 0s - loss: 0.2675 - accuracy: 0.9182\n",
      "Epoch 363: val_loss did not improve from 0.26852\n",
      "725/725 [==============================] - 1s 764us/step - loss: 0.2672 - accuracy: 0.9185 - val_loss: 0.2701 - val_accuracy: 0.9105\n",
      "Epoch 364/400\n",
      "724/725 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.9185\n",
      "Epoch 364: val_loss improved from 0.26852 to 0.26719, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 781us/step - loss: 0.2674 - accuracy: 0.9185 - val_loss: 0.2672 - val_accuracy: 0.9167\n",
      "Epoch 365/400\n",
      "695/725 [===========================>..] - ETA: 0s - loss: 0.2665 - accuracy: 0.9186\n",
      "Epoch 365: val_loss did not improve from 0.26719\n",
      "725/725 [==============================] - 1s 785us/step - loss: 0.2670 - accuracy: 0.9184 - val_loss: 0.2715 - val_accuracy: 0.9102\n",
      "Epoch 366/400\n",
      "660/725 [==========================>...] - ETA: 0s - loss: 0.2665 - accuracy: 0.9193\n",
      "Epoch 366: val_loss did not improve from 0.26719\n",
      "725/725 [==============================] - 1s 816us/step - loss: 0.2670 - accuracy: 0.9191 - val_loss: 0.2681 - val_accuracy: 0.9140\n",
      "Epoch 367/400\n",
      "722/725 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9178\n",
      "Epoch 367: val_loss did not improve from 0.26719\n",
      "725/725 [==============================] - 1s 747us/step - loss: 0.2668 - accuracy: 0.9179 - val_loss: 0.2678 - val_accuracy: 0.9109\n",
      "Epoch 368/400\n",
      "724/725 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9187\n",
      "Epoch 368: val_loss did not improve from 0.26719\n",
      "725/725 [==============================] - 1s 745us/step - loss: 0.2665 - accuracy: 0.9187 - val_loss: 0.2683 - val_accuracy: 0.9135\n",
      "Epoch 369/400\n",
      "716/725 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9182\n",
      "Epoch 369: val_loss did not improve from 0.26719\n",
      "725/725 [==============================] - 1s 753us/step - loss: 0.2662 - accuracy: 0.9184 - val_loss: 0.2718 - val_accuracy: 0.9162\n",
      "Epoch 370/400\n",
      "650/725 [=========================>....] - ETA: 0s - loss: 0.2661 - accuracy: 0.9194\n",
      "Epoch 370: val_loss did not improve from 0.26719\n",
      "725/725 [==============================] - 1s 755us/step - loss: 0.2663 - accuracy: 0.9193 - val_loss: 0.2678 - val_accuracy: 0.9167\n",
      "Epoch 371/400\n",
      "652/725 [=========================>....] - ETA: 0s - loss: 0.2653 - accuracy: 0.9185\n",
      "Epoch 371: val_loss did not improve from 0.26719\n",
      "725/725 [==============================] - 1s 736us/step - loss: 0.2659 - accuracy: 0.9188 - val_loss: 0.2680 - val_accuracy: 0.9179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/400\n",
      "646/725 [=========================>....] - ETA: 0s - loss: 0.2648 - accuracy: 0.9206\n",
      "Epoch 372: val_loss improved from 0.26719 to 0.26639, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 757us/step - loss: 0.2661 - accuracy: 0.9196 - val_loss: 0.2664 - val_accuracy: 0.9162\n",
      "Epoch 373/400\n",
      "722/725 [============================>.] - ETA: 0s - loss: 0.2659 - accuracy: 0.9175\n",
      "Epoch 373: val_loss did not improve from 0.26639\n",
      "725/725 [==============================] - 1s 749us/step - loss: 0.2658 - accuracy: 0.9176 - val_loss: 0.2685 - val_accuracy: 0.9170\n",
      "Epoch 374/400\n",
      "646/725 [=========================>....] - ETA: 0s - loss: 0.2651 - accuracy: 0.9207\n",
      "Epoch 374: val_loss improved from 0.26639 to 0.26552, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 762us/step - loss: 0.2655 - accuracy: 0.9208 - val_loss: 0.2655 - val_accuracy: 0.9150\n",
      "Epoch 375/400\n",
      "652/725 [=========================>....] - ETA: 0s - loss: 0.2645 - accuracy: 0.9198\n",
      "Epoch 375: val_loss did not improve from 0.26552\n",
      "725/725 [==============================] - 1s 730us/step - loss: 0.2653 - accuracy: 0.9191 - val_loss: 0.2659 - val_accuracy: 0.9171\n",
      "Epoch 376/400\n",
      "717/725 [============================>.] - ETA: 0s - loss: 0.2649 - accuracy: 0.9199\n",
      "Epoch 376: val_loss did not improve from 0.26552\n",
      "725/725 [==============================] - 1s 752us/step - loss: 0.2649 - accuracy: 0.9197 - val_loss: 0.2672 - val_accuracy: 0.9121\n",
      "Epoch 377/400\n",
      "705/725 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.9213\n",
      "Epoch 377: val_loss did not improve from 0.26552\n",
      "725/725 [==============================] - 1s 771us/step - loss: 0.2650 - accuracy: 0.9213 - val_loss: 0.2661 - val_accuracy: 0.9112\n",
      "Epoch 378/400\n",
      "718/725 [============================>.] - ETA: 0s - loss: 0.2652 - accuracy: 0.9206\n",
      "Epoch 378: val_loss improved from 0.26552 to 0.26441, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 777us/step - loss: 0.2651 - accuracy: 0.9205 - val_loss: 0.2644 - val_accuracy: 0.9153\n",
      "Epoch 379/400\n",
      "721/725 [============================>.] - ETA: 0s - loss: 0.2647 - accuracy: 0.9190\n",
      "Epoch 379: val_loss did not improve from 0.26441\n",
      "725/725 [==============================] - 1s 746us/step - loss: 0.2646 - accuracy: 0.9189 - val_loss: 0.2657 - val_accuracy: 0.9140\n",
      "Epoch 380/400\n",
      "648/725 [=========================>....] - ETA: 0s - loss: 0.2642 - accuracy: 0.9205\n",
      "Epoch 380: val_loss did not improve from 0.26441\n",
      "725/725 [==============================] - 1s 757us/step - loss: 0.2648 - accuracy: 0.9198 - val_loss: 0.2667 - val_accuracy: 0.9182\n",
      "Epoch 381/400\n",
      "709/725 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.9191\n",
      "Epoch 381: val_loss did not improve from 0.26441\n",
      "725/725 [==============================] - 1s 759us/step - loss: 0.2645 - accuracy: 0.9191 - val_loss: 0.2663 - val_accuracy: 0.9111\n",
      "Epoch 382/400\n",
      "659/725 [==========================>...] - ETA: 0s - loss: 0.2655 - accuracy: 0.9211\n",
      "Epoch 382: val_loss did not improve from 0.26441\n",
      "725/725 [==============================] - 1s 732us/step - loss: 0.2644 - accuracy: 0.9213 - val_loss: 0.2654 - val_accuracy: 0.9143\n",
      "Epoch 383/400\n",
      "650/725 [=========================>....] - ETA: 0s - loss: 0.2670 - accuracy: 0.9192\n",
      "Epoch 383: val_loss did not improve from 0.26441\n",
      "725/725 [==============================] - 1s 738us/step - loss: 0.2645 - accuracy: 0.9195 - val_loss: 0.2665 - val_accuracy: 0.9135\n",
      "Epoch 384/400\n",
      "657/725 [==========================>...] - ETA: 0s - loss: 0.2652 - accuracy: 0.9200\n",
      "Epoch 384: val_loss did not improve from 0.26441\n",
      "725/725 [==============================] - 1s 740us/step - loss: 0.2643 - accuracy: 0.9204 - val_loss: 0.2648 - val_accuracy: 0.9138\n",
      "Epoch 385/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.2639 - accuracy: 0.9195\n",
      "Epoch 385: val_loss did not improve from 0.26441\n",
      "725/725 [==============================] - 1s 747us/step - loss: 0.2640 - accuracy: 0.9194 - val_loss: 0.2660 - val_accuracy: 0.9138\n",
      "Epoch 386/400\n",
      "654/725 [==========================>...] - ETA: 0s - loss: 0.2638 - accuracy: 0.9206\n",
      "Epoch 386: val_loss improved from 0.26441 to 0.26428, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 765us/step - loss: 0.2641 - accuracy: 0.9206 - val_loss: 0.2643 - val_accuracy: 0.9140\n",
      "Epoch 387/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.9210\n",
      "Epoch 387: val_loss improved from 0.26428 to 0.26321, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 779us/step - loss: 0.2637 - accuracy: 0.9209 - val_loss: 0.2632 - val_accuracy: 0.9135\n",
      "Epoch 388/400\n",
      "688/725 [===========================>..] - ETA: 0s - loss: 0.2640 - accuracy: 0.9208\n",
      "Epoch 388: val_loss did not improve from 0.26321\n",
      "725/725 [==============================] - 1s 788us/step - loss: 0.2637 - accuracy: 0.9206 - val_loss: 0.2652 - val_accuracy: 0.9113\n",
      "Epoch 389/400\n",
      "679/725 [===========================>..] - ETA: 0s - loss: 0.2638 - accuracy: 0.9204\n",
      "Epoch 389: val_loss did not improve from 0.26321\n",
      "725/725 [==============================] - 1s 795us/step - loss: 0.2631 - accuracy: 0.9204 - val_loss: 0.2661 - val_accuracy: 0.9111\n",
      "Epoch 390/400\n",
      "706/725 [============================>.] - ETA: 0s - loss: 0.2635 - accuracy: 0.9211\n",
      "Epoch 390: val_loss did not improve from 0.26321\n",
      "725/725 [==============================] - 1s 839us/step - loss: 0.2639 - accuracy: 0.9210 - val_loss: 0.2641 - val_accuracy: 0.9204\n",
      "Epoch 391/400\n",
      "719/725 [============================>.] - ETA: 0s - loss: 0.2636 - accuracy: 0.9210\n",
      "Epoch 391: val_loss did not improve from 0.26321\n",
      "725/725 [==============================] - 1s 760us/step - loss: 0.2635 - accuracy: 0.9210 - val_loss: 0.2640 - val_accuracy: 0.9160\n",
      "Epoch 392/400\n",
      "661/725 [==========================>...] - ETA: 0s - loss: 0.2630 - accuracy: 0.9199\n",
      "Epoch 392: val_loss did not improve from 0.26321\n",
      "725/725 [==============================] - 1s 796us/step - loss: 0.2632 - accuracy: 0.9199 - val_loss: 0.2644 - val_accuracy: 0.9181\n",
      "Epoch 393/400\n",
      "648/725 [=========================>....] - ETA: 0s - loss: 0.2629 - accuracy: 0.9212\n",
      "Epoch 393: val_loss improved from 0.26321 to 0.26282, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 756us/step - loss: 0.2628 - accuracy: 0.9215 - val_loss: 0.2628 - val_accuracy: 0.9199\n",
      "Epoch 394/400\n",
      "717/725 [============================>.] - ETA: 0s - loss: 0.2628 - accuracy: 0.9204\n",
      "Epoch 394: val_loss did not improve from 0.26282\n",
      "725/725 [==============================] - 1s 757us/step - loss: 0.2626 - accuracy: 0.9205 - val_loss: 0.2641 - val_accuracy: 0.9178\n",
      "Epoch 395/400\n",
      "710/725 [============================>.] - ETA: 0s - loss: 0.2627 - accuracy: 0.9203\n",
      "Epoch 395: val_loss improved from 0.26282 to 0.26220, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 788us/step - loss: 0.2631 - accuracy: 0.9203 - val_loss: 0.2622 - val_accuracy: 0.9193\n",
      "Epoch 396/400\n",
      "686/725 [===========================>..] - ETA: 0s - loss: 0.2625 - accuracy: 0.9205\n",
      "Epoch 396: val_loss improved from 0.26220 to 0.26194, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 811us/step - loss: 0.2624 - accuracy: 0.9209 - val_loss: 0.2619 - val_accuracy: 0.9149\n",
      "Epoch 397/400\n",
      "707/725 [============================>.] - ETA: 0s - loss: 0.2624 - accuracy: 0.9208\n",
      "Epoch 397: val_loss did not improve from 0.26194\n",
      "725/725 [==============================] - 1s 761us/step - loss: 0.2628 - accuracy: 0.9208 - val_loss: 0.2629 - val_accuracy: 0.9146\n",
      "Epoch 398/400\n",
      "712/725 [============================>.] - ETA: 0s - loss: 0.2620 - accuracy: 0.9202\n",
      "Epoch 398: val_loss did not improve from 0.26194\n",
      "725/725 [==============================] - 1s 756us/step - loss: 0.2623 - accuracy: 0.9201 - val_loss: 0.2620 - val_accuracy: 0.9175\n",
      "Epoch 399/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718/725 [============================>.] - ETA: 0s - loss: 0.2618 - accuracy: 0.9207\n",
      "Epoch 399: val_loss improved from 0.26194 to 0.26056, saving model to ENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "725/725 [==============================] - 1s 773us/step - loss: 0.2624 - accuracy: 0.9206 - val_loss: 0.2606 - val_accuracy: 0.9231\n",
      "Epoch 400/400\n",
      "715/725 [============================>.] - ETA: 0s - loss: 0.2627 - accuracy: 0.9205\n",
      "Epoch 400: val_loss did not improve from 0.26056\n",
      "725/725 [==============================] - 1s 749us/step - loss: 0.2622 - accuracy: 0.9206 - val_loss: 0.2639 - val_accuracy: 0.9188\n",
      "name weight ENO3//model/trained_weights_Hn_7union_data.mat\n",
      "302/302 [==============================] - 0s 498us/step\n",
      "here\n",
      "Accuracy  : 0.9210007266687429\n",
      "Precision : 0.9230351177689997\n",
      "f1Score : 0.9209776546110229\n",
      "[[2036  276    0]\n",
      " [ 158 5107   38]\n",
      " [ 216   73 1729]]\n",
      "train history is strored in ENO3/History/history-Hn_7union_data.dat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is smoothdata\n",
      "Data file being used is: ENOL3/train_input_smoothdata.csv\n",
      "In load data (31720, 6) (31720,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 49        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73 (584.00 Byte)\n",
      "Trainable params: 73 (584.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "1414/1433 [============================>.] - ETA: 0s - loss: 0.5842 - accuracy: 0.7579\n",
      "Epoch 1: val_loss improved from inf to 0.53910, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 2s 914us/step - loss: 0.5837 - accuracy: 0.7577 - val_loss: 0.5391 - val_accuracy: 0.7758\n",
      "Epoch 2/400\n",
      " 243/1433 [====>.........................] - ETA: 0s - loss: 0.5581 - accuracy: 0.7729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\xai\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394/1433 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.8094\n",
      "Epoch 2: val_loss improved from 0.53910 to 0.50684, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 734us/step - loss: 0.5243 - accuracy: 0.8104 - val_loss: 0.5068 - val_accuracy: 0.8465\n",
      "Epoch 3/400\n",
      "1396/1433 [============================>.] - ETA: 0s - loss: 0.4924 - accuracy: 0.8539\n",
      "Epoch 3: val_loss improved from 0.50684 to 0.47657, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 793us/step - loss: 0.4932 - accuracy: 0.8535 - val_loss: 0.4766 - val_accuracy: 0.8643\n",
      "Epoch 4/400\n",
      "1372/1433 [===========================>..] - ETA: 0s - loss: 0.4663 - accuracy: 0.8748\n",
      "Epoch 4: val_loss improved from 0.47657 to 0.45279, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 741us/step - loss: 0.4649 - accuracy: 0.8749 - val_loss: 0.4528 - val_accuracy: 0.8672\n",
      "Epoch 5/400\n",
      "1379/1433 [===========================>..] - ETA: 0s - loss: 0.4397 - accuracy: 0.8773\n",
      "Epoch 5: val_loss improved from 0.45279 to 0.43147, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 760us/step - loss: 0.4418 - accuracy: 0.8766 - val_loss: 0.4315 - val_accuracy: 0.8705\n",
      "Epoch 6/400\n",
      "1365/1433 [===========================>..] - ETA: 0s - loss: 0.4194 - accuracy: 0.8811\n",
      "Epoch 6: val_loss improved from 0.43147 to 0.41079, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 748us/step - loss: 0.4183 - accuracy: 0.8817 - val_loss: 0.4108 - val_accuracy: 0.8900\n",
      "Epoch 7/400\n",
      "1413/1433 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.8881\n",
      "Epoch 7: val_loss improved from 0.41079 to 0.39682, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 759us/step - loss: 0.4007 - accuracy: 0.8879 - val_loss: 0.3968 - val_accuracy: 0.8855\n",
      "Epoch 8/400\n",
      "1408/1433 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8902\n",
      "Epoch 8: val_loss improved from 0.39682 to 0.38404, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 731us/step - loss: 0.3862 - accuracy: 0.8901 - val_loss: 0.3840 - val_accuracy: 0.8845\n",
      "Epoch 9/400\n",
      "1397/1433 [============================>.] - ETA: 0s - loss: 0.3766 - accuracy: 0.8934\n",
      "Epoch 9: val_loss improved from 0.38404 to 0.37549, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 733us/step - loss: 0.3764 - accuracy: 0.8934 - val_loss: 0.3755 - val_accuracy: 0.8841\n",
      "Epoch 10/400\n",
      "1367/1433 [===========================>..] - ETA: 0s - loss: 0.3683 - accuracy: 0.8966\n",
      "Epoch 10: val_loss improved from 0.37549 to 0.36720, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 781us/step - loss: 0.3681 - accuracy: 0.8972 - val_loss: 0.3672 - val_accuracy: 0.8981\n",
      "Epoch 11/400\n",
      "1414/1433 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.9021\n",
      "Epoch 11: val_loss improved from 0.36720 to 0.36360, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 720us/step - loss: 0.3596 - accuracy: 0.9019 - val_loss: 0.3636 - val_accuracy: 0.9150\n",
      "Epoch 12/400\n",
      "1412/1433 [============================>.] - ETA: 0s - loss: 0.3543 - accuracy: 0.9066\n",
      "Epoch 12: val_loss improved from 0.36360 to 0.35481, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 725us/step - loss: 0.3537 - accuracy: 0.9064 - val_loss: 0.3548 - val_accuracy: 0.9021\n",
      "Epoch 13/400\n",
      "1411/1433 [============================>.] - ETA: 0s - loss: 0.3474 - accuracy: 0.9093\n",
      "Epoch 13: val_loss improved from 0.35481 to 0.34832, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 718us/step - loss: 0.3474 - accuracy: 0.9094 - val_loss: 0.3483 - val_accuracy: 0.9004\n",
      "Epoch 14/400\n",
      "1415/1433 [============================>.] - ETA: 0s - loss: 0.3401 - accuracy: 0.9100\n",
      "Epoch 14: val_loss improved from 0.34832 to 0.34545, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 721us/step - loss: 0.3408 - accuracy: 0.9096 - val_loss: 0.3455 - val_accuracy: 0.9110\n",
      "Epoch 15/400\n",
      "1425/1433 [============================>.] - ETA: 0s - loss: 0.3346 - accuracy: 0.9101\n",
      "Epoch 15: val_loss improved from 0.34545 to 0.33934, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 719us/step - loss: 0.3347 - accuracy: 0.9102 - val_loss: 0.3393 - val_accuracy: 0.9085\n",
      "Epoch 16/400\n",
      "1365/1433 [===========================>..] - ETA: 0s - loss: 0.3310 - accuracy: 0.9113\n",
      "Epoch 16: val_loss improved from 0.33934 to 0.33433, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 784us/step - loss: 0.3304 - accuracy: 0.9112 - val_loss: 0.3343 - val_accuracy: 0.9155\n",
      "Epoch 17/400\n",
      "1401/1433 [============================>.] - ETA: 0s - loss: 0.3261 - accuracy: 0.9140\n",
      "Epoch 17: val_loss improved from 0.33433 to 0.32870, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 723us/step - loss: 0.3258 - accuracy: 0.9140 - val_loss: 0.3287 - val_accuracy: 0.9125\n",
      "Epoch 18/400\n",
      "1366/1433 [===========================>..] - ETA: 0s - loss: 0.3198 - accuracy: 0.9148\n",
      "Epoch 18: val_loss improved from 0.32870 to 0.32758, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 780us/step - loss: 0.3216 - accuracy: 0.9145 - val_loss: 0.3276 - val_accuracy: 0.9201\n",
      "Epoch 19/400\n",
      "1382/1433 [===========================>..] - ETA: 0s - loss: 0.3192 - accuracy: 0.9142\n",
      "Epoch 19: val_loss improved from 0.32758 to 0.32219, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 731us/step - loss: 0.3185 - accuracy: 0.9148 - val_loss: 0.3222 - val_accuracy: 0.9179\n",
      "Epoch 20/400\n",
      "1398/1433 [============================>.] - ETA: 0s - loss: 0.3155 - accuracy: 0.9150\n",
      "Epoch 20: val_loss improved from 0.32219 to 0.31892, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 743us/step - loss: 0.3154 - accuracy: 0.9146 - val_loss: 0.3189 - val_accuracy: 0.9105\n",
      "Epoch 21/400\n",
      "1399/1433 [============================>.] - ETA: 0s - loss: 0.3112 - accuracy: 0.9155\n",
      "Epoch 21: val_loss improved from 0.31892 to 0.31591, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 730us/step - loss: 0.3117 - accuracy: 0.9157 - val_loss: 0.3159 - val_accuracy: 0.9048\n",
      "Epoch 22/400\n",
      "1424/1433 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.9153\n",
      "Epoch 22: val_loss improved from 0.31591 to 0.31406, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 721us/step - loss: 0.3101 - accuracy: 0.9154 - val_loss: 0.3141 - val_accuracy: 0.9098\n",
      "Epoch 23/400\n",
      "1419/1433 [============================>.] - ETA: 0s - loss: 0.3064 - accuracy: 0.9164\n",
      "Epoch 23: val_loss improved from 0.31406 to 0.30954, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 716us/step - loss: 0.3064 - accuracy: 0.9163 - val_loss: 0.3095 - val_accuracy: 0.9137\n",
      "Epoch 24/400\n",
      "1428/1433 [============================>.] - ETA: 0s - loss: 0.3037 - accuracy: 0.9163\n",
      "Epoch 24: val_loss did not improve from 0.30954\n",
      "1433/1433 [==============================] - 1s 711us/step - loss: 0.3035 - accuracy: 0.9163 - val_loss: 0.3112 - val_accuracy: 0.9137\n",
      "Epoch 25/400\n",
      "1407/1433 [============================>.] - ETA: 0s - loss: 0.3016 - accuracy: 0.9173\n",
      "Epoch 25: val_loss did not improve from 0.30954\n",
      "1433/1433 [==============================] - 1s 713us/step - loss: 0.3016 - accuracy: 0.9172 - val_loss: 0.3113 - val_accuracy: 0.9162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/400\n",
      "1416/1433 [============================>.] - ETA: 0s - loss: 0.2996 - accuracy: 0.9172\n",
      "Epoch 26: val_loss improved from 0.30954 to 0.30429, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 720us/step - loss: 0.2993 - accuracy: 0.9173 - val_loss: 0.3043 - val_accuracy: 0.9204\n",
      "Epoch 27/400\n",
      "1392/1433 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.9187\n",
      "Epoch 27: val_loss improved from 0.30429 to 0.30199, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 734us/step - loss: 0.2973 - accuracy: 0.9184 - val_loss: 0.3020 - val_accuracy: 0.9209\n",
      "Epoch 28/400\n",
      "1381/1433 [===========================>..] - ETA: 0s - loss: 0.2945 - accuracy: 0.9200\n",
      "Epoch 28: val_loss improved from 0.30199 to 0.30068, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 741us/step - loss: 0.2950 - accuracy: 0.9198 - val_loss: 0.3007 - val_accuracy: 0.9189\n",
      "Epoch 29/400\n",
      "1427/1433 [============================>.] - ETA: 0s - loss: 0.2926 - accuracy: 0.9197\n",
      "Epoch 29: val_loss improved from 0.30068 to 0.29648, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 717us/step - loss: 0.2926 - accuracy: 0.9197 - val_loss: 0.2965 - val_accuracy: 0.9184\n",
      "Epoch 30/400\n",
      "1409/1433 [============================>.] - ETA: 0s - loss: 0.2913 - accuracy: 0.9188\n",
      "Epoch 30: val_loss did not improve from 0.29648\n",
      "1433/1433 [==============================] - 1s 716us/step - loss: 0.2909 - accuracy: 0.9189 - val_loss: 0.2984 - val_accuracy: 0.9197\n",
      "Epoch 31/400\n",
      "1411/1433 [============================>.] - ETA: 0s - loss: 0.2883 - accuracy: 0.9217\n",
      "Epoch 31: val_loss did not improve from 0.29648\n",
      "1433/1433 [==============================] - 1s 713us/step - loss: 0.2892 - accuracy: 0.9215 - val_loss: 0.2968 - val_accuracy: 0.9172\n",
      "Epoch 32/400\n",
      "1374/1433 [===========================>..] - ETA: 0s - loss: 0.2869 - accuracy: 0.9203\n",
      "Epoch 32: val_loss improved from 0.29648 to 0.29056, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 780us/step - loss: 0.2872 - accuracy: 0.9199 - val_loss: 0.2906 - val_accuracy: 0.9214\n",
      "Epoch 33/400\n",
      "1415/1433 [============================>.] - ETA: 0s - loss: 0.2854 - accuracy: 0.9227\n",
      "Epoch 33: val_loss did not improve from 0.29056\n",
      "1433/1433 [==============================] - 1s 709us/step - loss: 0.2854 - accuracy: 0.9222 - val_loss: 0.2920 - val_accuracy: 0.9132\n",
      "Epoch 34/400\n",
      "1422/1433 [============================>.] - ETA: 0s - loss: 0.2823 - accuracy: 0.9218\n",
      "Epoch 34: val_loss improved from 0.29056 to 0.28822, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 723us/step - loss: 0.2834 - accuracy: 0.9218 - val_loss: 0.2882 - val_accuracy: 0.9159\n",
      "Epoch 35/400\n",
      "1373/1433 [===========================>..] - ETA: 0s - loss: 0.2810 - accuracy: 0.9215\n",
      "Epoch 35: val_loss improved from 0.28822 to 0.28607, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 754us/step - loss: 0.2822 - accuracy: 0.9215 - val_loss: 0.2861 - val_accuracy: 0.9239\n",
      "Epoch 36/400\n",
      "1372/1433 [===========================>..] - ETA: 0s - loss: 0.2820 - accuracy: 0.9211\n",
      "Epoch 36: val_loss improved from 0.28607 to 0.28249, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 781us/step - loss: 0.2811 - accuracy: 0.9220 - val_loss: 0.2825 - val_accuracy: 0.9241\n",
      "Epoch 37/400\n",
      "1389/1433 [============================>.] - ETA: 0s - loss: 0.2782 - accuracy: 0.9207\n",
      "Epoch 37: val_loss improved from 0.28249 to 0.28140, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 736us/step - loss: 0.2790 - accuracy: 0.9210 - val_loss: 0.2814 - val_accuracy: 0.9211\n",
      "Epoch 38/400\n",
      "1400/1433 [============================>.] - ETA: 0s - loss: 0.2777 - accuracy: 0.9218\n",
      "Epoch 38: val_loss did not improve from 0.28140\n",
      "1433/1433 [==============================] - 1s 722us/step - loss: 0.2777 - accuracy: 0.9219 - val_loss: 0.2853 - val_accuracy: 0.9182\n",
      "Epoch 39/400\n",
      "1416/1433 [============================>.] - ETA: 0s - loss: 0.2770 - accuracy: 0.9230\n",
      "Epoch 39: val_loss improved from 0.28140 to 0.27884, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 722us/step - loss: 0.2770 - accuracy: 0.9228 - val_loss: 0.2788 - val_accuracy: 0.9263\n",
      "Epoch 40/400\n",
      "1384/1433 [===========================>..] - ETA: 0s - loss: 0.2764 - accuracy: 0.9221\n",
      "Epoch 40: val_loss did not improve from 0.27884\n",
      "1433/1433 [==============================] - 1s 728us/step - loss: 0.2751 - accuracy: 0.9226 - val_loss: 0.2792 - val_accuracy: 0.9268\n",
      "Epoch 41/400\n",
      "1397/1433 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.9225\n",
      "Epoch 41: val_loss did not improve from 0.27884\n",
      "1433/1433 [==============================] - 1s 717us/step - loss: 0.2741 - accuracy: 0.9218 - val_loss: 0.2880 - val_accuracy: 0.9187\n",
      "Epoch 42/400\n",
      "1407/1433 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.9220\n",
      "Epoch 42: val_loss improved from 0.27884 to 0.27407, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 732us/step - loss: 0.2730 - accuracy: 0.9224 - val_loss: 0.2741 - val_accuracy: 0.9226\n",
      "Epoch 43/400\n",
      "1382/1433 [===========================>..] - ETA: 0s - loss: 0.2715 - accuracy: 0.9227\n",
      "Epoch 43: val_loss did not improve from 0.27407\n",
      "1433/1433 [==============================] - 1s 724us/step - loss: 0.2722 - accuracy: 0.9223 - val_loss: 0.2831 - val_accuracy: 0.9318\n",
      "Epoch 44/400\n",
      "1399/1433 [============================>.] - ETA: 0s - loss: 0.2695 - accuracy: 0.9235\n",
      "Epoch 44: val_loss did not improve from 0.27407\n",
      "1433/1433 [==============================] - 1s 721us/step - loss: 0.2704 - accuracy: 0.9234 - val_loss: 0.2763 - val_accuracy: 0.9206\n",
      "Epoch 45/400\n",
      "1375/1433 [===========================>..] - ETA: 0s - loss: 0.2684 - accuracy: 0.9248\n",
      "Epoch 45: val_loss improved from 0.27407 to 0.27192, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 734us/step - loss: 0.2696 - accuracy: 0.9244 - val_loss: 0.2719 - val_accuracy: 0.9248\n",
      "Epoch 46/400\n",
      "1410/1433 [============================>.] - ETA: 0s - loss: 0.2682 - accuracy: 0.9225\n",
      "Epoch 46: val_loss improved from 0.27192 to 0.27072, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 729us/step - loss: 0.2683 - accuracy: 0.9224 - val_loss: 0.2707 - val_accuracy: 0.9214\n",
      "Epoch 47/400\n",
      "1423/1433 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9242\n",
      "Epoch 47: val_loss improved from 0.27072 to 0.26920, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 756us/step - loss: 0.2676 - accuracy: 0.9242 - val_loss: 0.2692 - val_accuracy: 0.9197\n",
      "Epoch 48/400\n",
      "1399/1433 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9229\n",
      "Epoch 48: val_loss did not improve from 0.26920\n",
      "1433/1433 [==============================] - 1s 783us/step - loss: 0.2663 - accuracy: 0.9236 - val_loss: 0.2693 - val_accuracy: 0.9244\n",
      "Epoch 49/400\n",
      "1379/1433 [===========================>..] - ETA: 0s - loss: 0.2656 - accuracy: 0.9239\n",
      "Epoch 49: val_loss improved from 0.26920 to 0.26911, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 839us/step - loss: 0.2654 - accuracy: 0.9239 - val_loss: 0.2691 - val_accuracy: 0.9189\n",
      "Epoch 50/400\n",
      "1392/1433 [============================>.] - ETA: 0s - loss: 0.2633 - accuracy: 0.9221\n",
      "Epoch 50: val_loss improved from 0.26911 to 0.26563, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 767us/step - loss: 0.2649 - accuracy: 0.9217 - val_loss: 0.2656 - val_accuracy: 0.9248\n",
      "Epoch 51/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1433 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9224\n",
      "Epoch 51: val_loss did not improve from 0.26563\n",
      "1433/1433 [==============================] - 1s 756us/step - loss: 0.2631 - accuracy: 0.9226 - val_loss: 0.2685 - val_accuracy: 0.9256\n",
      "Epoch 52/400\n",
      "1423/1433 [============================>.] - ETA: 0s - loss: 0.2620 - accuracy: 0.9239\n",
      "Epoch 52: val_loss improved from 0.26563 to 0.26361, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 758us/step - loss: 0.2622 - accuracy: 0.9236 - val_loss: 0.2636 - val_accuracy: 0.9209\n",
      "Epoch 53/400\n",
      "1432/1433 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.9230\n",
      "Epoch 53: val_loss did not improve from 0.26361\n",
      "1433/1433 [==============================] - 1s 739us/step - loss: 0.2619 - accuracy: 0.9230 - val_loss: 0.2686 - val_accuracy: 0.9206\n",
      "Epoch 54/400\n",
      "1432/1433 [============================>.] - ETA: 0s - loss: 0.2609 - accuracy: 0.9234\n",
      "Epoch 54: val_loss did not improve from 0.26361\n",
      "1433/1433 [==============================] - 1s 737us/step - loss: 0.2609 - accuracy: 0.9235 - val_loss: 0.2645 - val_accuracy: 0.9251\n",
      "Epoch 55/400\n",
      "1420/1433 [============================>.] - ETA: 0s - loss: 0.2611 - accuracy: 0.9228\n",
      "Epoch 55: val_loss improved from 0.26361 to 0.26102, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 753us/step - loss: 0.2603 - accuracy: 0.9231 - val_loss: 0.2610 - val_accuracy: 0.9278\n",
      "Epoch 56/400\n",
      "1381/1433 [===========================>..] - ETA: 0s - loss: 0.2584 - accuracy: 0.9229\n",
      "Epoch 56: val_loss did not improve from 0.26102\n",
      "1433/1433 [==============================] - 1s 761us/step - loss: 0.2592 - accuracy: 0.9228 - val_loss: 0.2624 - val_accuracy: 0.9290\n",
      "Epoch 57/400\n",
      "1367/1433 [===========================>..] - ETA: 0s - loss: 0.2592 - accuracy: 0.9228\n",
      "Epoch 57: val_loss improved from 0.26102 to 0.26013, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 746us/step - loss: 0.2581 - accuracy: 0.9226 - val_loss: 0.2601 - val_accuracy: 0.9209\n",
      "Epoch 58/400\n",
      "1395/1433 [============================>.] - ETA: 0s - loss: 0.2590 - accuracy: 0.9235\n",
      "Epoch 58: val_loss did not improve from 0.26013\n",
      "1433/1433 [==============================] - 1s 755us/step - loss: 0.2579 - accuracy: 0.9236 - val_loss: 0.2681 - val_accuracy: 0.9226\n",
      "Epoch 59/400\n",
      "1403/1433 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.9237\n",
      "Epoch 59: val_loss did not improve from 0.26013\n",
      "1433/1433 [==============================] - 1s 753us/step - loss: 0.2570 - accuracy: 0.9238 - val_loss: 0.2603 - val_accuracy: 0.9273\n",
      "Epoch 60/400\n",
      "1398/1433 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.9239\n",
      "Epoch 60: val_loss improved from 0.26013 to 0.25800, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 764us/step - loss: 0.2563 - accuracy: 0.9238 - val_loss: 0.2580 - val_accuracy: 0.9234\n",
      "Epoch 61/400\n",
      "1376/1433 [===========================>..] - ETA: 0s - loss: 0.2554 - accuracy: 0.9243\n",
      "Epoch 61: val_loss did not improve from 0.25800\n",
      "1433/1433 [==============================] - 1s 728us/step - loss: 0.2551 - accuracy: 0.9246 - val_loss: 0.2592 - val_accuracy: 0.9236\n",
      "Epoch 62/400\n",
      "1430/1433 [============================>.] - ETA: 0s - loss: 0.2547 - accuracy: 0.9257\n",
      "Epoch 62: val_loss improved from 0.25800 to 0.25749, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 751us/step - loss: 0.2547 - accuracy: 0.9257 - val_loss: 0.2575 - val_accuracy: 0.9293\n",
      "Epoch 63/400\n",
      "1396/1433 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9276\n",
      "Epoch 63: val_loss did not improve from 0.25749\n",
      "1433/1433 [==============================] - 1s 721us/step - loss: 0.2551 - accuracy: 0.9276 - val_loss: 0.2620 - val_accuracy: 0.9290\n",
      "Epoch 64/400\n",
      "1383/1433 [===========================>..] - ETA: 0s - loss: 0.2551 - accuracy: 0.9277\n",
      "Epoch 64: val_loss did not improve from 0.25749\n",
      "1433/1433 [==============================] - 1s 763us/step - loss: 0.2536 - accuracy: 0.9280 - val_loss: 0.2577 - val_accuracy: 0.9389\n",
      "Epoch 65/400\n",
      "1388/1433 [============================>.] - ETA: 0s - loss: 0.2543 - accuracy: 0.9282\n",
      "Epoch 65: val_loss improved from 0.25749 to 0.25692, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 741us/step - loss: 0.2538 - accuracy: 0.9283 - val_loss: 0.2569 - val_accuracy: 0.9303\n",
      "Epoch 66/400\n",
      "1393/1433 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.9283\n",
      "Epoch 66: val_loss did not improve from 0.25692\n",
      "1433/1433 [==============================] - 1s 793us/step - loss: 0.2528 - accuracy: 0.9284 - val_loss: 0.2618 - val_accuracy: 0.9303\n",
      "Epoch 67/400\n",
      "1368/1433 [===========================>..] - ETA: 0s - loss: 0.2534 - accuracy: 0.9297\n",
      "Epoch 67: val_loss improved from 0.25692 to 0.25353, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 740us/step - loss: 0.2524 - accuracy: 0.9300 - val_loss: 0.2535 - val_accuracy: 0.9345\n",
      "Epoch 68/400\n",
      "1409/1433 [============================>.] - ETA: 0s - loss: 0.2517 - accuracy: 0.9309\n",
      "Epoch 68: val_loss improved from 0.25353 to 0.25353, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 760us/step - loss: 0.2510 - accuracy: 0.9309 - val_loss: 0.2535 - val_accuracy: 0.9278\n",
      "Epoch 69/400\n",
      "1379/1433 [===========================>..] - ETA: 0s - loss: 0.2510 - accuracy: 0.9295\n",
      "Epoch 69: val_loss did not improve from 0.25353\n",
      "1433/1433 [==============================] - 1s 726us/step - loss: 0.2509 - accuracy: 0.9297 - val_loss: 0.2593 - val_accuracy: 0.9330\n",
      "Epoch 70/400\n",
      "1426/1433 [============================>.] - ETA: 0s - loss: 0.2502 - accuracy: 0.9285\n",
      "Epoch 70: val_loss improved from 0.25353 to 0.25161, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 756us/step - loss: 0.2500 - accuracy: 0.9286 - val_loss: 0.2516 - val_accuracy: 0.9295\n",
      "Epoch 71/400\n",
      "1375/1433 [===========================>..] - ETA: 0s - loss: 0.2483 - accuracy: 0.9288\n",
      "Epoch 71: val_loss did not improve from 0.25161\n",
      "1433/1433 [==============================] - 1s 726us/step - loss: 0.2503 - accuracy: 0.9290 - val_loss: 0.2544 - val_accuracy: 0.9253\n",
      "Epoch 72/400\n",
      "1415/1433 [============================>.] - ETA: 0s - loss: 0.2498 - accuracy: 0.9311\n",
      "Epoch 72: val_loss did not improve from 0.25161\n",
      "1433/1433 [==============================] - 1s 745us/step - loss: 0.2495 - accuracy: 0.9310 - val_loss: 0.2528 - val_accuracy: 0.9330\n",
      "Epoch 73/400\n",
      "1419/1433 [============================>.] - ETA: 0s - loss: 0.2488 - accuracy: 0.9311\n",
      "Epoch 73: val_loss improved from 0.25161 to 0.25039, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 762us/step - loss: 0.2487 - accuracy: 0.9309 - val_loss: 0.2504 - val_accuracy: 0.9295\n",
      "Epoch 74/400\n",
      "1425/1433 [============================>.] - ETA: 0s - loss: 0.2491 - accuracy: 0.9305\n",
      "Epoch 74: val_loss did not improve from 0.25039\n",
      "1433/1433 [==============================] - 1s 746us/step - loss: 0.2488 - accuracy: 0.9306 - val_loss: 0.2575 - val_accuracy: 0.9367\n",
      "Epoch 75/400\n",
      "1387/1433 [============================>.] - ETA: 0s - loss: 0.2485 - accuracy: 0.9313\n",
      "Epoch 75: val_loss did not improve from 0.25039\n",
      "1433/1433 [==============================] - 1s 724us/step - loss: 0.2481 - accuracy: 0.9312 - val_loss: 0.2523 - val_accuracy: 0.9412\n",
      "Epoch 76/400\n",
      "1421/1433 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9327\n",
      "Epoch 76: val_loss did not improve from 0.25039\n",
      "1433/1433 [==============================] - 1s 746us/step - loss: 0.2478 - accuracy: 0.9327 - val_loss: 0.2617 - val_accuracy: 0.9300\n",
      "Epoch 77/400\n",
      "1428/1433 [============================>.] - ETA: 0s - loss: 0.2463 - accuracy: 0.9305\n",
      "Epoch 77: val_loss improved from 0.25039 to 0.24870, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433/1433 [==============================] - 1s 753us/step - loss: 0.2470 - accuracy: 0.9304 - val_loss: 0.2487 - val_accuracy: 0.9365\n",
      "Epoch 78/400\n",
      "1424/1433 [============================>.] - ETA: 0s - loss: 0.2468 - accuracy: 0.9326\n",
      "Epoch 78: val_loss improved from 0.24870 to 0.24704, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 760us/step - loss: 0.2469 - accuracy: 0.9327 - val_loss: 0.2470 - val_accuracy: 0.9394\n",
      "Epoch 79/400\n",
      "1357/1433 [===========================>..] - ETA: 0s - loss: 0.2463 - accuracy: 0.9328\n",
      "Epoch 79: val_loss did not improve from 0.24704\n",
      "1433/1433 [==============================] - 1s 739us/step - loss: 0.2468 - accuracy: 0.9328 - val_loss: 0.2480 - val_accuracy: 0.9360\n",
      "Epoch 80/400\n",
      "1409/1433 [============================>.] - ETA: 0s - loss: 0.2456 - accuracy: 0.9306\n",
      "Epoch 80: val_loss improved from 0.24704 to 0.24665, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 764us/step - loss: 0.2456 - accuracy: 0.9307 - val_loss: 0.2466 - val_accuracy: 0.9397\n",
      "Epoch 81/400\n",
      "1371/1433 [===========================>..] - ETA: 0s - loss: 0.2483 - accuracy: 0.9313\n",
      "Epoch 81: val_loss did not improve from 0.24665\n",
      "1433/1433 [==============================] - 1s 731us/step - loss: 0.2458 - accuracy: 0.9317 - val_loss: 0.2490 - val_accuracy: 0.9281\n",
      "Epoch 82/400\n",
      "1370/1433 [===========================>..] - ETA: 0s - loss: 0.2449 - accuracy: 0.9309\n",
      "Epoch 82: val_loss did not improve from 0.24665\n",
      "1433/1433 [==============================] - 1s 843us/step - loss: 0.2456 - accuracy: 0.9310 - val_loss: 0.2477 - val_accuracy: 0.9320\n",
      "Epoch 83/400\n",
      "1379/1433 [===========================>..] - ETA: 0s - loss: 0.2451 - accuracy: 0.9313\n",
      "Epoch 83: val_loss did not improve from 0.24665\n",
      "1433/1433 [==============================] - 1s 777us/step - loss: 0.2450 - accuracy: 0.9311 - val_loss: 0.2530 - val_accuracy: 0.9308\n",
      "Epoch 84/400\n",
      "1417/1433 [============================>.] - ETA: 0s - loss: 0.2437 - accuracy: 0.9314\n",
      "Epoch 84: val_loss did not improve from 0.24665\n",
      "1433/1433 [==============================] - 1s 741us/step - loss: 0.2446 - accuracy: 0.9310 - val_loss: 0.2494 - val_accuracy: 0.9379\n",
      "Epoch 85/400\n",
      "1386/1433 [============================>.] - ETA: 0s - loss: 0.2453 - accuracy: 0.9322\n",
      "Epoch 85: val_loss did not improve from 0.24665\n",
      "1433/1433 [==============================] - 1s 727us/step - loss: 0.2447 - accuracy: 0.9321 - val_loss: 0.2487 - val_accuracy: 0.9367\n",
      "Epoch 86/400\n",
      "1397/1433 [============================>.] - ETA: 0s - loss: 0.2444 - accuracy: 0.9322\n",
      "Epoch 86: val_loss did not improve from 0.24665\n",
      "1433/1433 [==============================] - 1s 717us/step - loss: 0.2446 - accuracy: 0.9315 - val_loss: 0.2486 - val_accuracy: 0.9320\n",
      "Epoch 87/400\n",
      "1380/1433 [===========================>..] - ETA: 0s - loss: 0.2451 - accuracy: 0.9322\n",
      "Epoch 87: val_loss did not improve from 0.24665\n",
      "1433/1433 [==============================] - 1s 732us/step - loss: 0.2440 - accuracy: 0.9326 - val_loss: 0.2480 - val_accuracy: 0.9360\n",
      "Epoch 88/400\n",
      "1388/1433 [============================>.] - ETA: 0s - loss: 0.2407 - accuracy: 0.9325\n",
      "Epoch 88: val_loss improved from 0.24665 to 0.24495, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 727us/step - loss: 0.2436 - accuracy: 0.9318 - val_loss: 0.2449 - val_accuracy: 0.9333\n",
      "Epoch 89/400\n",
      "1409/1433 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.9318\n",
      "Epoch 89: val_loss did not improve from 0.24495\n",
      "1433/1433 [==============================] - 1s 717us/step - loss: 0.2430 - accuracy: 0.9317 - val_loss: 0.2469 - val_accuracy: 0.9342\n",
      "Epoch 90/400\n",
      "1418/1433 [============================>.] - ETA: 0s - loss: 0.2423 - accuracy: 0.9319\n",
      "Epoch 90: val_loss did not improve from 0.24495\n",
      "1433/1433 [==============================] - 1s 708us/step - loss: 0.2431 - accuracy: 0.9321 - val_loss: 0.2450 - val_accuracy: 0.9325\n",
      "Epoch 91/400\n",
      "1416/1433 [============================>.] - ETA: 0s - loss: 0.2431 - accuracy: 0.9322\n",
      "Epoch 91: val_loss did not improve from 0.24495\n",
      "1433/1433 [==============================] - 1s 709us/step - loss: 0.2426 - accuracy: 0.9325 - val_loss: 0.2532 - val_accuracy: 0.9367\n",
      "Epoch 92/400\n",
      "1377/1433 [===========================>..] - ETA: 0s - loss: 0.2423 - accuracy: 0.9327\n",
      "Epoch 92: val_loss did not improve from 0.24495\n",
      "1433/1433 [==============================] - 1s 724us/step - loss: 0.2418 - accuracy: 0.9328 - val_loss: 0.2461 - val_accuracy: 0.9387\n",
      "Epoch 93/400\n",
      "1411/1433 [============================>.] - ETA: 0s - loss: 0.2410 - accuracy: 0.9320\n",
      "Epoch 93: val_loss improved from 0.24495 to 0.24426, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 729us/step - loss: 0.2420 - accuracy: 0.9316 - val_loss: 0.2443 - val_accuracy: 0.9330\n",
      "Epoch 94/400\n",
      "1409/1433 [============================>.] - ETA: 0s - loss: 0.2414 - accuracy: 0.9325\n",
      "Epoch 94: val_loss improved from 0.24426 to 0.24346, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 726us/step - loss: 0.2421 - accuracy: 0.9326 - val_loss: 0.2435 - val_accuracy: 0.9288\n",
      "Epoch 95/400\n",
      "1418/1433 [============================>.] - ETA: 0s - loss: 0.2421 - accuracy: 0.9320\n",
      "Epoch 95: val_loss did not improve from 0.24346\n",
      "1433/1433 [==============================] - 1s 709us/step - loss: 0.2416 - accuracy: 0.9320 - val_loss: 0.2456 - val_accuracy: 0.9397\n",
      "Epoch 96/400\n",
      "1369/1433 [===========================>..] - ETA: 0s - loss: 0.2418 - accuracy: 0.9323\n",
      "Epoch 96: val_loss improved from 0.24346 to 0.24087, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 777us/step - loss: 0.2413 - accuracy: 0.9321 - val_loss: 0.2409 - val_accuracy: 0.9394\n",
      "Epoch 97/400\n",
      "1393/1433 [============================>.] - ETA: 0s - loss: 0.2418 - accuracy: 0.9332\n",
      "Epoch 97: val_loss did not improve from 0.24087\n",
      "1433/1433 [==============================] - 1s 730us/step - loss: 0.2410 - accuracy: 0.9331 - val_loss: 0.2496 - val_accuracy: 0.9355\n",
      "Epoch 98/400\n",
      "1372/1433 [===========================>..] - ETA: 0s - loss: 0.2387 - accuracy: 0.9323\n",
      "Epoch 98: val_loss did not improve from 0.24087\n",
      "1433/1433 [==============================] - 1s 726us/step - loss: 0.2411 - accuracy: 0.9322 - val_loss: 0.2418 - val_accuracy: 0.9350\n",
      "Epoch 99/400\n",
      "1383/1433 [===========================>..] - ETA: 0s - loss: 0.2422 - accuracy: 0.9326\n",
      "Epoch 99: val_loss did not improve from 0.24087\n",
      "1433/1433 [==============================] - 1s 766us/step - loss: 0.2405 - accuracy: 0.9329 - val_loss: 0.2457 - val_accuracy: 0.9372\n",
      "Epoch 100/400\n",
      "1414/1433 [============================>.] - ETA: 0s - loss: 0.2410 - accuracy: 0.9334\n",
      "Epoch 100: val_loss improved from 0.24087 to 0.24013, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 724us/step - loss: 0.2406 - accuracy: 0.9336 - val_loss: 0.2401 - val_accuracy: 0.9335\n",
      "Epoch 101/400\n",
      "1418/1433 [============================>.] - ETA: 0s - loss: 0.2401 - accuracy: 0.9335\n",
      "Epoch 101: val_loss did not improve from 0.24013\n",
      "1433/1433 [==============================] - 1s 756us/step - loss: 0.2400 - accuracy: 0.9334 - val_loss: 0.2451 - val_accuracy: 0.9313\n",
      "Epoch 102/400\n",
      "1361/1433 [===========================>..] - ETA: 0s - loss: 0.2413 - accuracy: 0.9340\n",
      "Epoch 102: val_loss did not improve from 0.24013\n",
      "1433/1433 [==============================] - 1s 734us/step - loss: 0.2398 - accuracy: 0.9338 - val_loss: 0.2435 - val_accuracy: 0.9384\n",
      "Epoch 103/400\n",
      "1411/1433 [============================>.] - ETA: 0s - loss: 0.2402 - accuracy: 0.9334\n",
      "Epoch 103: val_loss did not improve from 0.24013\n",
      "1433/1433 [==============================] - 1s 758us/step - loss: 0.2396 - accuracy: 0.9336 - val_loss: 0.2425 - val_accuracy: 0.9402\n",
      "Epoch 104/400\n",
      "1376/1433 [===========================>..] - ETA: 0s - loss: 0.2390 - accuracy: 0.9320\n",
      "Epoch 104: val_loss improved from 0.24013 to 0.23984, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 755us/step - loss: 0.2391 - accuracy: 0.9325 - val_loss: 0.2398 - val_accuracy: 0.9387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/400\n",
      "1406/1433 [============================>.] - ETA: 0s - loss: 0.2379 - accuracy: 0.9343\n",
      "Epoch 105: val_loss improved from 0.23984 to 0.23924, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 777us/step - loss: 0.2388 - accuracy: 0.9341 - val_loss: 0.2392 - val_accuracy: 0.9357\n",
      "Epoch 106/400\n",
      "1370/1433 [===========================>..] - ETA: 0s - loss: 0.2395 - accuracy: 0.9337\n",
      "Epoch 106: val_loss did not improve from 0.23924\n",
      "1433/1433 [==============================] - 1s 768us/step - loss: 0.2389 - accuracy: 0.9335 - val_loss: 0.2397 - val_accuracy: 0.9384\n",
      "Epoch 107/400\n",
      "1392/1433 [============================>.] - ETA: 0s - loss: 0.2384 - accuracy: 0.9341\n",
      "Epoch 107: val_loss did not improve from 0.23924\n",
      "1433/1433 [==============================] - 1s 754us/step - loss: 0.2386 - accuracy: 0.9339 - val_loss: 0.2402 - val_accuracy: 0.9352\n",
      "Epoch 108/400\n",
      "1376/1433 [===========================>..] - ETA: 0s - loss: 0.2400 - accuracy: 0.9325\n",
      "Epoch 108: val_loss did not improve from 0.23924\n",
      "1433/1433 [==============================] - 1s 731us/step - loss: 0.2385 - accuracy: 0.9327 - val_loss: 0.2440 - val_accuracy: 0.9333\n",
      "Epoch 109/400\n",
      "1404/1433 [============================>.] - ETA: 0s - loss: 0.2376 - accuracy: 0.9327\n",
      "Epoch 109: val_loss did not improve from 0.23924\n",
      "1433/1433 [==============================] - 1s 752us/step - loss: 0.2369 - accuracy: 0.9330 - val_loss: 0.2453 - val_accuracy: 0.9431\n",
      "Epoch 110/400\n",
      "1426/1433 [============================>.] - ETA: 0s - loss: 0.2371 - accuracy: 0.9333\n",
      "Epoch 110: val_loss did not improve from 0.23924\n",
      "1433/1433 [==============================] - 1s 741us/step - loss: 0.2377 - accuracy: 0.9333 - val_loss: 0.2422 - val_accuracy: 0.9342\n",
      "Epoch 111/400\n",
      "1423/1433 [============================>.] - ETA: 0s - loss: 0.2375 - accuracy: 0.9341\n",
      "Epoch 111: val_loss improved from 0.23924 to 0.23725, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 758us/step - loss: 0.2376 - accuracy: 0.9339 - val_loss: 0.2372 - val_accuracy: 0.9468\n",
      "Epoch 112/400\n",
      "1410/1433 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.9332\n",
      "Epoch 112: val_loss did not improve from 0.23725\n",
      "1433/1433 [==============================] - 1s 753us/step - loss: 0.2378 - accuracy: 0.9335 - val_loss: 0.2403 - val_accuracy: 0.9417\n",
      "Epoch 113/400\n",
      "1387/1433 [============================>.] - ETA: 0s - loss: 0.2387 - accuracy: 0.9346\n",
      "Epoch 113: val_loss did not improve from 0.23725\n",
      "1433/1433 [==============================] - 1s 760us/step - loss: 0.2379 - accuracy: 0.9344 - val_loss: 0.2380 - val_accuracy: 0.9365\n",
      "Epoch 114/400\n",
      "1415/1433 [============================>.] - ETA: 0s - loss: 0.2359 - accuracy: 0.9341\n",
      "Epoch 114: val_loss did not improve from 0.23725\n",
      "1433/1433 [==============================] - 1s 747us/step - loss: 0.2369 - accuracy: 0.9338 - val_loss: 0.2381 - val_accuracy: 0.9389\n",
      "Epoch 115/400\n",
      "1395/1433 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.9337\n",
      "Epoch 115: val_loss improved from 0.23725 to 0.23683, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 769us/step - loss: 0.2374 - accuracy: 0.9338 - val_loss: 0.2368 - val_accuracy: 0.9355\n",
      "Epoch 116/400\n",
      "1374/1433 [===========================>..] - ETA: 0s - loss: 0.2346 - accuracy: 0.9345\n",
      "Epoch 116: val_loss did not improve from 0.23683\n",
      "1433/1433 [==============================] - 1s 733us/step - loss: 0.2363 - accuracy: 0.9345 - val_loss: 0.2441 - val_accuracy: 0.9382\n",
      "Epoch 117/400\n",
      "1426/1433 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.9338\n",
      "Epoch 117: val_loss did not improve from 0.23683\n",
      "1433/1433 [==============================] - 1s 746us/step - loss: 0.2363 - accuracy: 0.9338 - val_loss: 0.2392 - val_accuracy: 0.9414\n",
      "Epoch 118/400\n",
      "1425/1433 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.9336\n",
      "Epoch 118: val_loss did not improve from 0.23683\n",
      "1433/1433 [==============================] - 1s 745us/step - loss: 0.2362 - accuracy: 0.9338 - val_loss: 0.2395 - val_accuracy: 0.9350\n",
      "Epoch 119/400\n",
      "1407/1433 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9341\n",
      "Epoch 119: val_loss did not improve from 0.23683\n",
      "1433/1433 [==============================] - 1s 749us/step - loss: 0.2361 - accuracy: 0.9340 - val_loss: 0.2453 - val_accuracy: 0.9394\n",
      "Epoch 120/400\n",
      "1367/1433 [===========================>..] - ETA: 0s - loss: 0.2366 - accuracy: 0.9340\n",
      "Epoch 120: val_loss did not improve from 0.23683\n",
      "1433/1433 [==============================] - 1s 730us/step - loss: 0.2355 - accuracy: 0.9342 - val_loss: 0.2398 - val_accuracy: 0.9333\n",
      "Epoch 121/400\n",
      "1422/1433 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.9334\n",
      "Epoch 121: val_loss improved from 0.23683 to 0.23568, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 757us/step - loss: 0.2363 - accuracy: 0.9332 - val_loss: 0.2357 - val_accuracy: 0.9352\n",
      "Epoch 122/400\n",
      "1389/1433 [============================>.] - ETA: 0s - loss: 0.2351 - accuracy: 0.9355\n",
      "Epoch 122: val_loss improved from 0.23568 to 0.23440, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 771us/step - loss: 0.2353 - accuracy: 0.9354 - val_loss: 0.2344 - val_accuracy: 0.9407\n",
      "Epoch 123/400\n",
      "1418/1433 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.9334\n",
      "Epoch 123: val_loss did not improve from 0.23440\n",
      "1433/1433 [==============================] - 1s 747us/step - loss: 0.2357 - accuracy: 0.9335 - val_loss: 0.2385 - val_accuracy: 0.9310\n",
      "Epoch 124/400\n",
      "1415/1433 [============================>.] - ETA: 0s - loss: 0.2351 - accuracy: 0.9341\n",
      "Epoch 124: val_loss did not improve from 0.23440\n",
      "1433/1433 [==============================] - 1s 748us/step - loss: 0.2350 - accuracy: 0.9342 - val_loss: 0.2354 - val_accuracy: 0.9384\n",
      "Epoch 125/400\n",
      "1374/1433 [===========================>..] - ETA: 0s - loss: 0.2339 - accuracy: 0.9331\n",
      "Epoch 125: val_loss did not improve from 0.23440\n",
      "1433/1433 [==============================] - 1s 764us/step - loss: 0.2350 - accuracy: 0.9328 - val_loss: 0.2394 - val_accuracy: 0.9318\n",
      "Epoch 126/400\n",
      "1370/1433 [===========================>..] - ETA: 0s - loss: 0.2350 - accuracy: 0.9339\n",
      "Epoch 126: val_loss did not improve from 0.23440\n",
      "1433/1433 [==============================] - 1s 730us/step - loss: 0.2349 - accuracy: 0.9338 - val_loss: 0.2356 - val_accuracy: 0.9342\n",
      "Epoch 127/400\n",
      "1424/1433 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9335\n",
      "Epoch 127: val_loss improved from 0.23440 to 0.23367, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 753us/step - loss: 0.2351 - accuracy: 0.9335 - val_loss: 0.2337 - val_accuracy: 0.9434\n",
      "Epoch 128/400\n",
      "1371/1433 [===========================>..] - ETA: 0s - loss: 0.2351 - accuracy: 0.9339\n",
      "Epoch 128: val_loss did not improve from 0.23367\n",
      "1433/1433 [==============================] - 1s 730us/step - loss: 0.2344 - accuracy: 0.9340 - val_loss: 0.2373 - val_accuracy: 0.9352\n",
      "Epoch 129/400\n",
      "1391/1433 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.9331\n",
      "Epoch 129: val_loss did not improve from 0.23367\n",
      "1433/1433 [==============================] - 1s 759us/step - loss: 0.2339 - accuracy: 0.9333 - val_loss: 0.2348 - val_accuracy: 0.9355\n",
      "Epoch 130/400\n",
      "1402/1433 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.9339\n",
      "Epoch 130: val_loss did not improve from 0.23367\n",
      "1433/1433 [==============================] - 1s 753us/step - loss: 0.2345 - accuracy: 0.9337 - val_loss: 0.2361 - val_accuracy: 0.9370\n",
      "Epoch 131/400\n",
      "1354/1433 [===========================>..] - ETA: 0s - loss: 0.2352 - accuracy: 0.9336\n",
      "Epoch 131: val_loss improved from 0.23367 to 0.23288, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 753us/step - loss: 0.2342 - accuracy: 0.9332 - val_loss: 0.2329 - val_accuracy: 0.9375\n",
      "Epoch 132/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372/1433 [===========================>..] - ETA: 0s - loss: 0.2338 - accuracy: 0.9341\n",
      "Epoch 132: val_loss did not improve from 0.23288\n",
      "1433/1433 [==============================] - 1s 733us/step - loss: 0.2341 - accuracy: 0.9337 - val_loss: 0.2371 - val_accuracy: 0.9389\n",
      "Epoch 133/400\n",
      "1431/1433 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9338\n",
      "Epoch 133: val_loss improved from 0.23288 to 0.23286, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 757us/step - loss: 0.2334 - accuracy: 0.9338 - val_loss: 0.2329 - val_accuracy: 0.9414\n",
      "Epoch 134/400\n",
      "1413/1433 [============================>.] - ETA: 0s - loss: 0.2331 - accuracy: 0.9338\n",
      "Epoch 134: val_loss did not improve from 0.23286\n",
      "1433/1433 [==============================] - 1s 748us/step - loss: 0.2333 - accuracy: 0.9337 - val_loss: 0.2354 - val_accuracy: 0.9350\n",
      "Epoch 135/400\n",
      "1431/1433 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9347\n",
      "Epoch 135: val_loss did not improve from 0.23286\n",
      "1433/1433 [==============================] - 1s 742us/step - loss: 0.2334 - accuracy: 0.9347 - val_loss: 0.2384 - val_accuracy: 0.9424\n",
      "Epoch 136/400\n",
      "1421/1433 [============================>.] - ETA: 0s - loss: 0.2337 - accuracy: 0.9338\n",
      "Epoch 136: val_loss did not improve from 0.23286\n",
      "1433/1433 [==============================] - 1s 742us/step - loss: 0.2333 - accuracy: 0.9338 - val_loss: 0.2331 - val_accuracy: 0.9328\n",
      "Epoch 137/400\n",
      "1429/1433 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9337\n",
      "Epoch 137: val_loss did not improve from 0.23286\n",
      "1433/1433 [==============================] - 1s 740us/step - loss: 0.2329 - accuracy: 0.9337 - val_loss: 0.2345 - val_accuracy: 0.9310\n",
      "Epoch 138/400\n",
      "1433/1433 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.9342\n",
      "Epoch 138: val_loss did not improve from 0.23286\n",
      "1433/1433 [==============================] - 1s 738us/step - loss: 0.2335 - accuracy: 0.9342 - val_loss: 0.2330 - val_accuracy: 0.9350\n",
      "Epoch 139/400\n",
      "1354/1433 [===========================>..] - ETA: 0s - loss: 0.2333 - accuracy: 0.9336\n",
      "Epoch 139: val_loss did not improve from 0.23286\n",
      "1433/1433 [==============================] - 1s 737us/step - loss: 0.2326 - accuracy: 0.9340 - val_loss: 0.2329 - val_accuracy: 0.9342\n",
      "Epoch 140/400\n",
      "1417/1433 [============================>.] - ETA: 0s - loss: 0.2329 - accuracy: 0.9329\n",
      "Epoch 140: val_loss did not improve from 0.23286\n",
      "1433/1433 [==============================] - 1s 784us/step - loss: 0.2328 - accuracy: 0.9329 - val_loss: 0.2340 - val_accuracy: 0.9379\n",
      "Epoch 141/400\n",
      "1364/1433 [===========================>..] - ETA: 0s - loss: 0.2294 - accuracy: 0.9360\n",
      "Epoch 141: val_loss did not improve from 0.23286\n",
      "1433/1433 [==============================] - 1s 772us/step - loss: 0.2322 - accuracy: 0.9353 - val_loss: 0.2339 - val_accuracy: 0.9330\n",
      "Epoch 142/400\n",
      "1413/1433 [============================>.] - ETA: 0s - loss: 0.2325 - accuracy: 0.9346\n",
      "Epoch 142: val_loss did not improve from 0.23286\n",
      "1433/1433 [==============================] - 1s 751us/step - loss: 0.2318 - accuracy: 0.9348 - val_loss: 0.2422 - val_accuracy: 0.9347\n",
      "Epoch 143/400\n",
      "1428/1433 [============================>.] - ETA: 0s - loss: 0.2322 - accuracy: 0.9331\n",
      "Epoch 143: val_loss improved from 0.23286 to 0.23217, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 755us/step - loss: 0.2321 - accuracy: 0.9331 - val_loss: 0.2322 - val_accuracy: 0.9384\n",
      "Epoch 144/400\n",
      "1381/1433 [===========================>..] - ETA: 0s - loss: 0.2326 - accuracy: 0.9348\n",
      "Epoch 144: val_loss did not improve from 0.23217\n",
      "1433/1433 [==============================] - 1s 732us/step - loss: 0.2314 - accuracy: 0.9349 - val_loss: 0.2372 - val_accuracy: 0.9402\n",
      "Epoch 145/400\n",
      "1377/1433 [===========================>..] - ETA: 0s - loss: 0.2317 - accuracy: 0.9345\n",
      "Epoch 145: val_loss improved from 0.23217 to 0.23173, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 741us/step - loss: 0.2321 - accuracy: 0.9340 - val_loss: 0.2317 - val_accuracy: 0.9337\n",
      "Epoch 146/400\n",
      "1380/1433 [===========================>..] - ETA: 0s - loss: 0.2329 - accuracy: 0.9343\n",
      "Epoch 146: val_loss did not improve from 0.23173\n",
      "1433/1433 [==============================] - 1s 734us/step - loss: 0.2320 - accuracy: 0.9342 - val_loss: 0.2349 - val_accuracy: 0.9340\n",
      "Epoch 147/400\n",
      "1367/1433 [===========================>..] - ETA: 0s - loss: 0.2319 - accuracy: 0.9346\n",
      "Epoch 147: val_loss did not improve from 0.23173\n",
      "1433/1433 [==============================] - 1s 749us/step - loss: 0.2320 - accuracy: 0.9345 - val_loss: 0.2348 - val_accuracy: 0.9335\n",
      "Epoch 148/400\n",
      "1386/1433 [============================>.] - ETA: 0s - loss: 0.2315 - accuracy: 0.9336\n",
      "Epoch 148: val_loss did not improve from 0.23173\n",
      "1433/1433 [==============================] - 1s 739us/step - loss: 0.2312 - accuracy: 0.9336 - val_loss: 0.2357 - val_accuracy: 0.9360\n",
      "Epoch 149/400\n",
      "1380/1433 [===========================>..] - ETA: 0s - loss: 0.2312 - accuracy: 0.9335\n",
      "Epoch 149: val_loss did not improve from 0.23173\n",
      "1433/1433 [==============================] - 1s 729us/step - loss: 0.2313 - accuracy: 0.9332 - val_loss: 0.2337 - val_accuracy: 0.9382\n",
      "Epoch 150/400\n",
      "1431/1433 [============================>.] - ETA: 0s - loss: 0.2311 - accuracy: 0.9342\n",
      "Epoch 150: val_loss improved from 0.23173 to 0.22990, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 757us/step - loss: 0.2311 - accuracy: 0.9342 - val_loss: 0.2299 - val_accuracy: 0.9399\n",
      "Epoch 151/400\n",
      "1382/1433 [===========================>..] - ETA: 0s - loss: 0.2306 - accuracy: 0.9357\n",
      "Epoch 151: val_loss did not improve from 0.22990\n",
      "1433/1433 [==============================] - 1s 727us/step - loss: 0.2303 - accuracy: 0.9356 - val_loss: 0.2311 - val_accuracy: 0.9342\n",
      "Epoch 152/400\n",
      "1413/1433 [============================>.] - ETA: 0s - loss: 0.2308 - accuracy: 0.9343\n",
      "Epoch 152: val_loss did not improve from 0.22990\n",
      "1433/1433 [==============================] - 1s 750us/step - loss: 0.2311 - accuracy: 0.9341 - val_loss: 0.2375 - val_accuracy: 0.9407\n",
      "Epoch 153/400\n",
      "1375/1433 [===========================>..] - ETA: 0s - loss: 0.2315 - accuracy: 0.9346\n",
      "Epoch 153: val_loss did not improve from 0.22990\n",
      "1433/1433 [==============================] - 1s 728us/step - loss: 0.2312 - accuracy: 0.9349 - val_loss: 0.2350 - val_accuracy: 0.9422\n",
      "Epoch 154/400\n",
      "1396/1433 [============================>.] - ETA: 0s - loss: 0.2311 - accuracy: 0.9338\n",
      "Epoch 154: val_loss did not improve from 0.22990\n",
      "1433/1433 [==============================] - 1s 756us/step - loss: 0.2312 - accuracy: 0.9332 - val_loss: 0.2323 - val_accuracy: 0.9350\n",
      "Epoch 155/400\n",
      "1400/1433 [============================>.] - ETA: 0s - loss: 0.2291 - accuracy: 0.9338\n",
      "Epoch 155: val_loss did not improve from 0.22990\n",
      "1433/1433 [==============================] - 1s 753us/step - loss: 0.2306 - accuracy: 0.9334 - val_loss: 0.2373 - val_accuracy: 0.9283\n",
      "Epoch 156/400\n",
      "1402/1433 [============================>.] - ETA: 0s - loss: 0.2316 - accuracy: 0.9338\n",
      "Epoch 156: val_loss did not improve from 0.22990\n",
      "1433/1433 [==============================] - 1s 752us/step - loss: 0.2308 - accuracy: 0.9339 - val_loss: 0.2304 - val_accuracy: 0.9333\n",
      "Epoch 157/400\n",
      "1423/1433 [============================>.] - ETA: 0s - loss: 0.2312 - accuracy: 0.9328\n",
      "Epoch 157: val_loss did not improve from 0.22990\n",
      "1433/1433 [==============================] - 1s 748us/step - loss: 0.2307 - accuracy: 0.9330 - val_loss: 0.2310 - val_accuracy: 0.9384\n",
      "Epoch 158/400\n",
      "1431/1433 [============================>.] - ETA: 0s - loss: 0.2305 - accuracy: 0.9355\n",
      "Epoch 158: val_loss improved from 0.22990 to 0.22890, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 746us/step - loss: 0.2304 - accuracy: 0.9355 - val_loss: 0.2289 - val_accuracy: 0.9375\n",
      "Epoch 159/400\n",
      "1412/1433 [============================>.] - ETA: 0s - loss: 0.2296 - accuracy: 0.9342\n",
      "Epoch 159: val_loss did not improve from 0.22890\n",
      "1433/1433 [==============================] - 1s 751us/step - loss: 0.2293 - accuracy: 0.9339 - val_loss: 0.2302 - val_accuracy: 0.9328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/400\n",
      "1415/1433 [============================>.] - ETA: 0s - loss: 0.2294 - accuracy: 0.9341\n",
      "Epoch 160: val_loss improved from 0.22890 to 0.22866, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 762us/step - loss: 0.2300 - accuracy: 0.9341 - val_loss: 0.2287 - val_accuracy: 0.9434\n",
      "Epoch 161/400\n",
      "1433/1433 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.9331\n",
      "Epoch 161: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 740us/step - loss: 0.2301 - accuracy: 0.9331 - val_loss: 0.2296 - val_accuracy: 0.9370\n",
      "Epoch 162/400\n",
      "1354/1433 [===========================>..] - ETA: 0s - loss: 0.2284 - accuracy: 0.9351\n",
      "Epoch 162: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 737us/step - loss: 0.2298 - accuracy: 0.9350 - val_loss: 0.2326 - val_accuracy: 0.9325\n",
      "Epoch 163/400\n",
      "1359/1433 [===========================>..] - ETA: 0s - loss: 0.2259 - accuracy: 0.9335\n",
      "Epoch 163: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 736us/step - loss: 0.2297 - accuracy: 0.9335 - val_loss: 0.2397 - val_accuracy: 0.9342\n",
      "Epoch 164/400\n",
      "1399/1433 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9336\n",
      "Epoch 164: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 754us/step - loss: 0.2290 - accuracy: 0.9333 - val_loss: 0.2302 - val_accuracy: 0.9352\n",
      "Epoch 165/400\n",
      "1371/1433 [===========================>..] - ETA: 0s - loss: 0.2305 - accuracy: 0.9348\n",
      "Epoch 165: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 733us/step - loss: 0.2298 - accuracy: 0.9347 - val_loss: 0.2296 - val_accuracy: 0.9340\n",
      "Epoch 166/400\n",
      "1405/1433 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9334\n",
      "Epoch 166: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 755us/step - loss: 0.2287 - accuracy: 0.9334 - val_loss: 0.2321 - val_accuracy: 0.9404\n",
      "Epoch 167/400\n",
      "1379/1433 [===========================>..] - ETA: 0s - loss: 0.2297 - accuracy: 0.9334\n",
      "Epoch 167: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 730us/step - loss: 0.2297 - accuracy: 0.9334 - val_loss: 0.2293 - val_accuracy: 0.9325\n",
      "Epoch 168/400\n",
      "1397/1433 [============================>.] - ETA: 0s - loss: 0.2307 - accuracy: 0.9331\n",
      "Epoch 168: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 754us/step - loss: 0.2290 - accuracy: 0.9335 - val_loss: 0.2310 - val_accuracy: 0.9394\n",
      "Epoch 169/400\n",
      "1426/1433 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9335\n",
      "Epoch 169: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 744us/step - loss: 0.2287 - accuracy: 0.9335 - val_loss: 0.2300 - val_accuracy: 0.9328\n",
      "Epoch 170/400\n",
      "1424/1433 [============================>.] - ETA: 0s - loss: 0.2296 - accuracy: 0.9339\n",
      "Epoch 170: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 744us/step - loss: 0.2290 - accuracy: 0.9342 - val_loss: 0.2320 - val_accuracy: 0.9350\n",
      "Epoch 171/400\n",
      "1433/1433 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.9333\n",
      "Epoch 171: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 775us/step - loss: 0.2286 - accuracy: 0.9333 - val_loss: 0.2297 - val_accuracy: 0.9333\n",
      "Epoch 172/400\n",
      "1421/1433 [============================>.] - ETA: 0s - loss: 0.2286 - accuracy: 0.9339\n",
      "Epoch 172: val_loss did not improve from 0.22866\n",
      "1433/1433 [==============================] - 1s 743us/step - loss: 0.2281 - accuracy: 0.9340 - val_loss: 0.2317 - val_accuracy: 0.9333\n",
      "Epoch 173/400\n",
      "1381/1433 [===========================>..] - ETA: 0s - loss: 0.2302 - accuracy: 0.9330\n",
      "Epoch 173: val_loss improved from 0.22866 to 0.22831, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 734us/step - loss: 0.2284 - accuracy: 0.9338 - val_loss: 0.2283 - val_accuracy: 0.9362\n",
      "Epoch 174/400\n",
      "1412/1433 [============================>.] - ETA: 0s - loss: 0.2292 - accuracy: 0.9325\n",
      "Epoch 174: val_loss did not improve from 0.22831\n",
      "1433/1433 [==============================] - 1s 750us/step - loss: 0.2281 - accuracy: 0.9328 - val_loss: 0.2309 - val_accuracy: 0.9315\n",
      "Epoch 175/400\n",
      "1432/1433 [============================>.] - ETA: 0s - loss: 0.2282 - accuracy: 0.9326\n",
      "Epoch 175: val_loss did not improve from 0.22831\n",
      "1433/1433 [==============================] - 1s 743us/step - loss: 0.2282 - accuracy: 0.9325 - val_loss: 0.2321 - val_accuracy: 0.9320\n",
      "Epoch 176/400\n",
      "1378/1433 [===========================>..] - ETA: 0s - loss: 0.2280 - accuracy: 0.9327\n",
      "Epoch 176: val_loss did not improve from 0.22831\n",
      "1433/1433 [==============================] - 1s 763us/step - loss: 0.2276 - accuracy: 0.9331 - val_loss: 0.2284 - val_accuracy: 0.9333\n",
      "Epoch 177/400\n",
      "1414/1433 [============================>.] - ETA: 0s - loss: 0.2272 - accuracy: 0.9327\n",
      "Epoch 177: val_loss improved from 0.22831 to 0.22820, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 755us/step - loss: 0.2265 - accuracy: 0.9328 - val_loss: 0.2282 - val_accuracy: 0.9377\n",
      "Epoch 178/400\n",
      "1381/1433 [===========================>..] - ETA: 0s - loss: 0.2274 - accuracy: 0.9338\n",
      "Epoch 178: val_loss did not improve from 0.22820\n",
      "1433/1433 [==============================] - 1s 764us/step - loss: 0.2265 - accuracy: 0.9339 - val_loss: 0.2345 - val_accuracy: 0.9320\n",
      "Epoch 179/400\n",
      "1371/1433 [===========================>..] - ETA: 0s - loss: 0.2270 - accuracy: 0.9331\n",
      "Epoch 179: val_loss improved from 0.22820 to 0.22711, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 741us/step - loss: 0.2267 - accuracy: 0.9330 - val_loss: 0.2271 - val_accuracy: 0.9370\n",
      "Epoch 180/400\n",
      "1380/1433 [===========================>..] - ETA: 0s - loss: 0.2263 - accuracy: 0.9331\n",
      "Epoch 180: val_loss did not improve from 0.22711\n",
      "1433/1433 [==============================] - 1s 761us/step - loss: 0.2263 - accuracy: 0.9329 - val_loss: 0.2278 - val_accuracy: 0.9315\n",
      "Epoch 181/400\n",
      "1404/1433 [============================>.] - ETA: 0s - loss: 0.2253 - accuracy: 0.9330\n",
      "Epoch 181: val_loss did not improve from 0.22711\n",
      "1433/1433 [==============================] - 1s 766us/step - loss: 0.2263 - accuracy: 0.9330 - val_loss: 0.2275 - val_accuracy: 0.9360\n",
      "Epoch 182/400\n",
      "1373/1433 [===========================>..] - ETA: 0s - loss: 0.2270 - accuracy: 0.9323\n",
      "Epoch 182: val_loss did not improve from 0.22711\n",
      "1433/1433 [==============================] - 1s 692us/step - loss: 0.2267 - accuracy: 0.9323 - val_loss: 0.2273 - val_accuracy: 0.9352\n",
      "Epoch 183/400\n",
      "1432/1433 [============================>.] - ETA: 0s - loss: 0.2268 - accuracy: 0.9336\n",
      "Epoch 183: val_loss did not improve from 0.22711\n",
      "1433/1433 [==============================] - 1s 714us/step - loss: 0.2268 - accuracy: 0.9336 - val_loss: 0.2293 - val_accuracy: 0.9389\n",
      "Epoch 184/400\n",
      "1351/1433 [===========================>..] - ETA: 0s - loss: 0.2281 - accuracy: 0.9333\n",
      "Epoch 184: val_loss did not improve from 0.22711\n",
      "1433/1433 [==============================] - 1s 699us/step - loss: 0.2262 - accuracy: 0.9340 - val_loss: 0.2284 - val_accuracy: 0.9340\n",
      "Epoch 185/400\n",
      "1365/1433 [===========================>..] - ETA: 0s - loss: 0.2263 - accuracy: 0.9335\n",
      "Epoch 185: val_loss improved from 0.22711 to 0.22563, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 702us/step - loss: 0.2263 - accuracy: 0.9332 - val_loss: 0.2256 - val_accuracy: 0.9422\n",
      "Epoch 186/400\n",
      "1364/1433 [===========================>..] - ETA: 0s - loss: 0.2269 - accuracy: 0.9327\n",
      "Epoch 186: val_loss did not improve from 0.22563\n",
      "1433/1433 [==============================] - 1s 694us/step - loss: 0.2259 - accuracy: 0.9329 - val_loss: 0.2264 - val_accuracy: 0.9345\n",
      "Epoch 187/400\n",
      "1381/1433 [===========================>..] - ETA: 0s - loss: 0.2269 - accuracy: 0.9339\n",
      "Epoch 187: val_loss improved from 0.22563 to 0.22524, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433/1433 [==============================] - 1s 701us/step - loss: 0.2258 - accuracy: 0.9337 - val_loss: 0.2252 - val_accuracy: 0.9337\n",
      "Epoch 188/400\n",
      "1392/1433 [============================>.] - ETA: 0s - loss: 0.2266 - accuracy: 0.9315\n",
      "Epoch 188: val_loss did not improve from 0.22524\n",
      "1433/1433 [==============================] - 1s 715us/step - loss: 0.2255 - accuracy: 0.9320 - val_loss: 0.2259 - val_accuracy: 0.9397\n",
      "Epoch 189/400\n",
      "1378/1433 [===========================>..] - ETA: 0s - loss: 0.2259 - accuracy: 0.9331\n",
      "Epoch 189: val_loss did not improve from 0.22524\n",
      "1433/1433 [==============================] - 1s 687us/step - loss: 0.2263 - accuracy: 0.9329 - val_loss: 0.2314 - val_accuracy: 0.9377\n",
      "Epoch 190/400\n",
      "1364/1433 [===========================>..] - ETA: 0s - loss: 0.2252 - accuracy: 0.9342\n",
      "Epoch 190: val_loss did not improve from 0.22524\n",
      "1433/1433 [==============================] - 1s 691us/step - loss: 0.2261 - accuracy: 0.9338 - val_loss: 0.2253 - val_accuracy: 0.9357\n",
      "Epoch 191/400\n",
      "1427/1433 [============================>.] - ETA: 0s - loss: 0.2257 - accuracy: 0.9329\n",
      "Epoch 191: val_loss did not improve from 0.22524\n",
      "1433/1433 [==============================] - 1s 703us/step - loss: 0.2254 - accuracy: 0.9330 - val_loss: 0.2253 - val_accuracy: 0.9305\n",
      "Epoch 192/400\n",
      "1361/1433 [===========================>..] - ETA: 0s - loss: 0.2243 - accuracy: 0.9347\n",
      "Epoch 192: val_loss did not improve from 0.22524\n",
      "1433/1433 [==============================] - 1s 692us/step - loss: 0.2246 - accuracy: 0.9338 - val_loss: 0.2315 - val_accuracy: 0.9345\n",
      "Epoch 193/400\n",
      "1386/1433 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.9332\n",
      "Epoch 193: val_loss improved from 0.22524 to 0.22504, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 689us/step - loss: 0.2249 - accuracy: 0.9331 - val_loss: 0.2250 - val_accuracy: 0.9340\n",
      "Epoch 194/400\n",
      "1357/1433 [===========================>..] - ETA: 0s - loss: 0.2251 - accuracy: 0.9333\n",
      "Epoch 194: val_loss did not improve from 0.22504\n",
      "1433/1433 [==============================] - 1s 697us/step - loss: 0.2253 - accuracy: 0.9326 - val_loss: 0.2277 - val_accuracy: 0.9370\n",
      "Epoch 195/400\n",
      "1354/1433 [===========================>..] - ETA: 0s - loss: 0.2252 - accuracy: 0.9334\n",
      "Epoch 195: val_loss did not improve from 0.22504\n",
      "1433/1433 [==============================] - 1s 698us/step - loss: 0.2259 - accuracy: 0.9335 - val_loss: 0.2280 - val_accuracy: 0.9345\n",
      "Epoch 196/400\n",
      "1391/1433 [============================>.] - ETA: 0s - loss: 0.2240 - accuracy: 0.9333\n",
      "Epoch 196: val_loss did not improve from 0.22504\n",
      "1433/1433 [==============================] - 1s 756us/step - loss: 0.2250 - accuracy: 0.9328 - val_loss: 0.2281 - val_accuracy: 0.9350\n",
      "Epoch 197/400\n",
      "1390/1433 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9330\n",
      "Epoch 197: val_loss improved from 0.22504 to 0.22429, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 878us/step - loss: 0.2245 - accuracy: 0.9329 - val_loss: 0.2243 - val_accuracy: 0.9426\n",
      "Epoch 198/400\n",
      "1433/1433 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.9335\n",
      "Epoch 198: val_loss did not improve from 0.22429\n",
      "1433/1433 [==============================] - 1s 750us/step - loss: 0.2245 - accuracy: 0.9335 - val_loss: 0.2246 - val_accuracy: 0.9323\n",
      "Epoch 199/400\n",
      "1381/1433 [===========================>..] - ETA: 0s - loss: 0.2251 - accuracy: 0.9337\n",
      "Epoch 199: val_loss did not improve from 0.22429\n",
      "1433/1433 [==============================] - 1s 809us/step - loss: 0.2249 - accuracy: 0.9333 - val_loss: 0.2269 - val_accuracy: 0.9342\n",
      "Epoch 200/400\n",
      "1427/1433 [============================>.] - ETA: 0s - loss: 0.2249 - accuracy: 0.9345\n",
      "Epoch 200: val_loss did not improve from 0.22429\n",
      "1433/1433 [==============================] - 1s 708us/step - loss: 0.2252 - accuracy: 0.9342 - val_loss: 0.2288 - val_accuracy: 0.9288\n",
      "Epoch 201/400\n",
      "1369/1433 [===========================>..] - ETA: 0s - loss: 0.2258 - accuracy: 0.9338\n",
      "Epoch 201: val_loss did not improve from 0.22429\n",
      "1433/1433 [==============================] - 1s 693us/step - loss: 0.2253 - accuracy: 0.9337 - val_loss: 0.2316 - val_accuracy: 0.9347\n",
      "Epoch 202/400\n",
      "1413/1433 [============================>.] - ETA: 0s - loss: 0.2244 - accuracy: 0.9329\n",
      "Epoch 202: val_loss did not improve from 0.22429\n",
      "1433/1433 [==============================] - 1s 706us/step - loss: 0.2238 - accuracy: 0.9330 - val_loss: 0.2247 - val_accuracy: 0.9313\n",
      "Epoch 203/400\n",
      "1353/1433 [===========================>..] - ETA: 0s - loss: 0.2246 - accuracy: 0.9326\n",
      "Epoch 203: val_loss did not improve from 0.22429\n",
      "1433/1433 [==============================] - 1s 696us/step - loss: 0.2243 - accuracy: 0.9328 - val_loss: 0.2244 - val_accuracy: 0.9323\n",
      "Epoch 204/400\n",
      "1351/1433 [===========================>..] - ETA: 0s - loss: 0.2240 - accuracy: 0.9345\n",
      "Epoch 204: val_loss did not improve from 0.22429\n",
      "1433/1433 [==============================] - 1s 700us/step - loss: 0.2248 - accuracy: 0.9336 - val_loss: 0.2276 - val_accuracy: 0.9394\n",
      "Epoch 205/400\n",
      "1365/1433 [===========================>..] - ETA: 0s - loss: 0.2251 - accuracy: 0.9332\n",
      "Epoch 205: val_loss did not improve from 0.22429\n",
      "1433/1433 [==============================] - 1s 731us/step - loss: 0.2242 - accuracy: 0.9332 - val_loss: 0.2251 - val_accuracy: 0.9310\n",
      "Epoch 206/400\n",
      "1413/1433 [============================>.] - ETA: 0s - loss: 0.2249 - accuracy: 0.9329\n",
      "Epoch 206: val_loss did not improve from 0.22429\n",
      "1433/1433 [==============================] - 1s 704us/step - loss: 0.2242 - accuracy: 0.9329 - val_loss: 0.2245 - val_accuracy: 0.9394\n",
      "Epoch 207/400\n",
      "1422/1433 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.9344\n",
      "Epoch 207: val_loss improved from 0.22429 to 0.22288, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 720us/step - loss: 0.2234 - accuracy: 0.9341 - val_loss: 0.2229 - val_accuracy: 0.9325\n",
      "Epoch 208/400\n",
      "1423/1433 [============================>.] - ETA: 0s - loss: 0.2239 - accuracy: 0.9325\n",
      "Epoch 208: val_loss did not improve from 0.22288\n",
      "1433/1433 [==============================] - 1s 749us/step - loss: 0.2236 - accuracy: 0.9326 - val_loss: 0.2257 - val_accuracy: 0.9431\n",
      "Epoch 209/400\n",
      "1430/1433 [============================>.] - ETA: 0s - loss: 0.2227 - accuracy: 0.9335\n",
      "Epoch 209: val_loss did not improve from 0.22288\n",
      "1433/1433 [==============================] - 1s 701us/step - loss: 0.2228 - accuracy: 0.9335 - val_loss: 0.2230 - val_accuracy: 0.9337\n",
      "Epoch 210/400\n",
      "1384/1433 [===========================>..] - ETA: 0s - loss: 0.2250 - accuracy: 0.9321\n",
      "Epoch 210: val_loss did not improve from 0.22288\n",
      "1433/1433 [==============================] - 1s 730us/step - loss: 0.2241 - accuracy: 0.9326 - val_loss: 0.2328 - val_accuracy: 0.9426\n",
      "Epoch 211/400\n",
      "1366/1433 [===========================>..] - ETA: 0s - loss: 0.2237 - accuracy: 0.9324\n",
      "Epoch 211: val_loss did not improve from 0.22288\n",
      "1433/1433 [==============================] - 1s 724us/step - loss: 0.2229 - accuracy: 0.9329 - val_loss: 0.2277 - val_accuracy: 0.9431\n",
      "Epoch 212/400\n",
      "1423/1433 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9338\n",
      "Epoch 212: val_loss did not improve from 0.22288\n",
      "1433/1433 [==============================] - 1s 705us/step - loss: 0.2229 - accuracy: 0.9336 - val_loss: 0.2240 - val_accuracy: 0.9347\n",
      "Epoch 213/400\n",
      "1353/1433 [===========================>..] - ETA: 0s - loss: 0.2240 - accuracy: 0.9324\n",
      "Epoch 213: val_loss improved from 0.22288 to 0.22183, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 706us/step - loss: 0.2224 - accuracy: 0.9331 - val_loss: 0.2218 - val_accuracy: 0.9379\n",
      "Epoch 214/400\n",
      "1362/1433 [===========================>..] - ETA: 0s - loss: 0.2248 - accuracy: 0.9339\n",
      "Epoch 214: val_loss did not improve from 0.22183\n",
      "1433/1433 [==============================] - 1s 737us/step - loss: 0.2235 - accuracy: 0.9343 - val_loss: 0.2233 - val_accuracy: 0.9323\n",
      "Epoch 215/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1414/1433 [============================>.] - ETA: 0s - loss: 0.2238 - accuracy: 0.9323\n",
      "Epoch 215: val_loss did not improve from 0.22183\n",
      "1433/1433 [==============================] - 1s 710us/step - loss: 0.2236 - accuracy: 0.9325 - val_loss: 0.2239 - val_accuracy: 0.9337\n",
      "Epoch 216/400\n",
      "1397/1433 [============================>.] - ETA: 0s - loss: 0.2238 - accuracy: 0.9343\n",
      "Epoch 216: val_loss did not improve from 0.22183\n",
      "1433/1433 [==============================] - 1s 718us/step - loss: 0.2224 - accuracy: 0.9346 - val_loss: 0.2441 - val_accuracy: 0.9293\n",
      "Epoch 217/400\n",
      "1359/1433 [===========================>..] - ETA: 0s - loss: 0.2221 - accuracy: 0.9327\n",
      "Epoch 217: val_loss did not improve from 0.22183\n",
      "1433/1433 [==============================] - 1s 731us/step - loss: 0.2237 - accuracy: 0.9328 - val_loss: 0.2228 - val_accuracy: 0.9340\n",
      "Epoch 218/400\n",
      "1416/1433 [============================>.] - ETA: 0s - loss: 0.2227 - accuracy: 0.9322\n",
      "Epoch 218: val_loss did not improve from 0.22183\n",
      "1433/1433 [==============================] - 1s 681us/step - loss: 0.2227 - accuracy: 0.9321 - val_loss: 0.2249 - val_accuracy: 0.9424\n",
      "Epoch 219/400\n",
      "1432/1433 [============================>.] - ETA: 0s - loss: 0.2225 - accuracy: 0.9329\n",
      "Epoch 219: val_loss did not improve from 0.22183\n",
      "1433/1433 [==============================] - 1s 705us/step - loss: 0.2224 - accuracy: 0.9329 - val_loss: 0.2326 - val_accuracy: 0.9379\n",
      "Epoch 220/400\n",
      "1385/1433 [===========================>..] - ETA: 0s - loss: 0.2225 - accuracy: 0.9333\n",
      "Epoch 220: val_loss did not improve from 0.22183\n",
      "1433/1433 [==============================] - 1s 685us/step - loss: 0.2223 - accuracy: 0.9338 - val_loss: 0.2344 - val_accuracy: 0.9320\n",
      "Epoch 221/400\n",
      "1354/1433 [===========================>..] - ETA: 0s - loss: 0.2243 - accuracy: 0.9322\n",
      "Epoch 221: val_loss did not improve from 0.22183\n",
      "1433/1433 [==============================] - 1s 690us/step - loss: 0.2219 - accuracy: 0.9326 - val_loss: 0.2228 - val_accuracy: 0.9394\n",
      "Epoch 222/400\n",
      "1391/1433 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.9330\n",
      "Epoch 222: val_loss improved from 0.22183 to 0.22123, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 740us/step - loss: 0.2233 - accuracy: 0.9330 - val_loss: 0.2212 - val_accuracy: 0.9367\n",
      "Epoch 223/400\n",
      "1418/1433 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9331\n",
      "Epoch 223: val_loss did not improve from 0.22123\n",
      "1433/1433 [==============================] - 1s 711us/step - loss: 0.2221 - accuracy: 0.9332 - val_loss: 0.2217 - val_accuracy: 0.9434\n",
      "Epoch 224/400\n",
      "1358/1433 [===========================>..] - ETA: 0s - loss: 0.2205 - accuracy: 0.9329\n",
      "Epoch 224: val_loss did not improve from 0.22123\n",
      "1433/1433 [==============================] - 1s 699us/step - loss: 0.2223 - accuracy: 0.9328 - val_loss: 0.2214 - val_accuracy: 0.9360\n",
      "Epoch 225/400\n",
      "1374/1433 [===========================>..] - ETA: 0s - loss: 0.2235 - accuracy: 0.9331\n",
      "Epoch 225: val_loss did not improve from 0.22123\n",
      "1433/1433 [==============================] - 1s 725us/step - loss: 0.2223 - accuracy: 0.9333 - val_loss: 0.2322 - val_accuracy: 0.9288\n",
      "Epoch 226/400\n",
      "1433/1433 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9328\n",
      "Epoch 226: val_loss did not improve from 0.22123\n",
      "1433/1433 [==============================] - 1s 701us/step - loss: 0.2229 - accuracy: 0.9328 - val_loss: 0.2235 - val_accuracy: 0.9320\n",
      "Epoch 227/400\n",
      "1429/1433 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9330\n",
      "Epoch 227: val_loss did not improve from 0.22123\n",
      "1433/1433 [==============================] - 1s 701us/step - loss: 0.2223 - accuracy: 0.9331 - val_loss: 0.2260 - val_accuracy: 0.9337\n",
      "Epoch 228/400\n",
      "1418/1433 [============================>.] - ETA: 0s - loss: 0.2220 - accuracy: 0.9323\n",
      "Epoch 228: val_loss did not improve from 0.22123\n",
      "1433/1433 [==============================] - 1s 708us/step - loss: 0.2218 - accuracy: 0.9325 - val_loss: 0.2219 - val_accuracy: 0.9340\n",
      "Epoch 229/400\n",
      "1360/1433 [===========================>..] - ETA: 0s - loss: 0.2201 - accuracy: 0.9335\n",
      "Epoch 229: val_loss did not improve from 0.22123\n",
      "1433/1433 [==============================] - 1s 697us/step - loss: 0.2220 - accuracy: 0.9329 - val_loss: 0.2231 - val_accuracy: 0.9276\n",
      "Epoch 230/400\n",
      "1356/1433 [===========================>..] - ETA: 0s - loss: 0.2198 - accuracy: 0.9331\n",
      "Epoch 230: val_loss did not improve from 0.22123\n",
      "1433/1433 [==============================] - 1s 698us/step - loss: 0.2217 - accuracy: 0.9330 - val_loss: 0.2267 - val_accuracy: 0.9323\n",
      "Epoch 231/400\n",
      "1391/1433 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9342\n",
      "Epoch 231: val_loss did not improve from 0.22123\n",
      "1433/1433 [==============================] - 1s 720us/step - loss: 0.2220 - accuracy: 0.9339 - val_loss: 0.2234 - val_accuracy: 0.9298\n",
      "Epoch 232/400\n",
      "1377/1433 [===========================>..] - ETA: 0s - loss: 0.2202 - accuracy: 0.9345\n",
      "Epoch 232: val_loss did not improve from 0.22123\n",
      "1433/1433 [==============================] - 1s 688us/step - loss: 0.2216 - accuracy: 0.9340 - val_loss: 0.2247 - val_accuracy: 0.9313\n",
      "Epoch 233/400\n",
      "1406/1433 [============================>.] - ETA: 0s - loss: 0.2219 - accuracy: 0.9330\n",
      "Epoch 233: val_loss improved from 0.22123 to 0.22070, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 724us/step - loss: 0.2223 - accuracy: 0.9327 - val_loss: 0.2207 - val_accuracy: 0.9394\n",
      "Epoch 234/400\n",
      "1400/1433 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9338\n",
      "Epoch 234: val_loss did not improve from 0.22070\n",
      "1433/1433 [==============================] - 1s 680us/step - loss: 0.2212 - accuracy: 0.9338 - val_loss: 0.2209 - val_accuracy: 0.9399\n",
      "Epoch 235/400\n",
      "1364/1433 [===========================>..] - ETA: 0s - loss: 0.2230 - accuracy: 0.9325\n",
      "Epoch 235: val_loss did not improve from 0.22070\n",
      "1433/1433 [==============================] - 1s 691us/step - loss: 0.2215 - accuracy: 0.9332 - val_loss: 0.2304 - val_accuracy: 0.9315\n",
      "Epoch 236/400\n",
      "1380/1433 [===========================>..] - ETA: 0s - loss: 0.2220 - accuracy: 0.9321\n",
      "Epoch 236: val_loss did not improve from 0.22070\n",
      "1433/1433 [==============================] - 1s 700us/step - loss: 0.2219 - accuracy: 0.9320 - val_loss: 0.2218 - val_accuracy: 0.9431\n",
      "Epoch 237/400\n",
      "1432/1433 [============================>.] - ETA: 0s - loss: 0.2211 - accuracy: 0.9332\n",
      "Epoch 237: val_loss improved from 0.22070 to 0.22038, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 744us/step - loss: 0.2210 - accuracy: 0.9332 - val_loss: 0.2204 - val_accuracy: 0.9392\n",
      "Epoch 238/400\n",
      "1423/1433 [============================>.] - ETA: 0s - loss: 0.2218 - accuracy: 0.9326\n",
      "Epoch 238: val_loss did not improve from 0.22038\n",
      "1433/1433 [==============================] - 1s 744us/step - loss: 0.2215 - accuracy: 0.9326 - val_loss: 0.2205 - val_accuracy: 0.9328\n",
      "Epoch 239/400\n",
      "1400/1433 [============================>.] - ETA: 0s - loss: 0.2208 - accuracy: 0.9333\n",
      "Epoch 239: val_loss did not improve from 0.22038\n",
      "1433/1433 [==============================] - 1s 749us/step - loss: 0.2208 - accuracy: 0.9329 - val_loss: 0.2221 - val_accuracy: 0.9313\n",
      "Epoch 240/400\n",
      "1407/1433 [============================>.] - ETA: 0s - loss: 0.2219 - accuracy: 0.9316\n",
      "Epoch 240: val_loss did not improve from 0.22038\n",
      "1433/1433 [==============================] - 1s 750us/step - loss: 0.2210 - accuracy: 0.9319 - val_loss: 0.2281 - val_accuracy: 0.9308\n",
      "Epoch 241/400\n",
      "1364/1433 [===========================>..] - ETA: 0s - loss: 0.2231 - accuracy: 0.9319\n",
      "Epoch 241: val_loss did not improve from 0.22038\n",
      "1433/1433 [==============================] - 1s 731us/step - loss: 0.2216 - accuracy: 0.9325 - val_loss: 0.2206 - val_accuracy: 0.9328\n",
      "Epoch 242/400\n",
      "1364/1433 [===========================>..] - ETA: 0s - loss: 0.2223 - accuracy: 0.9320\n",
      "Epoch 242: val_loss did not improve from 0.22038\n",
      "1433/1433 [==============================] - 1s 696us/step - loss: 0.2217 - accuracy: 0.9318 - val_loss: 0.2218 - val_accuracy: 0.9320\n",
      "Epoch 243/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374/1433 [===========================>..] - ETA: 0s - loss: 0.2216 - accuracy: 0.9327\n",
      "Epoch 243: val_loss did not improve from 0.22038\n",
      "1433/1433 [==============================] - 1s 686us/step - loss: 0.2204 - accuracy: 0.9329 - val_loss: 0.2225 - val_accuracy: 0.9323\n",
      "Epoch 244/400\n",
      "1403/1433 [============================>.] - ETA: 0s - loss: 0.2223 - accuracy: 0.9326\n",
      "Epoch 244: val_loss did not improve from 0.22038\n",
      "1433/1433 [==============================] - 1s 675us/step - loss: 0.2215 - accuracy: 0.9327 - val_loss: 0.2296 - val_accuracy: 0.9412\n",
      "Epoch 245/400\n",
      "1418/1433 [============================>.] - ETA: 0s - loss: 0.2210 - accuracy: 0.9330\n",
      "Epoch 245: val_loss improved from 0.22038 to 0.21947, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 678us/step - loss: 0.2207 - accuracy: 0.9332 - val_loss: 0.2195 - val_accuracy: 0.9384\n",
      "Epoch 246/400\n",
      "1350/1433 [===========================>..] - ETA: 0s - loss: 0.2196 - accuracy: 0.9330\n",
      "Epoch 246: val_loss did not improve from 0.21947\n",
      "1433/1433 [==============================] - 1s 658us/step - loss: 0.2205 - accuracy: 0.9332 - val_loss: 0.2243 - val_accuracy: 0.9293\n",
      "Epoch 247/400\n",
      "1364/1433 [===========================>..] - ETA: 0s - loss: 0.2197 - accuracy: 0.9329\n",
      "Epoch 247: val_loss did not improve from 0.21947\n",
      "1433/1433 [==============================] - 1s 656us/step - loss: 0.2207 - accuracy: 0.9331 - val_loss: 0.2203 - val_accuracy: 0.9375\n",
      "Epoch 248/400\n",
      "1350/1433 [===========================>..] - ETA: 0s - loss: 0.2213 - accuracy: 0.9320\n",
      "Epoch 248: val_loss did not improve from 0.21947\n",
      "1433/1433 [==============================] - 1s 655us/step - loss: 0.2208 - accuracy: 0.9323 - val_loss: 0.2228 - val_accuracy: 0.9318\n",
      "Epoch 249/400\n",
      "1378/1433 [===========================>..] - ETA: 0s - loss: 0.2207 - accuracy: 0.9327\n",
      "Epoch 249: val_loss did not improve from 0.21947\n",
      "1433/1433 [==============================] - 1s 689us/step - loss: 0.2204 - accuracy: 0.9326 - val_loss: 0.2263 - val_accuracy: 0.9283\n",
      "Epoch 250/400\n",
      "1425/1433 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9330\n",
      "Epoch 250: val_loss did not improve from 0.21947\n",
      "1433/1433 [==============================] - 1s 698us/step - loss: 0.2210 - accuracy: 0.9330 - val_loss: 0.2222 - val_accuracy: 0.9347\n",
      "Epoch 251/400\n",
      "1430/1433 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9329\n",
      "Epoch 251: val_loss did not improve from 0.21947\n",
      "1433/1433 [==============================] - 1s 702us/step - loss: 0.2204 - accuracy: 0.9329 - val_loss: 0.2228 - val_accuracy: 0.9350\n",
      "Epoch 252/400\n",
      "1357/1433 [===========================>..] - ETA: 0s - loss: 0.2178 - accuracy: 0.9330\n",
      "Epoch 252: val_loss did not improve from 0.21947\n",
      "1433/1433 [==============================] - 1s 736us/step - loss: 0.2191 - accuracy: 0.9323 - val_loss: 0.2457 - val_accuracy: 0.9320\n",
      "Epoch 253/400\n",
      "1394/1433 [============================>.] - ETA: 0s - loss: 0.2203 - accuracy: 0.9338\n",
      "Epoch 253: val_loss did not improve from 0.21947\n",
      "1433/1433 [==============================] - 1s 717us/step - loss: 0.2206 - accuracy: 0.9336 - val_loss: 0.2242 - val_accuracy: 0.9318\n",
      "Epoch 254/400\n",
      "1386/1433 [============================>.] - ETA: 0s - loss: 0.2206 - accuracy: 0.9329\n",
      "Epoch 254: val_loss did not improve from 0.21947\n",
      "1433/1433 [==============================] - 1s 713us/step - loss: 0.2198 - accuracy: 0.9333 - val_loss: 0.2254 - val_accuracy: 0.9303\n",
      "Epoch 255/400\n",
      "1350/1433 [===========================>..] - ETA: 0s - loss: 0.2185 - accuracy: 0.9343\n",
      "Epoch 255: val_loss improved from 0.21947 to 0.21859, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 662us/step - loss: 0.2207 - accuracy: 0.9340 - val_loss: 0.2186 - val_accuracy: 0.9382\n",
      "Epoch 256/400\n",
      "1382/1433 [===========================>..] - ETA: 0s - loss: 0.2207 - accuracy: 0.9326\n",
      "Epoch 256: val_loss did not improve from 0.21859\n",
      "1433/1433 [==============================] - 1s 683us/step - loss: 0.2193 - accuracy: 0.9332 - val_loss: 0.2225 - val_accuracy: 0.9330\n",
      "Epoch 257/400\n",
      "1388/1433 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9326\n",
      "Epoch 257: val_loss did not improve from 0.21859\n",
      "1433/1433 [==============================] - 1s 683us/step - loss: 0.2203 - accuracy: 0.9328 - val_loss: 0.2189 - val_accuracy: 0.9365\n",
      "Epoch 258/400\n",
      "1415/1433 [============================>.] - ETA: 0s - loss: 0.2200 - accuracy: 0.9326\n",
      "Epoch 258: val_loss did not improve from 0.21859\n",
      "1433/1433 [==============================] - 1s 756us/step - loss: 0.2199 - accuracy: 0.9326 - val_loss: 0.2237 - val_accuracy: 0.9313\n",
      "Epoch 259/400\n",
      "1396/1433 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9331\n",
      "Epoch 259: val_loss did not improve from 0.21859\n",
      "1433/1433 [==============================] - 1s 717us/step - loss: 0.2196 - accuracy: 0.9331 - val_loss: 0.2217 - val_accuracy: 0.9347\n",
      "Epoch 260/400\n",
      "1413/1433 [============================>.] - ETA: 0s - loss: 0.2182 - accuracy: 0.9328\n",
      "Epoch 260: val_loss did not improve from 0.21859\n",
      "1433/1433 [==============================] - 1s 705us/step - loss: 0.2197 - accuracy: 0.9328 - val_loss: 0.2197 - val_accuracy: 0.9325\n",
      "Epoch 261/400\n",
      "1397/1433 [============================>.] - ETA: 0s - loss: 0.2193 - accuracy: 0.9323\n",
      "Epoch 261: val_loss improved from 0.21859 to 0.21802, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 685us/step - loss: 0.2194 - accuracy: 0.9321 - val_loss: 0.2180 - val_accuracy: 0.9407\n",
      "Epoch 262/400\n",
      "1433/1433 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9333\n",
      "Epoch 262: val_loss did not improve from 0.21802\n",
      "1433/1433 [==============================] - 1s 737us/step - loss: 0.2197 - accuracy: 0.9333 - val_loss: 0.2186 - val_accuracy: 0.9365\n",
      "Epoch 263/400\n",
      "1360/1433 [===========================>..] - ETA: 0s - loss: 0.2214 - accuracy: 0.9328\n",
      "Epoch 263: val_loss did not improve from 0.21802\n",
      "1433/1433 [==============================] - 1s 693us/step - loss: 0.2196 - accuracy: 0.9332 - val_loss: 0.2335 - val_accuracy: 0.9283\n",
      "Epoch 264/400\n",
      "1349/1433 [===========================>..] - ETA: 0s - loss: 0.2181 - accuracy: 0.9327\n",
      "Epoch 264: val_loss improved from 0.21802 to 0.21723, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 705us/step - loss: 0.2195 - accuracy: 0.9332 - val_loss: 0.2172 - val_accuracy: 0.9330\n",
      "Epoch 265/400\n",
      "1417/1433 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9321\n",
      "Epoch 265: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 672us/step - loss: 0.2198 - accuracy: 0.9320 - val_loss: 0.2196 - val_accuracy: 0.9350\n",
      "Epoch 266/400\n",
      "1386/1433 [============================>.] - ETA: 0s - loss: 0.2184 - accuracy: 0.9328\n",
      "Epoch 266: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 698us/step - loss: 0.2194 - accuracy: 0.9325 - val_loss: 0.2204 - val_accuracy: 0.9412\n",
      "Epoch 267/400\n",
      "1422/1433 [============================>.] - ETA: 0s - loss: 0.2200 - accuracy: 0.9324\n",
      "Epoch 267: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 703us/step - loss: 0.2196 - accuracy: 0.9325 - val_loss: 0.2316 - val_accuracy: 0.9370\n",
      "Epoch 268/400\n",
      "1366/1433 [===========================>..] - ETA: 0s - loss: 0.2206 - accuracy: 0.9328\n",
      "Epoch 268: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 701us/step - loss: 0.2202 - accuracy: 0.9327 - val_loss: 0.2176 - val_accuracy: 0.9404\n",
      "Epoch 269/400\n",
      "1414/1433 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9342\n",
      "Epoch 269: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 712us/step - loss: 0.2186 - accuracy: 0.9343 - val_loss: 0.2185 - val_accuracy: 0.9342\n",
      "Epoch 270/400\n",
      "1352/1433 [===========================>..] - ETA: 0s - loss: 0.2172 - accuracy: 0.9332\n",
      "Epoch 270: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 704us/step - loss: 0.2188 - accuracy: 0.9328 - val_loss: 0.2201 - val_accuracy: 0.9323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/400\n",
      "1373/1433 [===========================>..] - ETA: 0s - loss: 0.2198 - accuracy: 0.9319\n",
      "Epoch 271: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 726us/step - loss: 0.2191 - accuracy: 0.9323 - val_loss: 0.2297 - val_accuracy: 0.9365\n",
      "Epoch 272/400\n",
      "1387/1433 [============================>.] - ETA: 0s - loss: 0.2208 - accuracy: 0.9327\n",
      "Epoch 272: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 684us/step - loss: 0.2192 - accuracy: 0.9330 - val_loss: 0.2191 - val_accuracy: 0.9315\n",
      "Epoch 273/400\n",
      "1386/1433 [============================>.] - ETA: 0s - loss: 0.2200 - accuracy: 0.9333\n",
      "Epoch 273: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 681us/step - loss: 0.2197 - accuracy: 0.9332 - val_loss: 0.2197 - val_accuracy: 0.9330\n",
      "Epoch 274/400\n",
      "1432/1433 [============================>.] - ETA: 0s - loss: 0.2195 - accuracy: 0.9328\n",
      "Epoch 274: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 707us/step - loss: 0.2195 - accuracy: 0.9328 - val_loss: 0.2275 - val_accuracy: 0.9325\n",
      "Epoch 275/400\n",
      "1402/1433 [============================>.] - ETA: 0s - loss: 0.2190 - accuracy: 0.9327\n",
      "Epoch 275: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 717us/step - loss: 0.2188 - accuracy: 0.9328 - val_loss: 0.2180 - val_accuracy: 0.9350\n",
      "Epoch 276/400\n",
      "1403/1433 [============================>.] - ETA: 0s - loss: 0.2188 - accuracy: 0.9325\n",
      "Epoch 276: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 798us/step - loss: 0.2190 - accuracy: 0.9325 - val_loss: 0.2204 - val_accuracy: 0.9330\n",
      "Epoch 277/400\n",
      "1413/1433 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9341\n",
      "Epoch 277: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 822us/step - loss: 0.2183 - accuracy: 0.9339 - val_loss: 0.2195 - val_accuracy: 0.9422\n",
      "Epoch 278/400\n",
      "1423/1433 [============================>.] - ETA: 0s - loss: 0.2189 - accuracy: 0.9343\n",
      "Epoch 278: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 768us/step - loss: 0.2191 - accuracy: 0.9342 - val_loss: 0.2270 - val_accuracy: 0.9340\n",
      "Epoch 279/400\n",
      "1416/1433 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9321\n",
      "Epoch 279: val_loss did not improve from 0.21723\n",
      "1433/1433 [==============================] - 1s 705us/step - loss: 0.2191 - accuracy: 0.9322 - val_loss: 0.2179 - val_accuracy: 0.9337\n",
      "Epoch 280/400\n",
      "1396/1433 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9324\n",
      "Epoch 280: val_loss improved from 0.21723 to 0.21638, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 686us/step - loss: 0.2185 - accuracy: 0.9332 - val_loss: 0.2164 - val_accuracy: 0.9360\n",
      "Epoch 281/400\n",
      "1377/1433 [===========================>..] - ETA: 0s - loss: 0.2202 - accuracy: 0.9329\n",
      "Epoch 281: val_loss did not improve from 0.21638\n",
      "1433/1433 [==============================] - 1s 694us/step - loss: 0.2187 - accuracy: 0.9332 - val_loss: 0.2193 - val_accuracy: 0.9315\n",
      "Epoch 282/400\n",
      "1382/1433 [===========================>..] - ETA: 0s - loss: 0.2189 - accuracy: 0.9337\n",
      "Epoch 282: val_loss did not improve from 0.21638\n",
      "1433/1433 [==============================] - 1s 731us/step - loss: 0.2186 - accuracy: 0.9336 - val_loss: 0.2224 - val_accuracy: 0.9290\n",
      "Epoch 283/400\n",
      "1419/1433 [============================>.] - ETA: 0s - loss: 0.2183 - accuracy: 0.9323\n",
      "Epoch 283: val_loss did not improve from 0.21638\n",
      "1433/1433 [==============================] - 1s 747us/step - loss: 0.2181 - accuracy: 0.9323 - val_loss: 0.2192 - val_accuracy: 0.9426\n",
      "Epoch 284/400\n",
      "1388/1433 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9323\n",
      "Epoch 284: val_loss did not improve from 0.21638\n",
      "1433/1433 [==============================] - 1s 724us/step - loss: 0.2187 - accuracy: 0.9321 - val_loss: 0.2277 - val_accuracy: 0.9298\n",
      "Epoch 285/400\n",
      "1428/1433 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9337\n",
      "Epoch 285: val_loss did not improve from 0.21638\n",
      "1433/1433 [==============================] - 1s 696us/step - loss: 0.2175 - accuracy: 0.9336 - val_loss: 0.2231 - val_accuracy: 0.9347\n",
      "Epoch 286/400\n",
      "1432/1433 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9330\n",
      "Epoch 286: val_loss did not improve from 0.21638\n",
      "1433/1433 [==============================] - 1s 664us/step - loss: 0.2187 - accuracy: 0.9330 - val_loss: 0.2165 - val_accuracy: 0.9389\n",
      "Epoch 287/400\n",
      "1432/1433 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9332\n",
      "Epoch 287: val_loss did not improve from 0.21638\n",
      "1433/1433 [==============================] - 1s 665us/step - loss: 0.2182 - accuracy: 0.9332 - val_loss: 0.2207 - val_accuracy: 0.9310\n",
      "Epoch 288/400\n",
      "1364/1433 [===========================>..] - ETA: 0s - loss: 0.2177 - accuracy: 0.9338\n",
      "Epoch 288: val_loss did not improve from 0.21638\n",
      "1433/1433 [==============================] - 1s 693us/step - loss: 0.2179 - accuracy: 0.9334 - val_loss: 0.2168 - val_accuracy: 0.9382\n",
      "Epoch 289/400\n",
      "1415/1433 [============================>.] - ETA: 0s - loss: 0.2182 - accuracy: 0.9334\n",
      "Epoch 289: val_loss improved from 0.21638 to 0.21612, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 712us/step - loss: 0.2177 - accuracy: 0.9335 - val_loss: 0.2161 - val_accuracy: 0.9328\n",
      "Epoch 290/400\n",
      "1355/1433 [===========================>..] - ETA: 0s - loss: 0.2193 - accuracy: 0.9326\n",
      "Epoch 290: val_loss did not improve from 0.21612\n",
      "1433/1433 [==============================] - 1s 653us/step - loss: 0.2178 - accuracy: 0.9331 - val_loss: 0.2164 - val_accuracy: 0.9352\n",
      "Epoch 291/400\n",
      "1383/1433 [===========================>..] - ETA: 0s - loss: 0.2193 - accuracy: 0.9329\n",
      "Epoch 291: val_loss did not improve from 0.21612\n",
      "1433/1433 [==============================] - 1s 698us/step - loss: 0.2180 - accuracy: 0.9332 - val_loss: 0.2182 - val_accuracy: 0.9387\n",
      "Epoch 292/400\n",
      "1421/1433 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.9324\n",
      "Epoch 292: val_loss did not improve from 0.21612\n",
      "1433/1433 [==============================] - 1s 711us/step - loss: 0.2173 - accuracy: 0.9322 - val_loss: 0.2193 - val_accuracy: 0.9308\n",
      "Epoch 293/400\n",
      "1362/1433 [===========================>..] - ETA: 0s - loss: 0.2189 - accuracy: 0.9321\n",
      "Epoch 293: val_loss did not improve from 0.21612\n",
      "1433/1433 [==============================] - 1s 730us/step - loss: 0.2179 - accuracy: 0.9328 - val_loss: 0.2225 - val_accuracy: 0.9315\n",
      "Epoch 294/400\n",
      "1376/1433 [===========================>..] - ETA: 0s - loss: 0.2180 - accuracy: 0.9330\n",
      "Epoch 294: val_loss did not improve from 0.21612\n",
      "1433/1433 [==============================] - 1s 690us/step - loss: 0.2187 - accuracy: 0.9327 - val_loss: 0.2305 - val_accuracy: 0.9362\n",
      "Epoch 295/400\n",
      "1363/1433 [===========================>..] - ETA: 0s - loss: 0.2174 - accuracy: 0.9345\n",
      "Epoch 295: val_loss did not improve from 0.21612\n",
      "1433/1433 [==============================] - 1s 697us/step - loss: 0.2180 - accuracy: 0.9341 - val_loss: 0.2226 - val_accuracy: 0.9330\n",
      "Epoch 296/400\n",
      "1401/1433 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9327\n",
      "Epoch 296: val_loss improved from 0.21612 to 0.21608, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 721us/step - loss: 0.2179 - accuracy: 0.9329 - val_loss: 0.2161 - val_accuracy: 0.9350\n",
      "Epoch 297/400\n",
      "1388/1433 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9326\n",
      "Epoch 297: val_loss did not improve from 0.21608\n",
      "1433/1433 [==============================] - 1s 681us/step - loss: 0.2177 - accuracy: 0.9326 - val_loss: 0.2245 - val_accuracy: 0.9409\n",
      "Epoch 298/400\n",
      "1409/1433 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9338\n",
      "Epoch 298: val_loss did not improve from 0.21608\n",
      "1433/1433 [==============================] - 1s 715us/step - loss: 0.2173 - accuracy: 0.9340 - val_loss: 0.2219 - val_accuracy: 0.9308\n",
      "Epoch 299/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376/1433 [===========================>..] - ETA: 0s - loss: 0.2156 - accuracy: 0.9339\n",
      "Epoch 299: val_loss did not improve from 0.21608\n",
      "1433/1433 [==============================] - 1s 800us/step - loss: 0.2174 - accuracy: 0.9334 - val_loss: 0.2190 - val_accuracy: 0.9323\n",
      "Epoch 300/400\n",
      "1417/1433 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9335\n",
      "Epoch 300: val_loss did not improve from 0.21608\n",
      "1433/1433 [==============================] - 1s 748us/step - loss: 0.2170 - accuracy: 0.9337 - val_loss: 0.2316 - val_accuracy: 0.9308\n",
      "Epoch 301/400\n",
      "1429/1433 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9329\n",
      "Epoch 301: val_loss did not improve from 0.21608\n",
      "1433/1433 [==============================] - 1s 757us/step - loss: 0.2175 - accuracy: 0.9328 - val_loss: 0.2175 - val_accuracy: 0.9330\n",
      "Epoch 302/400\n",
      "1371/1433 [===========================>..] - ETA: 0s - loss: 0.2169 - accuracy: 0.9325\n",
      "Epoch 302: val_loss did not improve from 0.21608\n",
      "1433/1433 [==============================] - 1s 836us/step - loss: 0.2174 - accuracy: 0.9323 - val_loss: 0.2198 - val_accuracy: 0.9340\n",
      "Epoch 303/400\n",
      "1433/1433 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9331\n",
      "Epoch 303: val_loss did not improve from 0.21608\n",
      "1433/1433 [==============================] - 1s 750us/step - loss: 0.2171 - accuracy: 0.9331 - val_loss: 0.2193 - val_accuracy: 0.9325\n",
      "Epoch 304/400\n",
      "1391/1433 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.9330\n",
      "Epoch 304: val_loss did not improve from 0.21608\n",
      "1433/1433 [==============================] - 1s 713us/step - loss: 0.2174 - accuracy: 0.9329 - val_loss: 0.2215 - val_accuracy: 0.9347\n",
      "Epoch 305/400\n",
      "1393/1433 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9337\n",
      "Epoch 305: val_loss did not improve from 0.21608\n",
      "1433/1433 [==============================] - 1s 677us/step - loss: 0.2171 - accuracy: 0.9336 - val_loss: 0.2187 - val_accuracy: 0.9355\n",
      "Epoch 306/400\n",
      "1351/1433 [===========================>..] - ETA: 0s - loss: 0.2165 - accuracy: 0.9321\n",
      "Epoch 306: val_loss did not improve from 0.21608\n",
      "1433/1433 [==============================] - 1s 704us/step - loss: 0.2175 - accuracy: 0.9324 - val_loss: 0.2164 - val_accuracy: 0.9375\n",
      "Epoch 307/400\n",
      "1360/1433 [===========================>..] - ETA: 0s - loss: 0.2176 - accuracy: 0.9336\n",
      "Epoch 307: val_loss improved from 0.21608 to 0.21512, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 700us/step - loss: 0.2171 - accuracy: 0.9339 - val_loss: 0.2151 - val_accuracy: 0.9360\n",
      "Epoch 308/400\n",
      "1388/1433 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.9330\n",
      "Epoch 308: val_loss improved from 0.21512 to 0.21503, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 723us/step - loss: 0.2169 - accuracy: 0.9331 - val_loss: 0.2150 - val_accuracy: 0.9407\n",
      "Epoch 309/400\n",
      "1363/1433 [===========================>..] - ETA: 0s - loss: 0.2181 - accuracy: 0.9339\n",
      "Epoch 309: val_loss did not improve from 0.21503\n",
      "1433/1433 [==============================] - 1s 732us/step - loss: 0.2168 - accuracy: 0.9343 - val_loss: 0.2166 - val_accuracy: 0.9350\n",
      "Epoch 310/400\n",
      "1425/1433 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9337\n",
      "Epoch 310: val_loss did not improve from 0.21503\n",
      "1433/1433 [==============================] - 1s 662us/step - loss: 0.2170 - accuracy: 0.9337 - val_loss: 0.2165 - val_accuracy: 0.9372\n",
      "Epoch 311/400\n",
      "1426/1433 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.9331\n",
      "Epoch 311: val_loss did not improve from 0.21503\n",
      "1433/1433 [==============================] - 1s 736us/step - loss: 0.2169 - accuracy: 0.9331 - val_loss: 0.2162 - val_accuracy: 0.9384\n",
      "Epoch 312/400\n",
      "1359/1433 [===========================>..] - ETA: 0s - loss: 0.2185 - accuracy: 0.9331\n",
      "Epoch 312: val_loss did not improve from 0.21503\n",
      "1433/1433 [==============================] - 1s 660us/step - loss: 0.2171 - accuracy: 0.9335 - val_loss: 0.2154 - val_accuracy: 0.9402\n",
      "Epoch 313/400\n",
      "1422/1433 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.9322\n",
      "Epoch 313: val_loss did not improve from 0.21503\n",
      "1433/1433 [==============================] - 1s 709us/step - loss: 0.2177 - accuracy: 0.9321 - val_loss: 0.2269 - val_accuracy: 0.9308\n",
      "Epoch 314/400\n",
      "1380/1433 [===========================>..] - ETA: 0s - loss: 0.2173 - accuracy: 0.9335\n",
      "Epoch 314: val_loss improved from 0.21503 to 0.21492, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 727us/step - loss: 0.2166 - accuracy: 0.9335 - val_loss: 0.2149 - val_accuracy: 0.9357\n",
      "Epoch 315/400\n",
      "1385/1433 [===========================>..] - ETA: 0s - loss: 0.2154 - accuracy: 0.9327\n",
      "Epoch 315: val_loss did not improve from 0.21492\n",
      "1433/1433 [==============================] - 1s 738us/step - loss: 0.2164 - accuracy: 0.9325 - val_loss: 0.2208 - val_accuracy: 0.9347\n",
      "Epoch 316/400\n",
      "1419/1433 [============================>.] - ETA: 0s - loss: 0.2173 - accuracy: 0.9334\n",
      "Epoch 316: val_loss did not improve from 0.21492\n",
      "1433/1433 [==============================] - 1s 741us/step - loss: 0.2167 - accuracy: 0.9337 - val_loss: 0.2260 - val_accuracy: 0.9323\n",
      "Epoch 317/400\n",
      "1427/1433 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9332\n",
      "Epoch 317: val_loss did not improve from 0.21492\n",
      "1433/1433 [==============================] - 1s 754us/step - loss: 0.2163 - accuracy: 0.9332 - val_loss: 0.2165 - val_accuracy: 0.9333\n",
      "Epoch 318/400\n",
      "1386/1433 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9343\n",
      "Epoch 318: val_loss did not improve from 0.21492\n",
      "1433/1433 [==============================] - 1s 766us/step - loss: 0.2161 - accuracy: 0.9344 - val_loss: 0.2171 - val_accuracy: 0.9419\n",
      "Epoch 319/400\n",
      "1394/1433 [============================>.] - ETA: 0s - loss: 0.2162 - accuracy: 0.9321\n",
      "Epoch 319: val_loss improved from 0.21492 to 0.21426, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 779us/step - loss: 0.2163 - accuracy: 0.9326 - val_loss: 0.2143 - val_accuracy: 0.9375\n",
      "Epoch 320/400\n",
      "1384/1433 [===========================>..] - ETA: 0s - loss: 0.2174 - accuracy: 0.9327\n",
      "Epoch 320: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 717us/step - loss: 0.2168 - accuracy: 0.9329 - val_loss: 0.2145 - val_accuracy: 0.9389\n",
      "Epoch 321/400\n",
      "1421/1433 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9327\n",
      "Epoch 321: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 823us/step - loss: 0.2165 - accuracy: 0.9328 - val_loss: 0.2159 - val_accuracy: 0.9360\n",
      "Epoch 322/400\n",
      "1355/1433 [===========================>..] - ETA: 0s - loss: 0.2187 - accuracy: 0.9331\n",
      "Epoch 322: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 734us/step - loss: 0.2161 - accuracy: 0.9337 - val_loss: 0.2196 - val_accuracy: 0.9328\n",
      "Epoch 323/400\n",
      "1426/1433 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9341\n",
      "Epoch 323: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 701us/step - loss: 0.2159 - accuracy: 0.9342 - val_loss: 0.2203 - val_accuracy: 0.9370\n",
      "Epoch 324/400\n",
      "1411/1433 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9336\n",
      "Epoch 324: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 671us/step - loss: 0.2156 - accuracy: 0.9338 - val_loss: 0.2145 - val_accuracy: 0.9387\n",
      "Epoch 325/400\n",
      "1371/1433 [===========================>..] - ETA: 0s - loss: 0.2147 - accuracy: 0.9345\n",
      "Epoch 325: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 696us/step - loss: 0.2160 - accuracy: 0.9340 - val_loss: 0.2190 - val_accuracy: 0.9375\n",
      "Epoch 326/400\n",
      "1360/1433 [===========================>..] - ETA: 0s - loss: 0.2131 - accuracy: 0.9343\n",
      "Epoch 326: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 690us/step - loss: 0.2160 - accuracy: 0.9338 - val_loss: 0.2151 - val_accuracy: 0.9335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/400\n",
      "1429/1433 [============================>.] - ETA: 0s - loss: 0.2162 - accuracy: 0.9337\n",
      "Epoch 327: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 711us/step - loss: 0.2161 - accuracy: 0.9337 - val_loss: 0.2171 - val_accuracy: 0.9340\n",
      "Epoch 328/400\n",
      "1379/1433 [===========================>..] - ETA: 0s - loss: 0.2179 - accuracy: 0.9330\n",
      "Epoch 328: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 679us/step - loss: 0.2169 - accuracy: 0.9331 - val_loss: 0.2152 - val_accuracy: 0.9305\n",
      "Epoch 329/400\n",
      "1393/1433 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9355\n",
      "Epoch 329: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 676us/step - loss: 0.2159 - accuracy: 0.9353 - val_loss: 0.2150 - val_accuracy: 0.9357\n",
      "Epoch 330/400\n",
      "1361/1433 [===========================>..] - ETA: 0s - loss: 0.2159 - accuracy: 0.9330\n",
      "Epoch 330: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 727us/step - loss: 0.2174 - accuracy: 0.9329 - val_loss: 0.2170 - val_accuracy: 0.9288\n",
      "Epoch 331/400\n",
      "1420/1433 [============================>.] - ETA: 0s - loss: 0.2148 - accuracy: 0.9328\n",
      "Epoch 331: val_loss did not improve from 0.21426\n",
      "1433/1433 [==============================] - 1s 702us/step - loss: 0.2153 - accuracy: 0.9325 - val_loss: 0.2177 - val_accuracy: 0.9340\n",
      "Epoch 332/400\n",
      "1373/1433 [===========================>..] - ETA: 0s - loss: 0.2156 - accuracy: 0.9327\n",
      "Epoch 332: val_loss improved from 0.21426 to 0.21409, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 738us/step - loss: 0.2159 - accuracy: 0.9332 - val_loss: 0.2141 - val_accuracy: 0.9434\n",
      "Epoch 333/400\n",
      "1359/1433 [===========================>..] - ETA: 0s - loss: 0.2169 - accuracy: 0.9323\n",
      "Epoch 333: val_loss did not improve from 0.21409\n",
      "1433/1433 [==============================] - 1s 694us/step - loss: 0.2167 - accuracy: 0.9328 - val_loss: 0.2151 - val_accuracy: 0.9320\n",
      "Epoch 334/400\n",
      "1386/1433 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9339\n",
      "Epoch 334: val_loss did not improve from 0.21409\n",
      "1433/1433 [==============================] - 1s 716us/step - loss: 0.2161 - accuracy: 0.9339 - val_loss: 0.2243 - val_accuracy: 0.9305\n",
      "Epoch 335/400\n",
      "1352/1433 [===========================>..] - ETA: 0s - loss: 0.2160 - accuracy: 0.9345\n",
      "Epoch 335: val_loss did not improve from 0.21409\n",
      "1433/1433 [==============================] - 1s 696us/step - loss: 0.2158 - accuracy: 0.9343 - val_loss: 0.2159 - val_accuracy: 0.9389\n",
      "Epoch 336/400\n",
      "1416/1433 [============================>.] - ETA: 0s - loss: 0.2162 - accuracy: 0.9330\n",
      "Epoch 336: val_loss did not improve from 0.21409\n",
      "1433/1433 [==============================] - 1s 702us/step - loss: 0.2158 - accuracy: 0.9329 - val_loss: 0.2143 - val_accuracy: 0.9360\n",
      "Epoch 337/400\n",
      "1366/1433 [===========================>..] - ETA: 0s - loss: 0.2157 - accuracy: 0.9335\n",
      "Epoch 337: val_loss did not improve from 0.21409\n",
      "1433/1433 [==============================] - 1s 698us/step - loss: 0.2153 - accuracy: 0.9338 - val_loss: 0.2205 - val_accuracy: 0.9337\n",
      "Epoch 338/400\n",
      "1400/1433 [============================>.] - ETA: 0s - loss: 0.2152 - accuracy: 0.9339\n",
      "Epoch 338: val_loss did not improve from 0.21409\n",
      "1433/1433 [==============================] - 1s 748us/step - loss: 0.2151 - accuracy: 0.9341 - val_loss: 0.2142 - val_accuracy: 0.9323\n",
      "Epoch 339/400\n",
      "1358/1433 [===========================>..] - ETA: 0s - loss: 0.2164 - accuracy: 0.9336\n",
      "Epoch 339: val_loss did not improve from 0.21409\n",
      "1433/1433 [==============================] - 1s 695us/step - loss: 0.2155 - accuracy: 0.9337 - val_loss: 0.2151 - val_accuracy: 0.9375\n",
      "Epoch 340/400\n",
      "1408/1433 [============================>.] - ETA: 0s - loss: 0.2166 - accuracy: 0.9344\n",
      "Epoch 340: val_loss did not improve from 0.21409\n",
      "1433/1433 [==============================] - 1s 747us/step - loss: 0.2154 - accuracy: 0.9348 - val_loss: 0.2225 - val_accuracy: 0.9330\n",
      "Epoch 341/400\n",
      "1391/1433 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.9339\n",
      "Epoch 341: val_loss did not improve from 0.21409\n",
      "1433/1433 [==============================] - 1s 677us/step - loss: 0.2157 - accuracy: 0.9339 - val_loss: 0.2152 - val_accuracy: 0.9325\n",
      "Epoch 342/400\n",
      "1367/1433 [===========================>..] - ETA: 0s - loss: 0.2145 - accuracy: 0.9342\n",
      "Epoch 342: val_loss improved from 0.21409 to 0.21322, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 707us/step - loss: 0.2149 - accuracy: 0.9338 - val_loss: 0.2132 - val_accuracy: 0.9345\n",
      "Epoch 343/400\n",
      "1403/1433 [============================>.] - ETA: 0s - loss: 0.2155 - accuracy: 0.9334\n",
      "Epoch 343: val_loss improved from 0.21322 to 0.21275, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 684us/step - loss: 0.2160 - accuracy: 0.9332 - val_loss: 0.2127 - val_accuracy: 0.9323\n",
      "Epoch 344/400\n",
      "1388/1433 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9327\n",
      "Epoch 344: val_loss did not improve from 0.21275\n",
      "1433/1433 [==============================] - 1s 679us/step - loss: 0.2152 - accuracy: 0.9328 - val_loss: 0.2139 - val_accuracy: 0.9367\n",
      "Epoch 345/400\n",
      "1425/1433 [============================>.] - ETA: 0s - loss: 0.2158 - accuracy: 0.9348\n",
      "Epoch 345: val_loss did not improve from 0.21275\n",
      "1433/1433 [==============================] - 1s 667us/step - loss: 0.2155 - accuracy: 0.9349 - val_loss: 0.2147 - val_accuracy: 0.9310\n",
      "Epoch 346/400\n",
      "1369/1433 [===========================>..] - ETA: 0s - loss: 0.2164 - accuracy: 0.9331\n",
      "Epoch 346: val_loss did not improve from 0.21275\n",
      "1433/1433 [==============================] - 1s 690us/step - loss: 0.2157 - accuracy: 0.9332 - val_loss: 0.2269 - val_accuracy: 0.9300\n",
      "Epoch 347/400\n",
      "1364/1433 [===========================>..] - ETA: 0s - loss: 0.2171 - accuracy: 0.9328\n",
      "Epoch 347: val_loss did not improve from 0.21275\n",
      "1433/1433 [==============================] - 1s 702us/step - loss: 0.2157 - accuracy: 0.9331 - val_loss: 0.2154 - val_accuracy: 0.9392\n",
      "Epoch 348/400\n",
      "1393/1433 [============================>.] - ETA: 0s - loss: 0.2150 - accuracy: 0.9344\n",
      "Epoch 348: val_loss did not improve from 0.21275\n",
      "1433/1433 [==============================] - 1s 687us/step - loss: 0.2151 - accuracy: 0.9345 - val_loss: 0.2135 - val_accuracy: 0.9392\n",
      "Epoch 349/400\n",
      "1428/1433 [============================>.] - ETA: 0s - loss: 0.2148 - accuracy: 0.9337\n",
      "Epoch 349: val_loss did not improve from 0.21275\n",
      "1433/1433 [==============================] - 1s 665us/step - loss: 0.2152 - accuracy: 0.9335 - val_loss: 0.2297 - val_accuracy: 0.9305\n",
      "Epoch 350/400\n",
      "1403/1433 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9327\n",
      "Epoch 350: val_loss improved from 0.21275 to 0.21180, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 698us/step - loss: 0.2147 - accuracy: 0.9331 - val_loss: 0.2118 - val_accuracy: 0.9392\n",
      "Epoch 351/400\n",
      "1409/1433 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9338\n",
      "Epoch 351: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 716us/step - loss: 0.2155 - accuracy: 0.9336 - val_loss: 0.2155 - val_accuracy: 0.9365\n",
      "Epoch 352/400\n",
      "1362/1433 [===========================>..] - ETA: 0s - loss: 0.2178 - accuracy: 0.9327\n",
      "Epoch 352: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 691us/step - loss: 0.2157 - accuracy: 0.9329 - val_loss: 0.2167 - val_accuracy: 0.9320\n",
      "Epoch 353/400\n",
      "1431/1433 [============================>.] - ETA: 0s - loss: 0.2154 - accuracy: 0.9341\n",
      "Epoch 353: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 697us/step - loss: 0.2153 - accuracy: 0.9342 - val_loss: 0.2194 - val_accuracy: 0.9333\n",
      "Epoch 354/400\n",
      "1368/1433 [===========================>..] - ETA: 0s - loss: 0.2143 - accuracy: 0.9338\n",
      "Epoch 354: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 648us/step - loss: 0.2150 - accuracy: 0.9334 - val_loss: 0.2202 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/400\n",
      "1379/1433 [===========================>..] - ETA: 0s - loss: 0.2156 - accuracy: 0.9327\n",
      "Epoch 355: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 679us/step - loss: 0.2150 - accuracy: 0.9327 - val_loss: 0.2145 - val_accuracy: 0.9352\n",
      "Epoch 356/400\n",
      "1361/1433 [===========================>..] - ETA: 0s - loss: 0.2167 - accuracy: 0.9341\n",
      "Epoch 356: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 649us/step - loss: 0.2149 - accuracy: 0.9347 - val_loss: 0.2126 - val_accuracy: 0.9335\n",
      "Epoch 357/400\n",
      "1412/1433 [============================>.] - ETA: 0s - loss: 0.2147 - accuracy: 0.9336\n",
      "Epoch 357: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 669us/step - loss: 0.2153 - accuracy: 0.9338 - val_loss: 0.2125 - val_accuracy: 0.9318\n",
      "Epoch 358/400\n",
      "1356/1433 [===========================>..] - ETA: 0s - loss: 0.2165 - accuracy: 0.9330\n",
      "Epoch 358: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 656us/step - loss: 0.2152 - accuracy: 0.9334 - val_loss: 0.2164 - val_accuracy: 0.9345\n",
      "Epoch 359/400\n",
      "1380/1433 [===========================>..] - ETA: 0s - loss: 0.2135 - accuracy: 0.9325\n",
      "Epoch 359: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 678us/step - loss: 0.2146 - accuracy: 0.9326 - val_loss: 0.2229 - val_accuracy: 0.9318\n",
      "Epoch 360/400\n",
      "1353/1433 [===========================>..] - ETA: 0s - loss: 0.2130 - accuracy: 0.9337\n",
      "Epoch 360: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 658us/step - loss: 0.2144 - accuracy: 0.9332 - val_loss: 0.2141 - val_accuracy: 0.9377\n",
      "Epoch 361/400\n",
      "1392/1433 [============================>.] - ETA: 0s - loss: 0.2142 - accuracy: 0.9336\n",
      "Epoch 361: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 684us/step - loss: 0.2145 - accuracy: 0.9333 - val_loss: 0.2125 - val_accuracy: 0.9360\n",
      "Epoch 362/400\n",
      "1415/1433 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9333\n",
      "Epoch 362: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 670us/step - loss: 0.2146 - accuracy: 0.9332 - val_loss: 0.2178 - val_accuracy: 0.9426\n",
      "Epoch 363/400\n",
      "1375/1433 [===========================>..] - ETA: 0s - loss: 0.2151 - accuracy: 0.9331\n",
      "Epoch 363: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 699us/step - loss: 0.2153 - accuracy: 0.9332 - val_loss: 0.2123 - val_accuracy: 0.9397\n",
      "Epoch 364/400\n",
      "1431/1433 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.9342\n",
      "Epoch 364: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 736us/step - loss: 0.2141 - accuracy: 0.9341 - val_loss: 0.2169 - val_accuracy: 0.9318\n",
      "Epoch 365/400\n",
      "1424/1433 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9332\n",
      "Epoch 365: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 667us/step - loss: 0.2142 - accuracy: 0.9330 - val_loss: 0.2175 - val_accuracy: 0.9382\n",
      "Epoch 366/400\n",
      "1407/1433 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9339\n",
      "Epoch 366: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 671us/step - loss: 0.2141 - accuracy: 0.9340 - val_loss: 0.2119 - val_accuracy: 0.9323\n",
      "Epoch 367/400\n",
      "1363/1433 [===========================>..] - ETA: 0s - loss: 0.2131 - accuracy: 0.9339\n",
      "Epoch 367: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 655us/step - loss: 0.2145 - accuracy: 0.9334 - val_loss: 0.2298 - val_accuracy: 0.9347\n",
      "Epoch 368/400\n",
      "1367/1433 [===========================>..] - ETA: 0s - loss: 0.2138 - accuracy: 0.9343\n",
      "Epoch 368: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 687us/step - loss: 0.2142 - accuracy: 0.9336 - val_loss: 0.2194 - val_accuracy: 0.9310\n",
      "Epoch 369/400\n",
      "1398/1433 [============================>.] - ETA: 0s - loss: 0.2129 - accuracy: 0.9341\n",
      "Epoch 369: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 714us/step - loss: 0.2141 - accuracy: 0.9338 - val_loss: 0.2122 - val_accuracy: 0.9367\n",
      "Epoch 370/400\n",
      "1380/1433 [===========================>..] - ETA: 0s - loss: 0.2146 - accuracy: 0.9337\n",
      "Epoch 370: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 683us/step - loss: 0.2143 - accuracy: 0.9335 - val_loss: 0.2132 - val_accuracy: 0.9305\n",
      "Epoch 371/400\n",
      "1429/1433 [============================>.] - ETA: 0s - loss: 0.2140 - accuracy: 0.9340\n",
      "Epoch 371: val_loss did not improve from 0.21180\n",
      "1433/1433 [==============================] - 1s 663us/step - loss: 0.2140 - accuracy: 0.9340 - val_loss: 0.2150 - val_accuracy: 0.9370\n",
      "Epoch 372/400\n",
      "1405/1433 [============================>.] - ETA: 0s - loss: 0.2141 - accuracy: 0.9338\n",
      "Epoch 372: val_loss improved from 0.21180 to 0.21157, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 680us/step - loss: 0.2139 - accuracy: 0.9335 - val_loss: 0.2116 - val_accuracy: 0.9337\n",
      "Epoch 373/400\n",
      "1359/1433 [===========================>..] - ETA: 0s - loss: 0.2132 - accuracy: 0.9343\n",
      "Epoch 373: val_loss did not improve from 0.21157\n",
      "1433/1433 [==============================] - 1s 652us/step - loss: 0.2133 - accuracy: 0.9348 - val_loss: 0.2152 - val_accuracy: 0.9436\n",
      "Epoch 374/400\n",
      "1399/1433 [============================>.] - ETA: 0s - loss: 0.2146 - accuracy: 0.9337\n",
      "Epoch 374: val_loss improved from 0.21157 to 0.21146, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 680us/step - loss: 0.2141 - accuracy: 0.9338 - val_loss: 0.2115 - val_accuracy: 0.9357\n",
      "Epoch 375/400\n",
      "1374/1433 [===========================>..] - ETA: 0s - loss: 0.2126 - accuracy: 0.9339\n",
      "Epoch 375: val_loss did not improve from 0.21146\n",
      "1433/1433 [==============================] - 1s 646us/step - loss: 0.2136 - accuracy: 0.9338 - val_loss: 0.2176 - val_accuracy: 0.9335\n",
      "Epoch 376/400\n",
      "1368/1433 [===========================>..] - ETA: 0s - loss: 0.2131 - accuracy: 0.9344\n",
      "Epoch 376: val_loss did not improve from 0.21146\n",
      "1433/1433 [==============================] - 1s 662us/step - loss: 0.2135 - accuracy: 0.9347 - val_loss: 0.2241 - val_accuracy: 0.9300\n",
      "Epoch 377/400\n",
      "1351/1433 [===========================>..] - ETA: 0s - loss: 0.2174 - accuracy: 0.9329\n",
      "Epoch 377: val_loss did not improve from 0.21146\n",
      "1433/1433 [==============================] - 1s 653us/step - loss: 0.2152 - accuracy: 0.9332 - val_loss: 0.2278 - val_accuracy: 0.9310\n",
      "Epoch 378/400\n",
      "1365/1433 [===========================>..] - ETA: 0s - loss: 0.2135 - accuracy: 0.9341\n",
      "Epoch 378: val_loss did not improve from 0.21146\n",
      "1433/1433 [==============================] - 1s 651us/step - loss: 0.2140 - accuracy: 0.9335 - val_loss: 0.2147 - val_accuracy: 0.9313\n",
      "Epoch 379/400\n",
      "1423/1433 [============================>.] - ETA: 0s - loss: 0.2140 - accuracy: 0.9330\n",
      "Epoch 379: val_loss did not improve from 0.21146\n",
      "1433/1433 [==============================] - 1s 662us/step - loss: 0.2146 - accuracy: 0.9331 - val_loss: 0.2127 - val_accuracy: 0.9362\n",
      "Epoch 380/400\n",
      "1382/1433 [===========================>..] - ETA: 0s - loss: 0.2134 - accuracy: 0.9342\n",
      "Epoch 380: val_loss did not improve from 0.21146\n",
      "1433/1433 [==============================] - 1s 650us/step - loss: 0.2142 - accuracy: 0.9336 - val_loss: 0.2131 - val_accuracy: 0.9347\n",
      "Epoch 381/400\n",
      "1421/1433 [============================>.] - ETA: 0s - loss: 0.2146 - accuracy: 0.9332\n",
      "Epoch 381: val_loss improved from 0.21146 to 0.21023, saving model to ENOL3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "1433/1433 [==============================] - 1s 673us/step - loss: 0.2145 - accuracy: 0.9334 - val_loss: 0.2102 - val_accuracy: 0.9392\n",
      "Epoch 382/400\n",
      "1359/1433 [===========================>..] - ETA: 0s - loss: 0.2141 - accuracy: 0.9344\n",
      "Epoch 382: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 651us/step - loss: 0.2134 - accuracy: 0.9345 - val_loss: 0.2108 - val_accuracy: 0.9389\n",
      "Epoch 383/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1409/1433 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9343\n",
      "Epoch 383: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 673us/step - loss: 0.2134 - accuracy: 0.9344 - val_loss: 0.2158 - val_accuracy: 0.9357\n",
      "Epoch 384/400\n",
      "1383/1433 [===========================>..] - ETA: 0s - loss: 0.2138 - accuracy: 0.9336\n",
      "Epoch 384: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 650us/step - loss: 0.2135 - accuracy: 0.9335 - val_loss: 0.2134 - val_accuracy: 0.9305\n",
      "Epoch 385/400\n",
      "1417/1433 [============================>.] - ETA: 0s - loss: 0.2138 - accuracy: 0.9339\n",
      "Epoch 385: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 671us/step - loss: 0.2139 - accuracy: 0.9337 - val_loss: 0.2153 - val_accuracy: 0.9328\n",
      "Epoch 386/400\n",
      "1375/1433 [===========================>..] - ETA: 0s - loss: 0.2144 - accuracy: 0.9337\n",
      "Epoch 386: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 647us/step - loss: 0.2138 - accuracy: 0.9336 - val_loss: 0.2117 - val_accuracy: 0.9422\n",
      "Epoch 387/400\n",
      "1366/1433 [===========================>..] - ETA: 0s - loss: 0.2138 - accuracy: 0.9333\n",
      "Epoch 387: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 651us/step - loss: 0.2133 - accuracy: 0.9338 - val_loss: 0.2137 - val_accuracy: 0.9320\n",
      "Epoch 388/400\n",
      "1417/1433 [============================>.] - ETA: 0s - loss: 0.2129 - accuracy: 0.9334\n",
      "Epoch 388: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 739us/step - loss: 0.2131 - accuracy: 0.9333 - val_loss: 0.2114 - val_accuracy: 0.9414\n",
      "Epoch 389/400\n",
      "1364/1433 [===========================>..] - ETA: 0s - loss: 0.2144 - accuracy: 0.9333\n",
      "Epoch 389: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 651us/step - loss: 0.2135 - accuracy: 0.9334 - val_loss: 0.2131 - val_accuracy: 0.9429\n",
      "Epoch 390/400\n",
      "1415/1433 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9336\n",
      "Epoch 390: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 672us/step - loss: 0.2139 - accuracy: 0.9338 - val_loss: 0.2105 - val_accuracy: 0.9426\n",
      "Epoch 391/400\n",
      "1360/1433 [===========================>..] - ETA: 0s - loss: 0.2125 - accuracy: 0.9342\n",
      "Epoch 391: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 741us/step - loss: 0.2131 - accuracy: 0.9342 - val_loss: 0.2132 - val_accuracy: 0.9357\n",
      "Epoch 392/400\n",
      "1416/1433 [============================>.] - ETA: 0s - loss: 0.2128 - accuracy: 0.9341\n",
      "Epoch 392: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 784us/step - loss: 0.2129 - accuracy: 0.9342 - val_loss: 0.2114 - val_accuracy: 0.9350\n",
      "Epoch 393/400\n",
      "1372/1433 [===========================>..] - ETA: 0s - loss: 0.2139 - accuracy: 0.9333\n",
      "Epoch 393: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 704us/step - loss: 0.2124 - accuracy: 0.9342 - val_loss: 0.2119 - val_accuracy: 0.9333\n",
      "Epoch 394/400\n",
      "1372/1433 [===========================>..] - ETA: 0s - loss: 0.2142 - accuracy: 0.9339\n",
      "Epoch 394: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 813us/step - loss: 0.2133 - accuracy: 0.9339 - val_loss: 0.2146 - val_accuracy: 0.9328\n",
      "Epoch 395/400\n",
      "1399/1433 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9343\n",
      "Epoch 395: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 737us/step - loss: 0.2129 - accuracy: 0.9348 - val_loss: 0.2203 - val_accuracy: 0.9387\n",
      "Epoch 396/400\n",
      "1393/1433 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9358\n",
      "Epoch 396: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 716us/step - loss: 0.2126 - accuracy: 0.9351 - val_loss: 0.2104 - val_accuracy: 0.9328\n",
      "Epoch 397/400\n",
      "1427/1433 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9344\n",
      "Epoch 397: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 704us/step - loss: 0.2132 - accuracy: 0.9345 - val_loss: 0.2125 - val_accuracy: 0.9342\n",
      "Epoch 398/400\n",
      "1375/1433 [===========================>..] - ETA: 0s - loss: 0.2129 - accuracy: 0.9335\n",
      "Epoch 398: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 685us/step - loss: 0.2137 - accuracy: 0.9332 - val_loss: 0.2122 - val_accuracy: 0.9347\n",
      "Epoch 399/400\n",
      "1426/1433 [============================>.] - ETA: 0s - loss: 0.2125 - accuracy: 0.9343\n",
      "Epoch 399: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 663us/step - loss: 0.2125 - accuracy: 0.9342 - val_loss: 0.2107 - val_accuracy: 0.9382\n",
      "Epoch 400/400\n",
      "1400/1433 [============================>.] - ETA: 0s - loss: 0.2130 - accuracy: 0.9345\n",
      "Epoch 400: val_loss did not improve from 0.21023\n",
      "1433/1433 [==============================] - 1s 677us/step - loss: 0.2123 - accuracy: 0.9347 - val_loss: 0.2219 - val_accuracy: 0.9382\n",
      "name weight ENOL3//model/trained_weights_Hn_7smoothdata.mat\n",
      "149/149 [==============================] - 0s 472us/step\n",
      "here\n",
      "Accuracy  : 0.9424127784783523\n",
      "Precision : 0.943192956231019\n",
      "f1Score : 0.9427525778028002\n",
      "[[ 512   47   36]\n",
      " [  60 3480   48]\n",
      " [  47   36  492]]\n",
      "train history is strored in ENOL3/History/history-Hn_7smoothdata.dat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is nonsmoothdata\n",
      "Data file being used is: ENOL3/train_input_nonsmoothdata.csv\n",
      "In load data (32500, 6) (32500,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 49        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73 (584.00 Byte)\n",
      "Trainable params: 73 (584.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "1447/1468 [============================>.] - ETA: 0s - loss: 0.8711 - accuracy: 0.6170\n",
      "Epoch 1: val_loss improved from inf to 0.70442, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 786us/step - loss: 0.8690 - accuracy: 0.6186 - val_loss: 0.7044 - val_accuracy: 0.7826\n",
      "Epoch 2/400\n",
      " 257/1468 [====>.........................] - ETA: 0s - loss: 0.7017 - accuracy: 0.7609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\xai\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1421/1468 [============================>.] - ETA: 0s - loss: 0.5807 - accuracy: 0.7871\n",
      "Epoch 2: val_loss improved from 0.70442 to 0.43742, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 784us/step - loss: 0.5762 - accuracy: 0.7884 - val_loss: 0.4374 - val_accuracy: 0.8279\n",
      "Epoch 3/400\n",
      "1401/1468 [===========================>..] - ETA: 0s - loss: 0.3602 - accuracy: 0.8527\n",
      "Epoch 3: val_loss improved from 0.43742 to 0.28500, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 716us/step - loss: 0.3578 - accuracy: 0.8542 - val_loss: 0.2850 - val_accuracy: 0.9131\n",
      "Epoch 4/400\n",
      "1449/1468 [============================>.] - ETA: 0s - loss: 0.2484 - accuracy: 0.9270\n",
      "Epoch 4: val_loss improved from 0.28500 to 0.21687, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 679us/step - loss: 0.2482 - accuracy: 0.9273 - val_loss: 0.2169 - val_accuracy: 0.9406\n",
      "Epoch 5/400\n",
      "1444/1468 [============================>.] - ETA: 0s - loss: 0.1976 - accuracy: 0.9460\n",
      "Epoch 5: val_loss improved from 0.21687 to 0.18197, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 739us/step - loss: 0.1979 - accuracy: 0.9457 - val_loss: 0.1820 - val_accuracy: 0.9469\n",
      "Epoch 6/400\n",
      "1411/1468 [===========================>..] - ETA: 0s - loss: 0.1684 - accuracy: 0.9529\n",
      "Epoch 6: val_loss improved from 0.18197 to 0.15812, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 761us/step - loss: 0.1688 - accuracy: 0.9526 - val_loss: 0.1581 - val_accuracy: 0.9549\n",
      "Epoch 7/400\n",
      "1403/1468 [===========================>..] - ETA: 0s - loss: 0.1505 - accuracy: 0.9566\n",
      "Epoch 7: val_loss improved from 0.15812 to 0.14370, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 770us/step - loss: 0.1500 - accuracy: 0.9569 - val_loss: 0.1437 - val_accuracy: 0.9578\n",
      "Epoch 8/400\n",
      "1420/1468 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.9597\n",
      "Epoch 8: val_loss improved from 0.14370 to 0.13223, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 730us/step - loss: 0.1370 - accuracy: 0.9598 - val_loss: 0.1322 - val_accuracy: 0.9614\n",
      "Epoch 9/400\n",
      "1462/1468 [============================>.] - ETA: 0s - loss: 0.1272 - accuracy: 0.9615\n",
      "Epoch 9: val_loss improved from 0.13223 to 0.12383, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 777us/step - loss: 0.1271 - accuracy: 0.9615 - val_loss: 0.1238 - val_accuracy: 0.9611\n",
      "Epoch 10/400\n",
      "1427/1468 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9635\n",
      "Epoch 10: val_loss improved from 0.12383 to 0.11898, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 740us/step - loss: 0.1198 - accuracy: 0.9640 - val_loss: 0.1190 - val_accuracy: 0.9611\n",
      "Epoch 11/400\n",
      "1441/1468 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9642\n",
      "Epoch 11: val_loss improved from 0.11898 to 0.11284, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 700us/step - loss: 0.1137 - accuracy: 0.9645 - val_loss: 0.1128 - val_accuracy: 0.9650\n",
      "Epoch 12/400\n",
      "1455/1468 [============================>.] - ETA: 0s - loss: 0.1086 - accuracy: 0.9658\n",
      "Epoch 12: val_loss improved from 0.11284 to 0.10893, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 657us/step - loss: 0.1087 - accuracy: 0.9658 - val_loss: 0.1089 - val_accuracy: 0.9662\n",
      "Epoch 13/400\n",
      "1417/1468 [===========================>..] - ETA: 0s - loss: 0.1049 - accuracy: 0.9669\n",
      "Epoch 13: val_loss improved from 0.10893 to 0.10421, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 713us/step - loss: 0.1046 - accuracy: 0.9669 - val_loss: 0.1042 - val_accuracy: 0.9640\n",
      "Epoch 14/400\n",
      "1410/1468 [===========================>..] - ETA: 0s - loss: 0.1019 - accuracy: 0.9669\n",
      "Epoch 14: val_loss improved from 0.10421 to 0.10213, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 678us/step - loss: 0.1013 - accuracy: 0.9675 - val_loss: 0.1021 - val_accuracy: 0.9633\n",
      "Epoch 15/400\n",
      "1416/1468 [===========================>..] - ETA: 0s - loss: 0.0979 - accuracy: 0.9681\n",
      "Epoch 15: val_loss improved from 0.10213 to 0.09762, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 711us/step - loss: 0.0981 - accuracy: 0.9680 - val_loss: 0.0976 - val_accuracy: 0.9667\n",
      "Epoch 16/400\n",
      "1458/1468 [============================>.] - ETA: 0s - loss: 0.0958 - accuracy: 0.9688\n",
      "Epoch 16: val_loss improved from 0.09762 to 0.09616, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 738us/step - loss: 0.0957 - accuracy: 0.9688 - val_loss: 0.0962 - val_accuracy: 0.9665\n",
      "Epoch 17/400\n",
      "1440/1468 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9692\n",
      "Epoch 17: val_loss improved from 0.09616 to 0.09461, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 847us/step - loss: 0.0931 - accuracy: 0.9692 - val_loss: 0.0946 - val_accuracy: 0.9662\n",
      "Epoch 18/400\n",
      "1430/1468 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 0.9696\n",
      "Epoch 18: val_loss improved from 0.09461 to 0.09295, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 786us/step - loss: 0.0912 - accuracy: 0.9697 - val_loss: 0.0929 - val_accuracy: 0.9679\n",
      "Epoch 19/400\n",
      "1404/1468 [===========================>..] - ETA: 0s - loss: 0.0892 - accuracy: 0.9706\n",
      "Epoch 19: val_loss improved from 0.09295 to 0.09120, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 760us/step - loss: 0.0891 - accuracy: 0.9703 - val_loss: 0.0912 - val_accuracy: 0.9669\n",
      "Epoch 20/400\n",
      "1391/1468 [===========================>..] - ETA: 0s - loss: 0.0876 - accuracy: 0.9702\n",
      "Epoch 20: val_loss improved from 0.09120 to 0.08968, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 728us/step - loss: 0.0873 - accuracy: 0.9702 - val_loss: 0.0897 - val_accuracy: 0.9686\n",
      "Epoch 21/400\n",
      "1391/1468 [===========================>..] - ETA: 0s - loss: 0.0853 - accuracy: 0.9704\n",
      "Epoch 21: val_loss improved from 0.08968 to 0.08681, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 726us/step - loss: 0.0856 - accuracy: 0.9705 - val_loss: 0.0868 - val_accuracy: 0.9681\n",
      "Epoch 22/400\n",
      "1407/1468 [===========================>..] - ETA: 0s - loss: 0.0839 - accuracy: 0.9710\n",
      "Epoch 22: val_loss improved from 0.08681 to 0.08591, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 798us/step - loss: 0.0842 - accuracy: 0.9710 - val_loss: 0.0859 - val_accuracy: 0.9708\n",
      "Epoch 23/400\n",
      "1445/1468 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9719\n",
      "Epoch 23: val_loss improved from 0.08591 to 0.08457, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 698us/step - loss: 0.0829 - accuracy: 0.9719 - val_loss: 0.0846 - val_accuracy: 0.9720\n",
      "Epoch 24/400\n",
      "1440/1468 [============================>.] - ETA: 0s - loss: 0.0814 - accuracy: 0.9715\n",
      "Epoch 24: val_loss improved from 0.08457 to 0.08224, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 747us/step - loss: 0.0813 - accuracy: 0.9717 - val_loss: 0.0822 - val_accuracy: 0.9703\n",
      "Epoch 25/400\n",
      "1421/1468 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 0.9719\n",
      "Epoch 25: val_loss improved from 0.08224 to 0.08191, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468/1468 [==============================] - 1s 782us/step - loss: 0.0804 - accuracy: 0.9721 - val_loss: 0.0819 - val_accuracy: 0.9713\n",
      "Epoch 26/400\n",
      "1426/1468 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 0.9724\n",
      "Epoch 26: val_loss improved from 0.08191 to 0.08173, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 749us/step - loss: 0.0792 - accuracy: 0.9727 - val_loss: 0.0817 - val_accuracy: 0.9696\n",
      "Epoch 27/400\n",
      "1445/1468 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 0.9726\n",
      "Epoch 27: val_loss improved from 0.08173 to 0.07951, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 660us/step - loss: 0.0781 - accuracy: 0.9727 - val_loss: 0.0795 - val_accuracy: 0.9710\n",
      "Epoch 28/400\n",
      "1400/1468 [===========================>..] - ETA: 0s - loss: 0.0771 - accuracy: 0.9739\n",
      "Epoch 28: val_loss improved from 0.07951 to 0.07860, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 678us/step - loss: 0.0771 - accuracy: 0.9739 - val_loss: 0.0786 - val_accuracy: 0.9720\n",
      "Epoch 29/400\n",
      "1440/1468 [============================>.] - ETA: 0s - loss: 0.0760 - accuracy: 0.9740\n",
      "Epoch 29: val_loss improved from 0.07860 to 0.07805, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 666us/step - loss: 0.0762 - accuracy: 0.9738 - val_loss: 0.0781 - val_accuracy: 0.9722\n",
      "Epoch 30/400\n",
      "1422/1468 [============================>.] - ETA: 0s - loss: 0.0753 - accuracy: 0.9743\n",
      "Epoch 30: val_loss improved from 0.07805 to 0.07782, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0751 - accuracy: 0.9746 - val_loss: 0.0778 - val_accuracy: 0.9720\n",
      "Epoch 31/400\n",
      "1452/1468 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9745\n",
      "Epoch 31: val_loss improved from 0.07782 to 0.07601, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 729us/step - loss: 0.0743 - accuracy: 0.9744 - val_loss: 0.0760 - val_accuracy: 0.9737\n",
      "Epoch 32/400\n",
      "1455/1468 [============================>.] - ETA: 0s - loss: 0.0735 - accuracy: 0.9756\n",
      "Epoch 32: val_loss did not improve from 0.07601\n",
      "1468/1468 [==============================] - 1s 663us/step - loss: 0.0735 - accuracy: 0.9756 - val_loss: 0.0760 - val_accuracy: 0.9749\n",
      "Epoch 33/400\n",
      "1411/1468 [===========================>..] - ETA: 0s - loss: 0.0728 - accuracy: 0.9751\n",
      "Epoch 33: val_loss improved from 0.07601 to 0.07389, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 711us/step - loss: 0.0728 - accuracy: 0.9753 - val_loss: 0.0739 - val_accuracy: 0.9747\n",
      "Epoch 34/400\n",
      "1423/1468 [============================>.] - ETA: 0s - loss: 0.0724 - accuracy: 0.9758\n",
      "Epoch 34: val_loss did not improve from 0.07389\n",
      "1468/1468 [==============================] - 1s 737us/step - loss: 0.0721 - accuracy: 0.9760 - val_loss: 0.0746 - val_accuracy: 0.9720\n",
      "Epoch 35/400\n",
      "1388/1468 [===========================>..] - ETA: 0s - loss: 0.0710 - accuracy: 0.9754\n",
      "Epoch 35: val_loss improved from 0.07389 to 0.07285, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 848us/step - loss: 0.0710 - accuracy: 0.9755 - val_loss: 0.0729 - val_accuracy: 0.9778\n",
      "Epoch 36/400\n",
      "1448/1468 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.9758\n",
      "Epoch 36: val_loss improved from 0.07285 to 0.07194, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 851us/step - loss: 0.0707 - accuracy: 0.9758 - val_loss: 0.0719 - val_accuracy: 0.9759\n",
      "Epoch 37/400\n",
      "1457/1468 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9752\n",
      "Epoch 37: val_loss did not improve from 0.07194\n",
      "1468/1468 [==============================] - 1s 853us/step - loss: 0.0701 - accuracy: 0.9753 - val_loss: 0.0724 - val_accuracy: 0.9747\n",
      "Epoch 38/400\n",
      "1449/1468 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9770\n",
      "Epoch 38: val_loss did not improve from 0.07194\n",
      "1468/1468 [==============================] - 1s 864us/step - loss: 0.0688 - accuracy: 0.9771 - val_loss: 0.0721 - val_accuracy: 0.9751\n",
      "Epoch 39/400\n",
      "1442/1468 [============================>.] - ETA: 0s - loss: 0.0688 - accuracy: 0.9761\n",
      "Epoch 39: val_loss improved from 0.07194 to 0.06991, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 740us/step - loss: 0.0690 - accuracy: 0.9761 - val_loss: 0.0699 - val_accuracy: 0.9780\n",
      "Epoch 40/400\n",
      "1441/1468 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9769\n",
      "Epoch 40: val_loss did not improve from 0.06991\n",
      "1468/1468 [==============================] - 1s 871us/step - loss: 0.0680 - accuracy: 0.9768 - val_loss: 0.0703 - val_accuracy: 0.9766\n",
      "Epoch 41/400\n",
      "1445/1468 [============================>.] - ETA: 0s - loss: 0.0675 - accuracy: 0.9772\n",
      "Epoch 41: val_loss improved from 0.06991 to 0.06886, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 778us/step - loss: 0.0675 - accuracy: 0.9771 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
      "Epoch 42/400\n",
      "1435/1468 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 0.9768\n",
      "Epoch 42: val_loss did not improve from 0.06886\n",
      "1468/1468 [==============================] - 1s 737us/step - loss: 0.0667 - accuracy: 0.9766 - val_loss: 0.0691 - val_accuracy: 0.9778\n",
      "Epoch 43/400\n",
      "1430/1468 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 0.9768\n",
      "Epoch 43: val_loss did not improve from 0.06886\n",
      "1468/1468 [==============================] - 1s 737us/step - loss: 0.0664 - accuracy: 0.9770 - val_loss: 0.0697 - val_accuracy: 0.9764\n",
      "Epoch 44/400\n",
      "1420/1468 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9773\n",
      "Epoch 44: val_loss improved from 0.06886 to 0.06755, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 709us/step - loss: 0.0657 - accuracy: 0.9777 - val_loss: 0.0675 - val_accuracy: 0.9754\n",
      "Epoch 45/400\n",
      "1387/1468 [===========================>..] - ETA: 0s - loss: 0.0652 - accuracy: 0.9773\n",
      "Epoch 45: val_loss did not improve from 0.06755\n",
      "1468/1468 [==============================] - 1s 715us/step - loss: 0.0655 - accuracy: 0.9772 - val_loss: 0.0676 - val_accuracy: 0.9788\n",
      "Epoch 46/400\n",
      "1442/1468 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9774\n",
      "Epoch 46: val_loss improved from 0.06755 to 0.06700, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 747us/step - loss: 0.0650 - accuracy: 0.9774 - val_loss: 0.0670 - val_accuracy: 0.9780\n",
      "Epoch 47/400\n",
      "1436/1468 [============================>.] - ETA: 0s - loss: 0.0642 - accuracy: 0.9776\n",
      "Epoch 47: val_loss improved from 0.06700 to 0.06573, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 746us/step - loss: 0.0644 - accuracy: 0.9775 - val_loss: 0.0657 - val_accuracy: 0.9802\n",
      "Epoch 48/400\n",
      "1459/1468 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9776\n",
      "Epoch 48: val_loss improved from 0.06573 to 0.06470, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 706us/step - loss: 0.0642 - accuracy: 0.9775 - val_loss: 0.0647 - val_accuracy: 0.9795\n",
      "Epoch 49/400\n",
      "1451/1468 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9774\n",
      "Epoch 49: val_loss did not improve from 0.06470\n",
      "1468/1468 [==============================] - 1s 722us/step - loss: 0.0635 - accuracy: 0.9775 - val_loss: 0.0660 - val_accuracy: 0.9768\n",
      "Epoch 50/400\n",
      "1407/1468 [===========================>..] - ETA: 0s - loss: 0.0631 - accuracy: 0.9777\n",
      "Epoch 50: val_loss did not improve from 0.06470\n",
      "1468/1468 [==============================] - 1s 677us/step - loss: 0.0630 - accuracy: 0.9777 - val_loss: 0.0652 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/400\n",
      "1461/1468 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9776\n",
      "Epoch 51: val_loss improved from 0.06470 to 0.06346, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 697us/step - loss: 0.0626 - accuracy: 0.9776 - val_loss: 0.0635 - val_accuracy: 0.9785\n",
      "Epoch 52/400\n",
      "1395/1468 [===========================>..] - ETA: 0s - loss: 0.0625 - accuracy: 0.9780\n",
      "Epoch 52: val_loss improved from 0.06346 to 0.06311, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 722us/step - loss: 0.0621 - accuracy: 0.9782 - val_loss: 0.0631 - val_accuracy: 0.9778\n",
      "Epoch 53/400\n",
      "1456/1468 [============================>.] - ETA: 0s - loss: 0.0616 - accuracy: 0.9787\n",
      "Epoch 53: val_loss did not improve from 0.06311\n",
      "1468/1468 [==============================] - 1s 770us/step - loss: 0.0617 - accuracy: 0.9786 - val_loss: 0.0637 - val_accuracy: 0.9792\n",
      "Epoch 54/400\n",
      "1461/1468 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9784\n",
      "Epoch 54: val_loss did not improve from 0.06311\n",
      "1468/1468 [==============================] - 1s 726us/step - loss: 0.0612 - accuracy: 0.9784 - val_loss: 0.0635 - val_accuracy: 0.9795\n",
      "Epoch 55/400\n",
      "1424/1468 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9788\n",
      "Epoch 55: val_loss improved from 0.06311 to 0.06274, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 715us/step - loss: 0.0610 - accuracy: 0.9788 - val_loss: 0.0627 - val_accuracy: 0.9773\n",
      "Epoch 56/400\n",
      "1465/1468 [============================>.] - ETA: 0s - loss: 0.0607 - accuracy: 0.9786\n",
      "Epoch 56: val_loss improved from 0.06274 to 0.06203, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 765us/step - loss: 0.0606 - accuracy: 0.9786 - val_loss: 0.0620 - val_accuracy: 0.9773\n",
      "Epoch 57/400\n",
      "1432/1468 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9789\n",
      "Epoch 57: val_loss improved from 0.06203 to 0.06138, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 740us/step - loss: 0.0598 - accuracy: 0.9789 - val_loss: 0.0614 - val_accuracy: 0.9797\n",
      "Epoch 58/400\n",
      "1447/1468 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9790\n",
      "Epoch 58: val_loss did not improve from 0.06138\n",
      "1468/1468 [==============================] - 1s 728us/step - loss: 0.0597 - accuracy: 0.9791 - val_loss: 0.0619 - val_accuracy: 0.9785\n",
      "Epoch 59/400\n",
      "1451/1468 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9792\n",
      "Epoch 59: val_loss did not improve from 0.06138\n",
      "1468/1468 [==============================] - 1s 728us/step - loss: 0.0594 - accuracy: 0.9792 - val_loss: 0.0626 - val_accuracy: 0.9790\n",
      "Epoch 60/400\n",
      "1468/1468 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9794\n",
      "Epoch 60: val_loss did not improve from 0.06138\n",
      "1468/1468 [==============================] - 1s 723us/step - loss: 0.0590 - accuracy: 0.9794 - val_loss: 0.0617 - val_accuracy: 0.9788\n",
      "Epoch 61/400\n",
      "1465/1468 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9790\n",
      "Epoch 61: val_loss improved from 0.06138 to 0.06000, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 840us/step - loss: 0.0588 - accuracy: 0.9789 - val_loss: 0.0600 - val_accuracy: 0.9807\n",
      "Epoch 62/400\n",
      "1434/1468 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9800\n",
      "Epoch 62: val_loss improved from 0.06000 to 0.05926, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 780us/step - loss: 0.0583 - accuracy: 0.9800 - val_loss: 0.0593 - val_accuracy: 0.9785\n",
      "Epoch 63/400\n",
      "1429/1468 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9798\n",
      "Epoch 63: val_loss did not improve from 0.05926\n",
      "1468/1468 [==============================] - 1s 775us/step - loss: 0.0578 - accuracy: 0.9796 - val_loss: 0.0607 - val_accuracy: 0.9783\n",
      "Epoch 64/400\n",
      "1449/1468 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9797\n",
      "Epoch 64: val_loss improved from 0.05926 to 0.05867, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 706us/step - loss: 0.0576 - accuracy: 0.9797 - val_loss: 0.0587 - val_accuracy: 0.9800\n",
      "Epoch 65/400\n",
      "1388/1468 [===========================>..] - ETA: 0s - loss: 0.0577 - accuracy: 0.9802\n",
      "Epoch 65: val_loss did not improve from 0.05867\n",
      "1468/1468 [==============================] - 1s 718us/step - loss: 0.0573 - accuracy: 0.9804 - val_loss: 0.0592 - val_accuracy: 0.9778\n",
      "Epoch 66/400\n",
      "1408/1468 [===========================>..] - ETA: 0s - loss: 0.0567 - accuracy: 0.9803\n",
      "Epoch 66: val_loss did not improve from 0.05867\n",
      "1468/1468 [==============================] - 1s 715us/step - loss: 0.0568 - accuracy: 0.9802 - val_loss: 0.0587 - val_accuracy: 0.9790\n",
      "Epoch 67/400\n",
      "1445/1468 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9803\n",
      "Epoch 67: val_loss improved from 0.05867 to 0.05772, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 741us/step - loss: 0.0569 - accuracy: 0.9803 - val_loss: 0.0577 - val_accuracy: 0.9788\n",
      "Epoch 68/400\n",
      "1454/1468 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 0.9798\n",
      "Epoch 68: val_loss did not improve from 0.05772\n",
      "1468/1468 [==============================] - 1s 774us/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 0.0589 - val_accuracy: 0.9795\n",
      "Epoch 69/400\n",
      "1445/1468 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9798\n",
      "Epoch 69: val_loss improved from 0.05772 to 0.05752, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 778us/step - loss: 0.0561 - accuracy: 0.9799 - val_loss: 0.0575 - val_accuracy: 0.9800\n",
      "Epoch 70/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9803\n",
      "Epoch 70: val_loss did not improve from 0.05752\n",
      "1468/1468 [==============================] - 1s 799us/step - loss: 0.0553 - accuracy: 0.9803 - val_loss: 0.0592 - val_accuracy: 0.9800\n",
      "Epoch 71/400\n",
      "1398/1468 [===========================>..] - ETA: 0s - loss: 0.0553 - accuracy: 0.9805\n",
      "Epoch 71: val_loss did not improve from 0.05752\n",
      "1468/1468 [==============================] - 1s 706us/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 0.0579 - val_accuracy: 0.9812\n",
      "Epoch 72/400\n",
      "1426/1468 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 0.9804\n",
      "Epoch 72: val_loss improved from 0.05752 to 0.05710, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 758us/step - loss: 0.0551 - accuracy: 0.9802 - val_loss: 0.0571 - val_accuracy: 0.9797\n",
      "Epoch 73/400\n",
      "1468/1468 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9806\n",
      "Epoch 73: val_loss did not improve from 0.05710\n",
      "1468/1468 [==============================] - 1s 759us/step - loss: 0.0548 - accuracy: 0.9806 - val_loss: 0.0583 - val_accuracy: 0.9792\n",
      "Epoch 74/400\n",
      "1453/1468 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 0.9804\n",
      "Epoch 74: val_loss did not improve from 0.05710\n",
      "1468/1468 [==============================] - 1s 770us/step - loss: 0.0546 - accuracy: 0.9804 - val_loss: 0.0571 - val_accuracy: 0.9807\n",
      "Epoch 75/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9806\n",
      "Epoch 75: val_loss did not improve from 0.05710\n",
      "1468/1468 [==============================] - 1s 792us/step - loss: 0.0547 - accuracy: 0.9807 - val_loss: 0.0572 - val_accuracy: 0.9800\n",
      "Epoch 76/400\n",
      "1407/1468 [===========================>..] - ETA: 0s - loss: 0.0542 - accuracy: 0.9809\n",
      "Epoch 76: val_loss did not improve from 0.05710\n",
      "1468/1468 [==============================] - 1s 749us/step - loss: 0.0542 - accuracy: 0.9809 - val_loss: 0.0573 - val_accuracy: 0.9797\n",
      "Epoch 77/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445/1468 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9810\n",
      "Epoch 77: val_loss improved from 0.05710 to 0.05409, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 751us/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0541 - val_accuracy: 0.9812\n",
      "Epoch 78/400\n",
      "1460/1468 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9813\n",
      "Epoch 78: val_loss did not improve from 0.05409\n",
      "1468/1468 [==============================] - 1s 760us/step - loss: 0.0537 - accuracy: 0.9813 - val_loss: 0.0552 - val_accuracy: 0.9814\n",
      "Epoch 79/400\n",
      "1420/1468 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9813\n",
      "Epoch 79: val_loss did not improve from 0.05409\n",
      "1468/1468 [==============================] - 1s 705us/step - loss: 0.0534 - accuracy: 0.9811 - val_loss: 0.0544 - val_accuracy: 0.9817\n",
      "Epoch 80/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9809\n",
      "Epoch 80: val_loss improved from 0.05409 to 0.05303, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 729us/step - loss: 0.0531 - accuracy: 0.9809 - val_loss: 0.0530 - val_accuracy: 0.9824\n",
      "Epoch 81/400\n",
      "1427/1468 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9814\n",
      "Epoch 81: val_loss did not improve from 0.05303\n",
      "1468/1468 [==============================] - 1s 699us/step - loss: 0.0529 - accuracy: 0.9813 - val_loss: 0.0556 - val_accuracy: 0.9800\n",
      "Epoch 82/400\n",
      "1459/1468 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9814\n",
      "Epoch 82: val_loss did not improve from 0.05303\n",
      "1468/1468 [==============================] - 1s 717us/step - loss: 0.0526 - accuracy: 0.9814 - val_loss: 0.0557 - val_accuracy: 0.9821\n",
      "Epoch 83/400\n",
      "1466/1468 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9818\n",
      "Epoch 83: val_loss did not improve from 0.05303\n",
      "1468/1468 [==============================] - 1s 736us/step - loss: 0.0526 - accuracy: 0.9819 - val_loss: 0.0539 - val_accuracy: 0.9812\n",
      "Epoch 84/400\n",
      "1436/1468 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9815\n",
      "Epoch 84: val_loss did not improve from 0.05303\n",
      "1468/1468 [==============================] - 1s 737us/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.0543 - val_accuracy: 0.9795\n",
      "Epoch 85/400\n",
      "1415/1468 [===========================>..] - ETA: 0s - loss: 0.0520 - accuracy: 0.9811\n",
      "Epoch 85: val_loss did not improve from 0.05303\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0521 - accuracy: 0.9812 - val_loss: 0.0537 - val_accuracy: 0.9807\n",
      "Epoch 86/400\n",
      "1398/1468 [===========================>..] - ETA: 0s - loss: 0.0516 - accuracy: 0.9821\n",
      "Epoch 86: val_loss did not improve from 0.05303\n",
      "1468/1468 [==============================] - 1s 749us/step - loss: 0.0518 - accuracy: 0.9819 - val_loss: 0.0537 - val_accuracy: 0.9826\n",
      "Epoch 87/400\n",
      "1423/1468 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9819\n",
      "Epoch 87: val_loss improved from 0.05303 to 0.05181, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 708us/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.0518 - val_accuracy: 0.9824\n",
      "Epoch 88/400\n",
      "1406/1468 [===========================>..] - ETA: 0s - loss: 0.0510 - accuracy: 0.9824\n",
      "Epoch 88: val_loss did not improve from 0.05181\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0513 - accuracy: 0.9822 - val_loss: 0.0544 - val_accuracy: 0.9814\n",
      "Epoch 89/400\n",
      "1423/1468 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9819\n",
      "Epoch 89: val_loss did not improve from 0.05181\n",
      "1468/1468 [==============================] - 1s 695us/step - loss: 0.0513 - accuracy: 0.9821 - val_loss: 0.0529 - val_accuracy: 0.9807\n",
      "Epoch 90/400\n",
      "1398/1468 [===========================>..] - ETA: 0s - loss: 0.0508 - accuracy: 0.9826\n",
      "Epoch 90: val_loss improved from 0.05181 to 0.05178, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 746us/step - loss: 0.0512 - accuracy: 0.9824 - val_loss: 0.0518 - val_accuracy: 0.9812\n",
      "Epoch 91/400\n",
      "1430/1468 [============================>.] - ETA: 0s - loss: 0.0507 - accuracy: 0.9819\n",
      "Epoch 91: val_loss did not improve from 0.05178\n",
      "1468/1468 [==============================] - 1s 661us/step - loss: 0.0511 - accuracy: 0.9818 - val_loss: 0.0523 - val_accuracy: 0.9819\n",
      "Epoch 92/400\n",
      "1402/1468 [===========================>..] - ETA: 0s - loss: 0.0501 - accuracy: 0.9827\n",
      "Epoch 92: val_loss did not improve from 0.05178\n",
      "1468/1468 [==============================] - 1s 678us/step - loss: 0.0505 - accuracy: 0.9828 - val_loss: 0.0536 - val_accuracy: 0.9814\n",
      "Epoch 93/400\n",
      "1455/1468 [============================>.] - ETA: 0s - loss: 0.0507 - accuracy: 0.9826\n",
      "Epoch 93: val_loss improved from 0.05178 to 0.05006, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 656us/step - loss: 0.0507 - accuracy: 0.9825 - val_loss: 0.0501 - val_accuracy: 0.9833\n",
      "Epoch 94/400\n",
      "1429/1468 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9825\n",
      "Epoch 94: val_loss did not improve from 0.05006\n",
      "1468/1468 [==============================] - 1s 769us/step - loss: 0.0500 - accuracy: 0.9825 - val_loss: 0.0533 - val_accuracy: 0.9819\n",
      "Epoch 95/400\n",
      "1467/1468 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9819\n",
      "Epoch 95: val_loss did not improve from 0.05006\n",
      "1468/1468 [==============================] - 1s 681us/step - loss: 0.0499 - accuracy: 0.9819 - val_loss: 0.0504 - val_accuracy: 0.9829\n",
      "Epoch 96/400\n",
      "1422/1468 [============================>.] - ETA: 0s - loss: 0.0498 - accuracy: 0.9830\n",
      "Epoch 96: val_loss did not improve from 0.05006\n",
      "1468/1468 [==============================] - 1s 706us/step - loss: 0.0499 - accuracy: 0.9828 - val_loss: 0.0512 - val_accuracy: 0.9836\n",
      "Epoch 97/400\n",
      "1430/1468 [============================>.] - ETA: 0s - loss: 0.0498 - accuracy: 0.9824\n",
      "Epoch 97: val_loss did not improve from 0.05006\n",
      "1468/1468 [==============================] - 1s 701us/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 0.0514 - val_accuracy: 0.9821\n",
      "Epoch 98/400\n",
      "1422/1468 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9826\n",
      "Epoch 98: val_loss did not improve from 0.05006\n",
      "1468/1468 [==============================] - 1s 697us/step - loss: 0.0495 - accuracy: 0.9826 - val_loss: 0.0517 - val_accuracy: 0.9824\n",
      "Epoch 99/400\n",
      "1462/1468 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9829\n",
      "Epoch 99: val_loss did not improve from 0.05006\n",
      "1468/1468 [==============================] - 1s 683us/step - loss: 0.0496 - accuracy: 0.9829 - val_loss: 0.0508 - val_accuracy: 0.9824\n",
      "Epoch 100/400\n",
      "1456/1468 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9828\n",
      "Epoch 100: val_loss improved from 0.05006 to 0.04956, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 693us/step - loss: 0.0492 - accuracy: 0.9828 - val_loss: 0.0496 - val_accuracy: 0.9826\n",
      "Epoch 101/400\n",
      "1420/1468 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9823\n",
      "Epoch 101: val_loss did not improve from 0.04956\n",
      "1468/1468 [==============================] - 1s 663us/step - loss: 0.0490 - accuracy: 0.9824 - val_loss: 0.0522 - val_accuracy: 0.9821\n",
      "Epoch 102/400\n",
      "1391/1468 [===========================>..] - ETA: 0s - loss: 0.0494 - accuracy: 0.9821\n",
      "Epoch 102: val_loss did not improve from 0.04956\n",
      "1468/1468 [==============================] - 1s 673us/step - loss: 0.0489 - accuracy: 0.9824 - val_loss: 0.0519 - val_accuracy: 0.9807\n",
      "Epoch 103/400\n",
      "1455/1468 [============================>.] - ETA: 0s - loss: 0.0487 - accuracy: 0.9829\n",
      "Epoch 103: val_loss improved from 0.04956 to 0.04880, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 662us/step - loss: 0.0489 - accuracy: 0.9829 - val_loss: 0.0488 - val_accuracy: 0.9831\n",
      "Epoch 104/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1442/1468 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9833\n",
      "Epoch 104: val_loss did not improve from 0.04880\n",
      "1468/1468 [==============================] - 1s 690us/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 0.0520 - val_accuracy: 0.9814\n",
      "Epoch 105/400\n",
      "1444/1468 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9826\n",
      "Epoch 105: val_loss did not improve from 0.04880\n",
      "1468/1468 [==============================] - 1s 658us/step - loss: 0.0486 - accuracy: 0.9827 - val_loss: 0.0508 - val_accuracy: 0.9824\n",
      "Epoch 106/400\n",
      "1376/1468 [===========================>..] - ETA: 0s - loss: 0.0484 - accuracy: 0.9826\n",
      "Epoch 106: val_loss improved from 0.04880 to 0.04857, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 707us/step - loss: 0.0484 - accuracy: 0.9826 - val_loss: 0.0486 - val_accuracy: 0.9829\n",
      "Epoch 107/400\n",
      "1443/1468 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9825\n",
      "Epoch 107: val_loss did not improve from 0.04857\n",
      "1468/1468 [==============================] - 1s 687us/step - loss: 0.0480 - accuracy: 0.9827 - val_loss: 0.0498 - val_accuracy: 0.9826\n",
      "Epoch 108/400\n",
      "1440/1468 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9832\n",
      "Epoch 108: val_loss did not improve from 0.04857\n",
      "1468/1468 [==============================] - 1s 659us/step - loss: 0.0477 - accuracy: 0.9832 - val_loss: 0.0490 - val_accuracy: 0.9848\n",
      "Epoch 109/400\n",
      "1461/1468 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9826\n",
      "Epoch 109: val_loss did not improve from 0.04857\n",
      "1468/1468 [==============================] - 1s 691us/step - loss: 0.0479 - accuracy: 0.9826 - val_loss: 0.0489 - val_accuracy: 0.9841\n",
      "Epoch 110/400\n",
      "1431/1468 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9835\n",
      "Epoch 110: val_loss did not improve from 0.04857\n",
      "1468/1468 [==============================] - 1s 691us/step - loss: 0.0475 - accuracy: 0.9834 - val_loss: 0.0486 - val_accuracy: 0.9838\n",
      "Epoch 111/400\n",
      "1445/1468 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9832\n",
      "Epoch 111: val_loss did not improve from 0.04857\n",
      "1468/1468 [==============================] - 1s 730us/step - loss: 0.0475 - accuracy: 0.9833 - val_loss: 0.0495 - val_accuracy: 0.9819\n",
      "Epoch 112/400\n",
      "1466/1468 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9830\n",
      "Epoch 112: val_loss did not improve from 0.04857\n",
      "1468/1468 [==============================] - 1s 681us/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 0.0494 - val_accuracy: 0.9824\n",
      "Epoch 113/400\n",
      "1455/1468 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9834\n",
      "Epoch 113: val_loss did not improve from 0.04857\n",
      "1468/1468 [==============================] - 1s 762us/step - loss: 0.0470 - accuracy: 0.9835 - val_loss: 0.0487 - val_accuracy: 0.9821\n",
      "Epoch 114/400\n",
      "1405/1468 [===========================>..] - ETA: 0s - loss: 0.0467 - accuracy: 0.9832\n",
      "Epoch 114: val_loss improved from 0.04857 to 0.04764, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 739us/step - loss: 0.0471 - accuracy: 0.9832 - val_loss: 0.0476 - val_accuracy: 0.9836\n",
      "Epoch 115/400\n",
      "1453/1468 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9832\n",
      "Epoch 115: val_loss improved from 0.04764 to 0.04709, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 730us/step - loss: 0.0472 - accuracy: 0.9833 - val_loss: 0.0471 - val_accuracy: 0.9846\n",
      "Epoch 116/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9835\n",
      "Epoch 116: val_loss did not improve from 0.04709\n",
      "1468/1468 [==============================] - 1s 664us/step - loss: 0.0469 - accuracy: 0.9834 - val_loss: 0.0476 - val_accuracy: 0.9831\n",
      "Epoch 117/400\n",
      "1413/1468 [===========================>..] - ETA: 0s - loss: 0.0461 - accuracy: 0.9840\n",
      "Epoch 117: val_loss did not improve from 0.04709\n",
      "1468/1468 [==============================] - 1s 701us/step - loss: 0.0466 - accuracy: 0.9836 - val_loss: 0.0497 - val_accuracy: 0.9831\n",
      "Epoch 118/400\n",
      "1407/1468 [===========================>..] - ETA: 0s - loss: 0.0466 - accuracy: 0.9837\n",
      "Epoch 118: val_loss did not improve from 0.04709\n",
      "1468/1468 [==============================] - 1s 720us/step - loss: 0.0467 - accuracy: 0.9836 - val_loss: 0.0482 - val_accuracy: 0.9817\n",
      "Epoch 119/400\n",
      "1433/1468 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9835\n",
      "Epoch 119: val_loss did not improve from 0.04709\n",
      "1468/1468 [==============================] - 1s 765us/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.0489 - val_accuracy: 0.9826\n",
      "Epoch 120/400\n",
      "1431/1468 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9832\n",
      "Epoch 120: val_loss improved from 0.04709 to 0.04640, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 686us/step - loss: 0.0465 - accuracy: 0.9833 - val_loss: 0.0464 - val_accuracy: 0.9836\n",
      "Epoch 121/400\n",
      "1419/1468 [===========================>..] - ETA: 0s - loss: 0.0461 - accuracy: 0.9834\n",
      "Epoch 121: val_loss improved from 0.04640 to 0.04615, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 713us/step - loss: 0.0462 - accuracy: 0.9833 - val_loss: 0.0462 - val_accuracy: 0.9843\n",
      "Epoch 122/400\n",
      "1445/1468 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9833\n",
      "Epoch 122: val_loss did not improve from 0.04615\n",
      "1468/1468 [==============================] - 1s 706us/step - loss: 0.0459 - accuracy: 0.9834 - val_loss: 0.0471 - val_accuracy: 0.9821\n",
      "Epoch 123/400\n",
      "1404/1468 [===========================>..] - ETA: 0s - loss: 0.0457 - accuracy: 0.9838\n",
      "Epoch 123: val_loss did not improve from 0.04615\n",
      "1468/1468 [==============================] - 1s 708us/step - loss: 0.0457 - accuracy: 0.9838 - val_loss: 0.0494 - val_accuracy: 0.9829\n",
      "Epoch 124/400\n",
      "1468/1468 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9834\n",
      "Epoch 124: val_loss did not improve from 0.04615\n",
      "1468/1468 [==============================] - 1s 677us/step - loss: 0.0459 - accuracy: 0.9834 - val_loss: 0.0474 - val_accuracy: 0.9821\n",
      "Epoch 125/400\n",
      "1390/1468 [===========================>..] - ETA: 0s - loss: 0.0456 - accuracy: 0.9835\n",
      "Epoch 125: val_loss did not improve from 0.04615\n",
      "1468/1468 [==============================] - 1s 679us/step - loss: 0.0456 - accuracy: 0.9837 - val_loss: 0.0478 - val_accuracy: 0.9819\n",
      "Epoch 126/400\n",
      "1393/1468 [===========================>..] - ETA: 0s - loss: 0.0455 - accuracy: 0.9839\n",
      "Epoch 126: val_loss did not improve from 0.04615\n",
      "1468/1468 [==============================] - 1s 673us/step - loss: 0.0455 - accuracy: 0.9837 - val_loss: 0.0473 - val_accuracy: 0.9829\n",
      "Epoch 127/400\n",
      "1455/1468 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9839\n",
      "Epoch 127: val_loss improved from 0.04615 to 0.04512, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 735us/step - loss: 0.0451 - accuracy: 0.9839 - val_loss: 0.0451 - val_accuracy: 0.9846\n",
      "Epoch 128/400\n",
      "1393/1468 [===========================>..] - ETA: 0s - loss: 0.0457 - accuracy: 0.9835\n",
      "Epoch 128: val_loss did not improve from 0.04512\n",
      "1468/1468 [==============================] - 1s 678us/step - loss: 0.0454 - accuracy: 0.9837 - val_loss: 0.0470 - val_accuracy: 0.9831\n",
      "Epoch 129/400\n",
      "1413/1468 [===========================>..] - ETA: 0s - loss: 0.0446 - accuracy: 0.9847\n",
      "Epoch 129: val_loss did not improve from 0.04512\n",
      "1468/1468 [==============================] - 1s 704us/step - loss: 0.0446 - accuracy: 0.9846 - val_loss: 0.0490 - val_accuracy: 0.9829\n",
      "Epoch 130/400\n",
      "1448/1468 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9838\n",
      "Epoch 130: val_loss did not improve from 0.04512\n",
      "1468/1468 [==============================] - 1s 697us/step - loss: 0.0450 - accuracy: 0.9838 - val_loss: 0.0468 - val_accuracy: 0.9831\n",
      "Epoch 131/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1384/1468 [===========================>..] - ETA: 0s - loss: 0.0448 - accuracy: 0.9842\n",
      "Epoch 131: val_loss did not improve from 0.04512\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0448 - accuracy: 0.9842 - val_loss: 0.0475 - val_accuracy: 0.9833\n",
      "Epoch 132/400\n",
      "1448/1468 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9843\n",
      "Epoch 132: val_loss did not improve from 0.04512\n",
      "1468/1468 [==============================] - 1s 687us/step - loss: 0.0448 - accuracy: 0.9844 - val_loss: 0.0465 - val_accuracy: 0.9848\n",
      "Epoch 133/400\n",
      "1464/1468 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9839\n",
      "Epoch 133: val_loss did not improve from 0.04512\n",
      "1468/1468 [==============================] - 1s 681us/step - loss: 0.0447 - accuracy: 0.9839 - val_loss: 0.0472 - val_accuracy: 0.9838\n",
      "Epoch 134/400\n",
      "1411/1468 [===========================>..] - ETA: 0s - loss: 0.0446 - accuracy: 0.9838\n",
      "Epoch 134: val_loss did not improve from 0.04512\n",
      "1468/1468 [==============================] - 1s 672us/step - loss: 0.0446 - accuracy: 0.9839 - val_loss: 0.0490 - val_accuracy: 0.9829\n",
      "Epoch 135/400\n",
      "1413/1468 [===========================>..] - ETA: 0s - loss: 0.0445 - accuracy: 0.9841\n",
      "Epoch 135: val_loss did not improve from 0.04512\n",
      "1468/1468 [==============================] - 1s 705us/step - loss: 0.0443 - accuracy: 0.9842 - val_loss: 0.0479 - val_accuracy: 0.9814\n",
      "Epoch 136/400\n",
      "1465/1468 [============================>.] - ETA: 0s - loss: 0.0444 - accuracy: 0.9839\n",
      "Epoch 136: val_loss did not improve from 0.04512\n",
      "1468/1468 [==============================] - 1s 686us/step - loss: 0.0444 - accuracy: 0.9839 - val_loss: 0.0464 - val_accuracy: 0.9843\n",
      "Epoch 137/400\n",
      "1428/1468 [============================>.] - ETA: 0s - loss: 0.0444 - accuracy: 0.9844\n",
      "Epoch 137: val_loss improved from 0.04512 to 0.04454, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0440 - accuracy: 0.9847 - val_loss: 0.0445 - val_accuracy: 0.9838\n",
      "Epoch 138/400\n",
      "1455/1468 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9836\n",
      "Epoch 138: val_loss did not improve from 0.04454\n",
      "1468/1468 [==============================] - 1s 690us/step - loss: 0.0441 - accuracy: 0.9837 - val_loss: 0.0454 - val_accuracy: 0.9838\n",
      "Epoch 139/400\n",
      "1410/1468 [===========================>..] - ETA: 0s - loss: 0.0445 - accuracy: 0.9840\n",
      "Epoch 139: val_loss did not improve from 0.04454\n",
      "1468/1468 [==============================] - 1s 723us/step - loss: 0.0443 - accuracy: 0.9840 - val_loss: 0.0461 - val_accuracy: 0.9826\n",
      "Epoch 140/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9836\n",
      "Epoch 140: val_loss did not improve from 0.04454\n",
      "1468/1468 [==============================] - 1s 709us/step - loss: 0.0440 - accuracy: 0.9837 - val_loss: 0.0463 - val_accuracy: 0.9843\n",
      "Epoch 141/400\n",
      "1462/1468 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9844\n",
      "Epoch 141: val_loss did not improve from 0.04454\n",
      "1468/1468 [==============================] - 1s 735us/step - loss: 0.0438 - accuracy: 0.9844 - val_loss: 0.0459 - val_accuracy: 0.9833\n",
      "Epoch 142/400\n",
      "1400/1468 [===========================>..] - ETA: 0s - loss: 0.0436 - accuracy: 0.9844\n",
      "Epoch 142: val_loss improved from 0.04454 to 0.04400, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 726us/step - loss: 0.0436 - accuracy: 0.9844 - val_loss: 0.0440 - val_accuracy: 0.9843\n",
      "Epoch 143/400\n",
      "1458/1468 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9842\n",
      "Epoch 143: val_loss did not improve from 0.04400\n",
      "1468/1468 [==============================] - 1s 726us/step - loss: 0.0434 - accuracy: 0.9843 - val_loss: 0.0452 - val_accuracy: 0.9843\n",
      "Epoch 144/400\n",
      "1400/1468 [===========================>..] - ETA: 0s - loss: 0.0438 - accuracy: 0.9842\n",
      "Epoch 144: val_loss did not improve from 0.04400\n",
      "1468/1468 [==============================] - 1s 714us/step - loss: 0.0436 - accuracy: 0.9843 - val_loss: 0.0455 - val_accuracy: 0.9841\n",
      "Epoch 145/400\n",
      "1410/1468 [===========================>..] - ETA: 0s - loss: 0.0433 - accuracy: 0.9844\n",
      "Epoch 145: val_loss did not improve from 0.04400\n",
      "1468/1468 [==============================] - 1s 754us/step - loss: 0.0435 - accuracy: 0.9843 - val_loss: 0.0469 - val_accuracy: 0.9838\n",
      "Epoch 146/400\n",
      "1404/1468 [===========================>..] - ETA: 0s - loss: 0.0435 - accuracy: 0.9847\n",
      "Epoch 146: val_loss did not improve from 0.04400\n",
      "1468/1468 [==============================] - 1s 708us/step - loss: 0.0433 - accuracy: 0.9848 - val_loss: 0.0461 - val_accuracy: 0.9838\n",
      "Epoch 147/400\n",
      "1391/1468 [===========================>..] - ETA: 0s - loss: 0.0432 - accuracy: 0.9846\n",
      "Epoch 147: val_loss improved from 0.04400 to 0.04389, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 729us/step - loss: 0.0429 - accuracy: 0.9846 - val_loss: 0.0439 - val_accuracy: 0.9860\n",
      "Epoch 148/400\n",
      "1421/1468 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9848\n",
      "Epoch 148: val_loss did not improve from 0.04389\n",
      "1468/1468 [==============================] - 1s 702us/step - loss: 0.0434 - accuracy: 0.9848 - val_loss: 0.0449 - val_accuracy: 0.9850\n",
      "Epoch 149/400\n",
      "1430/1468 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9846\n",
      "Epoch 149: val_loss did not improve from 0.04389\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0430 - accuracy: 0.9849 - val_loss: 0.0454 - val_accuracy: 0.9836\n",
      "Epoch 150/400\n",
      "1458/1468 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9844\n",
      "Epoch 150: val_loss did not improve from 0.04389\n",
      "1468/1468 [==============================] - 1s 685us/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.0450 - val_accuracy: 0.9850\n",
      "Epoch 151/400\n",
      "1384/1468 [===========================>..] - ETA: 0s - loss: 0.0430 - accuracy: 0.9838\n",
      "Epoch 151: val_loss did not improve from 0.04389\n",
      "1468/1468 [==============================] - 1s 715us/step - loss: 0.0429 - accuracy: 0.9839 - val_loss: 0.0455 - val_accuracy: 0.9821\n",
      "Epoch 152/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9844\n",
      "Epoch 152: val_loss did not improve from 0.04389\n",
      "1468/1468 [==============================] - 1s 703us/step - loss: 0.0428 - accuracy: 0.9844 - val_loss: 0.0461 - val_accuracy: 0.9855\n",
      "Epoch 153/400\n",
      "1429/1468 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9845\n",
      "Epoch 153: val_loss did not improve from 0.04389\n",
      "1468/1468 [==============================] - 1s 739us/step - loss: 0.0426 - accuracy: 0.9847 - val_loss: 0.0452 - val_accuracy: 0.9836\n",
      "Epoch 154/400\n",
      "1423/1468 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9854\n",
      "Epoch 154: val_loss did not improve from 0.04389\n",
      "1468/1468 [==============================] - 1s 705us/step - loss: 0.0422 - accuracy: 0.9853 - val_loss: 0.0442 - val_accuracy: 0.9841\n",
      "Epoch 155/400\n",
      "1456/1468 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9848\n",
      "Epoch 155: val_loss did not improve from 0.04389\n",
      "1468/1468 [==============================] - 1s 723us/step - loss: 0.0424 - accuracy: 0.9848 - val_loss: 0.0454 - val_accuracy: 0.9841\n",
      "Epoch 156/400\n",
      "1410/1468 [===========================>..] - ETA: 0s - loss: 0.0426 - accuracy: 0.9847\n",
      "Epoch 156: val_loss did not improve from 0.04389\n",
      "1468/1468 [==============================] - 1s 707us/step - loss: 0.0426 - accuracy: 0.9847 - val_loss: 0.0442 - val_accuracy: 0.9841\n",
      "Epoch 157/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0421 - accuracy: 0.9848\n",
      "Epoch 157: val_loss did not improve from 0.04389\n",
      "1468/1468 [==============================] - 1s 718us/step - loss: 0.0422 - accuracy: 0.9848 - val_loss: 0.0439 - val_accuracy: 0.9836\n",
      "Epoch 158/400\n",
      "1421/1468 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9847\n",
      "Epoch 158: val_loss improved from 0.04389 to 0.04348, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 709us/step - loss: 0.0421 - accuracy: 0.9848 - val_loss: 0.0435 - val_accuracy: 0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/400\n",
      "1424/1468 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9846\n",
      "Epoch 159: val_loss did not improve from 0.04348\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0419 - accuracy: 0.9845 - val_loss: 0.0439 - val_accuracy: 0.9831\n",
      "Epoch 160/400\n",
      "1388/1468 [===========================>..] - ETA: 0s - loss: 0.0423 - accuracy: 0.9846\n",
      "Epoch 160: val_loss did not improve from 0.04348\n",
      "1468/1468 [==============================] - 1s 679us/step - loss: 0.0419 - accuracy: 0.9848 - val_loss: 0.0459 - val_accuracy: 0.9824\n",
      "Epoch 161/400\n",
      "1444/1468 [============================>.] - ETA: 0s - loss: 0.0416 - accuracy: 0.9846\n",
      "Epoch 161: val_loss did not improve from 0.04348\n",
      "1468/1468 [==============================] - 1s 691us/step - loss: 0.0419 - accuracy: 0.9845 - val_loss: 0.0436 - val_accuracy: 0.9829\n",
      "Epoch 162/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9850\n",
      "Epoch 162: val_loss improved from 0.04348 to 0.04287, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 705us/step - loss: 0.0418 - accuracy: 0.9849 - val_loss: 0.0429 - val_accuracy: 0.9855\n",
      "Epoch 163/400\n",
      "1419/1468 [===========================>..] - ETA: 0s - loss: 0.0417 - accuracy: 0.9854\n",
      "Epoch 163: val_loss did not improve from 0.04287\n",
      "1468/1468 [==============================] - 1s 704us/step - loss: 0.0416 - accuracy: 0.9853 - val_loss: 0.0437 - val_accuracy: 0.9850\n",
      "Epoch 164/400\n",
      "1412/1468 [===========================>..] - ETA: 0s - loss: 0.0415 - accuracy: 0.9854\n",
      "Epoch 164: val_loss improved from 0.04287 to 0.04214, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 719us/step - loss: 0.0415 - accuracy: 0.9855 - val_loss: 0.0421 - val_accuracy: 0.9846\n",
      "Epoch 165/400\n",
      "1408/1468 [===========================>..] - ETA: 0s - loss: 0.0414 - accuracy: 0.9852\n",
      "Epoch 165: val_loss did not improve from 0.04214\n",
      "1468/1468 [==============================] - 1s 711us/step - loss: 0.0414 - accuracy: 0.9851 - val_loss: 0.0439 - val_accuracy: 0.9843\n",
      "Epoch 166/400\n",
      "1455/1468 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9851\n",
      "Epoch 166: val_loss did not improve from 0.04214\n",
      "1468/1468 [==============================] - 1s 687us/step - loss: 0.0414 - accuracy: 0.9851 - val_loss: 0.0442 - val_accuracy: 0.9853\n",
      "Epoch 167/400\n",
      "1414/1468 [===========================>..] - ETA: 0s - loss: 0.0420 - accuracy: 0.9848\n",
      "Epoch 167: val_loss did not improve from 0.04214\n",
      "1468/1468 [==============================] - 1s 702us/step - loss: 0.0415 - accuracy: 0.9852 - val_loss: 0.0435 - val_accuracy: 0.9843\n",
      "Epoch 168/400\n",
      "1418/1468 [===========================>..] - ETA: 0s - loss: 0.0412 - accuracy: 0.9848\n",
      "Epoch 168: val_loss did not improve from 0.04214\n",
      "1468/1468 [==============================] - 1s 740us/step - loss: 0.0414 - accuracy: 0.9848 - val_loss: 0.0452 - val_accuracy: 0.9833\n",
      "Epoch 169/400\n",
      "1417/1468 [===========================>..] - ETA: 0s - loss: 0.0414 - accuracy: 0.9851\n",
      "Epoch 169: val_loss did not improve from 0.04214\n",
      "1468/1468 [==============================] - 1s 704us/step - loss: 0.0413 - accuracy: 0.9852 - val_loss: 0.0436 - val_accuracy: 0.9836\n",
      "Epoch 170/400\n",
      "1423/1468 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9854\n",
      "Epoch 170: val_loss did not improve from 0.04214\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0409 - accuracy: 0.9853 - val_loss: 0.0426 - val_accuracy: 0.9850\n",
      "Epoch 171/400\n",
      "1439/1468 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9849\n",
      "Epoch 171: val_loss did not improve from 0.04214\n",
      "1468/1468 [==============================] - 1s 737us/step - loss: 0.0411 - accuracy: 0.9851 - val_loss: 0.0433 - val_accuracy: 0.9838\n",
      "Epoch 172/400\n",
      "1459/1468 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9856\n",
      "Epoch 172: val_loss did not improve from 0.04214\n",
      "1468/1468 [==============================] - 1s 681us/step - loss: 0.0409 - accuracy: 0.9855 - val_loss: 0.0429 - val_accuracy: 0.9848\n",
      "Epoch 173/400\n",
      "1456/1468 [============================>.] - ETA: 0s - loss: 0.0406 - accuracy: 0.9852\n",
      "Epoch 173: val_loss did not improve from 0.04214\n",
      "1468/1468 [==============================] - 1s 690us/step - loss: 0.0407 - accuracy: 0.9851 - val_loss: 0.0429 - val_accuracy: 0.9846\n",
      "Epoch 174/400\n",
      "1389/1468 [===========================>..] - ETA: 0s - loss: 0.0406 - accuracy: 0.9852\n",
      "Epoch 174: val_loss did not improve from 0.04214\n",
      "1468/1468 [==============================] - 1s 715us/step - loss: 0.0407 - accuracy: 0.9850 - val_loss: 0.0436 - val_accuracy: 0.9836\n",
      "Epoch 175/400\n",
      "1459/1468 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9852\n",
      "Epoch 175: val_loss improved from 0.04214 to 0.04168, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 697us/step - loss: 0.0405 - accuracy: 0.9851 - val_loss: 0.0417 - val_accuracy: 0.9850\n",
      "Epoch 176/400\n",
      "1427/1468 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9853\n",
      "Epoch 176: val_loss did not improve from 0.04168\n",
      "1468/1468 [==============================] - 1s 772us/step - loss: 0.0407 - accuracy: 0.9850 - val_loss: 0.0425 - val_accuracy: 0.9858\n",
      "Epoch 177/400\n",
      "1393/1468 [===========================>..] - ETA: 0s - loss: 0.0407 - accuracy: 0.9853\n",
      "Epoch 177: val_loss did not improve from 0.04168\n",
      "1468/1468 [==============================] - 1s 715us/step - loss: 0.0405 - accuracy: 0.9854 - val_loss: 0.0418 - val_accuracy: 0.9848\n",
      "Epoch 178/400\n",
      "1400/1468 [===========================>..] - ETA: 0s - loss: 0.0404 - accuracy: 0.9851\n",
      "Epoch 178: val_loss improved from 0.04168 to 0.04100, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 731us/step - loss: 0.0401 - accuracy: 0.9852 - val_loss: 0.0410 - val_accuracy: 0.9853\n",
      "Epoch 179/400\n",
      "1440/1468 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9857\n",
      "Epoch 179: val_loss did not improve from 0.04100\n",
      "1468/1468 [==============================] - 1s 731us/step - loss: 0.0402 - accuracy: 0.9856 - val_loss: 0.0436 - val_accuracy: 0.9841\n",
      "Epoch 180/400\n",
      "1396/1468 [===========================>..] - ETA: 0s - loss: 0.0401 - accuracy: 0.9859\n",
      "Epoch 180: val_loss did not improve from 0.04100\n",
      "1468/1468 [==============================] - 1s 725us/step - loss: 0.0401 - accuracy: 0.9859 - val_loss: 0.0426 - val_accuracy: 0.9833\n",
      "Epoch 181/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9854\n",
      "Epoch 181: val_loss did not improve from 0.04100\n",
      "1468/1468 [==============================] - 1s 720us/step - loss: 0.0400 - accuracy: 0.9854 - val_loss: 0.0442 - val_accuracy: 0.9836\n",
      "Epoch 182/400\n",
      "1425/1468 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9852\n",
      "Epoch 182: val_loss improved from 0.04100 to 0.04069, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 717us/step - loss: 0.0402 - accuracy: 0.9851 - val_loss: 0.0407 - val_accuracy: 0.9865\n",
      "Epoch 183/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9856\n",
      "Epoch 183: val_loss did not improve from 0.04069\n",
      "1468/1468 [==============================] - 1s 719us/step - loss: 0.0400 - accuracy: 0.9855 - val_loss: 0.0426 - val_accuracy: 0.9843\n",
      "Epoch 184/400\n",
      "1418/1468 [===========================>..] - ETA: 0s - loss: 0.0397 - accuracy: 0.9853\n",
      "Epoch 184: val_loss did not improve from 0.04069\n",
      "1468/1468 [==============================] - 1s 702us/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.0418 - val_accuracy: 0.9848\n",
      "Epoch 185/400\n",
      "1438/1468 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9849\n",
      "Epoch 185: val_loss did not improve from 0.04069\n",
      "1468/1468 [==============================] - 1s 697us/step - loss: 0.0401 - accuracy: 0.9850 - val_loss: 0.0410 - val_accuracy: 0.9846\n",
      "Epoch 186/400\n",
      "1414/1468 [===========================>..] - ETA: 0s - loss: 0.0390 - accuracy: 0.9856\n",
      "Epoch 186: val_loss did not improve from 0.04069\n",
      "1468/1468 [==============================] - 1s 746us/step - loss: 0.0394 - accuracy: 0.9853 - val_loss: 0.0410 - val_accuracy: 0.9865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/400\n",
      "1438/1468 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9853\n",
      "Epoch 187: val_loss did not improve from 0.04069\n",
      "1468/1468 [==============================] - 1s 769us/step - loss: 0.0397 - accuracy: 0.9852 - val_loss: 0.0426 - val_accuracy: 0.9848\n",
      "Epoch 188/400\n",
      "1452/1468 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9859\n",
      "Epoch 188: val_loss improved from 0.04069 to 0.04060, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 745us/step - loss: 0.0391 - accuracy: 0.9859 - val_loss: 0.0406 - val_accuracy: 0.9848\n",
      "Epoch 189/400\n",
      "1460/1468 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9854\n",
      "Epoch 189: val_loss did not improve from 0.04060\n",
      "1468/1468 [==============================] - 1s 823us/step - loss: 0.0394 - accuracy: 0.9853 - val_loss: 0.0429 - val_accuracy: 0.9841\n",
      "Epoch 190/400\n",
      "1387/1468 [===========================>..] - ETA: 0s - loss: 0.0390 - accuracy: 0.9863\n",
      "Epoch 190: val_loss did not improve from 0.04060\n",
      "1468/1468 [==============================] - 1s 721us/step - loss: 0.0394 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9858\n",
      "Epoch 191/400\n",
      "1466/1468 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9858\n",
      "Epoch 191: val_loss did not improve from 0.04060\n",
      "1468/1468 [==============================] - 1s 678us/step - loss: 0.0394 - accuracy: 0.9859 - val_loss: 0.0425 - val_accuracy: 0.9829\n",
      "Epoch 192/400\n",
      "1411/1468 [===========================>..] - ETA: 0s - loss: 0.0391 - accuracy: 0.9857\n",
      "Epoch 192: val_loss did not improve from 0.04060\n",
      "1468/1468 [==============================] - 1s 667us/step - loss: 0.0389 - accuracy: 0.9859 - val_loss: 0.0407 - val_accuracy: 0.9853\n",
      "Epoch 193/400\n",
      "1417/1468 [===========================>..] - ETA: 0s - loss: 0.0394 - accuracy: 0.9854\n",
      "Epoch 193: val_loss did not improve from 0.04060\n",
      "1468/1468 [==============================] - 1s 701us/step - loss: 0.0391 - accuracy: 0.9855 - val_loss: 0.0416 - val_accuracy: 0.9843\n",
      "Epoch 194/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9852\n",
      "Epoch 194: val_loss improved from 0.04060 to 0.03975, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 742us/step - loss: 0.0388 - accuracy: 0.9852 - val_loss: 0.0398 - val_accuracy: 0.9848\n",
      "Epoch 195/400\n",
      "1385/1468 [===========================>..] - ETA: 0s - loss: 0.0387 - accuracy: 0.9861\n",
      "Epoch 195: val_loss did not improve from 0.03975\n",
      "1468/1468 [==============================] - 1s 675us/step - loss: 0.0389 - accuracy: 0.9859 - val_loss: 0.0412 - val_accuracy: 0.9848\n",
      "Epoch 196/400\n",
      "1462/1468 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9856\n",
      "Epoch 196: val_loss did not improve from 0.03975\n",
      "1468/1468 [==============================] - 1s 690us/step - loss: 0.0388 - accuracy: 0.9856 - val_loss: 0.0424 - val_accuracy: 0.9843\n",
      "Epoch 197/400\n",
      "1464/1468 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9854\n",
      "Epoch 197: val_loss did not improve from 0.03975\n",
      "1468/1468 [==============================] - 1s 719us/step - loss: 0.0387 - accuracy: 0.9854 - val_loss: 0.0418 - val_accuracy: 0.9850\n",
      "Epoch 198/400\n",
      "1401/1468 [===========================>..] - ETA: 0s - loss: 0.0390 - accuracy: 0.9856\n",
      "Epoch 198: val_loss did not improve from 0.03975\n",
      "1468/1468 [==============================] - 1s 675us/step - loss: 0.0389 - accuracy: 0.9859 - val_loss: 0.0405 - val_accuracy: 0.9860\n",
      "Epoch 199/400\n",
      "1382/1468 [===========================>..] - ETA: 0s - loss: 0.0387 - accuracy: 0.9862\n",
      "Epoch 199: val_loss improved from 0.03975 to 0.03972, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 703us/step - loss: 0.0385 - accuracy: 0.9863 - val_loss: 0.0397 - val_accuracy: 0.9855\n",
      "Epoch 200/400\n",
      "1430/1468 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9865\n",
      "Epoch 200: val_loss did not improve from 0.03972\n",
      "1468/1468 [==============================] - 1s 665us/step - loss: 0.0385 - accuracy: 0.9863 - val_loss: 0.0414 - val_accuracy: 0.9853\n",
      "Epoch 201/400\n",
      "1456/1468 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9860\n",
      "Epoch 201: val_loss did not improve from 0.03972\n",
      "1468/1468 [==============================] - 1s 725us/step - loss: 0.0382 - accuracy: 0.9860 - val_loss: 0.0409 - val_accuracy: 0.9853\n",
      "Epoch 202/400\n",
      "1435/1468 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.9865\n",
      "Epoch 202: val_loss did not improve from 0.03972\n",
      "1468/1468 [==============================] - 1s 731us/step - loss: 0.0381 - accuracy: 0.9867 - val_loss: 0.0408 - val_accuracy: 0.9836\n",
      "Epoch 203/400\n",
      "1460/1468 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9860\n",
      "Epoch 203: val_loss did not improve from 0.03972\n",
      "1468/1468 [==============================] - 1s 723us/step - loss: 0.0384 - accuracy: 0.9860 - val_loss: 0.0402 - val_accuracy: 0.9862\n",
      "Epoch 204/400\n",
      "1465/1468 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9861\n",
      "Epoch 204: val_loss did not improve from 0.03972\n",
      "1468/1468 [==============================] - 1s 683us/step - loss: 0.0383 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9838\n",
      "Epoch 205/400\n",
      "1439/1468 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9861\n",
      "Epoch 205: val_loss did not improve from 0.03972\n",
      "1468/1468 [==============================] - 1s 748us/step - loss: 0.0378 - accuracy: 0.9860 - val_loss: 0.0432 - val_accuracy: 0.9853\n",
      "Epoch 206/400\n",
      "1415/1468 [===========================>..] - ETA: 0s - loss: 0.0382 - accuracy: 0.9860\n",
      "Epoch 206: val_loss did not improve from 0.03972\n",
      "1468/1468 [==============================] - 1s 701us/step - loss: 0.0380 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9848\n",
      "Epoch 207/400\n",
      "1415/1468 [===========================>..] - ETA: 0s - loss: 0.0382 - accuracy: 0.9855\n",
      "Epoch 207: val_loss did not improve from 0.03972\n",
      "1468/1468 [==============================] - 1s 742us/step - loss: 0.0379 - accuracy: 0.9857 - val_loss: 0.0407 - val_accuracy: 0.9848\n",
      "Epoch 208/400\n",
      "1422/1468 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9859\n",
      "Epoch 208: val_loss improved from 0.03972 to 0.03897, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0378 - accuracy: 0.9860 - val_loss: 0.0390 - val_accuracy: 0.9870\n",
      "Epoch 209/400\n",
      "1421/1468 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9864\n",
      "Epoch 209: val_loss did not improve from 0.03897\n",
      "1468/1468 [==============================] - 1s 698us/step - loss: 0.0378 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9846\n",
      "Epoch 210/400\n",
      "1390/1468 [===========================>..] - ETA: 0s - loss: 0.0378 - accuracy: 0.9866\n",
      "Epoch 210: val_loss did not improve from 0.03897\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0377 - accuracy: 0.9868 - val_loss: 0.0392 - val_accuracy: 0.9862\n",
      "Epoch 211/400\n",
      "1427/1468 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9860\n",
      "Epoch 211: val_loss did not improve from 0.03897\n",
      "1468/1468 [==============================] - 1s 732us/step - loss: 0.0377 - accuracy: 0.9861 - val_loss: 0.0396 - val_accuracy: 0.9853\n",
      "Epoch 212/400\n",
      "1409/1468 [===========================>..] - ETA: 0s - loss: 0.0377 - accuracy: 0.9864\n",
      "Epoch 212: val_loss improved from 0.03897 to 0.03737, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 718us/step - loss: 0.0378 - accuracy: 0.9864 - val_loss: 0.0374 - val_accuracy: 0.9867\n",
      "Epoch 213/400\n",
      "1438/1468 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9860\n",
      "Epoch 213: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 695us/step - loss: 0.0375 - accuracy: 0.9862 - val_loss: 0.0381 - val_accuracy: 0.9860\n",
      "Epoch 214/400\n",
      "1436/1468 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9864\n",
      "Epoch 214: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 673us/step - loss: 0.0373 - accuracy: 0.9862 - val_loss: 0.0376 - val_accuracy: 0.9853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/400\n",
      "1440/1468 [============================>.] - ETA: 0s - loss: 0.0372 - accuracy: 0.9868\n",
      "Epoch 215: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 804us/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 0.0412 - val_accuracy: 0.9850\n",
      "Epoch 216/400\n",
      "1398/1468 [===========================>..] - ETA: 0s - loss: 0.0376 - accuracy: 0.9861\n",
      "Epoch 216: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 787us/step - loss: 0.0375 - accuracy: 0.9862 - val_loss: 0.0403 - val_accuracy: 0.9875\n",
      "Epoch 217/400\n",
      "1416/1468 [===========================>..] - ETA: 0s - loss: 0.0370 - accuracy: 0.9870\n",
      "Epoch 217: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 713us/step - loss: 0.0371 - accuracy: 0.9870 - val_loss: 0.0406 - val_accuracy: 0.9853\n",
      "Epoch 218/400\n",
      "1398/1468 [===========================>..] - ETA: 0s - loss: 0.0370 - accuracy: 0.9865\n",
      "Epoch 218: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 708us/step - loss: 0.0374 - accuracy: 0.9861 - val_loss: 0.0403 - val_accuracy: 0.9860\n",
      "Epoch 219/400\n",
      "1464/1468 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9870\n",
      "Epoch 219: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 723us/step - loss: 0.0371 - accuracy: 0.9869 - val_loss: 0.0394 - val_accuracy: 0.9860\n",
      "Epoch 220/400\n",
      "1448/1468 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9870\n",
      "Epoch 220: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 699us/step - loss: 0.0368 - accuracy: 0.9868 - val_loss: 0.0414 - val_accuracy: 0.9846\n",
      "Epoch 221/400\n",
      "1428/1468 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9861\n",
      "Epoch 221: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 736us/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.0403 - val_accuracy: 0.9843\n",
      "Epoch 222/400\n",
      "1427/1468 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9868\n",
      "Epoch 222: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 699us/step - loss: 0.0365 - accuracy: 0.9868 - val_loss: 0.0396 - val_accuracy: 0.9853\n",
      "Epoch 223/400\n",
      "1405/1468 [===========================>..] - ETA: 0s - loss: 0.0366 - accuracy: 0.9863\n",
      "Epoch 223: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 709us/step - loss: 0.0367 - accuracy: 0.9862 - val_loss: 0.0393 - val_accuracy: 0.9865\n",
      "Epoch 224/400\n",
      "1446/1468 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9868\n",
      "Epoch 224: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 691us/step - loss: 0.0367 - accuracy: 0.9868 - val_loss: 0.0385 - val_accuracy: 0.9865\n",
      "Epoch 225/400\n",
      "1451/1468 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9869\n",
      "Epoch 225: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 726us/step - loss: 0.0367 - accuracy: 0.9868 - val_loss: 0.0376 - val_accuracy: 0.9862\n",
      "Epoch 226/400\n",
      "1442/1468 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9873\n",
      "Epoch 226: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 731us/step - loss: 0.0365 - accuracy: 0.9872 - val_loss: 0.0396 - val_accuracy: 0.9860\n",
      "Epoch 227/400\n",
      "1398/1468 [===========================>..] - ETA: 0s - loss: 0.0364 - accuracy: 0.9872\n",
      "Epoch 227: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 716us/step - loss: 0.0363 - accuracy: 0.9871 - val_loss: 0.0413 - val_accuracy: 0.9833\n",
      "Epoch 228/400\n",
      "1464/1468 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9866\n",
      "Epoch 228: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 686us/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 0.0395 - val_accuracy: 0.9860\n",
      "Epoch 229/400\n",
      "1391/1468 [===========================>..] - ETA: 0s - loss: 0.0364 - accuracy: 0.9873\n",
      "Epoch 229: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 717us/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 0.0375 - val_accuracy: 0.9887\n",
      "Epoch 230/400\n",
      "1390/1468 [===========================>..] - ETA: 0s - loss: 0.0358 - accuracy: 0.9872\n",
      "Epoch 230: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 683us/step - loss: 0.0365 - accuracy: 0.9867 - val_loss: 0.0408 - val_accuracy: 0.9862\n",
      "Epoch 231/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9871\n",
      "Epoch 231: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 733us/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.0383 - val_accuracy: 0.9860\n",
      "Epoch 232/400\n",
      "1388/1468 [===========================>..] - ETA: 0s - loss: 0.0363 - accuracy: 0.9869\n",
      "Epoch 232: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 756us/step - loss: 0.0362 - accuracy: 0.9870 - val_loss: 0.0387 - val_accuracy: 0.9860\n",
      "Epoch 233/400\n",
      "1388/1468 [===========================>..] - ETA: 0s - loss: 0.0358 - accuracy: 0.9871\n",
      "Epoch 233: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 713us/step - loss: 0.0363 - accuracy: 0.9867 - val_loss: 0.0379 - val_accuracy: 0.9872\n",
      "Epoch 234/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9869\n",
      "Epoch 234: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 686us/step - loss: 0.0360 - accuracy: 0.9870 - val_loss: 0.0404 - val_accuracy: 0.9846\n",
      "Epoch 235/400\n",
      "1391/1468 [===========================>..] - ETA: 0s - loss: 0.0360 - accuracy: 0.9871\n",
      "Epoch 235: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0363 - accuracy: 0.9868 - val_loss: 0.0383 - val_accuracy: 0.9870\n",
      "Epoch 236/400\n",
      "1422/1468 [============================>.] - ETA: 0s - loss: 0.0357 - accuracy: 0.9869\n",
      "Epoch 236: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0358 - accuracy: 0.9868 - val_loss: 0.0396 - val_accuracy: 0.9865\n",
      "Epoch 237/400\n",
      "1442/1468 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9870\n",
      "Epoch 237: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 688us/step - loss: 0.0362 - accuracy: 0.9869 - val_loss: 0.0395 - val_accuracy: 0.9860\n",
      "Epoch 238/400\n",
      "1451/1468 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.9873\n",
      "Epoch 238: val_loss did not improve from 0.03737\n",
      "1468/1468 [==============================] - 1s 649us/step - loss: 0.0358 - accuracy: 0.9874 - val_loss: 0.0389 - val_accuracy: 0.9855\n",
      "Epoch 239/400\n",
      "1465/1468 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9871\n",
      "Epoch 239: val_loss improved from 0.03737 to 0.03698, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0359 - accuracy: 0.9871 - val_loss: 0.0370 - val_accuracy: 0.9862\n",
      "Epoch 240/400\n",
      "1445/1468 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.9870\n",
      "Epoch 240: val_loss did not improve from 0.03698\n",
      "1468/1468 [==============================] - 1s 697us/step - loss: 0.0359 - accuracy: 0.9871 - val_loss: 0.0381 - val_accuracy: 0.9860\n",
      "Epoch 241/400\n",
      "1396/1468 [===========================>..] - ETA: 0s - loss: 0.0350 - accuracy: 0.9869\n",
      "Epoch 241: val_loss did not improve from 0.03698\n",
      "1468/1468 [==============================] - 1s 708us/step - loss: 0.0356 - accuracy: 0.9867 - val_loss: 0.0389 - val_accuracy: 0.9860\n",
      "Epoch 242/400\n",
      "1440/1468 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9868\n",
      "Epoch 242: val_loss improved from 0.03698 to 0.03570, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 700us/step - loss: 0.0360 - accuracy: 0.9867 - val_loss: 0.0357 - val_accuracy: 0.9865\n",
      "Epoch 243/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1468 [===========================>..] - ETA: 0s - loss: 0.0361 - accuracy: 0.9864\n",
      "Epoch 243: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 710us/step - loss: 0.0356 - accuracy: 0.9868 - val_loss: 0.0375 - val_accuracy: 0.9858\n",
      "Epoch 244/400\n",
      "1421/1468 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9867\n",
      "Epoch 244: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 705us/step - loss: 0.0353 - accuracy: 0.9867 - val_loss: 0.0396 - val_accuracy: 0.9865\n",
      "Epoch 245/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9873\n",
      "Epoch 245: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 706us/step - loss: 0.0354 - accuracy: 0.9872 - val_loss: 0.0389 - val_accuracy: 0.9870\n",
      "Epoch 246/400\n",
      "1442/1468 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9867\n",
      "Epoch 246: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 692us/step - loss: 0.0357 - accuracy: 0.9867 - val_loss: 0.0380 - val_accuracy: 0.9855\n",
      "Epoch 247/400\n",
      "1414/1468 [===========================>..] - ETA: 0s - loss: 0.0349 - accuracy: 0.9873\n",
      "Epoch 247: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 703us/step - loss: 0.0352 - accuracy: 0.9871 - val_loss: 0.0402 - val_accuracy: 0.9867\n",
      "Epoch 248/400\n",
      "1436/1468 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9872\n",
      "Epoch 248: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 698us/step - loss: 0.0356 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9855\n",
      "Epoch 249/400\n",
      "1431/1468 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9872\n",
      "Epoch 249: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 713us/step - loss: 0.0351 - accuracy: 0.9871 - val_loss: 0.0392 - val_accuracy: 0.9860\n",
      "Epoch 250/400\n",
      "1441/1468 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.9871\n",
      "Epoch 250: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0348 - accuracy: 0.9871 - val_loss: 0.0373 - val_accuracy: 0.9860\n",
      "Epoch 251/400\n",
      "1454/1468 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9866\n",
      "Epoch 251: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 733us/step - loss: 0.0349 - accuracy: 0.9867 - val_loss: 0.0387 - val_accuracy: 0.9858\n",
      "Epoch 252/400\n",
      "1410/1468 [===========================>..] - ETA: 0s - loss: 0.0350 - accuracy: 0.9873\n",
      "Epoch 252: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 710us/step - loss: 0.0351 - accuracy: 0.9873 - val_loss: 0.0370 - val_accuracy: 0.9855\n",
      "Epoch 253/400\n",
      "1424/1468 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9874\n",
      "Epoch 253: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 699us/step - loss: 0.0349 - accuracy: 0.9874 - val_loss: 0.0368 - val_accuracy: 0.9867\n",
      "Epoch 254/400\n",
      "1402/1468 [===========================>..] - ETA: 0s - loss: 0.0348 - accuracy: 0.9873\n",
      "Epoch 254: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0351 - accuracy: 0.9871 - val_loss: 0.0387 - val_accuracy: 0.9865\n",
      "Epoch 255/400\n",
      "1434/1468 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9872\n",
      "Epoch 255: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 739us/step - loss: 0.0352 - accuracy: 0.9872 - val_loss: 0.0376 - val_accuracy: 0.9865\n",
      "Epoch 256/400\n",
      "1461/1468 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9872\n",
      "Epoch 256: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 726us/step - loss: 0.0350 - accuracy: 0.9872 - val_loss: 0.0361 - val_accuracy: 0.9862\n",
      "Epoch 257/400\n",
      "1443/1468 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9879\n",
      "Epoch 257: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 729us/step - loss: 0.0344 - accuracy: 0.9877 - val_loss: 0.0395 - val_accuracy: 0.9853\n",
      "Epoch 258/400\n",
      "1419/1468 [===========================>..] - ETA: 0s - loss: 0.0353 - accuracy: 0.9873\n",
      "Epoch 258: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 702us/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 0.0379 - val_accuracy: 0.9853\n",
      "Epoch 259/400\n",
      "1409/1468 [===========================>..] - ETA: 0s - loss: 0.0349 - accuracy: 0.9878\n",
      "Epoch 259: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 744us/step - loss: 0.0348 - accuracy: 0.9877 - val_loss: 0.0360 - val_accuracy: 0.9860\n",
      "Epoch 260/400\n",
      "1460/1468 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9874\n",
      "Epoch 260: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 692us/step - loss: 0.0347 - accuracy: 0.9874 - val_loss: 0.0375 - val_accuracy: 0.9877\n",
      "Epoch 261/400\n",
      "1430/1468 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9874\n",
      "Epoch 261: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 700us/step - loss: 0.0348 - accuracy: 0.9873 - val_loss: 0.0371 - val_accuracy: 0.9855\n",
      "Epoch 262/400\n",
      "1450/1468 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9873\n",
      "Epoch 262: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 694us/step - loss: 0.0349 - accuracy: 0.9874 - val_loss: 0.0378 - val_accuracy: 0.9867\n",
      "Epoch 263/400\n",
      "1427/1468 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9871\n",
      "Epoch 263: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 703us/step - loss: 0.0348 - accuracy: 0.9871 - val_loss: 0.0364 - val_accuracy: 0.9865\n",
      "Epoch 264/400\n",
      "1462/1468 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9873\n",
      "Epoch 264: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 687us/step - loss: 0.0344 - accuracy: 0.9873 - val_loss: 0.0366 - val_accuracy: 0.9855\n",
      "Epoch 265/400\n",
      "1431/1468 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9876\n",
      "Epoch 265: val_loss did not improve from 0.03570\n",
      "1468/1468 [==============================] - 1s 698us/step - loss: 0.0346 - accuracy: 0.9876 - val_loss: 0.0366 - val_accuracy: 0.9862\n",
      "Epoch 266/400\n",
      "1388/1468 [===========================>..] - ETA: 0s - loss: 0.0345 - accuracy: 0.9873\n",
      "Epoch 266: val_loss improved from 0.03570 to 0.03512, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0345 - accuracy: 0.9874 - val_loss: 0.0351 - val_accuracy: 0.9870\n",
      "Epoch 267/400\n",
      "1435/1468 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9871\n",
      "Epoch 267: val_loss did not improve from 0.03512\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0342 - accuracy: 0.9869 - val_loss: 0.0381 - val_accuracy: 0.9875\n",
      "Epoch 268/400\n",
      "1446/1468 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.9872\n",
      "Epoch 268: val_loss did not improve from 0.03512\n",
      "1468/1468 [==============================] - 1s 691us/step - loss: 0.0345 - accuracy: 0.9872 - val_loss: 0.0380 - val_accuracy: 0.9855\n",
      "Epoch 269/400\n",
      "1452/1468 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9876\n",
      "Epoch 269: val_loss improved from 0.03512 to 0.03496, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 698us/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.0350 - val_accuracy: 0.9870\n",
      "Epoch 270/400\n",
      "1391/1468 [===========================>..] - ETA: 0s - loss: 0.0339 - accuracy: 0.9875\n",
      "Epoch 270: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 682us/step - loss: 0.0340 - accuracy: 0.9872 - val_loss: 0.0390 - val_accuracy: 0.9865\n",
      "Epoch 271/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1435/1468 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9878\n",
      "Epoch 271: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 693us/step - loss: 0.0338 - accuracy: 0.9876 - val_loss: 0.0382 - val_accuracy: 0.9855\n",
      "Epoch 272/400\n",
      "1464/1468 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9876\n",
      "Epoch 272: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 685us/step - loss: 0.0341 - accuracy: 0.9876 - val_loss: 0.0366 - val_accuracy: 0.9865\n",
      "Epoch 273/400\n",
      "1396/1468 [===========================>..] - ETA: 0s - loss: 0.0340 - accuracy: 0.9875\n",
      "Epoch 273: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 711us/step - loss: 0.0339 - accuracy: 0.9876 - val_loss: 0.0370 - val_accuracy: 0.9846\n",
      "Epoch 274/400\n",
      "1398/1468 [===========================>..] - ETA: 0s - loss: 0.0341 - accuracy: 0.9878\n",
      "Epoch 274: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 677us/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.0356 - val_accuracy: 0.9870\n",
      "Epoch 275/400\n",
      "1407/1468 [===========================>..] - ETA: 0s - loss: 0.0345 - accuracy: 0.9870\n",
      "Epoch 275: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0340 - accuracy: 0.9872 - val_loss: 0.0370 - val_accuracy: 0.9867\n",
      "Epoch 276/400\n",
      "1464/1468 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9880\n",
      "Epoch 276: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 682us/step - loss: 0.0331 - accuracy: 0.9879 - val_loss: 0.0384 - val_accuracy: 0.9875\n",
      "Epoch 277/400\n",
      "1450/1468 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9878\n",
      "Epoch 277: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 694us/step - loss: 0.0334 - accuracy: 0.9878 - val_loss: 0.0360 - val_accuracy: 0.9877\n",
      "Epoch 278/400\n",
      "1431/1468 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9879\n",
      "Epoch 278: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 747us/step - loss: 0.0337 - accuracy: 0.9880 - val_loss: 0.0362 - val_accuracy: 0.9870\n",
      "Epoch 279/400\n",
      "1455/1468 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9876\n",
      "Epoch 279: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 757us/step - loss: 0.0337 - accuracy: 0.9876 - val_loss: 0.0369 - val_accuracy: 0.9858\n",
      "Epoch 280/400\n",
      "1429/1468 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9875\n",
      "Epoch 280: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0335 - accuracy: 0.9872 - val_loss: 0.0365 - val_accuracy: 0.9877\n",
      "Epoch 281/400\n",
      "1428/1468 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9883\n",
      "Epoch 281: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 697us/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 0.0368 - val_accuracy: 0.9860\n",
      "Epoch 282/400\n",
      "1402/1468 [===========================>..] - ETA: 0s - loss: 0.0332 - accuracy: 0.9874\n",
      "Epoch 282: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 673us/step - loss: 0.0331 - accuracy: 0.9873 - val_loss: 0.0358 - val_accuracy: 0.9865\n",
      "Epoch 283/400\n",
      "1417/1468 [===========================>..] - ETA: 0s - loss: 0.0334 - accuracy: 0.9880\n",
      "Epoch 283: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0332 - accuracy: 0.9880 - val_loss: 0.0352 - val_accuracy: 0.9872\n",
      "Epoch 284/400\n",
      "1384/1468 [===========================>..] - ETA: 0s - loss: 0.0330 - accuracy: 0.9879\n",
      "Epoch 284: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 677us/step - loss: 0.0333 - accuracy: 0.9877 - val_loss: 0.0359 - val_accuracy: 0.9855\n",
      "Epoch 285/400\n",
      "1421/1468 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9879\n",
      "Epoch 285: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 712us/step - loss: 0.0331 - accuracy: 0.9879 - val_loss: 0.0383 - val_accuracy: 0.9862\n",
      "Epoch 286/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9881\n",
      "Epoch 286: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 683us/step - loss: 0.0330 - accuracy: 0.9881 - val_loss: 0.0351 - val_accuracy: 0.9865\n",
      "Epoch 287/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9877\n",
      "Epoch 287: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 691us/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.0357 - val_accuracy: 0.9865\n",
      "Epoch 288/400\n",
      "1449/1468 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9878\n",
      "Epoch 288: val_loss did not improve from 0.03496\n",
      "1468/1468 [==============================] - 1s 688us/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.0360 - val_accuracy: 0.9867\n",
      "Epoch 289/400\n",
      "1378/1468 [===========================>..] - ETA: 0s - loss: 0.0326 - accuracy: 0.9883\n",
      "Epoch 289: val_loss improved from 0.03496 to 0.03444, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 693us/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.0344 - val_accuracy: 0.9870\n",
      "Epoch 290/400\n",
      "1413/1468 [===========================>..] - ETA: 0s - loss: 0.0326 - accuracy: 0.9878\n",
      "Epoch 290: val_loss did not improve from 0.03444\n",
      "1468/1468 [==============================] - 1s 718us/step - loss: 0.0328 - accuracy: 0.9878 - val_loss: 0.0356 - val_accuracy: 0.9870\n",
      "Epoch 291/400\n",
      "1460/1468 [============================>.] - ETA: 0s - loss: 0.0325 - accuracy: 0.9882\n",
      "Epoch 291: val_loss did not improve from 0.03444\n",
      "1468/1468 [==============================] - 1s 686us/step - loss: 0.0326 - accuracy: 0.9882 - val_loss: 0.0393 - val_accuracy: 0.9865\n",
      "Epoch 292/400\n",
      "1404/1468 [===========================>..] - ETA: 0s - loss: 0.0328 - accuracy: 0.9881\n",
      "Epoch 292: val_loss improved from 0.03444 to 0.03401, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 713us/step - loss: 0.0327 - accuracy: 0.9881 - val_loss: 0.0340 - val_accuracy: 0.9879\n",
      "Epoch 293/400\n",
      "1462/1468 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9883\n",
      "Epoch 293: val_loss did not improve from 0.03401\n",
      "1468/1468 [==============================] - 1s 687us/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: 0.0348 - val_accuracy: 0.9879\n",
      "Epoch 294/400\n",
      "1390/1468 [===========================>..] - ETA: 0s - loss: 0.0324 - accuracy: 0.9879\n",
      "Epoch 294: val_loss did not improve from 0.03401\n",
      "1468/1468 [==============================] - 1s 714us/step - loss: 0.0325 - accuracy: 0.9879 - val_loss: 0.0368 - val_accuracy: 0.9867\n",
      "Epoch 295/400\n",
      "1419/1468 [===========================>..] - ETA: 0s - loss: 0.0327 - accuracy: 0.9885\n",
      "Epoch 295: val_loss did not improve from 0.03401\n",
      "1468/1468 [==============================] - 1s 698us/step - loss: 0.0324 - accuracy: 0.9886 - val_loss: 0.0390 - val_accuracy: 0.9865\n",
      "Epoch 296/400\n",
      "1383/1468 [===========================>..] - ETA: 0s - loss: 0.0327 - accuracy: 0.9880\n",
      "Epoch 296: val_loss did not improve from 0.03401\n",
      "1468/1468 [==============================] - 1s 677us/step - loss: 0.0325 - accuracy: 0.9882 - val_loss: 0.0353 - val_accuracy: 0.9862\n",
      "Epoch 297/400\n",
      "1433/1468 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9882\n",
      "Epoch 297: val_loss did not improve from 0.03401\n",
      "1468/1468 [==============================] - 1s 702us/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.0341 - val_accuracy: 0.9870\n",
      "Epoch 298/400\n",
      "1452/1468 [============================>.] - ETA: 0s - loss: 0.0325 - accuracy: 0.9884\n",
      "Epoch 298: val_loss did not improve from 0.03401\n",
      "1468/1468 [==============================] - 1s 719us/step - loss: 0.0324 - accuracy: 0.9885 - val_loss: 0.0382 - val_accuracy: 0.9858\n",
      "Epoch 299/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394/1468 [===========================>..] - ETA: 0s - loss: 0.0320 - accuracy: 0.9884\n",
      "Epoch 299: val_loss improved from 0.03401 to 0.03370, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 683us/step - loss: 0.0323 - accuracy: 0.9882 - val_loss: 0.0337 - val_accuracy: 0.9872\n",
      "Epoch 300/400\n",
      "1449/1468 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9883\n",
      "Epoch 300: val_loss did not improve from 0.03370\n",
      "1468/1468 [==============================] - 1s 687us/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.0358 - val_accuracy: 0.9879\n",
      "Epoch 301/400\n",
      "1395/1468 [===========================>..] - ETA: 0s - loss: 0.0326 - accuracy: 0.9884\n",
      "Epoch 301: val_loss did not improve from 0.03370\n",
      "1468/1468 [==============================] - 1s 715us/step - loss: 0.0322 - accuracy: 0.9884 - val_loss: 0.0363 - val_accuracy: 0.9877\n",
      "Epoch 302/400\n",
      "1401/1468 [===========================>..] - ETA: 0s - loss: 0.0324 - accuracy: 0.9885\n",
      "Epoch 302: val_loss did not improve from 0.03370\n",
      "1468/1468 [==============================] - 1s 707us/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.0359 - val_accuracy: 0.9870\n",
      "Epoch 303/400\n",
      "1427/1468 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9881\n",
      "Epoch 303: val_loss did not improve from 0.03370\n",
      "1468/1468 [==============================] - 1s 700us/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.0351 - val_accuracy: 0.9865\n",
      "Epoch 304/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9886\n",
      "Epoch 304: val_loss improved from 0.03370 to 0.03358, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 702us/step - loss: 0.0318 - accuracy: 0.9886 - val_loss: 0.0336 - val_accuracy: 0.9872\n",
      "Epoch 305/400\n",
      "1428/1468 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9886\n",
      "Epoch 305: val_loss did not improve from 0.03358\n",
      "1468/1468 [==============================] - 1s 698us/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 0.0343 - val_accuracy: 0.9884\n",
      "Epoch 306/400\n",
      "1392/1468 [===========================>..] - ETA: 0s - loss: 0.0323 - accuracy: 0.9882\n",
      "Epoch 306: val_loss did not improve from 0.03358\n",
      "1468/1468 [==============================] - 1s 715us/step - loss: 0.0320 - accuracy: 0.9884 - val_loss: 0.0341 - val_accuracy: 0.9884\n",
      "Epoch 307/400\n",
      "1441/1468 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9887\n",
      "Epoch 307: val_loss improved from 0.03358 to 0.03310, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 703us/step - loss: 0.0319 - accuracy: 0.9886 - val_loss: 0.0331 - val_accuracy: 0.9875\n",
      "Epoch 308/400\n",
      "1453/1468 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9883\n",
      "Epoch 308: val_loss did not improve from 0.03310\n",
      "1468/1468 [==============================] - 1s 726us/step - loss: 0.0317 - accuracy: 0.9883 - val_loss: 0.0346 - val_accuracy: 0.9879\n",
      "Epoch 309/400\n",
      "1434/1468 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9887\n",
      "Epoch 309: val_loss did not improve from 0.03310\n",
      "1468/1468 [==============================] - 1s 659us/step - loss: 0.0313 - accuracy: 0.9888 - val_loss: 0.0340 - val_accuracy: 0.9870\n",
      "Epoch 310/400\n",
      "1402/1468 [===========================>..] - ETA: 0s - loss: 0.0316 - accuracy: 0.9889\n",
      "Epoch 310: val_loss did not improve from 0.03310\n",
      "1468/1468 [==============================] - 1s 746us/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.0336 - val_accuracy: 0.9872\n",
      "Epoch 311/400\n",
      "1438/1468 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9884\n",
      "Epoch 311: val_loss did not improve from 0.03310\n",
      "1468/1468 [==============================] - 1s 689us/step - loss: 0.0316 - accuracy: 0.9884 - val_loss: 0.0335 - val_accuracy: 0.9879\n",
      "Epoch 312/400\n",
      "1433/1468 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9891\n",
      "Epoch 312: val_loss did not improve from 0.03310\n",
      "1468/1468 [==============================] - 1s 695us/step - loss: 0.0317 - accuracy: 0.9888 - val_loss: 0.0334 - val_accuracy: 0.9884\n",
      "Epoch 313/400\n",
      "1418/1468 [===========================>..] - ETA: 0s - loss: 0.0319 - accuracy: 0.9885\n",
      "Epoch 313: val_loss did not improve from 0.03310\n",
      "1468/1468 [==============================] - 1s 705us/step - loss: 0.0317 - accuracy: 0.9885 - val_loss: 0.0334 - val_accuracy: 0.9862\n",
      "Epoch 314/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9889\n",
      "Epoch 314: val_loss did not improve from 0.03310\n",
      "1468/1468 [==============================] - 1s 735us/step - loss: 0.0316 - accuracy: 0.9889 - val_loss: 0.0340 - val_accuracy: 0.9860\n",
      "Epoch 315/400\n",
      "1467/1468 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9882\n",
      "Epoch 315: val_loss improved from 0.03310 to 0.03265, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 728us/step - loss: 0.0315 - accuracy: 0.9882 - val_loss: 0.0327 - val_accuracy: 0.9884\n",
      "Epoch 316/400\n",
      "1445/1468 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9888\n",
      "Epoch 316: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 693us/step - loss: 0.0312 - accuracy: 0.9890 - val_loss: 0.0344 - val_accuracy: 0.9872\n",
      "Epoch 317/400\n",
      "1423/1468 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9891\n",
      "Epoch 317: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 703us/step - loss: 0.0313 - accuracy: 0.9889 - val_loss: 0.0332 - val_accuracy: 0.9887\n",
      "Epoch 318/400\n",
      "1415/1468 [===========================>..] - ETA: 0s - loss: 0.0311 - accuracy: 0.9888\n",
      "Epoch 318: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 709us/step - loss: 0.0311 - accuracy: 0.9888 - val_loss: 0.0335 - val_accuracy: 0.9884\n",
      "Epoch 319/400\n",
      "1440/1468 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9883\n",
      "Epoch 319: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 693us/step - loss: 0.0313 - accuracy: 0.9884 - val_loss: 0.0334 - val_accuracy: 0.9867\n",
      "Epoch 320/400\n",
      "1425/1468 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9889\n",
      "Epoch 320: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0313 - accuracy: 0.9889 - val_loss: 0.0338 - val_accuracy: 0.9872\n",
      "Epoch 321/400\n",
      "1438/1468 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9886\n",
      "Epoch 321: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 654us/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 0.0361 - val_accuracy: 0.9867\n",
      "Epoch 322/400\n",
      "1421/1468 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9885\n",
      "Epoch 322: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 702us/step - loss: 0.0311 - accuracy: 0.9885 - val_loss: 0.0330 - val_accuracy: 0.9872\n",
      "Epoch 323/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9888\n",
      "Epoch 323: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 693us/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 0.0347 - val_accuracy: 0.9884\n",
      "Epoch 324/400\n",
      "1444/1468 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9888\n",
      "Epoch 324: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 689us/step - loss: 0.0310 - accuracy: 0.9888 - val_loss: 0.0337 - val_accuracy: 0.9870\n",
      "Epoch 325/400\n",
      "1410/1468 [===========================>..] - ETA: 0s - loss: 0.0303 - accuracy: 0.9891\n",
      "Epoch 325: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 667us/step - loss: 0.0309 - accuracy: 0.9889 - val_loss: 0.0334 - val_accuracy: 0.9884\n",
      "Epoch 326/400\n",
      "1409/1468 [===========================>..] - ETA: 0s - loss: 0.0310 - accuracy: 0.9894\n",
      "Epoch 326: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 704us/step - loss: 0.0307 - accuracy: 0.9895 - val_loss: 0.0340 - val_accuracy: 0.9872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/400\n",
      "1406/1468 [===========================>..] - ETA: 0s - loss: 0.0309 - accuracy: 0.9889\n",
      "Epoch 327: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 711us/step - loss: 0.0311 - accuracy: 0.9889 - val_loss: 0.0339 - val_accuracy: 0.9882\n",
      "Epoch 328/400\n",
      "1462/1468 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9890\n",
      "Epoch 328: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 730us/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.0332 - val_accuracy: 0.9870\n",
      "Epoch 329/400\n",
      "1410/1468 [===========================>..] - ETA: 0s - loss: 0.0308 - accuracy: 0.9891\n",
      "Epoch 329: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 742us/step - loss: 0.0307 - accuracy: 0.9892 - val_loss: 0.0331 - val_accuracy: 0.9877\n",
      "Epoch 330/400\n",
      "1402/1468 [===========================>..] - ETA: 0s - loss: 0.0304 - accuracy: 0.9891\n",
      "Epoch 330: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 708us/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.0335 - val_accuracy: 0.9887\n",
      "Epoch 331/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9893\n",
      "Epoch 331: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 682us/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.0330 - val_accuracy: 0.9872\n",
      "Epoch 332/400\n",
      "1418/1468 [===========================>..] - ETA: 0s - loss: 0.0308 - accuracy: 0.9889\n",
      "Epoch 332: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 700us/step - loss: 0.0307 - accuracy: 0.9891 - val_loss: 0.0346 - val_accuracy: 0.9877\n",
      "Epoch 333/400\n",
      "1429/1468 [============================>.] - ETA: 0s - loss: 0.0304 - accuracy: 0.9894\n",
      "Epoch 333: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 699us/step - loss: 0.0306 - accuracy: 0.9892 - val_loss: 0.0342 - val_accuracy: 0.9879\n",
      "Epoch 334/400\n",
      "1462/1468 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9891\n",
      "Epoch 334: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 723us/step - loss: 0.0306 - accuracy: 0.9891 - val_loss: 0.0328 - val_accuracy: 0.9877\n",
      "Epoch 335/400\n",
      "1420/1468 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9886\n",
      "Epoch 335: val_loss did not improve from 0.03265\n",
      "1468/1468 [==============================] - 1s 704us/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 0.0337 - val_accuracy: 0.9884\n",
      "Epoch 336/400\n",
      "1440/1468 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9887\n",
      "Epoch 336: val_loss improved from 0.03265 to 0.03257, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 769us/step - loss: 0.0306 - accuracy: 0.9888 - val_loss: 0.0326 - val_accuracy: 0.9882\n",
      "Epoch 337/400\n",
      "1391/1468 [===========================>..] - ETA: 0s - loss: 0.0307 - accuracy: 0.9890\n",
      "Epoch 337: val_loss improved from 0.03257 to 0.03162, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 726us/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.0316 - val_accuracy: 0.9889\n",
      "Epoch 338/400\n",
      "1383/1468 [===========================>..] - ETA: 0s - loss: 0.0295 - accuracy: 0.9895\n",
      "Epoch 338: val_loss did not improve from 0.03162\n",
      "1468/1468 [==============================] - 1s 714us/step - loss: 0.0302 - accuracy: 0.9892 - val_loss: 0.0322 - val_accuracy: 0.9882\n",
      "Epoch 339/400\n",
      "1441/1468 [============================>.] - ETA: 0s - loss: 0.0304 - accuracy: 0.9890\n",
      "Epoch 339: val_loss did not improve from 0.03162\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.0329 - val_accuracy: 0.9872\n",
      "Epoch 340/400\n",
      "1421/1468 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9892\n",
      "Epoch 340: val_loss did not improve from 0.03162\n",
      "1468/1468 [==============================] - 1s 701us/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.0326 - val_accuracy: 0.9875\n",
      "Epoch 341/400\n",
      "1455/1468 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9890\n",
      "Epoch 341: val_loss improved from 0.03162 to 0.03084, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 703us/step - loss: 0.0302 - accuracy: 0.9890 - val_loss: 0.0308 - val_accuracy: 0.9882\n",
      "Epoch 342/400\n",
      "1415/1468 [===========================>..] - ETA: 0s - loss: 0.0303 - accuracy: 0.9885\n",
      "Epoch 342: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 704us/step - loss: 0.0302 - accuracy: 0.9886 - val_loss: 0.0337 - val_accuracy: 0.9882\n",
      "Epoch 343/400\n",
      "1437/1468 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9888\n",
      "Epoch 343: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.0337 - val_accuracy: 0.9872\n",
      "Epoch 344/400\n",
      "1452/1468 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9892\n",
      "Epoch 344: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 726us/step - loss: 0.0302 - accuracy: 0.9891 - val_loss: 0.0334 - val_accuracy: 0.9884\n",
      "Epoch 345/400\n",
      "1441/1468 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9894\n",
      "Epoch 345: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 694us/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.0331 - val_accuracy: 0.9879\n",
      "Epoch 346/400\n",
      "1429/1468 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9893\n",
      "Epoch 346: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 738us/step - loss: 0.0297 - accuracy: 0.9893 - val_loss: 0.0326 - val_accuracy: 0.9891\n",
      "Epoch 347/400\n",
      "1407/1468 [===========================>..] - ETA: 0s - loss: 0.0298 - accuracy: 0.9893\n",
      "Epoch 347: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 708us/step - loss: 0.0302 - accuracy: 0.9891 - val_loss: 0.0323 - val_accuracy: 0.9882\n",
      "Epoch 348/400\n",
      "1460/1468 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9895\n",
      "Epoch 348: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 718us/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.0312 - val_accuracy: 0.9896\n",
      "Epoch 349/400\n",
      "1452/1468 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9893\n",
      "Epoch 349: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 727us/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0328 - val_accuracy: 0.9879\n",
      "Epoch 350/400\n",
      "1424/1468 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9895\n",
      "Epoch 350: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 709us/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 0.0342 - val_accuracy: 0.9870\n",
      "Epoch 351/400\n",
      "1443/1468 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9895\n",
      "Epoch 351: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 729us/step - loss: 0.0298 - accuracy: 0.9895 - val_loss: 0.0312 - val_accuracy: 0.9889\n",
      "Epoch 352/400\n",
      "1413/1468 [===========================>..] - ETA: 0s - loss: 0.0302 - accuracy: 0.9892\n",
      "Epoch 352: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 740us/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 0.0342 - val_accuracy: 0.9879\n",
      "Epoch 353/400\n",
      "1440/1468 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9895\n",
      "Epoch 353: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 695us/step - loss: 0.0296 - accuracy: 0.9895 - val_loss: 0.0336 - val_accuracy: 0.9877\n",
      "Epoch 354/400\n",
      "1391/1468 [===========================>..] - ETA: 0s - loss: 0.0302 - accuracy: 0.9892\n",
      "Epoch 354: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 711us/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0323 - val_accuracy: 0.9872\n",
      "Epoch 355/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1432/1468 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9892\n",
      "Epoch 355: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 703us/step - loss: 0.0299 - accuracy: 0.9892 - val_loss: 0.0320 - val_accuracy: 0.9896\n",
      "Epoch 356/400\n",
      "1465/1468 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9895\n",
      "Epoch 356: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 723us/step - loss: 0.0297 - accuracy: 0.9896 - val_loss: 0.0350 - val_accuracy: 0.9865\n",
      "Epoch 357/400\n",
      "1457/1468 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9889\n",
      "Epoch 357: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 756us/step - loss: 0.0296 - accuracy: 0.9890 - val_loss: 0.0317 - val_accuracy: 0.9877\n",
      "Epoch 358/400\n",
      "1402/1468 [===========================>..] - ETA: 0s - loss: 0.0293 - accuracy: 0.9896\n",
      "Epoch 358: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 747us/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.0319 - val_accuracy: 0.9887\n",
      "Epoch 359/400\n",
      "1407/1468 [===========================>..] - ETA: 0s - loss: 0.0295 - accuracy: 0.9901\n",
      "Epoch 359: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 730us/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 0.0315 - val_accuracy: 0.9887\n",
      "Epoch 360/400\n",
      "1402/1468 [===========================>..] - ETA: 0s - loss: 0.0296 - accuracy: 0.9893\n",
      "Epoch 360: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 723us/step - loss: 0.0297 - accuracy: 0.9894 - val_loss: 0.0322 - val_accuracy: 0.9879\n",
      "Epoch 361/400\n",
      "1406/1468 [===========================>..] - ETA: 0s - loss: 0.0295 - accuracy: 0.9898\n",
      "Epoch 361: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 705us/step - loss: 0.0296 - accuracy: 0.9897 - val_loss: 0.0315 - val_accuracy: 0.9889\n",
      "Epoch 362/400\n",
      "1409/1468 [===========================>..] - ETA: 0s - loss: 0.0293 - accuracy: 0.9900\n",
      "Epoch 362: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 701us/step - loss: 0.0295 - accuracy: 0.9899 - val_loss: 0.0333 - val_accuracy: 0.9882\n",
      "Epoch 363/400\n",
      "1422/1468 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9898\n",
      "Epoch 363: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 716us/step - loss: 0.0295 - accuracy: 0.9898 - val_loss: 0.0327 - val_accuracy: 0.9884\n",
      "Epoch 364/400\n",
      "1436/1468 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9901\n",
      "Epoch 364: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 696us/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 0.0328 - val_accuracy: 0.9875\n",
      "Epoch 365/400\n",
      "1459/1468 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9897\n",
      "Epoch 365: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 685us/step - loss: 0.0293 - accuracy: 0.9897 - val_loss: 0.0334 - val_accuracy: 0.9872\n",
      "Epoch 366/400\n",
      "1381/1468 [===========================>..] - ETA: 0s - loss: 0.0291 - accuracy: 0.9894\n",
      "Epoch 366: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 683us/step - loss: 0.0291 - accuracy: 0.9895 - val_loss: 0.0327 - val_accuracy: 0.9891\n",
      "Epoch 367/400\n",
      "1396/1468 [===========================>..] - ETA: 0s - loss: 0.0288 - accuracy: 0.9898\n",
      "Epoch 367: val_loss did not improve from 0.03084\n",
      "1468/1468 [==============================] - 1s 713us/step - loss: 0.0291 - accuracy: 0.9897 - val_loss: 0.0330 - val_accuracy: 0.9882\n",
      "Epoch 368/400\n",
      "1429/1468 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9899\n",
      "Epoch 368: val_loss improved from 0.03084 to 0.03046, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 748us/step - loss: 0.0291 - accuracy: 0.9900 - val_loss: 0.0305 - val_accuracy: 0.9894\n",
      "Epoch 369/400\n",
      "1410/1468 [===========================>..] - ETA: 0s - loss: 0.0292 - accuracy: 0.9895\n",
      "Epoch 369: val_loss did not improve from 0.03046\n",
      "1468/1468 [==============================] - 1s 671us/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.0315 - val_accuracy: 0.9894\n",
      "Epoch 370/400\n",
      "1439/1468 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9895\n",
      "Epoch 370: val_loss did not improve from 0.03046\n",
      "1468/1468 [==============================] - 1s 697us/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.0323 - val_accuracy: 0.9889\n",
      "Epoch 371/400\n",
      "1444/1468 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9900\n",
      "Epoch 371: val_loss did not improve from 0.03046\n",
      "1468/1468 [==============================] - 1s 706us/step - loss: 0.0291 - accuracy: 0.9900 - val_loss: 0.0317 - val_accuracy: 0.9884\n",
      "Epoch 372/400\n",
      "1404/1468 [===========================>..] - ETA: 0s - loss: 0.0294 - accuracy: 0.9898\n",
      "Epoch 372: val_loss did not improve from 0.03046\n",
      "1468/1468 [==============================] - 1s 710us/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.0318 - val_accuracy: 0.9884\n",
      "Epoch 373/400\n",
      "1429/1468 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9903\n",
      "Epoch 373: val_loss did not improve from 0.03046\n",
      "1468/1468 [==============================] - 1s 700us/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 0.0336 - val_accuracy: 0.9867\n",
      "Epoch 374/400\n",
      "1466/1468 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9900\n",
      "Epoch 374: val_loss did not improve from 0.03046\n",
      "1468/1468 [==============================] - 1s 717us/step - loss: 0.0291 - accuracy: 0.9900 - val_loss: 0.0316 - val_accuracy: 0.9884\n",
      "Epoch 375/400\n",
      "1389/1468 [===========================>..] - ETA: 0s - loss: 0.0294 - accuracy: 0.9901\n",
      "Epoch 375: val_loss improved from 0.03046 to 0.02992, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 684us/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.0299 - val_accuracy: 0.9899\n",
      "Epoch 376/400\n",
      "1451/1468 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9898\n",
      "Epoch 376: val_loss did not improve from 0.02992\n",
      "1468/1468 [==============================] - 1s 733us/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.0311 - val_accuracy: 0.9891\n",
      "Epoch 377/400\n",
      "1464/1468 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9902\n",
      "Epoch 377: val_loss did not improve from 0.02992\n",
      "1468/1468 [==============================] - 1s 787us/step - loss: 0.0287 - accuracy: 0.9902 - val_loss: 0.0319 - val_accuracy: 0.9882\n",
      "Epoch 378/400\n",
      "1409/1468 [===========================>..] - ETA: 0s - loss: 0.0290 - accuracy: 0.9894\n",
      "Epoch 378: val_loss did not improve from 0.02992\n",
      "1468/1468 [==============================] - 1s 707us/step - loss: 0.0290 - accuracy: 0.9894 - val_loss: 0.0320 - val_accuracy: 0.9891\n",
      "Epoch 379/400\n",
      "1425/1468 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9900\n",
      "Epoch 379: val_loss did not improve from 0.02992\n",
      "1468/1468 [==============================] - 1s 704us/step - loss: 0.0285 - accuracy: 0.9902 - val_loss: 0.0316 - val_accuracy: 0.9884\n",
      "Epoch 380/400\n",
      "1429/1468 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9897\n",
      "Epoch 380: val_loss did not improve from 0.02992\n",
      "1468/1468 [==============================] - 1s 703us/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.0319 - val_accuracy: 0.9882\n",
      "Epoch 381/400\n",
      "1422/1468 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9902\n",
      "Epoch 381: val_loss did not improve from 0.02992\n",
      "1468/1468 [==============================] - 1s 715us/step - loss: 0.0287 - accuracy: 0.9901 - val_loss: 0.0317 - val_accuracy: 0.9882\n",
      "Epoch 382/400\n",
      "1391/1468 [===========================>..] - ETA: 0s - loss: 0.0290 - accuracy: 0.9896\n",
      "Epoch 382: val_loss improved from 0.02992 to 0.02956, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 723us/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.0296 - val_accuracy: 0.9896\n",
      "Epoch 383/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1389/1468 [===========================>..] - ETA: 0s - loss: 0.0285 - accuracy: 0.9902\n",
      "Epoch 383: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 673us/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 0.0307 - val_accuracy: 0.9894\n",
      "Epoch 384/400\n",
      "1436/1468 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9899\n",
      "Epoch 384: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 691us/step - loss: 0.0286 - accuracy: 0.9899 - val_loss: 0.0296 - val_accuracy: 0.9896\n",
      "Epoch 385/400\n",
      "1448/1468 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9900\n",
      "Epoch 385: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 689us/step - loss: 0.0286 - accuracy: 0.9898 - val_loss: 0.0312 - val_accuracy: 0.9887\n",
      "Epoch 386/400\n",
      "1461/1468 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9898\n",
      "Epoch 386: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 722us/step - loss: 0.0285 - accuracy: 0.9898 - val_loss: 0.0302 - val_accuracy: 0.9889\n",
      "Epoch 387/400\n",
      "1450/1468 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9899\n",
      "Epoch 387: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 691us/step - loss: 0.0288 - accuracy: 0.9897 - val_loss: 0.0305 - val_accuracy: 0.9887\n",
      "Epoch 388/400\n",
      "1460/1468 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9898\n",
      "Epoch 388: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 682us/step - loss: 0.0283 - accuracy: 0.9898 - val_loss: 0.0321 - val_accuracy: 0.9887\n",
      "Epoch 389/400\n",
      "1382/1468 [===========================>..] - ETA: 0s - loss: 0.0285 - accuracy: 0.9900\n",
      "Epoch 389: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 675us/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 0.0325 - val_accuracy: 0.9875\n",
      "Epoch 390/400\n",
      "1426/1468 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9899\n",
      "Epoch 390: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 672us/step - loss: 0.0283 - accuracy: 0.9897 - val_loss: 0.0323 - val_accuracy: 0.9877\n",
      "Epoch 391/400\n",
      "1417/1468 [===========================>..] - ETA: 0s - loss: 0.0284 - accuracy: 0.9904\n",
      "Epoch 391: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 667us/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.0319 - val_accuracy: 0.9891\n",
      "Epoch 392/400\n",
      "1383/1468 [===========================>..] - ETA: 0s - loss: 0.0286 - accuracy: 0.9898\n",
      "Epoch 392: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 685us/step - loss: 0.0284 - accuracy: 0.9899 - val_loss: 0.0310 - val_accuracy: 0.9884\n",
      "Epoch 393/400\n",
      "1424/1468 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9901\n",
      "Epoch 393: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 657us/step - loss: 0.0284 - accuracy: 0.9901 - val_loss: 0.0311 - val_accuracy: 0.9875\n",
      "Epoch 394/400\n",
      "1406/1468 [===========================>..] - ETA: 0s - loss: 0.0284 - accuracy: 0.9901\n",
      "Epoch 394: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 663us/step - loss: 0.0282 - accuracy: 0.9902 - val_loss: 0.0302 - val_accuracy: 0.9882\n",
      "Epoch 395/400\n",
      "1464/1468 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9901\n",
      "Epoch 395: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 683us/step - loss: 0.0279 - accuracy: 0.9901 - val_loss: 0.0302 - val_accuracy: 0.9891\n",
      "Epoch 396/400\n",
      "1452/1468 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9902\n",
      "Epoch 396: val_loss improved from 0.02956 to 0.02956, saving model to ENOL3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "1468/1468 [==============================] - 1s 743us/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.0296 - val_accuracy: 0.9896\n",
      "Epoch 397/400\n",
      "1448/1468 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9899\n",
      "Epoch 397: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 725us/step - loss: 0.0282 - accuracy: 0.9898 - val_loss: 0.0307 - val_accuracy: 0.9889\n",
      "Epoch 398/400\n",
      "1456/1468 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9899\n",
      "Epoch 398: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 730us/step - loss: 0.0283 - accuracy: 0.9899 - val_loss: 0.0319 - val_accuracy: 0.9879\n",
      "Epoch 399/400\n",
      "1389/1468 [===========================>..] - ETA: 0s - loss: 0.0280 - accuracy: 0.9906\n",
      "Epoch 399: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 717us/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.0303 - val_accuracy: 0.9879\n",
      "Epoch 400/400\n",
      "1463/1468 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9901\n",
      "Epoch 400: val_loss did not improve from 0.02956\n",
      "1468/1468 [==============================] - 1s 765us/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.0296 - val_accuracy: 0.9896\n",
      "name weight ENOL3//model/trained_weights_Hn_7nonsmoothdata.mat\n",
      "153/153 [==============================] - 0s 527us/step\n",
      "here\n",
      "Accuracy  : 0.9874871794871795\n",
      "Precision : 0.9874999870594007\n",
      "f1Score : 0.987470615528889\n",
      "[[1533   11    0]\n",
      " [  24 2724    6]\n",
      " [   0   20  557]]\n",
      "train history is strored in ENOL3/History/history-Hn_7nonsmoothdata.dat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is union_data\n",
      "Data file being used is: ENOL3/train_input_union_data.csv\n",
      "In load data (64220, 6) (64220,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 49        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73 (584.00 Byte)\n",
      "Trainable params: 73 (584.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "2868/2900 [============================>.] - ETA: 0s - loss: 0.8064 - accuracy: 0.6448\n",
      "Epoch 1: val_loss improved from inf to 0.72151, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 3s 778us/step - loss: 0.8055 - accuracy: 0.6450 - val_loss: 0.7215 - val_accuracy: 0.6785\n",
      "Epoch 2/400\n",
      " 245/2900 [=>............................] - ETA: 1s - loss: 0.7309 - accuracy: 0.6793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\xai\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2826/2900 [============================>.] - ETA: 0s - loss: 0.6686 - accuracy: 0.7162\n",
      "Epoch 2: val_loss improved from 0.72151 to 0.61332, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 704us/step - loss: 0.6671 - accuracy: 0.7186 - val_loss: 0.6133 - val_accuracy: 0.7972\n",
      "Epoch 3/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.5760 - accuracy: 0.8166\n",
      "Epoch 3: val_loss improved from 0.61332 to 0.53638, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 677us/step - loss: 0.5754 - accuracy: 0.8169 - val_loss: 0.5364 - val_accuracy: 0.8262\n",
      "Epoch 4/400\n",
      "2857/2900 [============================>.] - ETA: 0s - loss: 0.5078 - accuracy: 0.8358\n",
      "Epoch 4: val_loss improved from 0.53638 to 0.47892, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 717us/step - loss: 0.5072 - accuracy: 0.8361 - val_loss: 0.4789 - val_accuracy: 0.8431\n",
      "Epoch 5/400\n",
      "2875/2900 [============================>.] - ETA: 0s - loss: 0.4642 - accuracy: 0.8531\n",
      "Epoch 5: val_loss improved from 0.47892 to 0.44705, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.4638 - accuracy: 0.8531 - val_loss: 0.4470 - val_accuracy: 0.8518\n",
      "Epoch 6/400\n",
      "2830/2900 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.8599\n",
      "Epoch 6: val_loss improved from 0.44705 to 0.42668, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.4385 - accuracy: 0.8599 - val_loss: 0.4267 - val_accuracy: 0.8604\n",
      "Epoch 7/400\n",
      "2848/2900 [============================>.] - ETA: 0s - loss: 0.4211 - accuracy: 0.8649\n",
      "Epoch 7: val_loss improved from 0.42668 to 0.41113, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 683us/step - loss: 0.4205 - accuracy: 0.8651 - val_loss: 0.4111 - val_accuracy: 0.8656\n",
      "Epoch 8/400\n",
      "2831/2900 [============================>.] - ETA: 0s - loss: 0.4014 - accuracy: 0.8714\n",
      "Epoch 8: val_loss improved from 0.41113 to 0.39134, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.4020 - accuracy: 0.8712 - val_loss: 0.3913 - val_accuracy: 0.8764\n",
      "Epoch 9/400\n",
      "2845/2900 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8798\n",
      "Epoch 9: val_loss improved from 0.39134 to 0.37750, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.3845 - accuracy: 0.8798 - val_loss: 0.3775 - val_accuracy: 0.8813\n",
      "Epoch 10/400\n",
      "2859/2900 [============================>.] - ETA: 0s - loss: 0.3724 - accuracy: 0.8832\n",
      "Epoch 10: val_loss improved from 0.37750 to 0.36599, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.3721 - accuracy: 0.8834 - val_loss: 0.3660 - val_accuracy: 0.8857\n",
      "Epoch 11/400\n",
      "2862/2900 [============================>.] - ETA: 0s - loss: 0.3632 - accuracy: 0.8847\n",
      "Epoch 11: val_loss improved from 0.36599 to 0.35943, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 703us/step - loss: 0.3635 - accuracy: 0.8846 - val_loss: 0.3594 - val_accuracy: 0.8845\n",
      "Epoch 12/400\n",
      "2833/2900 [============================>.] - ETA: 0s - loss: 0.3561 - accuracy: 0.8864\n",
      "Epoch 12: val_loss improved from 0.35943 to 0.35392, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.3562 - accuracy: 0.8861 - val_loss: 0.3539 - val_accuracy: 0.8870\n",
      "Epoch 13/400\n",
      "2869/2900 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.8885\n",
      "Epoch 13: val_loss improved from 0.35392 to 0.34721, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 702us/step - loss: 0.3507 - accuracy: 0.8885 - val_loss: 0.3472 - val_accuracy: 0.8858\n",
      "Epoch 14/400\n",
      "2829/2900 [============================>.] - ETA: 0s - loss: 0.3451 - accuracy: 0.8929\n",
      "Epoch 14: val_loss improved from 0.34721 to 0.34115, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 716us/step - loss: 0.3460 - accuracy: 0.8927 - val_loss: 0.3411 - val_accuracy: 0.8950\n",
      "Epoch 15/400\n",
      "2893/2900 [============================>.] - ETA: 0s - loss: 0.3423 - accuracy: 0.8949\n",
      "Epoch 15: val_loss improved from 0.34115 to 0.33876, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 715us/step - loss: 0.3421 - accuracy: 0.8949 - val_loss: 0.3388 - val_accuracy: 0.8912\n",
      "Epoch 16/400\n",
      "2876/2900 [============================>.] - ETA: 0s - loss: 0.3386 - accuracy: 0.8970\n",
      "Epoch 16: val_loss improved from 0.33876 to 0.33582, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 697us/step - loss: 0.3387 - accuracy: 0.8970 - val_loss: 0.3358 - val_accuracy: 0.8940\n",
      "Epoch 17/400\n",
      "2899/2900 [============================>.] - ETA: 0s - loss: 0.3360 - accuracy: 0.8987\n",
      "Epoch 17: val_loss improved from 0.33582 to 0.33358, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.3359 - accuracy: 0.8987 - val_loss: 0.3336 - val_accuracy: 0.8941\n",
      "Epoch 18/400\n",
      "2841/2900 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.9001\n",
      "Epoch 18: val_loss improved from 0.33358 to 0.33179, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 699us/step - loss: 0.3333 - accuracy: 0.9000 - val_loss: 0.3318 - val_accuracy: 0.9000\n",
      "Epoch 19/400\n",
      "2893/2900 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.9018\n",
      "Epoch 19: val_loss improved from 0.33179 to 0.32855, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 693us/step - loss: 0.3309 - accuracy: 0.9017 - val_loss: 0.3286 - val_accuracy: 0.9015\n",
      "Epoch 20/400\n",
      "2860/2900 [============================>.] - ETA: 0s - loss: 0.3286 - accuracy: 0.9030\n",
      "Epoch 20: val_loss improved from 0.32855 to 0.32652, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 721us/step - loss: 0.3288 - accuracy: 0.9030 - val_loss: 0.3265 - val_accuracy: 0.9043\n",
      "Epoch 21/400\n",
      "2854/2900 [============================>.] - ETA: 0s - loss: 0.3267 - accuracy: 0.9031\n",
      "Epoch 21: val_loss did not improve from 0.32652\n",
      "2900/2900 [==============================] - 2s 717us/step - loss: 0.3265 - accuracy: 0.9030 - val_loss: 0.3275 - val_accuracy: 0.8997\n",
      "Epoch 22/400\n",
      "2831/2900 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.9040\n",
      "Epoch 22: val_loss improved from 0.32652 to 0.32481, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 731us/step - loss: 0.3250 - accuracy: 0.9041 - val_loss: 0.3248 - val_accuracy: 0.9023\n",
      "Epoch 23/400\n",
      "2897/2900 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.9045\n",
      "Epoch 23: val_loss improved from 0.32481 to 0.32110, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 731us/step - loss: 0.3234 - accuracy: 0.9045 - val_loss: 0.3211 - val_accuracy: 0.9001\n",
      "Epoch 24/400\n",
      "2868/2900 [============================>.] - ETA: 0s - loss: 0.3221 - accuracy: 0.9048\n",
      "Epoch 24: val_loss improved from 0.32110 to 0.31975, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 715us/step - loss: 0.3220 - accuracy: 0.9048 - val_loss: 0.3197 - val_accuracy: 0.9035\n",
      "Epoch 25/400\n",
      "2860/2900 [============================>.] - ETA: 0s - loss: 0.3202 - accuracy: 0.9050\n",
      "Epoch 25: val_loss improved from 0.31975 to 0.31905, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 700us/step - loss: 0.3204 - accuracy: 0.9048 - val_loss: 0.3191 - val_accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/400\n",
      "2886/2900 [============================>.] - ETA: 0s - loss: 0.3194 - accuracy: 0.9055\n",
      "Epoch 26: val_loss did not improve from 0.31905\n",
      "2900/2900 [==============================] - 2s 670us/step - loss: 0.3191 - accuracy: 0.9056 - val_loss: 0.3197 - val_accuracy: 0.8995\n",
      "Epoch 27/400\n",
      "2866/2900 [============================>.] - ETA: 0s - loss: 0.3173 - accuracy: 0.9056\n",
      "Epoch 27: val_loss improved from 0.31905 to 0.31643, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 682us/step - loss: 0.3181 - accuracy: 0.9053 - val_loss: 0.3164 - val_accuracy: 0.9021\n",
      "Epoch 28/400\n",
      "2850/2900 [============================>.] - ETA: 0s - loss: 0.3168 - accuracy: 0.9066\n",
      "Epoch 28: val_loss did not improve from 0.31643\n",
      "2900/2900 [==============================] - 2s 721us/step - loss: 0.3171 - accuracy: 0.9066 - val_loss: 0.3167 - val_accuracy: 0.9166\n",
      "Epoch 29/400\n",
      "2822/2900 [============================>.] - ETA: 0s - loss: 0.3157 - accuracy: 0.9067\n",
      "Epoch 29: val_loss improved from 0.31643 to 0.31464, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 734us/step - loss: 0.3159 - accuracy: 0.9064 - val_loss: 0.3146 - val_accuracy: 0.9018\n",
      "Epoch 30/400\n",
      "2873/2900 [============================>.] - ETA: 0s - loss: 0.3147 - accuracy: 0.9074\n",
      "Epoch 30: val_loss did not improve from 0.31464\n",
      "2900/2900 [==============================] - 2s 748us/step - loss: 0.3146 - accuracy: 0.9074 - val_loss: 0.3147 - val_accuracy: 0.9023\n",
      "Epoch 31/400\n",
      "2851/2900 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.9063\n",
      "Epoch 31: val_loss improved from 0.31464 to 0.31233, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 711us/step - loss: 0.3141 - accuracy: 0.9064 - val_loss: 0.3123 - val_accuracy: 0.9007\n",
      "Epoch 32/400\n",
      "2841/2900 [============================>.] - ETA: 0s - loss: 0.3140 - accuracy: 0.9069\n",
      "Epoch 32: val_loss improved from 0.31233 to 0.31233, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 685us/step - loss: 0.3130 - accuracy: 0.9070 - val_loss: 0.3123 - val_accuracy: 0.9089\n",
      "Epoch 33/400\n",
      "2851/2900 [============================>.] - ETA: 0s - loss: 0.3124 - accuracy: 0.9083\n",
      "Epoch 33: val_loss improved from 0.31233 to 0.31189, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 717us/step - loss: 0.3121 - accuracy: 0.9081 - val_loss: 0.3119 - val_accuracy: 0.9029\n",
      "Epoch 34/400\n",
      "2897/2900 [============================>.] - ETA: 0s - loss: 0.3116 - accuracy: 0.9078\n",
      "Epoch 34: val_loss improved from 0.31189 to 0.31104, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 727us/step - loss: 0.3115 - accuracy: 0.9078 - val_loss: 0.3110 - val_accuracy: 0.8993\n",
      "Epoch 35/400\n",
      "2841/2900 [============================>.] - ETA: 0s - loss: 0.3104 - accuracy: 0.9084\n",
      "Epoch 35: val_loss improved from 0.31104 to 0.30891, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 733us/step - loss: 0.3104 - accuracy: 0.9085 - val_loss: 0.3089 - val_accuracy: 0.9013\n",
      "Epoch 36/400\n",
      "2822/2900 [============================>.] - ETA: 0s - loss: 0.3103 - accuracy: 0.9084\n",
      "Epoch 36: val_loss did not improve from 0.30891\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.3098 - accuracy: 0.9085 - val_loss: 0.3091 - val_accuracy: 0.9037\n",
      "Epoch 37/400\n",
      "2840/2900 [============================>.] - ETA: 0s - loss: 0.3087 - accuracy: 0.9084\n",
      "Epoch 37: val_loss improved from 0.30891 to 0.30759, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 681us/step - loss: 0.3089 - accuracy: 0.9082 - val_loss: 0.3076 - val_accuracy: 0.9121\n",
      "Epoch 38/400\n",
      "2821/2900 [============================>.] - ETA: 0s - loss: 0.3092 - accuracy: 0.9095\n",
      "Epoch 38: val_loss did not improve from 0.30759\n",
      "2900/2900 [==============================] - 2s 676us/step - loss: 0.3081 - accuracy: 0.9096 - val_loss: 0.3094 - val_accuracy: 0.9001\n",
      "Epoch 39/400\n",
      "2871/2900 [============================>.] - ETA: 0s - loss: 0.3072 - accuracy: 0.9095\n",
      "Epoch 39: val_loss improved from 0.30759 to 0.30676, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 677us/step - loss: 0.3071 - accuracy: 0.9094 - val_loss: 0.3068 - val_accuracy: 0.9054\n",
      "Epoch 40/400\n",
      "2852/2900 [============================>.] - ETA: 0s - loss: 0.3069 - accuracy: 0.9097\n",
      "Epoch 40: val_loss improved from 0.30676 to 0.30632, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 704us/step - loss: 0.3071 - accuracy: 0.9096 - val_loss: 0.3063 - val_accuracy: 0.9051\n",
      "Epoch 41/400\n",
      "2886/2900 [============================>.] - ETA: 0s - loss: 0.3064 - accuracy: 0.9102\n",
      "Epoch 41: val_loss improved from 0.30632 to 0.30447, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 691us/step - loss: 0.3061 - accuracy: 0.9103 - val_loss: 0.3045 - val_accuracy: 0.9082\n",
      "Epoch 42/400\n",
      "2849/2900 [============================>.] - ETA: 0s - loss: 0.3054 - accuracy: 0.9100\n",
      "Epoch 42: val_loss did not improve from 0.30447\n",
      "2900/2900 [==============================] - 2s 699us/step - loss: 0.3056 - accuracy: 0.9101 - val_loss: 0.3048 - val_accuracy: 0.9007\n",
      "Epoch 43/400\n",
      "2823/2900 [============================>.] - ETA: 0s - loss: 0.3051 - accuracy: 0.9106\n",
      "Epoch 43: val_loss improved from 0.30447 to 0.30359, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 759us/step - loss: 0.3048 - accuracy: 0.9107 - val_loss: 0.3036 - val_accuracy: 0.9101\n",
      "Epoch 44/400\n",
      "2861/2900 [============================>.] - ETA: 0s - loss: 0.3041 - accuracy: 0.9108\n",
      "Epoch 44: val_loss did not improve from 0.30359\n",
      "2900/2900 [==============================] - 2s 707us/step - loss: 0.3043 - accuracy: 0.9107 - val_loss: 0.3042 - val_accuracy: 0.9050\n",
      "Epoch 45/400\n",
      "2848/2900 [============================>.] - ETA: 0s - loss: 0.3033 - accuracy: 0.9116\n",
      "Epoch 45: val_loss did not improve from 0.30359\n",
      "2900/2900 [==============================] - 2s 695us/step - loss: 0.3040 - accuracy: 0.9114 - val_loss: 0.3040 - val_accuracy: 0.9077\n",
      "Epoch 46/400\n",
      "2886/2900 [============================>.] - ETA: 0s - loss: 0.3033 - accuracy: 0.9119\n",
      "Epoch 46: val_loss improved from 0.30359 to 0.30229, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 732us/step - loss: 0.3034 - accuracy: 0.9119 - val_loss: 0.3023 - val_accuracy: 0.9067\n",
      "Epoch 47/400\n",
      "2875/2900 [============================>.] - ETA: 0s - loss: 0.3035 - accuracy: 0.9113\n",
      "Epoch 47: val_loss did not improve from 0.30229\n",
      "2900/2900 [==============================] - 2s 711us/step - loss: 0.3030 - accuracy: 0.9114 - val_loss: 0.3059 - val_accuracy: 0.9058\n",
      "Epoch 48/400\n",
      "2899/2900 [============================>.] - ETA: 0s - loss: 0.3026 - accuracy: 0.9120\n",
      "Epoch 48: val_loss improved from 0.30229 to 0.30067, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 715us/step - loss: 0.3026 - accuracy: 0.9120 - val_loss: 0.3007 - val_accuracy: 0.9057\n",
      "Epoch 49/400\n",
      "2838/2900 [============================>.] - ETA: 0s - loss: 0.3026 - accuracy: 0.9116\n",
      "Epoch 49: val_loss did not improve from 0.30067\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.3018 - accuracy: 0.9119 - val_loss: 0.3027 - val_accuracy: 0.9045\n",
      "Epoch 50/400\n",
      "2825/2900 [============================>.] - ETA: 0s - loss: 0.3025 - accuracy: 0.9123\n",
      "Epoch 50: val_loss improved from 0.30067 to 0.30053, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 730us/step - loss: 0.3017 - accuracy: 0.9128 - val_loss: 0.3005 - val_accuracy: 0.9048\n",
      "Epoch 51/400\n",
      "2900/2900 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.9119\n",
      "Epoch 51: val_loss did not improve from 0.30053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900/2900 [==============================] - 2s 720us/step - loss: 0.3014 - accuracy: 0.9119 - val_loss: 0.3038 - val_accuracy: 0.9022\n",
      "Epoch 52/400\n",
      "2897/2900 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.9124\n",
      "Epoch 52: val_loss improved from 0.30053 to 0.29979, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.3004 - accuracy: 0.9123 - val_loss: 0.2998 - val_accuracy: 0.9029\n",
      "Epoch 53/400\n",
      "2897/2900 [============================>.] - ETA: 0s - loss: 0.3008 - accuracy: 0.9121\n",
      "Epoch 53: val_loss improved from 0.29979 to 0.29977, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 706us/step - loss: 0.3009 - accuracy: 0.9121 - val_loss: 0.2998 - val_accuracy: 0.9106\n",
      "Epoch 54/400\n",
      "2827/2900 [============================>.] - ETA: 0s - loss: 0.3007 - accuracy: 0.9121\n",
      "Epoch 54: val_loss did not improve from 0.29977\n",
      "2900/2900 [==============================] - 2s 664us/step - loss: 0.3001 - accuracy: 0.9123 - val_loss: 0.3002 - val_accuracy: 0.9085\n",
      "Epoch 55/400\n",
      "2850/2900 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.9125\n",
      "Epoch 55: val_loss improved from 0.29977 to 0.29950, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.3001 - accuracy: 0.9127 - val_loss: 0.2995 - val_accuracy: 0.9096\n",
      "Epoch 56/400\n",
      "2824/2900 [============================>.] - ETA: 0s - loss: 0.2991 - accuracy: 0.9130\n",
      "Epoch 56: val_loss improved from 0.29950 to 0.29811, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 706us/step - loss: 0.2991 - accuracy: 0.9131 - val_loss: 0.2981 - val_accuracy: 0.9087\n",
      "Epoch 57/400\n",
      "2900/2900 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.9128\n",
      "Epoch 57: val_loss improved from 0.29811 to 0.29806, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 707us/step - loss: 0.2988 - accuracy: 0.9128 - val_loss: 0.2981 - val_accuracy: 0.9077\n",
      "Epoch 58/400\n",
      "2898/2900 [============================>.] - ETA: 0s - loss: 0.2986 - accuracy: 0.9135\n",
      "Epoch 58: val_loss improved from 0.29806 to 0.29724, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 710us/step - loss: 0.2986 - accuracy: 0.9135 - val_loss: 0.2972 - val_accuracy: 0.9134\n",
      "Epoch 59/400\n",
      "2889/2900 [============================>.] - ETA: 0s - loss: 0.2982 - accuracy: 0.9132\n",
      "Epoch 59: val_loss improved from 0.29724 to 0.29686, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 678us/step - loss: 0.2981 - accuracy: 0.9133 - val_loss: 0.2969 - val_accuracy: 0.9078\n",
      "Epoch 60/400\n",
      "2887/2900 [============================>.] - ETA: 0s - loss: 0.2976 - accuracy: 0.9138\n",
      "Epoch 60: val_loss did not improve from 0.29686\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2974 - accuracy: 0.9138 - val_loss: 0.2977 - val_accuracy: 0.9065\n",
      "Epoch 61/400\n",
      "2827/2900 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.9144\n",
      "Epoch 61: val_loss did not improve from 0.29686\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2976 - accuracy: 0.9145 - val_loss: 0.2991 - val_accuracy: 0.9068\n",
      "Epoch 62/400\n",
      "2833/2900 [============================>.] - ETA: 0s - loss: 0.2970 - accuracy: 0.9138\n",
      "Epoch 62: val_loss improved from 0.29686 to 0.29516, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 707us/step - loss: 0.2971 - accuracy: 0.9137 - val_loss: 0.2952 - val_accuracy: 0.9157\n",
      "Epoch 63/400\n",
      "2896/2900 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.9141\n",
      "Epoch 63: val_loss improved from 0.29516 to 0.29511, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 692us/step - loss: 0.2971 - accuracy: 0.9142 - val_loss: 0.2951 - val_accuracy: 0.9084\n",
      "Epoch 64/400\n",
      "2884/2900 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.9147\n",
      "Epoch 64: val_loss did not improve from 0.29511\n",
      "2900/2900 [==============================] - 2s 705us/step - loss: 0.2963 - accuracy: 0.9148 - val_loss: 0.2964 - val_accuracy: 0.9080\n",
      "Epoch 65/400\n",
      "2893/2900 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.9142\n",
      "Epoch 65: val_loss did not improve from 0.29511\n",
      "2900/2900 [==============================] - 2s 721us/step - loss: 0.2963 - accuracy: 0.9142 - val_loss: 0.3027 - val_accuracy: 0.9117\n",
      "Epoch 66/400\n",
      "2830/2900 [============================>.] - ETA: 0s - loss: 0.2959 - accuracy: 0.9145\n",
      "Epoch 66: val_loss improved from 0.29511 to 0.29499, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 705us/step - loss: 0.2964 - accuracy: 0.9145 - val_loss: 0.2950 - val_accuracy: 0.9170\n",
      "Epoch 67/400\n",
      "2849/2900 [============================>.] - ETA: 0s - loss: 0.2957 - accuracy: 0.9149\n",
      "Epoch 67: val_loss did not improve from 0.29499\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.2960 - accuracy: 0.9147 - val_loss: 0.2993 - val_accuracy: 0.9095\n",
      "Epoch 68/400\n",
      "2833/2900 [============================>.] - ETA: 0s - loss: 0.2945 - accuracy: 0.9150\n",
      "Epoch 68: val_loss did not improve from 0.29499\n",
      "2900/2900 [==============================] - 2s 680us/step - loss: 0.2952 - accuracy: 0.9149 - val_loss: 0.2959 - val_accuracy: 0.9102\n",
      "Epoch 69/400\n",
      "2865/2900 [============================>.] - ETA: 0s - loss: 0.2955 - accuracy: 0.9149\n",
      "Epoch 69: val_loss improved from 0.29499 to 0.29465, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 698us/step - loss: 0.2950 - accuracy: 0.9149 - val_loss: 0.2947 - val_accuracy: 0.9078\n",
      "Epoch 70/400\n",
      "2850/2900 [============================>.] - ETA: 0s - loss: 0.2942 - accuracy: 0.9150\n",
      "Epoch 70: val_loss improved from 0.29465 to 0.29424, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 700us/step - loss: 0.2949 - accuracy: 0.9147 - val_loss: 0.2942 - val_accuracy: 0.9133\n",
      "Epoch 71/400\n",
      "2842/2900 [============================>.] - ETA: 0s - loss: 0.2940 - accuracy: 0.9148\n",
      "Epoch 71: val_loss did not improve from 0.29424\n",
      "2900/2900 [==============================] - 2s 698us/step - loss: 0.2947 - accuracy: 0.9147 - val_loss: 0.2967 - val_accuracy: 0.9151\n",
      "Epoch 72/400\n",
      "2865/2900 [============================>.] - ETA: 0s - loss: 0.2950 - accuracy: 0.9153\n",
      "Epoch 72: val_loss improved from 0.29424 to 0.29340, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 678us/step - loss: 0.2942 - accuracy: 0.9156 - val_loss: 0.2934 - val_accuracy: 0.9078\n",
      "Epoch 73/400\n",
      "2841/2900 [============================>.] - ETA: 0s - loss: 0.2942 - accuracy: 0.9154\n",
      "Epoch 73: val_loss did not improve from 0.29340\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.2942 - accuracy: 0.9153 - val_loss: 0.2960 - val_accuracy: 0.9192\n",
      "Epoch 74/400\n",
      "2814/2900 [============================>.] - ETA: 0s - loss: 0.2933 - accuracy: 0.9157\n",
      "Epoch 74: val_loss improved from 0.29340 to 0.29178, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.2936 - accuracy: 0.9155 - val_loss: 0.2918 - val_accuracy: 0.9124\n",
      "Epoch 75/400\n",
      "2855/2900 [============================>.] - ETA: 0s - loss: 0.2936 - accuracy: 0.9151\n",
      "Epoch 75: val_loss improved from 0.29178 to 0.29159, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 697us/step - loss: 0.2935 - accuracy: 0.9152 - val_loss: 0.2916 - val_accuracy: 0.9080\n",
      "Epoch 76/400\n",
      "2898/2900 [============================>.] - ETA: 0s - loss: 0.2937 - accuracy: 0.9155\n",
      "Epoch 76: val_loss improved from 0.29159 to 0.29099, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 707us/step - loss: 0.2936 - accuracy: 0.9155 - val_loss: 0.2910 - val_accuracy: 0.9128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/400\n",
      "2846/2900 [============================>.] - ETA: 0s - loss: 0.2935 - accuracy: 0.9157\n",
      "Epoch 77: val_loss did not improve from 0.29099\n",
      "2900/2900 [==============================] - 2s 699us/step - loss: 0.2932 - accuracy: 0.9158 - val_loss: 0.2927 - val_accuracy: 0.9126\n",
      "Epoch 78/400\n",
      "2878/2900 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.9163\n",
      "Epoch 78: val_loss did not improve from 0.29099\n",
      "2900/2900 [==============================] - 2s 723us/step - loss: 0.2928 - accuracy: 0.9163 - val_loss: 0.2924 - val_accuracy: 0.9079\n",
      "Epoch 79/400\n",
      "2894/2900 [============================>.] - ETA: 0s - loss: 0.2924 - accuracy: 0.9161\n",
      "Epoch 79: val_loss did not improve from 0.29099\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2924 - accuracy: 0.9161 - val_loss: 0.2949 - val_accuracy: 0.9088\n",
      "Epoch 80/400\n",
      "2895/2900 [============================>.] - ETA: 0s - loss: 0.2919 - accuracy: 0.9165\n",
      "Epoch 80: val_loss did not improve from 0.29099\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2919 - accuracy: 0.9165 - val_loss: 0.2921 - val_accuracy: 0.9210\n",
      "Epoch 81/400\n",
      "2879/2900 [============================>.] - ETA: 0s - loss: 0.2918 - accuracy: 0.9158\n",
      "Epoch 81: val_loss did not improve from 0.29099\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2916 - accuracy: 0.9159 - val_loss: 0.2920 - val_accuracy: 0.9093\n",
      "Epoch 82/400\n",
      "2842/2900 [============================>.] - ETA: 0s - loss: 0.2912 - accuracy: 0.9166\n",
      "Epoch 82: val_loss did not improve from 0.29099\n",
      "2900/2900 [==============================] - 2s 700us/step - loss: 0.2916 - accuracy: 0.9165 - val_loss: 0.2926 - val_accuracy: 0.9126\n",
      "Epoch 83/400\n",
      "2869/2900 [============================>.] - ETA: 0s - loss: 0.2918 - accuracy: 0.9168\n",
      "Epoch 83: val_loss did not improve from 0.29099\n",
      "2900/2900 [==============================] - 2s 692us/step - loss: 0.2917 - accuracy: 0.9167 - val_loss: 0.2913 - val_accuracy: 0.9096\n",
      "Epoch 84/400\n",
      "2854/2900 [============================>.] - ETA: 0s - loss: 0.2914 - accuracy: 0.9167\n",
      "Epoch 84: val_loss improved from 0.29099 to 0.29008, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.2912 - accuracy: 0.9166 - val_loss: 0.2901 - val_accuracy: 0.9159\n",
      "Epoch 85/400\n",
      "2863/2900 [============================>.] - ETA: 0s - loss: 0.2902 - accuracy: 0.9166\n",
      "Epoch 85: val_loss did not improve from 0.29008\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2908 - accuracy: 0.9163 - val_loss: 0.2904 - val_accuracy: 0.9142\n",
      "Epoch 86/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2905 - accuracy: 0.9167\n",
      "Epoch 86: val_loss did not improve from 0.29008\n",
      "2900/2900 [==============================] - 2s 705us/step - loss: 0.2903 - accuracy: 0.9169 - val_loss: 0.2912 - val_accuracy: 0.9160\n",
      "Epoch 87/400\n",
      "2859/2900 [============================>.] - ETA: 0s - loss: 0.2902 - accuracy: 0.9174\n",
      "Epoch 87: val_loss improved from 0.29008 to 0.28917, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 700us/step - loss: 0.2906 - accuracy: 0.9173 - val_loss: 0.2892 - val_accuracy: 0.9123\n",
      "Epoch 88/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.2898 - accuracy: 0.9174\n",
      "Epoch 88: val_loss did not improve from 0.28917\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.2902 - accuracy: 0.9174 - val_loss: 0.2908 - val_accuracy: 0.9074\n",
      "Epoch 89/400\n",
      "2829/2900 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.9168\n",
      "Epoch 89: val_loss improved from 0.28917 to 0.28776, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 691us/step - loss: 0.2896 - accuracy: 0.9170 - val_loss: 0.2878 - val_accuracy: 0.9183\n",
      "Epoch 90/400\n",
      "2863/2900 [============================>.] - ETA: 0s - loss: 0.2895 - accuracy: 0.9185\n",
      "Epoch 90: val_loss did not improve from 0.28776\n",
      "2900/2900 [==============================] - 2s 697us/step - loss: 0.2895 - accuracy: 0.9184 - val_loss: 0.2927 - val_accuracy: 0.9138\n",
      "Epoch 91/400\n",
      "2848/2900 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.9169\n",
      "Epoch 91: val_loss did not improve from 0.28776\n",
      "2900/2900 [==============================] - 2s 698us/step - loss: 0.2895 - accuracy: 0.9172 - val_loss: 0.2884 - val_accuracy: 0.9099\n",
      "Epoch 92/400\n",
      "2889/2900 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.9184\n",
      "Epoch 92: val_loss did not improve from 0.28776\n",
      "2900/2900 [==============================] - 2s 691us/step - loss: 0.2888 - accuracy: 0.9184 - val_loss: 0.2899 - val_accuracy: 0.9087\n",
      "Epoch 93/400\n",
      "2896/2900 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.9178\n",
      "Epoch 93: val_loss did not improve from 0.28776\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2888 - accuracy: 0.9178 - val_loss: 0.2887 - val_accuracy: 0.9194\n",
      "Epoch 94/400\n",
      "2849/2900 [============================>.] - ETA: 0s - loss: 0.2887 - accuracy: 0.9185\n",
      "Epoch 94: val_loss improved from 0.28776 to 0.28608, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 703us/step - loss: 0.2887 - accuracy: 0.9184 - val_loss: 0.2861 - val_accuracy: 0.9176\n",
      "Epoch 95/400\n",
      "2879/2900 [============================>.] - ETA: 0s - loss: 0.2882 - accuracy: 0.9177\n",
      "Epoch 95: val_loss did not improve from 0.28608\n",
      "2900/2900 [==============================] - 2s 694us/step - loss: 0.2885 - accuracy: 0.9175 - val_loss: 0.2907 - val_accuracy: 0.9157\n",
      "Epoch 96/400\n",
      "2842/2900 [============================>.] - ETA: 0s - loss: 0.2877 - accuracy: 0.9183\n",
      "Epoch 96: val_loss did not improve from 0.28608\n",
      "2900/2900 [==============================] - 2s 705us/step - loss: 0.2884 - accuracy: 0.9181 - val_loss: 0.2871 - val_accuracy: 0.9137\n",
      "Epoch 97/400\n",
      "2825/2900 [============================>.] - ETA: 0s - loss: 0.2885 - accuracy: 0.9175\n",
      "Epoch 97: val_loss did not improve from 0.28608\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.2881 - accuracy: 0.9178 - val_loss: 0.2873 - val_accuracy: 0.9111\n",
      "Epoch 98/400\n",
      "2863/2900 [============================>.] - ETA: 0s - loss: 0.2883 - accuracy: 0.9178\n",
      "Epoch 98: val_loss did not improve from 0.28608\n",
      "2900/2900 [==============================] - 2s 695us/step - loss: 0.2878 - accuracy: 0.9182 - val_loss: 0.2862 - val_accuracy: 0.9217\n",
      "Epoch 99/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.2877 - accuracy: 0.9188\n",
      "Epoch 99: val_loss did not improve from 0.28608\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2879 - accuracy: 0.9188 - val_loss: 0.2864 - val_accuracy: 0.9159\n",
      "Epoch 100/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2877 - accuracy: 0.9175\n",
      "Epoch 100: val_loss improved from 0.28608 to 0.28605, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 712us/step - loss: 0.2877 - accuracy: 0.9176 - val_loss: 0.2861 - val_accuracy: 0.9178\n",
      "Epoch 101/400\n",
      "2820/2900 [============================>.] - ETA: 0s - loss: 0.2880 - accuracy: 0.9175\n",
      "Epoch 101: val_loss did not improve from 0.28605\n",
      "2900/2900 [==============================] - 2s 706us/step - loss: 0.2873 - accuracy: 0.9177 - val_loss: 0.2882 - val_accuracy: 0.9117\n",
      "Epoch 102/400\n",
      "2859/2900 [============================>.] - ETA: 0s - loss: 0.2876 - accuracy: 0.9181\n",
      "Epoch 102: val_loss did not improve from 0.28605\n",
      "2900/2900 [==============================] - 2s 715us/step - loss: 0.2872 - accuracy: 0.9183 - val_loss: 0.2866 - val_accuracy: 0.9188\n",
      "Epoch 103/400\n",
      "2820/2900 [============================>.] - ETA: 0s - loss: 0.2863 - accuracy: 0.9184\n",
      "Epoch 103: val_loss did not improve from 0.28605\n",
      "2900/2900 [==============================] - 2s 702us/step - loss: 0.2872 - accuracy: 0.9183 - val_loss: 0.2872 - val_accuracy: 0.9179\n",
      "Epoch 104/400\n",
      "2896/2900 [============================>.] - ETA: 0s - loss: 0.2867 - accuracy: 0.9176\n",
      "Epoch 104: val_loss improved from 0.28605 to 0.28559, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900/2900 [==============================] - 2s 707us/step - loss: 0.2866 - accuracy: 0.9176 - val_loss: 0.2856 - val_accuracy: 0.9127\n",
      "Epoch 105/400\n",
      "2850/2900 [============================>.] - ETA: 0s - loss: 0.2871 - accuracy: 0.9184\n",
      "Epoch 105: val_loss did not improve from 0.28559\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.2870 - accuracy: 0.9184 - val_loss: 0.2899 - val_accuracy: 0.9084\n",
      "Epoch 106/400\n",
      "2858/2900 [============================>.] - ETA: 0s - loss: 0.2862 - accuracy: 0.9178\n",
      "Epoch 106: val_loss improved from 0.28559 to 0.28492, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 721us/step - loss: 0.2863 - accuracy: 0.9176 - val_loss: 0.2849 - val_accuracy: 0.9170\n",
      "Epoch 107/400\n",
      "2835/2900 [============================>.] - ETA: 0s - loss: 0.2864 - accuracy: 0.9186\n",
      "Epoch 107: val_loss did not improve from 0.28492\n",
      "2900/2900 [==============================] - 2s 703us/step - loss: 0.2864 - accuracy: 0.9186 - val_loss: 0.2880 - val_accuracy: 0.9110\n",
      "Epoch 108/400\n",
      "2886/2900 [============================>.] - ETA: 0s - loss: 0.2859 - accuracy: 0.9179\n",
      "Epoch 108: val_loss did not improve from 0.28492\n",
      "2900/2900 [==============================] - 2s 728us/step - loss: 0.2863 - accuracy: 0.9178 - val_loss: 0.2852 - val_accuracy: 0.9210\n",
      "Epoch 109/400\n",
      "2829/2900 [============================>.] - ETA: 0s - loss: 0.2857 - accuracy: 0.9179\n",
      "Epoch 109: val_loss improved from 0.28492 to 0.28471, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 725us/step - loss: 0.2855 - accuracy: 0.9180 - val_loss: 0.2847 - val_accuracy: 0.9182\n",
      "Epoch 110/400\n",
      "2894/2900 [============================>.] - ETA: 0s - loss: 0.2858 - accuracy: 0.9183\n",
      "Epoch 110: val_loss improved from 0.28471 to 0.28406, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 716us/step - loss: 0.2858 - accuracy: 0.9183 - val_loss: 0.2841 - val_accuracy: 0.9168\n",
      "Epoch 111/400\n",
      "2875/2900 [============================>.] - ETA: 0s - loss: 0.2857 - accuracy: 0.9182\n",
      "Epoch 111: val_loss did not improve from 0.28406\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2854 - accuracy: 0.9183 - val_loss: 0.2876 - val_accuracy: 0.9167\n",
      "Epoch 112/400\n",
      "2821/2900 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.9186\n",
      "Epoch 112: val_loss improved from 0.28406 to 0.28338, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2853 - accuracy: 0.9185 - val_loss: 0.2834 - val_accuracy: 0.9102\n",
      "Epoch 113/400\n",
      "2849/2900 [============================>.] - ETA: 0s - loss: 0.2854 - accuracy: 0.9177\n",
      "Epoch 113: val_loss did not improve from 0.28338\n",
      "2900/2900 [==============================] - 2s 714us/step - loss: 0.2853 - accuracy: 0.9178 - val_loss: 0.2868 - val_accuracy: 0.9134\n",
      "Epoch 114/400\n",
      "2817/2900 [============================>.] - ETA: 0s - loss: 0.2852 - accuracy: 0.9183\n",
      "Epoch 114: val_loss did not improve from 0.28338\n",
      "2900/2900 [==============================] - 2s 726us/step - loss: 0.2850 - accuracy: 0.9184 - val_loss: 0.2845 - val_accuracy: 0.9133\n",
      "Epoch 115/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.2851 - accuracy: 0.9178\n",
      "Epoch 115: val_loss did not improve from 0.28338\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2848 - accuracy: 0.9179 - val_loss: 0.2854 - val_accuracy: 0.9211\n",
      "Epoch 116/400\n",
      "2832/2900 [============================>.] - ETA: 0s - loss: 0.2845 - accuracy: 0.9187\n",
      "Epoch 116: val_loss did not improve from 0.28338\n",
      "2900/2900 [==============================] - 2s 703us/step - loss: 0.2844 - accuracy: 0.9190 - val_loss: 0.2855 - val_accuracy: 0.9228\n",
      "Epoch 117/400\n",
      "2825/2900 [============================>.] - ETA: 0s - loss: 0.2847 - accuracy: 0.9185\n",
      "Epoch 117: val_loss did not improve from 0.28338\n",
      "2900/2900 [==============================] - 2s 710us/step - loss: 0.2845 - accuracy: 0.9187 - val_loss: 0.2840 - val_accuracy: 0.9127\n",
      "Epoch 118/400\n",
      "2849/2900 [============================>.] - ETA: 0s - loss: 0.2839 - accuracy: 0.9184\n",
      "Epoch 118: val_loss did not improve from 0.28338\n",
      "2900/2900 [==============================] - 2s 716us/step - loss: 0.2839 - accuracy: 0.9185 - val_loss: 0.2836 - val_accuracy: 0.9123\n",
      "Epoch 119/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2841 - accuracy: 0.9182\n",
      "Epoch 119: val_loss did not improve from 0.28338\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2841 - accuracy: 0.9183 - val_loss: 0.2853 - val_accuracy: 0.9161\n",
      "Epoch 120/400\n",
      "2856/2900 [============================>.] - ETA: 0s - loss: 0.2845 - accuracy: 0.9182\n",
      "Epoch 120: val_loss did not improve from 0.28338\n",
      "2900/2900 [==============================] - 2s 715us/step - loss: 0.2838 - accuracy: 0.9186 - val_loss: 0.2879 - val_accuracy: 0.9121\n",
      "Epoch 121/400\n",
      "2898/2900 [============================>.] - ETA: 0s - loss: 0.2836 - accuracy: 0.9190\n",
      "Epoch 121: val_loss did not improve from 0.28338\n",
      "2900/2900 [==============================] - 2s 726us/step - loss: 0.2835 - accuracy: 0.9190 - val_loss: 0.2841 - val_accuracy: 0.9179\n",
      "Epoch 122/400\n",
      "2827/2900 [============================>.] - ETA: 0s - loss: 0.2840 - accuracy: 0.9182\n",
      "Epoch 122: val_loss improved from 0.28338 to 0.28173, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 725us/step - loss: 0.2835 - accuracy: 0.9182 - val_loss: 0.2817 - val_accuracy: 0.9109\n",
      "Epoch 123/400\n",
      "2831/2900 [============================>.] - ETA: 0s - loss: 0.2829 - accuracy: 0.9182\n",
      "Epoch 123: val_loss did not improve from 0.28173\n",
      "2900/2900 [==============================] - 2s 699us/step - loss: 0.2835 - accuracy: 0.9181 - val_loss: 0.2837 - val_accuracy: 0.9173\n",
      "Epoch 124/400\n",
      "2850/2900 [============================>.] - ETA: 0s - loss: 0.2828 - accuracy: 0.9177\n",
      "Epoch 124: val_loss did not improve from 0.28173\n",
      "2900/2900 [==============================] - 2s 707us/step - loss: 0.2827 - accuracy: 0.9178 - val_loss: 0.2818 - val_accuracy: 0.9096\n",
      "Epoch 125/400\n",
      "2857/2900 [============================>.] - ETA: 0s - loss: 0.2829 - accuracy: 0.9182\n",
      "Epoch 125: val_loss did not improve from 0.28173\n",
      "2900/2900 [==============================] - 2s 711us/step - loss: 0.2831 - accuracy: 0.9181 - val_loss: 0.2817 - val_accuracy: 0.9137\n",
      "Epoch 126/400\n",
      "2859/2900 [============================>.] - ETA: 0s - loss: 0.2831 - accuracy: 0.9175\n",
      "Epoch 126: val_loss did not improve from 0.28173\n",
      "2900/2900 [==============================] - 2s 697us/step - loss: 0.2829 - accuracy: 0.9176 - val_loss: 0.2844 - val_accuracy: 0.9195\n",
      "Epoch 127/400\n",
      "2864/2900 [============================>.] - ETA: 0s - loss: 0.2825 - accuracy: 0.9183\n",
      "Epoch 127: val_loss did not improve from 0.28173\n",
      "2900/2900 [==============================] - 2s 695us/step - loss: 0.2821 - accuracy: 0.9184 - val_loss: 0.2823 - val_accuracy: 0.9144\n",
      "Epoch 128/400\n",
      "2891/2900 [============================>.] - ETA: 0s - loss: 0.2823 - accuracy: 0.9181\n",
      "Epoch 128: val_loss did not improve from 0.28173\n",
      "2900/2900 [==============================] - 2s 704us/step - loss: 0.2823 - accuracy: 0.9181 - val_loss: 0.2837 - val_accuracy: 0.9137\n",
      "Epoch 129/400\n",
      "2815/2900 [============================>.] - ETA: 0s - loss: 0.2815 - accuracy: 0.9184\n",
      "Epoch 129: val_loss improved from 0.28173 to 0.28127, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2823 - accuracy: 0.9180 - val_loss: 0.2813 - val_accuracy: 0.9172\n",
      "Epoch 130/400\n",
      "2848/2900 [============================>.] - ETA: 0s - loss: 0.2813 - accuracy: 0.9181\n",
      "Epoch 130: val_loss did not improve from 0.28127\n",
      "2900/2900 [==============================] - 2s 716us/step - loss: 0.2819 - accuracy: 0.9178 - val_loss: 0.2878 - val_accuracy: 0.9128\n",
      "Epoch 131/400\n",
      "2874/2900 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.9188\n",
      "Epoch 131: val_loss improved from 0.28127 to 0.28041, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.2816 - accuracy: 0.9188 - val_loss: 0.2804 - val_accuracy: 0.9162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/400\n",
      "2866/2900 [============================>.] - ETA: 0s - loss: 0.2812 - accuracy: 0.9184\n",
      "Epoch 132: val_loss did not improve from 0.28041\n",
      "2900/2900 [==============================] - 2s 708us/step - loss: 0.2815 - accuracy: 0.9183 - val_loss: 0.2833 - val_accuracy: 0.9156\n",
      "Epoch 133/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2817 - accuracy: 0.9180\n",
      "Epoch 133: val_loss improved from 0.28041 to 0.28017, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 692us/step - loss: 0.2815 - accuracy: 0.9181 - val_loss: 0.2802 - val_accuracy: 0.9145\n",
      "Epoch 134/400\n",
      "2856/2900 [============================>.] - ETA: 0s - loss: 0.2819 - accuracy: 0.9182\n",
      "Epoch 134: val_loss improved from 0.28017 to 0.27982, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 702us/step - loss: 0.2818 - accuracy: 0.9181 - val_loss: 0.2798 - val_accuracy: 0.9131\n",
      "Epoch 135/400\n",
      "2832/2900 [============================>.] - ETA: 0s - loss: 0.2823 - accuracy: 0.9180\n",
      "Epoch 135: val_loss did not improve from 0.27982\n",
      "2900/2900 [==============================] - 2s 685us/step - loss: 0.2814 - accuracy: 0.9185 - val_loss: 0.2803 - val_accuracy: 0.9172\n",
      "Epoch 136/400\n",
      "2835/2900 [============================>.] - ETA: 0s - loss: 0.2809 - accuracy: 0.9178\n",
      "Epoch 136: val_loss improved from 0.27982 to 0.27950, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2810 - accuracy: 0.9178 - val_loss: 0.2795 - val_accuracy: 0.9159\n",
      "Epoch 137/400\n",
      "2838/2900 [============================>.] - ETA: 0s - loss: 0.2811 - accuracy: 0.9182\n",
      "Epoch 137: val_loss did not improve from 0.27950\n",
      "2900/2900 [==============================] - 2s 686us/step - loss: 0.2811 - accuracy: 0.9182 - val_loss: 0.2811 - val_accuracy: 0.9217\n",
      "Epoch 138/400\n",
      "2873/2900 [============================>.] - ETA: 0s - loss: 0.2805 - accuracy: 0.9180\n",
      "Epoch 138: val_loss did not improve from 0.27950\n",
      "2900/2900 [==============================] - 2s 692us/step - loss: 0.2806 - accuracy: 0.9179 - val_loss: 0.2797 - val_accuracy: 0.9149\n",
      "Epoch 139/400\n",
      "2884/2900 [============================>.] - ETA: 0s - loss: 0.2798 - accuracy: 0.9184\n",
      "Epoch 139: val_loss did not improve from 0.27950\n",
      "2900/2900 [==============================] - 2s 713us/step - loss: 0.2803 - accuracy: 0.9183 - val_loss: 0.2809 - val_accuracy: 0.9161\n",
      "Epoch 140/400\n",
      "2864/2900 [============================>.] - ETA: 0s - loss: 0.2804 - accuracy: 0.9182\n",
      "Epoch 140: val_loss did not improve from 0.27950\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.2806 - accuracy: 0.9181 - val_loss: 0.2806 - val_accuracy: 0.9154\n",
      "Epoch 141/400\n",
      "2897/2900 [============================>.] - ETA: 0s - loss: 0.2805 - accuracy: 0.9172\n",
      "Epoch 141: val_loss did not improve from 0.27950\n",
      "2900/2900 [==============================] - 2s 702us/step - loss: 0.2804 - accuracy: 0.9172 - val_loss: 0.2800 - val_accuracy: 0.9176\n",
      "Epoch 142/400\n",
      "2828/2900 [============================>.] - ETA: 0s - loss: 0.2813 - accuracy: 0.9178\n",
      "Epoch 142: val_loss improved from 0.27950 to 0.27815, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 703us/step - loss: 0.2801 - accuracy: 0.9181 - val_loss: 0.2782 - val_accuracy: 0.9149\n",
      "Epoch 143/400\n",
      "2887/2900 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.9172\n",
      "Epoch 143: val_loss did not improve from 0.27815\n",
      "2900/2900 [==============================] - 2s 703us/step - loss: 0.2803 - accuracy: 0.9172 - val_loss: 0.2842 - val_accuracy: 0.9139\n",
      "Epoch 144/400\n",
      "2847/2900 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.9181\n",
      "Epoch 144: val_loss did not improve from 0.27815\n",
      "2900/2900 [==============================] - 2s 698us/step - loss: 0.2801 - accuracy: 0.9182 - val_loss: 0.2808 - val_accuracy: 0.9122\n",
      "Epoch 145/400\n",
      "2828/2900 [============================>.] - ETA: 0s - loss: 0.2802 - accuracy: 0.9179\n",
      "Epoch 145: val_loss did not improve from 0.27815\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.2801 - accuracy: 0.9181 - val_loss: 0.2794 - val_accuracy: 0.9239\n",
      "Epoch 146/400\n",
      "2838/2900 [============================>.] - ETA: 0s - loss: 0.2796 - accuracy: 0.9183\n",
      "Epoch 146: val_loss did not improve from 0.27815\n",
      "2900/2900 [==============================] - 2s 699us/step - loss: 0.2796 - accuracy: 0.9185 - val_loss: 0.2793 - val_accuracy: 0.9118\n",
      "Epoch 147/400\n",
      "2898/2900 [============================>.] - ETA: 0s - loss: 0.2796 - accuracy: 0.9178\n",
      "Epoch 147: val_loss did not improve from 0.27815\n",
      "2900/2900 [==============================] - 2s 705us/step - loss: 0.2796 - accuracy: 0.9178 - val_loss: 0.2801 - val_accuracy: 0.9194\n",
      "Epoch 148/400\n",
      "2855/2900 [============================>.] - ETA: 0s - loss: 0.2784 - accuracy: 0.9188\n",
      "Epoch 148: val_loss did not improve from 0.27815\n",
      "2900/2900 [==============================] - 2s 693us/step - loss: 0.2788 - accuracy: 0.9186 - val_loss: 0.2847 - val_accuracy: 0.9127\n",
      "Epoch 149/400\n",
      "2821/2900 [============================>.] - ETA: 0s - loss: 0.2794 - accuracy: 0.9178\n",
      "Epoch 149: val_loss did not improve from 0.27815\n",
      "2900/2900 [==============================] - 2s 704us/step - loss: 0.2795 - accuracy: 0.9178 - val_loss: 0.2819 - val_accuracy: 0.9123\n",
      "Epoch 150/400\n",
      "2878/2900 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.9177\n",
      "Epoch 150: val_loss did not improve from 0.27815\n",
      "2900/2900 [==============================] - 2s 687us/step - loss: 0.2794 - accuracy: 0.9178 - val_loss: 0.2832 - val_accuracy: 0.9170\n",
      "Epoch 151/400\n",
      "2882/2900 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.9180\n",
      "Epoch 151: val_loss did not improve from 0.27815\n",
      "2900/2900 [==============================] - 2s 687us/step - loss: 0.2785 - accuracy: 0.9180 - val_loss: 0.2799 - val_accuracy: 0.9140\n",
      "Epoch 152/400\n",
      "2890/2900 [============================>.] - ETA: 0s - loss: 0.2787 - accuracy: 0.9173\n",
      "Epoch 152: val_loss did not improve from 0.27815\n",
      "2900/2900 [==============================] - 2s 706us/step - loss: 0.2788 - accuracy: 0.9172 - val_loss: 0.2804 - val_accuracy: 0.9120\n",
      "Epoch 153/400\n",
      "2843/2900 [============================>.] - ETA: 0s - loss: 0.2790 - accuracy: 0.9180\n",
      "Epoch 153: val_loss improved from 0.27815 to 0.27775, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.2790 - accuracy: 0.9178 - val_loss: 0.2778 - val_accuracy: 0.9160\n",
      "Epoch 154/400\n",
      "2822/2900 [============================>.] - ETA: 0s - loss: 0.2781 - accuracy: 0.9181\n",
      "Epoch 154: val_loss did not improve from 0.27775\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.2786 - accuracy: 0.9179 - val_loss: 0.2819 - val_accuracy: 0.9120\n",
      "Epoch 155/400\n",
      "2890/2900 [============================>.] - ETA: 0s - loss: 0.2785 - accuracy: 0.9181\n",
      "Epoch 155: val_loss did not improve from 0.27775\n",
      "2900/2900 [==============================] - 2s 685us/step - loss: 0.2786 - accuracy: 0.9180 - val_loss: 0.2780 - val_accuracy: 0.9140\n",
      "Epoch 156/400\n",
      "2829/2900 [============================>.] - ETA: 0s - loss: 0.2781 - accuracy: 0.9189\n",
      "Epoch 156: val_loss did not improve from 0.27775\n",
      "2900/2900 [==============================] - 2s 699us/step - loss: 0.2779 - accuracy: 0.9191 - val_loss: 0.2805 - val_accuracy: 0.9187\n",
      "Epoch 157/400\n",
      "2877/2900 [============================>.] - ETA: 0s - loss: 0.2782 - accuracy: 0.9181\n",
      "Epoch 157: val_loss did not improve from 0.27775\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2780 - accuracy: 0.9181 - val_loss: 0.2826 - val_accuracy: 0.9187\n",
      "Epoch 158/400\n",
      "2877/2900 [============================>.] - ETA: 0s - loss: 0.2782 - accuracy: 0.9176\n",
      "Epoch 158: val_loss improved from 0.27775 to 0.27715, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 711us/step - loss: 0.2782 - accuracy: 0.9177 - val_loss: 0.2772 - val_accuracy: 0.9212\n",
      "Epoch 159/400\n",
      "2840/2900 [============================>.] - ETA: 0s - loss: 0.2781 - accuracy: 0.9181\n",
      "Epoch 159: val_loss did not improve from 0.27715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900/2900 [==============================] - 2s 675us/step - loss: 0.2780 - accuracy: 0.9183 - val_loss: 0.2826 - val_accuracy: 0.9137\n",
      "Epoch 160/400\n",
      "2829/2900 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.9173\n",
      "Epoch 160: val_loss did not improve from 0.27715\n",
      "2900/2900 [==============================] - 2s 677us/step - loss: 0.2781 - accuracy: 0.9176 - val_loss: 0.2799 - val_accuracy: 0.9151\n",
      "Epoch 161/400\n",
      "2877/2900 [============================>.] - ETA: 0s - loss: 0.2777 - accuracy: 0.9179\n",
      "Epoch 161: val_loss did not improve from 0.27715\n",
      "2900/2900 [==============================] - 2s 686us/step - loss: 0.2777 - accuracy: 0.9180 - val_loss: 0.2783 - val_accuracy: 0.9091\n",
      "Epoch 162/400\n",
      "2883/2900 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.9181\n",
      "Epoch 162: val_loss did not improve from 0.27715\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2774 - accuracy: 0.9182 - val_loss: 0.2773 - val_accuracy: 0.9171\n",
      "Epoch 163/400\n",
      "2897/2900 [============================>.] - ETA: 0s - loss: 0.2770 - accuracy: 0.9177\n",
      "Epoch 163: val_loss did not improve from 0.27715\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2771 - accuracy: 0.9177 - val_loss: 0.2793 - val_accuracy: 0.9175\n",
      "Epoch 164/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.9181\n",
      "Epoch 164: val_loss did not improve from 0.27715\n",
      "2900/2900 [==============================] - 2s 710us/step - loss: 0.2770 - accuracy: 0.9182 - val_loss: 0.2818 - val_accuracy: 0.9233\n",
      "Epoch 165/400\n",
      "2854/2900 [============================>.] - ETA: 0s - loss: 0.2777 - accuracy: 0.9183\n",
      "Epoch 165: val_loss did not improve from 0.27715\n",
      "2900/2900 [==============================] - 2s 700us/step - loss: 0.2770 - accuracy: 0.9185 - val_loss: 0.2805 - val_accuracy: 0.9134\n",
      "Epoch 166/400\n",
      "2837/2900 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.9177\n",
      "Epoch 166: val_loss did not improve from 0.27715\n",
      "2900/2900 [==============================] - 2s 686us/step - loss: 0.2769 - accuracy: 0.9179 - val_loss: 0.2780 - val_accuracy: 0.9115\n",
      "Epoch 167/400\n",
      "2840/2900 [============================>.] - ETA: 0s - loss: 0.2766 - accuracy: 0.9176\n",
      "Epoch 167: val_loss did not improve from 0.27715\n",
      "2900/2900 [==============================] - 2s 680us/step - loss: 0.2767 - accuracy: 0.9176 - val_loss: 0.2774 - val_accuracy: 0.9150\n",
      "Epoch 168/400\n",
      "2893/2900 [============================>.] - ETA: 0s - loss: 0.2761 - accuracy: 0.9173\n",
      "Epoch 168: val_loss did not improve from 0.27715\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.2760 - accuracy: 0.9173 - val_loss: 0.2776 - val_accuracy: 0.9135\n",
      "Epoch 169/400\n",
      "2822/2900 [============================>.] - ETA: 0s - loss: 0.2763 - accuracy: 0.9182\n",
      "Epoch 169: val_loss improved from 0.27715 to 0.27656, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 669us/step - loss: 0.2765 - accuracy: 0.9183 - val_loss: 0.2766 - val_accuracy: 0.9193\n",
      "Epoch 170/400\n",
      "2862/2900 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.9175\n",
      "Epoch 170: val_loss did not improve from 0.27656\n",
      "2900/2900 [==============================] - 2s 678us/step - loss: 0.2763 - accuracy: 0.9176 - val_loss: 0.2797 - val_accuracy: 0.9183\n",
      "Epoch 171/400\n",
      "2821/2900 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.9185\n",
      "Epoch 171: val_loss did not improve from 0.27656\n",
      "2900/2900 [==============================] - 2s 681us/step - loss: 0.2764 - accuracy: 0.9179 - val_loss: 0.2789 - val_accuracy: 0.9135\n",
      "Epoch 172/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.9185\n",
      "Epoch 172: val_loss did not improve from 0.27656\n",
      "2900/2900 [==============================] - 2s 693us/step - loss: 0.2764 - accuracy: 0.9185 - val_loss: 0.2780 - val_accuracy: 0.9118\n",
      "Epoch 173/400\n",
      "2869/2900 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.9176\n",
      "Epoch 173: val_loss did not improve from 0.27656\n",
      "2900/2900 [==============================] - 2s 675us/step - loss: 0.2763 - accuracy: 0.9176 - val_loss: 0.2767 - val_accuracy: 0.9120\n",
      "Epoch 174/400\n",
      "2861/2900 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.9182\n",
      "Epoch 174: val_loss did not improve from 0.27656\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.2760 - accuracy: 0.9183 - val_loss: 0.2768 - val_accuracy: 0.9087\n",
      "Epoch 175/400\n",
      "2897/2900 [============================>.] - ETA: 0s - loss: 0.2760 - accuracy: 0.9181\n",
      "Epoch 175: val_loss improved from 0.27656 to 0.27568, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 667us/step - loss: 0.2759 - accuracy: 0.9181 - val_loss: 0.2757 - val_accuracy: 0.9199\n",
      "Epoch 176/400\n",
      "2894/2900 [============================>.] - ETA: 0s - loss: 0.2756 - accuracy: 0.9174\n",
      "Epoch 176: val_loss did not improve from 0.27568\n",
      "2900/2900 [==============================] - 2s 667us/step - loss: 0.2757 - accuracy: 0.9173 - val_loss: 0.2767 - val_accuracy: 0.9176\n",
      "Epoch 177/400\n",
      "2816/2900 [============================>.] - ETA: 0s - loss: 0.2754 - accuracy: 0.9187\n",
      "Epoch 177: val_loss improved from 0.27568 to 0.27413, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 669us/step - loss: 0.2756 - accuracy: 0.9185 - val_loss: 0.2741 - val_accuracy: 0.9179\n",
      "Epoch 178/400\n",
      "2869/2900 [============================>.] - ETA: 0s - loss: 0.2750 - accuracy: 0.9183\n",
      "Epoch 178: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 693us/step - loss: 0.2754 - accuracy: 0.9182 - val_loss: 0.2760 - val_accuracy: 0.9175\n",
      "Epoch 179/400\n",
      "2871/2900 [============================>.] - ETA: 0s - loss: 0.2755 - accuracy: 0.9180\n",
      "Epoch 179: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 692us/step - loss: 0.2754 - accuracy: 0.9179 - val_loss: 0.2755 - val_accuracy: 0.9116\n",
      "Epoch 180/400\n",
      "2829/2900 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.9175\n",
      "Epoch 180: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 681us/step - loss: 0.2754 - accuracy: 0.9176 - val_loss: 0.2754 - val_accuracy: 0.9193\n",
      "Epoch 181/400\n",
      "2867/2900 [============================>.] - ETA: 0s - loss: 0.2750 - accuracy: 0.9173\n",
      "Epoch 181: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 678us/step - loss: 0.2751 - accuracy: 0.9173 - val_loss: 0.2797 - val_accuracy: 0.9149\n",
      "Epoch 182/400\n",
      "2841/2900 [============================>.] - ETA: 0s - loss: 0.2753 - accuracy: 0.9173\n",
      "Epoch 182: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 702us/step - loss: 0.2753 - accuracy: 0.9175 - val_loss: 0.2767 - val_accuracy: 0.9134\n",
      "Epoch 183/400\n",
      "2812/2900 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.9181\n",
      "Epoch 183: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.2745 - accuracy: 0.9179 - val_loss: 0.2777 - val_accuracy: 0.9134\n",
      "Epoch 184/400\n",
      "2880/2900 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.9179\n",
      "Epoch 184: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 668us/step - loss: 0.2750 - accuracy: 0.9178 - val_loss: 0.2775 - val_accuracy: 0.9150\n",
      "Epoch 185/400\n",
      "2863/2900 [============================>.] - ETA: 0s - loss: 0.2745 - accuracy: 0.9178\n",
      "Epoch 185: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 686us/step - loss: 0.2748 - accuracy: 0.9177 - val_loss: 0.2745 - val_accuracy: 0.9122\n",
      "Epoch 186/400\n",
      "2825/2900 [============================>.] - ETA: 0s - loss: 0.2747 - accuracy: 0.9170\n",
      "Epoch 186: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 678us/step - loss: 0.2746 - accuracy: 0.9174 - val_loss: 0.2760 - val_accuracy: 0.9160\n",
      "Epoch 187/400\n",
      "2827/2900 [============================>.] - ETA: 0s - loss: 0.2749 - accuracy: 0.9177\n",
      "Epoch 187: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 698us/step - loss: 0.2745 - accuracy: 0.9178 - val_loss: 0.2786 - val_accuracy: 0.9165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/400\n",
      "2853/2900 [============================>.] - ETA: 0s - loss: 0.2745 - accuracy: 0.9180\n",
      "Epoch 188: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 676us/step - loss: 0.2745 - accuracy: 0.9180 - val_loss: 0.2744 - val_accuracy: 0.9154\n",
      "Epoch 189/400\n",
      "2831/2900 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.9176\n",
      "Epoch 189: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 681us/step - loss: 0.2743 - accuracy: 0.9175 - val_loss: 0.2764 - val_accuracy: 0.9199\n",
      "Epoch 190/400\n",
      "2847/2900 [============================>.] - ETA: 0s - loss: 0.2753 - accuracy: 0.9173\n",
      "Epoch 190: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 677us/step - loss: 0.2746 - accuracy: 0.9175 - val_loss: 0.2795 - val_accuracy: 0.9156\n",
      "Epoch 191/400\n",
      "2838/2900 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.9177\n",
      "Epoch 191: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 679us/step - loss: 0.2739 - accuracy: 0.9175 - val_loss: 0.2784 - val_accuracy: 0.9144\n",
      "Epoch 192/400\n",
      "2876/2900 [============================>.] - ETA: 0s - loss: 0.2744 - accuracy: 0.9187\n",
      "Epoch 192: val_loss did not improve from 0.27413\n",
      "2900/2900 [==============================] - 2s 691us/step - loss: 0.2743 - accuracy: 0.9187 - val_loss: 0.2771 - val_accuracy: 0.9164\n",
      "Epoch 193/400\n",
      "2828/2900 [============================>.] - ETA: 0s - loss: 0.2745 - accuracy: 0.9173\n",
      "Epoch 193: val_loss improved from 0.27413 to 0.27405, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2738 - accuracy: 0.9175 - val_loss: 0.2741 - val_accuracy: 0.9173\n",
      "Epoch 194/400\n",
      "2864/2900 [============================>.] - ETA: 0s - loss: 0.2741 - accuracy: 0.9173\n",
      "Epoch 194: val_loss did not improve from 0.27405\n",
      "2900/2900 [==============================] - 2s 691us/step - loss: 0.2740 - accuracy: 0.9175 - val_loss: 0.2756 - val_accuracy: 0.9215\n",
      "Epoch 195/400\n",
      "2859/2900 [============================>.] - ETA: 0s - loss: 0.2737 - accuracy: 0.9181\n",
      "Epoch 195: val_loss did not improve from 0.27405\n",
      "2900/2900 [==============================] - 2s 678us/step - loss: 0.2739 - accuracy: 0.9181 - val_loss: 0.2752 - val_accuracy: 0.9133\n",
      "Epoch 196/400\n",
      "2860/2900 [============================>.] - ETA: 0s - loss: 0.2726 - accuracy: 0.9185\n",
      "Epoch 196: val_loss did not improve from 0.27405\n",
      "2900/2900 [==============================] - 2s 678us/step - loss: 0.2736 - accuracy: 0.9182 - val_loss: 0.2747 - val_accuracy: 0.9126\n",
      "Epoch 197/400\n",
      "2855/2900 [============================>.] - ETA: 0s - loss: 0.2739 - accuracy: 0.9174\n",
      "Epoch 197: val_loss did not improve from 0.27405\n",
      "2900/2900 [==============================] - 2s 674us/step - loss: 0.2738 - accuracy: 0.9172 - val_loss: 0.2746 - val_accuracy: 0.9170\n",
      "Epoch 198/400\n",
      "2885/2900 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.9179\n",
      "Epoch 198: val_loss did not improve from 0.27405\n",
      "2900/2900 [==============================] - 2s 669us/step - loss: 0.2735 - accuracy: 0.9178 - val_loss: 0.2756 - val_accuracy: 0.9207\n",
      "Epoch 199/400\n",
      "2817/2900 [============================>.] - ETA: 0s - loss: 0.2732 - accuracy: 0.9182\n",
      "Epoch 199: val_loss did not improve from 0.27405\n",
      "2900/2900 [==============================] - 2s 674us/step - loss: 0.2734 - accuracy: 0.9181 - val_loss: 0.2774 - val_accuracy: 0.9124\n",
      "Epoch 200/400\n",
      "2900/2900 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.9174\n",
      "Epoch 200: val_loss improved from 0.27405 to 0.27250, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 675us/step - loss: 0.2733 - accuracy: 0.9174 - val_loss: 0.2725 - val_accuracy: 0.9156\n",
      "Epoch 201/400\n",
      "2884/2900 [============================>.] - ETA: 0s - loss: 0.2732 - accuracy: 0.9178\n",
      "Epoch 201: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 668us/step - loss: 0.2734 - accuracy: 0.9178 - val_loss: 0.2757 - val_accuracy: 0.9182\n",
      "Epoch 202/400\n",
      "2825/2900 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.9176\n",
      "Epoch 202: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 679us/step - loss: 0.2735 - accuracy: 0.9177 - val_loss: 0.2747 - val_accuracy: 0.9178\n",
      "Epoch 203/400\n",
      "2864/2900 [============================>.] - ETA: 0s - loss: 0.2726 - accuracy: 0.9184\n",
      "Epoch 203: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 675us/step - loss: 0.2727 - accuracy: 0.9183 - val_loss: 0.2800 - val_accuracy: 0.9166\n",
      "Epoch 204/400\n",
      "2853/2900 [============================>.] - ETA: 0s - loss: 0.2732 - accuracy: 0.9178\n",
      "Epoch 204: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 673us/step - loss: 0.2731 - accuracy: 0.9181 - val_loss: 0.2746 - val_accuracy: 0.9166\n",
      "Epoch 205/400\n",
      "2869/2900 [============================>.] - ETA: 0s - loss: 0.2727 - accuracy: 0.9176\n",
      "Epoch 205: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 675us/step - loss: 0.2726 - accuracy: 0.9178 - val_loss: 0.2764 - val_accuracy: 0.9176\n",
      "Epoch 206/400\n",
      "2827/2900 [============================>.] - ETA: 0s - loss: 0.2728 - accuracy: 0.9182\n",
      "Epoch 206: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 680us/step - loss: 0.2729 - accuracy: 0.9183 - val_loss: 0.2728 - val_accuracy: 0.9176\n",
      "Epoch 207/400\n",
      "2873/2900 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9171\n",
      "Epoch 207: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 669us/step - loss: 0.2728 - accuracy: 0.9172 - val_loss: 0.2733 - val_accuracy: 0.9177\n",
      "Epoch 208/400\n",
      "2873/2900 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.9182\n",
      "Epoch 208: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 667us/step - loss: 0.2728 - accuracy: 0.9182 - val_loss: 0.2739 - val_accuracy: 0.9170\n",
      "Epoch 209/400\n",
      "2868/2900 [============================>.] - ETA: 0s - loss: 0.2728 - accuracy: 0.9176\n",
      "Epoch 209: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 670us/step - loss: 0.2728 - accuracy: 0.9175 - val_loss: 0.2748 - val_accuracy: 0.9082\n",
      "Epoch 210/400\n",
      "2857/2900 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9173\n",
      "Epoch 210: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 675us/step - loss: 0.2728 - accuracy: 0.9171 - val_loss: 0.2747 - val_accuracy: 0.9215\n",
      "Epoch 211/400\n",
      "2883/2900 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.9183\n",
      "Epoch 211: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 703us/step - loss: 0.2726 - accuracy: 0.9183 - val_loss: 0.2776 - val_accuracy: 0.9079\n",
      "Epoch 212/400\n",
      "2849/2900 [============================>.] - ETA: 0s - loss: 0.2724 - accuracy: 0.9166\n",
      "Epoch 212: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 710us/step - loss: 0.2722 - accuracy: 0.9169 - val_loss: 0.2740 - val_accuracy: 0.9121\n",
      "Epoch 213/400\n",
      "2823/2900 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.9180\n",
      "Epoch 213: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.2724 - accuracy: 0.9182 - val_loss: 0.2738 - val_accuracy: 0.9183\n",
      "Epoch 214/400\n",
      "2857/2900 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9179\n",
      "Epoch 214: val_loss did not improve from 0.27250\n",
      "2900/2900 [==============================] - 2s 674us/step - loss: 0.2721 - accuracy: 0.9181 - val_loss: 0.2766 - val_accuracy: 0.9178\n",
      "Epoch 215/400\n",
      "2818/2900 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9183\n",
      "Epoch 215: val_loss improved from 0.27250 to 0.27234, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 674us/step - loss: 0.2718 - accuracy: 0.9183 - val_loss: 0.2723 - val_accuracy: 0.9146\n",
      "Epoch 216/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825/2900 [============================>.] - ETA: 0s - loss: 0.2719 - accuracy: 0.9170\n",
      "Epoch 216: val_loss did not improve from 0.27234\n",
      "2900/2900 [==============================] - 2s 665us/step - loss: 0.2719 - accuracy: 0.9168 - val_loss: 0.2757 - val_accuracy: 0.9072\n",
      "Epoch 217/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.2725 - accuracy: 0.9173\n",
      "Epoch 217: val_loss did not improve from 0.27234\n",
      "2900/2900 [==============================] - 2s 672us/step - loss: 0.2715 - accuracy: 0.9177 - val_loss: 0.2756 - val_accuracy: 0.9184\n",
      "Epoch 218/400\n",
      "2830/2900 [============================>.] - ETA: 0s - loss: 0.2717 - accuracy: 0.9181\n",
      "Epoch 218: val_loss did not improve from 0.27234\n",
      "2900/2900 [==============================] - 2s 681us/step - loss: 0.2715 - accuracy: 0.9181 - val_loss: 0.2745 - val_accuracy: 0.9091\n",
      "Epoch 219/400\n",
      "2852/2900 [============================>.] - ETA: 0s - loss: 0.2716 - accuracy: 0.9178\n",
      "Epoch 219: val_loss did not improve from 0.27234\n",
      "2900/2900 [==============================] - 2s 694us/step - loss: 0.2717 - accuracy: 0.9177 - val_loss: 0.2756 - val_accuracy: 0.9144\n",
      "Epoch 220/400\n",
      "2851/2900 [============================>.] - ETA: 0s - loss: 0.2718 - accuracy: 0.9176\n",
      "Epoch 220: val_loss did not improve from 0.27234\n",
      "2900/2900 [==============================] - 2s 675us/step - loss: 0.2720 - accuracy: 0.9175 - val_loss: 0.2757 - val_accuracy: 0.9245\n",
      "Epoch 221/400\n",
      "2853/2900 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.9176\n",
      "Epoch 221: val_loss improved from 0.27234 to 0.27227, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.2722 - accuracy: 0.9177 - val_loss: 0.2723 - val_accuracy: 0.9175\n",
      "Epoch 222/400\n",
      "2822/2900 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9175\n",
      "Epoch 222: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 703us/step - loss: 0.2718 - accuracy: 0.9172 - val_loss: 0.2747 - val_accuracy: 0.9238\n",
      "Epoch 223/400\n",
      "2841/2900 [============================>.] - ETA: 0s - loss: 0.2711 - accuracy: 0.9181\n",
      "Epoch 223: val_loss improved from 0.27227 to 0.27227, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 680us/step - loss: 0.2716 - accuracy: 0.9181 - val_loss: 0.2723 - val_accuracy: 0.9118\n",
      "Epoch 224/400\n",
      "2849/2900 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.9177\n",
      "Epoch 224: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 695us/step - loss: 0.2715 - accuracy: 0.9178 - val_loss: 0.2747 - val_accuracy: 0.9153\n",
      "Epoch 225/400\n",
      "2833/2900 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9178\n",
      "Epoch 225: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.2708 - accuracy: 0.9178 - val_loss: 0.2790 - val_accuracy: 0.9137\n",
      "Epoch 226/400\n",
      "2827/2900 [============================>.] - ETA: 0s - loss: 0.2713 - accuracy: 0.9180\n",
      "Epoch 226: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 679us/step - loss: 0.2715 - accuracy: 0.9182 - val_loss: 0.2772 - val_accuracy: 0.9126\n",
      "Epoch 227/400\n",
      "2853/2900 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9174\n",
      "Epoch 227: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 673us/step - loss: 0.2712 - accuracy: 0.9173 - val_loss: 0.2724 - val_accuracy: 0.9162\n",
      "Epoch 228/400\n",
      "2843/2900 [============================>.] - ETA: 0s - loss: 0.2716 - accuracy: 0.9178\n",
      "Epoch 228: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 675us/step - loss: 0.2715 - accuracy: 0.9179 - val_loss: 0.2740 - val_accuracy: 0.9162\n",
      "Epoch 229/400\n",
      "2893/2900 [============================>.] - ETA: 0s - loss: 0.2711 - accuracy: 0.9178\n",
      "Epoch 229: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.2710 - accuracy: 0.9178 - val_loss: 0.2760 - val_accuracy: 0.9083\n",
      "Epoch 230/400\n",
      "2895/2900 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.9171\n",
      "Epoch 230: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.2714 - accuracy: 0.9172 - val_loss: 0.2731 - val_accuracy: 0.9143\n",
      "Epoch 231/400\n",
      "2876/2900 [============================>.] - ETA: 0s - loss: 0.2716 - accuracy: 0.9174\n",
      "Epoch 231: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 668us/step - loss: 0.2716 - accuracy: 0.9175 - val_loss: 0.2726 - val_accuracy: 0.9207\n",
      "Epoch 232/400\n",
      "2857/2900 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.9191\n",
      "Epoch 232: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 697us/step - loss: 0.2706 - accuracy: 0.9189 - val_loss: 0.2765 - val_accuracy: 0.9100\n",
      "Epoch 233/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2716 - accuracy: 0.9171\n",
      "Epoch 233: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 693us/step - loss: 0.2714 - accuracy: 0.9171 - val_loss: 0.2725 - val_accuracy: 0.9227\n",
      "Epoch 234/400\n",
      "2859/2900 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.9174\n",
      "Epoch 234: val_loss did not improve from 0.27227\n",
      "2900/2900 [==============================] - 2s 683us/step - loss: 0.2712 - accuracy: 0.9175 - val_loss: 0.2739 - val_accuracy: 0.9206\n",
      "Epoch 235/400\n",
      "2878/2900 [============================>.] - ETA: 0s - loss: 0.2711 - accuracy: 0.9175\n",
      "Epoch 235: val_loss improved from 0.27227 to 0.27211, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.2711 - accuracy: 0.9175 - val_loss: 0.2721 - val_accuracy: 0.9183\n",
      "Epoch 236/400\n",
      "2900/2900 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.9176\n",
      "Epoch 236: val_loss did not improve from 0.27211\n",
      "2900/2900 [==============================] - 2s 686us/step - loss: 0.2706 - accuracy: 0.9176 - val_loss: 0.2752 - val_accuracy: 0.9242\n",
      "Epoch 237/400\n",
      "2855/2900 [============================>.] - ETA: 0s - loss: 0.2706 - accuracy: 0.9187\n",
      "Epoch 237: val_loss did not improve from 0.27211\n",
      "2900/2900 [==============================] - 2s 683us/step - loss: 0.2707 - accuracy: 0.9184 - val_loss: 0.2726 - val_accuracy: 0.9177\n",
      "Epoch 238/400\n",
      "2875/2900 [============================>.] - ETA: 0s - loss: 0.2710 - accuracy: 0.9189\n",
      "Epoch 238: val_loss did not improve from 0.27211\n",
      "2900/2900 [==============================] - 2s 685us/step - loss: 0.2708 - accuracy: 0.9189 - val_loss: 0.2842 - val_accuracy: 0.9118\n",
      "Epoch 239/400\n",
      "2835/2900 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.9174\n",
      "Epoch 239: val_loss did not improve from 0.27211\n",
      "2900/2900 [==============================] - 2s 697us/step - loss: 0.2711 - accuracy: 0.9174 - val_loss: 0.2737 - val_accuracy: 0.9244\n",
      "Epoch 240/400\n",
      "2850/2900 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9187\n",
      "Epoch 240: val_loss improved from 0.27211 to 0.27175, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 683us/step - loss: 0.2704 - accuracy: 0.9187 - val_loss: 0.2718 - val_accuracy: 0.9132\n",
      "Epoch 241/400\n",
      "2875/2900 [============================>.] - ETA: 0s - loss: 0.2699 - accuracy: 0.9178\n",
      "Epoch 241: val_loss did not improve from 0.27175\n",
      "2900/2900 [==============================] - 2s 672us/step - loss: 0.2704 - accuracy: 0.9178 - val_loss: 0.2735 - val_accuracy: 0.9210\n",
      "Epoch 242/400\n",
      "2826/2900 [============================>.] - ETA: 0s - loss: 0.2698 - accuracy: 0.9182\n",
      "Epoch 242: val_loss improved from 0.27175 to 0.27132, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2705 - accuracy: 0.9181 - val_loss: 0.2713 - val_accuracy: 0.9196\n",
      "Epoch 243/400\n",
      "2812/2900 [============================>.] - ETA: 0s - loss: 0.2706 - accuracy: 0.9183\n",
      "Epoch 243: val_loss did not improve from 0.27132\n",
      "2900/2900 [==============================] - 2s 687us/step - loss: 0.2700 - accuracy: 0.9186 - val_loss: 0.2724 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/400\n",
      "2844/2900 [============================>.] - ETA: 0s - loss: 0.2699 - accuracy: 0.9178\n",
      "Epoch 244: val_loss did not improve from 0.27132\n",
      "2900/2900 [==============================] - 2s 674us/step - loss: 0.2706 - accuracy: 0.9178 - val_loss: 0.2719 - val_accuracy: 0.9193\n",
      "Epoch 245/400\n",
      "2829/2900 [============================>.] - ETA: 0s - loss: 0.2709 - accuracy: 0.9183\n",
      "Epoch 245: val_loss did not improve from 0.27132\n",
      "2900/2900 [==============================] - 2s 679us/step - loss: 0.2705 - accuracy: 0.9183 - val_loss: 0.2727 - val_accuracy: 0.9175\n",
      "Epoch 246/400\n",
      "2843/2900 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9183\n",
      "Epoch 246: val_loss did not improve from 0.27132\n",
      "2900/2900 [==============================] - 2s 691us/step - loss: 0.2702 - accuracy: 0.9183 - val_loss: 0.2738 - val_accuracy: 0.9199\n",
      "Epoch 247/400\n",
      "2899/2900 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9178\n",
      "Epoch 247: val_loss improved from 0.27132 to 0.27001, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 687us/step - loss: 0.2700 - accuracy: 0.9178 - val_loss: 0.2700 - val_accuracy: 0.9201\n",
      "Epoch 248/400\n",
      "2832/2900 [============================>.] - ETA: 0s - loss: 0.2701 - accuracy: 0.9177\n",
      "Epoch 248: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.2702 - accuracy: 0.9178 - val_loss: 0.2796 - val_accuracy: 0.9181\n",
      "Epoch 249/400\n",
      "2859/2900 [============================>.] - ETA: 0s - loss: 0.2702 - accuracy: 0.9181\n",
      "Epoch 249: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 694us/step - loss: 0.2701 - accuracy: 0.9182 - val_loss: 0.2756 - val_accuracy: 0.9153\n",
      "Epoch 250/400\n",
      "2860/2900 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9181\n",
      "Epoch 250: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2704 - accuracy: 0.9181 - val_loss: 0.2709 - val_accuracy: 0.9132\n",
      "Epoch 251/400\n",
      "2870/2900 [============================>.] - ETA: 0s - loss: 0.2696 - accuracy: 0.9179\n",
      "Epoch 251: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 672us/step - loss: 0.2699 - accuracy: 0.9177 - val_loss: 0.2742 - val_accuracy: 0.9110\n",
      "Epoch 252/400\n",
      "2870/2900 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9178\n",
      "Epoch 252: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2700 - accuracy: 0.9177 - val_loss: 0.2765 - val_accuracy: 0.9091\n",
      "Epoch 253/400\n",
      "2874/2900 [============================>.] - ETA: 0s - loss: 0.2697 - accuracy: 0.9176\n",
      "Epoch 253: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 676us/step - loss: 0.2701 - accuracy: 0.9174 - val_loss: 0.2763 - val_accuracy: 0.9178\n",
      "Epoch 254/400\n",
      "2819/2900 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.9189\n",
      "Epoch 254: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 665us/step - loss: 0.2699 - accuracy: 0.9188 - val_loss: 0.2703 - val_accuracy: 0.9211\n",
      "Epoch 255/400\n",
      "2837/2900 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.9178\n",
      "Epoch 255: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 681us/step - loss: 0.2696 - accuracy: 0.9181 - val_loss: 0.2724 - val_accuracy: 0.9164\n",
      "Epoch 256/400\n",
      "2823/2900 [============================>.] - ETA: 0s - loss: 0.2699 - accuracy: 0.9178\n",
      "Epoch 256: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 685us/step - loss: 0.2699 - accuracy: 0.9179 - val_loss: 0.2721 - val_accuracy: 0.9117\n",
      "Epoch 257/400\n",
      "2894/2900 [============================>.] - ETA: 0s - loss: 0.2695 - accuracy: 0.9180\n",
      "Epoch 257: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2696 - accuracy: 0.9179 - val_loss: 0.2754 - val_accuracy: 0.9142\n",
      "Epoch 258/400\n",
      "2853/2900 [============================>.] - ETA: 0s - loss: 0.2695 - accuracy: 0.9184\n",
      "Epoch 258: val_loss did not improve from 0.27001\n",
      "2900/2900 [==============================] - 2s 694us/step - loss: 0.2696 - accuracy: 0.9180 - val_loss: 0.2708 - val_accuracy: 0.9229\n",
      "Epoch 259/400\n",
      "2862/2900 [============================>.] - ETA: 0s - loss: 0.2697 - accuracy: 0.9178\n",
      "Epoch 259: val_loss improved from 0.27001 to 0.26937, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 683us/step - loss: 0.2699 - accuracy: 0.9177 - val_loss: 0.2694 - val_accuracy: 0.9190\n",
      "Epoch 260/400\n",
      "2828/2900 [============================>.] - ETA: 0s - loss: 0.2695 - accuracy: 0.9180\n",
      "Epoch 260: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 678us/step - loss: 0.2690 - accuracy: 0.9182 - val_loss: 0.2727 - val_accuracy: 0.9155\n",
      "Epoch 261/400\n",
      "2848/2900 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.9181\n",
      "Epoch 261: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 676us/step - loss: 0.2697 - accuracy: 0.9180 - val_loss: 0.2710 - val_accuracy: 0.9181\n",
      "Epoch 262/400\n",
      "2840/2900 [============================>.] - ETA: 0s - loss: 0.2698 - accuracy: 0.9180\n",
      "Epoch 262: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 679us/step - loss: 0.2692 - accuracy: 0.9181 - val_loss: 0.2703 - val_accuracy: 0.9181\n",
      "Epoch 263/400\n",
      "2820/2900 [============================>.] - ETA: 0s - loss: 0.2711 - accuracy: 0.9178\n",
      "Epoch 263: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 685us/step - loss: 0.2695 - accuracy: 0.9183 - val_loss: 0.2752 - val_accuracy: 0.9170\n",
      "Epoch 264/400\n",
      "2849/2900 [============================>.] - ETA: 0s - loss: 0.2694 - accuracy: 0.9185\n",
      "Epoch 264: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 714us/step - loss: 0.2696 - accuracy: 0.9184 - val_loss: 0.2706 - val_accuracy: 0.9090\n",
      "Epoch 265/400\n",
      "2828/2900 [============================>.] - ETA: 0s - loss: 0.2682 - accuracy: 0.9181\n",
      "Epoch 265: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 698us/step - loss: 0.2685 - accuracy: 0.9179 - val_loss: 0.2749 - val_accuracy: 0.9182\n",
      "Epoch 266/400\n",
      "2875/2900 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9177\n",
      "Epoch 266: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2693 - accuracy: 0.9177 - val_loss: 0.2704 - val_accuracy: 0.9237\n",
      "Epoch 267/400\n",
      "2853/2900 [============================>.] - ETA: 0s - loss: 0.2689 - accuracy: 0.9186\n",
      "Epoch 267: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 692us/step - loss: 0.2687 - accuracy: 0.9186 - val_loss: 0.2707 - val_accuracy: 0.9212\n",
      "Epoch 268/400\n",
      "2894/2900 [============================>.] - ETA: 0s - loss: 0.2691 - accuracy: 0.9174\n",
      "Epoch 268: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 686us/step - loss: 0.2689 - accuracy: 0.9175 - val_loss: 0.2780 - val_accuracy: 0.9176\n",
      "Epoch 269/400\n",
      "2869/2900 [============================>.] - ETA: 0s - loss: 0.2691 - accuracy: 0.9176\n",
      "Epoch 269: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2687 - accuracy: 0.9177 - val_loss: 0.2724 - val_accuracy: 0.9167\n",
      "Epoch 270/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2691 - accuracy: 0.9175\n",
      "Epoch 270: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 687us/step - loss: 0.2690 - accuracy: 0.9175 - val_loss: 0.2703 - val_accuracy: 0.9112\n",
      "Epoch 271/400\n",
      "2861/2900 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.9182\n",
      "Epoch 271: val_loss did not improve from 0.26937\n",
      "2900/2900 [==============================] - 2s 693us/step - loss: 0.2693 - accuracy: 0.9182 - val_loss: 0.2708 - val_accuracy: 0.9134\n",
      "Epoch 272/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2877/2900 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9184\n",
      "Epoch 272: val_loss improved from 0.26937 to 0.26928, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 686us/step - loss: 0.2693 - accuracy: 0.9184 - val_loss: 0.2693 - val_accuracy: 0.9128\n",
      "Epoch 273/400\n",
      "2816/2900 [============================>.] - ETA: 0s - loss: 0.2682 - accuracy: 0.9176\n",
      "Epoch 273: val_loss did not improve from 0.26928\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2690 - accuracy: 0.9176 - val_loss: 0.2696 - val_accuracy: 0.9176\n",
      "Epoch 274/400\n",
      "2867/2900 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.9179\n",
      "Epoch 274: val_loss did not improve from 0.26928\n",
      "2900/2900 [==============================] - 2s 674us/step - loss: 0.2683 - accuracy: 0.9179 - val_loss: 0.2719 - val_accuracy: 0.9060\n",
      "Epoch 275/400\n",
      "2831/2900 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9184\n",
      "Epoch 275: val_loss did not improve from 0.26928\n",
      "2900/2900 [==============================] - 2s 681us/step - loss: 0.2688 - accuracy: 0.9185 - val_loss: 0.2710 - val_accuracy: 0.9139\n",
      "Epoch 276/400\n",
      "2884/2900 [============================>.] - ETA: 0s - loss: 0.2694 - accuracy: 0.9179\n",
      "Epoch 276: val_loss did not improve from 0.26928\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2694 - accuracy: 0.9179 - val_loss: 0.2720 - val_accuracy: 0.9210\n",
      "Epoch 277/400\n",
      "2831/2900 [============================>.] - ETA: 0s - loss: 0.2687 - accuracy: 0.9177\n",
      "Epoch 277: val_loss did not improve from 0.26928\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.2683 - accuracy: 0.9177 - val_loss: 0.2734 - val_accuracy: 0.9192\n",
      "Epoch 278/400\n",
      "2820/2900 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9181\n",
      "Epoch 278: val_loss did not improve from 0.26928\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.2689 - accuracy: 0.9184 - val_loss: 0.2761 - val_accuracy: 0.9196\n",
      "Epoch 279/400\n",
      "2857/2900 [============================>.] - ETA: 0s - loss: 0.2691 - accuracy: 0.9175\n",
      "Epoch 279: val_loss did not improve from 0.26928\n",
      "2900/2900 [==============================] - 2s 700us/step - loss: 0.2686 - accuracy: 0.9177 - val_loss: 0.2693 - val_accuracy: 0.9151\n",
      "Epoch 280/400\n",
      "2827/2900 [============================>.] - ETA: 0s - loss: 0.2696 - accuracy: 0.9178\n",
      "Epoch 280: val_loss improved from 0.26928 to 0.26911, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 702us/step - loss: 0.2691 - accuracy: 0.9179 - val_loss: 0.2691 - val_accuracy: 0.9221\n",
      "Epoch 281/400\n",
      "2880/2900 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.9186\n",
      "Epoch 281: val_loss did not improve from 0.26911\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2687 - accuracy: 0.9185 - val_loss: 0.2746 - val_accuracy: 0.9132\n",
      "Epoch 282/400\n",
      "2899/2900 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.9182\n",
      "Epoch 282: val_loss did not improve from 0.26911\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.2684 - accuracy: 0.9181 - val_loss: 0.2750 - val_accuracy: 0.9146\n",
      "Epoch 283/400\n",
      "2840/2900 [============================>.] - ETA: 0s - loss: 0.2694 - accuracy: 0.9176\n",
      "Epoch 283: val_loss did not improve from 0.26911\n",
      "2900/2900 [==============================] - 2s 694us/step - loss: 0.2686 - accuracy: 0.9181 - val_loss: 0.2699 - val_accuracy: 0.9124\n",
      "Epoch 284/400\n",
      "2827/2900 [============================>.] - ETA: 0s - loss: 0.2687 - accuracy: 0.9182\n",
      "Epoch 284: val_loss improved from 0.26911 to 0.26909, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 689us/step - loss: 0.2683 - accuracy: 0.9184 - val_loss: 0.2691 - val_accuracy: 0.9164\n",
      "Epoch 285/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.9182\n",
      "Epoch 285: val_loss did not improve from 0.26909\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.2680 - accuracy: 0.9181 - val_loss: 0.2712 - val_accuracy: 0.9117\n",
      "Epoch 286/400\n",
      "2845/2900 [============================>.] - ETA: 0s - loss: 0.2691 - accuracy: 0.9183\n",
      "Epoch 286: val_loss did not improve from 0.26909\n",
      "2900/2900 [==============================] - 2s 699us/step - loss: 0.2685 - accuracy: 0.9185 - val_loss: 0.2707 - val_accuracy: 0.9104\n",
      "Epoch 287/400\n",
      "2820/2900 [============================>.] - ETA: 0s - loss: 0.2679 - accuracy: 0.9175\n",
      "Epoch 287: val_loss did not improve from 0.26909\n",
      "2900/2900 [==============================] - 2s 722us/step - loss: 0.2682 - accuracy: 0.9174 - val_loss: 0.2776 - val_accuracy: 0.9123\n",
      "Epoch 288/400\n",
      "2818/2900 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9182\n",
      "Epoch 288: val_loss did not improve from 0.26909\n",
      "2900/2900 [==============================] - 2s 700us/step - loss: 0.2680 - accuracy: 0.9178 - val_loss: 0.2731 - val_accuracy: 0.9078\n",
      "Epoch 289/400\n",
      "2855/2900 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 0.9183\n",
      "Epoch 289: val_loss did not improve from 0.26909\n",
      "2900/2900 [==============================] - 2s 711us/step - loss: 0.2681 - accuracy: 0.9181 - val_loss: 0.2736 - val_accuracy: 0.9160\n",
      "Epoch 290/400\n",
      "2865/2900 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9182\n",
      "Epoch 290: val_loss did not improve from 0.26909\n",
      "2900/2900 [==============================] - 2s 698us/step - loss: 0.2683 - accuracy: 0.9181 - val_loss: 0.2702 - val_accuracy: 0.9164\n",
      "Epoch 291/400\n",
      "2870/2900 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9184\n",
      "Epoch 291: val_loss did not improve from 0.26909\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2677 - accuracy: 0.9183 - val_loss: 0.2707 - val_accuracy: 0.9188\n",
      "Epoch 292/400\n",
      "2874/2900 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9182\n",
      "Epoch 292: val_loss did not improve from 0.26909\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.2679 - accuracy: 0.9180 - val_loss: 0.2710 - val_accuracy: 0.9159\n",
      "Epoch 293/400\n",
      "2857/2900 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.9182\n",
      "Epoch 293: val_loss did not improve from 0.26909\n",
      "2900/2900 [==============================] - 2s 695us/step - loss: 0.2679 - accuracy: 0.9183 - val_loss: 0.2713 - val_accuracy: 0.9142\n",
      "Epoch 294/400\n",
      "2878/2900 [============================>.] - ETA: 0s - loss: 0.2682 - accuracy: 0.9190\n",
      "Epoch 294: val_loss did not improve from 0.26909\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.2680 - accuracy: 0.9191 - val_loss: 0.2704 - val_accuracy: 0.9138\n",
      "Epoch 295/400\n",
      "2887/2900 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.9182\n",
      "Epoch 295: val_loss improved from 0.26909 to 0.26831, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 695us/step - loss: 0.2675 - accuracy: 0.9182 - val_loss: 0.2683 - val_accuracy: 0.9170\n",
      "Epoch 296/400\n",
      "2883/2900 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.9179\n",
      "Epoch 296: val_loss did not improve from 0.26831\n",
      "2900/2900 [==============================] - 2s 706us/step - loss: 0.2675 - accuracy: 0.9179 - val_loss: 0.2694 - val_accuracy: 0.9206\n",
      "Epoch 297/400\n",
      "2869/2900 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.9172\n",
      "Epoch 297: val_loss did not improve from 0.26831\n",
      "2900/2900 [==============================] - 2s 693us/step - loss: 0.2674 - accuracy: 0.9172 - val_loss: 0.2767 - val_accuracy: 0.9168\n",
      "Epoch 298/400\n",
      "2838/2900 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.9184\n",
      "Epoch 298: val_loss did not improve from 0.26831\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2674 - accuracy: 0.9185 - val_loss: 0.2690 - val_accuracy: 0.9258\n",
      "Epoch 299/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.9186\n",
      "Epoch 299: val_loss did not improve from 0.26831\n",
      "2900/2900 [==============================] - 2s 752us/step - loss: 0.2678 - accuracy: 0.9187 - val_loss: 0.2775 - val_accuracy: 0.9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/400\n",
      "2890/2900 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.9187\n",
      "Epoch 300: val_loss did not improve from 0.26831\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2679 - accuracy: 0.9188 - val_loss: 0.2696 - val_accuracy: 0.9168\n",
      "Epoch 301/400\n",
      "2856/2900 [============================>.] - ETA: 0s - loss: 0.2680 - accuracy: 0.9182\n",
      "Epoch 301: val_loss did not improve from 0.26831\n",
      "2900/2900 [==============================] - 2s 722us/step - loss: 0.2682 - accuracy: 0.9181 - val_loss: 0.2691 - val_accuracy: 0.9189\n",
      "Epoch 302/400\n",
      "2871/2900 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.9183\n",
      "Epoch 302: val_loss did not improve from 0.26831\n",
      "2900/2900 [==============================] - 2s 711us/step - loss: 0.2678 - accuracy: 0.9182 - val_loss: 0.2722 - val_accuracy: 0.9133\n",
      "Epoch 303/400\n",
      "2886/2900 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9179\n",
      "Epoch 303: val_loss did not improve from 0.26831\n",
      "2900/2900 [==============================] - 2s 656us/step - loss: 0.2676 - accuracy: 0.9181 - val_loss: 0.2685 - val_accuracy: 0.9156\n",
      "Epoch 304/400\n",
      "2883/2900 [============================>.] - ETA: 0s - loss: 0.2679 - accuracy: 0.9185\n",
      "Epoch 304: val_loss did not improve from 0.26831\n",
      "2900/2900 [==============================] - 2s 672us/step - loss: 0.2678 - accuracy: 0.9186 - val_loss: 0.2684 - val_accuracy: 0.9231\n",
      "Epoch 305/400\n",
      "2892/2900 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9187\n",
      "Epoch 305: val_loss did not improve from 0.26831\n",
      "2900/2900 [==============================] - 2s 705us/step - loss: 0.2673 - accuracy: 0.9188 - val_loss: 0.2709 - val_accuracy: 0.9090\n",
      "Epoch 306/400\n",
      "2837/2900 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9174\n",
      "Epoch 306: val_loss improved from 0.26831 to 0.26818, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 681us/step - loss: 0.2668 - accuracy: 0.9174 - val_loss: 0.2682 - val_accuracy: 0.9128\n",
      "Epoch 307/400\n",
      "2849/2900 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.9182\n",
      "Epoch 307: val_loss did not improve from 0.26818\n",
      "2900/2900 [==============================] - 2s 662us/step - loss: 0.2671 - accuracy: 0.9182 - val_loss: 0.2685 - val_accuracy: 0.9223\n",
      "Epoch 308/400\n",
      "2875/2900 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.9182\n",
      "Epoch 308: val_loss did not improve from 0.26818\n",
      "2900/2900 [==============================] - 2s 706us/step - loss: 0.2675 - accuracy: 0.9179 - val_loss: 0.2748 - val_accuracy: 0.9194\n",
      "Epoch 309/400\n",
      "2823/2900 [============================>.] - ETA: 0s - loss: 0.2665 - accuracy: 0.9189\n",
      "Epoch 309: val_loss did not improve from 0.26818\n",
      "2900/2900 [==============================] - 2s 663us/step - loss: 0.2676 - accuracy: 0.9183 - val_loss: 0.2758 - val_accuracy: 0.9187\n",
      "Epoch 310/400\n",
      "2830/2900 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.9186\n",
      "Epoch 310: val_loss did not improve from 0.26818\n",
      "2900/2900 [==============================] - 2s 719us/step - loss: 0.2672 - accuracy: 0.9183 - val_loss: 0.2683 - val_accuracy: 0.9168\n",
      "Epoch 311/400\n",
      "2850/2900 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.9186\n",
      "Epoch 311: val_loss did not improve from 0.26818\n",
      "2900/2900 [==============================] - 2s 695us/step - loss: 0.2671 - accuracy: 0.9187 - val_loss: 0.2687 - val_accuracy: 0.9251\n",
      "Epoch 312/400\n",
      "2897/2900 [============================>.] - ETA: 0s - loss: 0.2678 - accuracy: 0.9180\n",
      "Epoch 312: val_loss did not improve from 0.26818\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2677 - accuracy: 0.9181 - val_loss: 0.2691 - val_accuracy: 0.9172\n",
      "Epoch 313/400\n",
      "2869/2900 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9181\n",
      "Epoch 313: val_loss did not improve from 0.26818\n",
      "2900/2900 [==============================] - 2s 693us/step - loss: 0.2673 - accuracy: 0.9182 - val_loss: 0.2685 - val_accuracy: 0.9106\n",
      "Epoch 314/400\n",
      "2831/2900 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.9180\n",
      "Epoch 314: val_loss did not improve from 0.26818\n",
      "2900/2900 [==============================] - 2s 700us/step - loss: 0.2675 - accuracy: 0.9184 - val_loss: 0.2712 - val_accuracy: 0.9166\n",
      "Epoch 315/400\n",
      "2834/2900 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.9180\n",
      "Epoch 315: val_loss did not improve from 0.26818\n",
      "2900/2900 [==============================] - 2s 682us/step - loss: 0.2674 - accuracy: 0.9180 - val_loss: 0.2688 - val_accuracy: 0.9189\n",
      "Epoch 316/400\n",
      "2828/2900 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9194\n",
      "Epoch 316: val_loss improved from 0.26818 to 0.26794, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 731us/step - loss: 0.2669 - accuracy: 0.9189 - val_loss: 0.2679 - val_accuracy: 0.9183\n",
      "Epoch 317/400\n",
      "2879/2900 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.9188\n",
      "Epoch 317: val_loss did not improve from 0.26794\n",
      "2900/2900 [==============================] - 2s 749us/step - loss: 0.2668 - accuracy: 0.9189 - val_loss: 0.2708 - val_accuracy: 0.9109\n",
      "Epoch 318/400\n",
      "2857/2900 [============================>.] - ETA: 0s - loss: 0.2680 - accuracy: 0.9186\n",
      "Epoch 318: val_loss did not improve from 0.26794\n",
      "2900/2900 [==============================] - 2s 735us/step - loss: 0.2679 - accuracy: 0.9185 - val_loss: 0.2730 - val_accuracy: 0.9265\n",
      "Epoch 319/400\n",
      "2900/2900 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9185\n",
      "Epoch 319: val_loss did not improve from 0.26794\n",
      "2900/2900 [==============================] - 2s 681us/step - loss: 0.2665 - accuracy: 0.9185 - val_loss: 0.2689 - val_accuracy: 0.9277\n",
      "Epoch 320/400\n",
      "2822/2900 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9188\n",
      "Epoch 320: val_loss did not improve from 0.26794\n",
      "2900/2900 [==============================] - 2s 686us/step - loss: 0.2667 - accuracy: 0.9186 - val_loss: 0.2727 - val_accuracy: 0.9210\n",
      "Epoch 321/400\n",
      "2832/2900 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.9190\n",
      "Epoch 321: val_loss improved from 0.26794 to 0.26704, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 702us/step - loss: 0.2667 - accuracy: 0.9191 - val_loss: 0.2670 - val_accuracy: 0.9205\n",
      "Epoch 322/400\n",
      "2829/2900 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9189\n",
      "Epoch 322: val_loss did not improve from 0.26704\n",
      "2900/2900 [==============================] - 2s 674us/step - loss: 0.2672 - accuracy: 0.9188 - val_loss: 0.2727 - val_accuracy: 0.9210\n",
      "Epoch 323/400\n",
      "2843/2900 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9187\n",
      "Epoch 323: val_loss did not improve from 0.26704\n",
      "2900/2900 [==============================] - 2s 675us/step - loss: 0.2668 - accuracy: 0.9185 - val_loss: 0.2761 - val_accuracy: 0.9164\n",
      "Epoch 324/400\n",
      "2881/2900 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9187\n",
      "Epoch 324: val_loss did not improve from 0.26704\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.2667 - accuracy: 0.9187 - val_loss: 0.2702 - val_accuracy: 0.9218\n",
      "Epoch 325/400\n",
      "2826/2900 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.9187\n",
      "Epoch 325: val_loss did not improve from 0.26704\n",
      "2900/2900 [==============================] - 2s 717us/step - loss: 0.2667 - accuracy: 0.9187 - val_loss: 0.2701 - val_accuracy: 0.9107\n",
      "Epoch 326/400\n",
      "2862/2900 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.9191\n",
      "Epoch 326: val_loss did not improve from 0.26704\n",
      "2900/2900 [==============================] - 2s 659us/step - loss: 0.2668 - accuracy: 0.9192 - val_loss: 0.2789 - val_accuracy: 0.9193\n",
      "Epoch 327/400\n",
      "2869/2900 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.9177\n",
      "Epoch 327: val_loss did not improve from 0.26704\n",
      "2900/2900 [==============================] - 2s 655us/step - loss: 0.2666 - accuracy: 0.9178 - val_loss: 0.2715 - val_accuracy: 0.9193\n",
      "Epoch 328/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2821/2900 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9185\n",
      "Epoch 328: val_loss did not improve from 0.26704\n",
      "2900/2900 [==============================] - 2s 682us/step - loss: 0.2667 - accuracy: 0.9183 - val_loss: 0.2681 - val_accuracy: 0.9168\n",
      "Epoch 329/400\n",
      "2857/2900 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 0.9186\n",
      "Epoch 329: val_loss improved from 0.26704 to 0.26665, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 674us/step - loss: 0.2668 - accuracy: 0.9184 - val_loss: 0.2667 - val_accuracy: 0.9112\n",
      "Epoch 330/400\n",
      "2826/2900 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9186\n",
      "Epoch 330: val_loss did not improve from 0.26665\n",
      "2900/2900 [==============================] - 2s 686us/step - loss: 0.2666 - accuracy: 0.9188 - val_loss: 0.2742 - val_accuracy: 0.9204\n",
      "Epoch 331/400\n",
      "2823/2900 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9190\n",
      "Epoch 331: val_loss improved from 0.26665 to 0.26565, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 692us/step - loss: 0.2667 - accuracy: 0.9189 - val_loss: 0.2657 - val_accuracy: 0.9168\n",
      "Epoch 332/400\n",
      "2827/2900 [============================>.] - ETA: 0s - loss: 0.2659 - accuracy: 0.9189\n",
      "Epoch 332: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 687us/step - loss: 0.2661 - accuracy: 0.9189 - val_loss: 0.2809 - val_accuracy: 0.9222\n",
      "Epoch 333/400\n",
      "2878/2900 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9193\n",
      "Epoch 333: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 711us/step - loss: 0.2664 - accuracy: 0.9195 - val_loss: 0.2753 - val_accuracy: 0.9127\n",
      "Epoch 334/400\n",
      "2866/2900 [============================>.] - ETA: 0s - loss: 0.2670 - accuracy: 0.9183\n",
      "Epoch 334: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 693us/step - loss: 0.2665 - accuracy: 0.9184 - val_loss: 0.2705 - val_accuracy: 0.9237\n",
      "Epoch 335/400\n",
      "2828/2900 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9188\n",
      "Epoch 335: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 703us/step - loss: 0.2663 - accuracy: 0.9193 - val_loss: 0.2661 - val_accuracy: 0.9171\n",
      "Epoch 336/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2670 - accuracy: 0.9188\n",
      "Epoch 336: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 724us/step - loss: 0.2668 - accuracy: 0.9188 - val_loss: 0.2669 - val_accuracy: 0.9267\n",
      "Epoch 337/400\n",
      "2886/2900 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9191\n",
      "Epoch 337: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 687us/step - loss: 0.2662 - accuracy: 0.9191 - val_loss: 0.2697 - val_accuracy: 0.9229\n",
      "Epoch 338/400\n",
      "2900/2900 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.9190\n",
      "Epoch 338: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 737us/step - loss: 0.2664 - accuracy: 0.9190 - val_loss: 0.2670 - val_accuracy: 0.9135\n",
      "Epoch 339/400\n",
      "2818/2900 [============================>.] - ETA: 0s - loss: 0.2667 - accuracy: 0.9194\n",
      "Epoch 339: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 700us/step - loss: 0.2663 - accuracy: 0.9192 - val_loss: 0.2711 - val_accuracy: 0.9074\n",
      "Epoch 340/400\n",
      "2829/2900 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9191\n",
      "Epoch 340: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 679us/step - loss: 0.2659 - accuracy: 0.9191 - val_loss: 0.2715 - val_accuracy: 0.9170\n",
      "Epoch 341/400\n",
      "2880/2900 [============================>.] - ETA: 0s - loss: 0.2667 - accuracy: 0.9190\n",
      "Epoch 341: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 688us/step - loss: 0.2669 - accuracy: 0.9190 - val_loss: 0.2706 - val_accuracy: 0.9192\n",
      "Epoch 342/400\n",
      "2851/2900 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9194\n",
      "Epoch 342: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 694us/step - loss: 0.2661 - accuracy: 0.9194 - val_loss: 0.2675 - val_accuracy: 0.9203\n",
      "Epoch 343/400\n",
      "2887/2900 [============================>.] - ETA: 0s - loss: 0.2661 - accuracy: 0.9195\n",
      "Epoch 343: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 702us/step - loss: 0.2659 - accuracy: 0.9195 - val_loss: 0.2725 - val_accuracy: 0.9175\n",
      "Epoch 344/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.9190\n",
      "Epoch 344: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 692us/step - loss: 0.2657 - accuracy: 0.9189 - val_loss: 0.2658 - val_accuracy: 0.9199\n",
      "Epoch 345/400\n",
      "2822/2900 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.9196\n",
      "Epoch 345: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.2654 - accuracy: 0.9199 - val_loss: 0.2668 - val_accuracy: 0.9209\n",
      "Epoch 346/400\n",
      "2828/2900 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9193\n",
      "Epoch 346: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 678us/step - loss: 0.2654 - accuracy: 0.9195 - val_loss: 0.2696 - val_accuracy: 0.9087\n",
      "Epoch 347/400\n",
      "2860/2900 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9191\n",
      "Epoch 347: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 725us/step - loss: 0.2658 - accuracy: 0.9190 - val_loss: 0.2727 - val_accuracy: 0.9209\n",
      "Epoch 348/400\n",
      "2853/2900 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9196\n",
      "Epoch 348: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 700us/step - loss: 0.2662 - accuracy: 0.9194 - val_loss: 0.2705 - val_accuracy: 0.9209\n",
      "Epoch 349/400\n",
      "2899/2900 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9194\n",
      "Epoch 349: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 684us/step - loss: 0.2661 - accuracy: 0.9193 - val_loss: 0.2682 - val_accuracy: 0.9288\n",
      "Epoch 350/400\n",
      "2822/2900 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.9191\n",
      "Epoch 350: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.2651 - accuracy: 0.9193 - val_loss: 0.2688 - val_accuracy: 0.9203\n",
      "Epoch 351/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2651 - accuracy: 0.9183\n",
      "Epoch 351: val_loss did not improve from 0.26565\n",
      "2900/2900 [==============================] - 2s 691us/step - loss: 0.2654 - accuracy: 0.9183 - val_loss: 0.2673 - val_accuracy: 0.9260\n",
      "Epoch 352/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 0.9197\n",
      "Epoch 352: val_loss improved from 0.26565 to 0.26552, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.2660 - accuracy: 0.9197 - val_loss: 0.2655 - val_accuracy: 0.9220\n",
      "Epoch 353/400\n",
      "2810/2900 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.9193\n",
      "Epoch 353: val_loss did not improve from 0.26552\n",
      "2900/2900 [==============================] - 2s 683us/step - loss: 0.2654 - accuracy: 0.9193 - val_loss: 0.2655 - val_accuracy: 0.9249\n",
      "Epoch 354/400\n",
      "2820/2900 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9208\n",
      "Epoch 354: val_loss improved from 0.26552 to 0.26498, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2652 - accuracy: 0.9208 - val_loss: 0.2650 - val_accuracy: 0.9228\n",
      "Epoch 355/400\n",
      "2865/2900 [============================>.] - ETA: 0s - loss: 0.2652 - accuracy: 0.9199\n",
      "Epoch 355: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.2654 - accuracy: 0.9200 - val_loss: 0.2672 - val_accuracy: 0.9203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/400\n",
      "2868/2900 [============================>.] - ETA: 0s - loss: 0.2647 - accuracy: 0.9198\n",
      "Epoch 356: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 710us/step - loss: 0.2654 - accuracy: 0.9195 - val_loss: 0.2748 - val_accuracy: 0.9133\n",
      "Epoch 357/400\n",
      "2860/2900 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.9202\n",
      "Epoch 357: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 714us/step - loss: 0.2652 - accuracy: 0.9200 - val_loss: 0.2716 - val_accuracy: 0.9176\n",
      "Epoch 358/400\n",
      "2826/2900 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.9189\n",
      "Epoch 358: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 722us/step - loss: 0.2651 - accuracy: 0.9190 - val_loss: 0.2664 - val_accuracy: 0.9204\n",
      "Epoch 359/400\n",
      "2830/2900 [============================>.] - ETA: 0s - loss: 0.2661 - accuracy: 0.9194\n",
      "Epoch 359: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.2657 - accuracy: 0.9195 - val_loss: 0.2651 - val_accuracy: 0.9223\n",
      "Epoch 360/400\n",
      "2889/2900 [============================>.] - ETA: 0s - loss: 0.2653 - accuracy: 0.9197\n",
      "Epoch 360: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 701us/step - loss: 0.2651 - accuracy: 0.9199 - val_loss: 0.2653 - val_accuracy: 0.9236\n",
      "Epoch 361/400\n",
      "2877/2900 [============================>.] - ETA: 0s - loss: 0.2651 - accuracy: 0.9199\n",
      "Epoch 361: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 715us/step - loss: 0.2654 - accuracy: 0.9198 - val_loss: 0.2757 - val_accuracy: 0.9178\n",
      "Epoch 362/400\n",
      "2891/2900 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9196\n",
      "Epoch 362: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 665us/step - loss: 0.2651 - accuracy: 0.9196 - val_loss: 0.2687 - val_accuracy: 0.9204\n",
      "Epoch 363/400\n",
      "2843/2900 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.9197\n",
      "Epoch 363: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 719us/step - loss: 0.2659 - accuracy: 0.9197 - val_loss: 0.2655 - val_accuracy: 0.9206\n",
      "Epoch 364/400\n",
      "2855/2900 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9207\n",
      "Epoch 364: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 718us/step - loss: 0.2648 - accuracy: 0.9208 - val_loss: 0.2701 - val_accuracy: 0.9210\n",
      "Epoch 365/400\n",
      "2847/2900 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9205\n",
      "Epoch 365: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 699us/step - loss: 0.2652 - accuracy: 0.9203 - val_loss: 0.2661 - val_accuracy: 0.9194\n",
      "Epoch 366/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2649 - accuracy: 0.9212\n",
      "Epoch 366: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 729us/step - loss: 0.2650 - accuracy: 0.9211 - val_loss: 0.2715 - val_accuracy: 0.9175\n",
      "Epoch 367/400\n",
      "2821/2900 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9201\n",
      "Epoch 367: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 699us/step - loss: 0.2649 - accuracy: 0.9201 - val_loss: 0.2676 - val_accuracy: 0.9161\n",
      "Epoch 368/400\n",
      "2884/2900 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9203\n",
      "Epoch 368: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 690us/step - loss: 0.2650 - accuracy: 0.9202 - val_loss: 0.2682 - val_accuracy: 0.9239\n",
      "Epoch 369/400\n",
      "2864/2900 [============================>.] - ETA: 0s - loss: 0.2649 - accuracy: 0.9207\n",
      "Epoch 369: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 722us/step - loss: 0.2647 - accuracy: 0.9207 - val_loss: 0.2652 - val_accuracy: 0.9183\n",
      "Epoch 370/400\n",
      "2854/2900 [============================>.] - ETA: 0s - loss: 0.2653 - accuracy: 0.9199\n",
      "Epoch 370: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 788us/step - loss: 0.2648 - accuracy: 0.9202 - val_loss: 0.2691 - val_accuracy: 0.9247\n",
      "Epoch 371/400\n",
      "2885/2900 [============================>.] - ETA: 0s - loss: 0.2652 - accuracy: 0.9206\n",
      "Epoch 371: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 783us/step - loss: 0.2649 - accuracy: 0.9206 - val_loss: 0.2673 - val_accuracy: 0.9227\n",
      "Epoch 372/400\n",
      "2892/2900 [============================>.] - ETA: 0s - loss: 0.2648 - accuracy: 0.9204\n",
      "Epoch 372: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 779us/step - loss: 0.2648 - accuracy: 0.9204 - val_loss: 0.2704 - val_accuracy: 0.9171\n",
      "Epoch 373/400\n",
      "2874/2900 [============================>.] - ETA: 0s - loss: 0.2653 - accuracy: 0.9207\n",
      "Epoch 373: val_loss did not improve from 0.26498\n",
      "2900/2900 [==============================] - 2s 794us/step - loss: 0.2652 - accuracy: 0.9209 - val_loss: 0.2697 - val_accuracy: 0.9254\n",
      "Epoch 374/400\n",
      "2832/2900 [============================>.] - ETA: 0s - loss: 0.2653 - accuracy: 0.9198\n",
      "Epoch 374: val_loss improved from 0.26498 to 0.26425, saving model to ENOL3//Details\\best_modelHn_7union_data.hdf5\n",
      "2900/2900 [==============================] - 2s 758us/step - loss: 0.2649 - accuracy: 0.9199 - val_loss: 0.2642 - val_accuracy: 0.9250\n",
      "Epoch 375/400\n",
      "2849/2900 [============================>.] - ETA: 0s - loss: 0.2645 - accuracy: 0.9210\n",
      "Epoch 375: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 696us/step - loss: 0.2643 - accuracy: 0.9211 - val_loss: 0.2645 - val_accuracy: 0.9253\n",
      "Epoch 376/400\n",
      "2820/2900 [============================>.] - ETA: 0s - loss: 0.2639 - accuracy: 0.9216\n",
      "Epoch 376: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 685us/step - loss: 0.2644 - accuracy: 0.9216 - val_loss: 0.2664 - val_accuracy: 0.9198\n",
      "Epoch 377/400\n",
      "2872/2900 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9207\n",
      "Epoch 377: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 673us/step - loss: 0.2643 - accuracy: 0.9207 - val_loss: 0.2706 - val_accuracy: 0.9060\n",
      "Epoch 378/400\n",
      "2839/2900 [============================>.] - ETA: 0s - loss: 0.2651 - accuracy: 0.9202\n",
      "Epoch 378: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 682us/step - loss: 0.2647 - accuracy: 0.9203 - val_loss: 0.2678 - val_accuracy: 0.9161\n",
      "Epoch 379/400\n",
      "2855/2900 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9207\n",
      "Epoch 379: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 698us/step - loss: 0.2646 - accuracy: 0.9205 - val_loss: 0.2664 - val_accuracy: 0.9133\n",
      "Epoch 380/400\n",
      "2834/2900 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.9208\n",
      "Epoch 380: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 777us/step - loss: 0.2646 - accuracy: 0.9210 - val_loss: 0.2671 - val_accuracy: 0.9216\n",
      "Epoch 381/400\n",
      "2823/2900 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.9209\n",
      "Epoch 381: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 741us/step - loss: 0.2646 - accuracy: 0.9210 - val_loss: 0.2660 - val_accuracy: 0.9269\n",
      "Epoch 382/400\n",
      "2875/2900 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9201\n",
      "Epoch 382: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 740us/step - loss: 0.2643 - accuracy: 0.9201 - val_loss: 0.2655 - val_accuracy: 0.9149\n",
      "Epoch 383/400\n",
      "2895/2900 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.9208\n",
      "Epoch 383: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 728us/step - loss: 0.2637 - accuracy: 0.9208 - val_loss: 0.2688 - val_accuracy: 0.9126\n",
      "Epoch 384/400\n",
      "2894/2900 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.9216\n",
      "Epoch 384: val_loss did not improve from 0.26425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900/2900 [==============================] - 2s 771us/step - loss: 0.2643 - accuracy: 0.9216 - val_loss: 0.2655 - val_accuracy: 0.9222\n",
      "Epoch 385/400\n",
      "2833/2900 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.9214\n",
      "Epoch 385: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 706us/step - loss: 0.2643 - accuracy: 0.9212 - val_loss: 0.2712 - val_accuracy: 0.9234\n",
      "Epoch 386/400\n",
      "2882/2900 [============================>.] - ETA: 0s - loss: 0.2648 - accuracy: 0.9206\n",
      "Epoch 386: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 666us/step - loss: 0.2646 - accuracy: 0.9207 - val_loss: 0.2654 - val_accuracy: 0.9184\n",
      "Epoch 387/400\n",
      "2896/2900 [============================>.] - ETA: 0s - loss: 0.2635 - accuracy: 0.9216\n",
      "Epoch 387: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 682us/step - loss: 0.2635 - accuracy: 0.9217 - val_loss: 0.2647 - val_accuracy: 0.9247\n",
      "Epoch 388/400\n",
      "2875/2900 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9210\n",
      "Epoch 388: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 676us/step - loss: 0.2647 - accuracy: 0.9211 - val_loss: 0.2662 - val_accuracy: 0.9160\n",
      "Epoch 389/400\n",
      "2856/2900 [============================>.] - ETA: 0s - loss: 0.2649 - accuracy: 0.9210\n",
      "Epoch 389: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 732us/step - loss: 0.2644 - accuracy: 0.9212 - val_loss: 0.2693 - val_accuracy: 0.9204\n",
      "Epoch 390/400\n",
      "2888/2900 [============================>.] - ETA: 0s - loss: 0.2641 - accuracy: 0.9217\n",
      "Epoch 390: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 703us/step - loss: 0.2639 - accuracy: 0.9218 - val_loss: 0.2646 - val_accuracy: 0.9260\n",
      "Epoch 391/400\n",
      "2866/2900 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.9218\n",
      "Epoch 391: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 675us/step - loss: 0.2642 - accuracy: 0.9217 - val_loss: 0.2663 - val_accuracy: 0.9145\n",
      "Epoch 392/400\n",
      "2859/2900 [============================>.] - ETA: 0s - loss: 0.2629 - accuracy: 0.9222\n",
      "Epoch 392: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 693us/step - loss: 0.2638 - accuracy: 0.9220 - val_loss: 0.2648 - val_accuracy: 0.9240\n",
      "Epoch 393/400\n",
      "2897/2900 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.9221\n",
      "Epoch 393: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 827us/step - loss: 0.2640 - accuracy: 0.9220 - val_loss: 0.2665 - val_accuracy: 0.9111\n",
      "Epoch 394/400\n",
      "2887/2900 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.9212\n",
      "Epoch 394: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 763us/step - loss: 0.2639 - accuracy: 0.9214 - val_loss: 0.2664 - val_accuracy: 0.9264\n",
      "Epoch 395/400\n",
      "2858/2900 [============================>.] - ETA: 0s - loss: 0.2635 - accuracy: 0.9219\n",
      "Epoch 395: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 714us/step - loss: 0.2639 - accuracy: 0.9218 - val_loss: 0.2666 - val_accuracy: 0.9195\n",
      "Epoch 396/400\n",
      "2850/2900 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9215\n",
      "Epoch 396: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 712us/step - loss: 0.2636 - accuracy: 0.9217 - val_loss: 0.2662 - val_accuracy: 0.9277\n",
      "Epoch 397/400\n",
      "2894/2900 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9227\n",
      "Epoch 397: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2638 - accuracy: 0.9227 - val_loss: 0.2653 - val_accuracy: 0.9217\n",
      "Epoch 398/400\n",
      "2823/2900 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.9218\n",
      "Epoch 398: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 709us/step - loss: 0.2636 - accuracy: 0.9220 - val_loss: 0.2686 - val_accuracy: 0.9250\n",
      "Epoch 399/400\n",
      "2856/2900 [============================>.] - ETA: 0s - loss: 0.2624 - accuracy: 0.9220\n",
      "Epoch 399: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 752us/step - loss: 0.2632 - accuracy: 0.9220 - val_loss: 0.2647 - val_accuracy: 0.9195\n",
      "Epoch 400/400\n",
      "2830/2900 [============================>.] - ETA: 0s - loss: 0.2639 - accuracy: 0.9220\n",
      "Epoch 400: val_loss did not improve from 0.26425\n",
      "2900/2900 [==============================] - 2s 771us/step - loss: 0.2639 - accuracy: 0.9219 - val_loss: 0.2746 - val_accuracy: 0.9220\n",
      "name weight ENOL3//model/trained_weights_Hn_7union_data.mat\n",
      "302/302 [==============================] - 0s 564us/step\n",
      "here\n",
      "Accuracy  : 0.9274369355341016\n",
      "Precision : 0.9274524113625532\n",
      "f1Score : 0.9272330727464442\n",
      "[[1892  234    2]\n",
      " [ 204 6151   84]\n",
      " [  76   99  891]]\n",
      "train history is strored in ENOL3/History/history-Hn_7union_data.dat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is smoothdata\n",
      "Data file being used is: WENO3/train_input_smoothdata.csv\n",
      "In load data (31920, 4) (31920,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 35        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59 (472.00 Byte)\n",
      "Trainable params: 59 (472.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 1.1850 - accuracy: 0.1136 \n",
      "Epoch 1: val_loss improved from inf to 0.94191, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.1520 - accuracy: 0.1830 - val_loss: 0.9419 - val_accuracy: 0.7307\n",
      "Epoch 2/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.8024 - accuracy: 0.7631\n",
      "Epoch 2: val_loss improved from 0.94191 to 0.63078, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.7839 - accuracy: 0.7699 - val_loss: 0.6308 - val_accuracy: 0.8258\n",
      "Epoch 3/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.5213 - accuracy: 0.9418\n",
      "Epoch 3: val_loss improved from 0.63078 to 0.39211, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\xai\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.9453 - val_loss: 0.3921 - val_accuracy: 0.9784\n",
      "Epoch 4/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.3204 - accuracy: 0.9782\n",
      "Epoch 4: val_loss improved from 0.39211 to 0.24715, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.3151 - accuracy: 0.9777 - val_loss: 0.2471 - val_accuracy: 0.9784\n",
      "Epoch 5/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.2126 - accuracy: 0.9780\n",
      "Epoch 5: val_loss improved from 0.24715 to 0.18079, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.2106 - accuracy: 0.9777 - val_loss: 0.1808 - val_accuracy: 0.9784\n",
      "Epoch 6/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.1664 - accuracy: 0.9779\n",
      "Epoch 6: val_loss improved from 0.18079 to 0.15349, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9777 - val_loss: 0.1535 - val_accuracy: 0.9784\n",
      "Epoch 7/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.1441 - accuracy: 0.9783\n",
      "Epoch 7: val_loss improved from 0.15349 to 0.14134, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9777 - val_loss: 0.1413 - val_accuracy: 0.9784\n",
      "Epoch 8/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1392 - accuracy: 0.9775\n",
      "Epoch 8: val_loss improved from 0.14134 to 0.13545, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9777 - val_loss: 0.1355 - val_accuracy: 0.9784\n",
      "Epoch 9/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.1349 - accuracy: 0.9774\n",
      "Epoch 9: val_loss improved from 0.13545 to 0.13204, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9777 - val_loss: 0.1320 - val_accuracy: 0.9784\n",
      "Epoch 10/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.1284 - accuracy: 0.9782\n",
      "Epoch 10: val_loss improved from 0.13204 to 0.12977, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9777 - val_loss: 0.1298 - val_accuracy: 0.9784\n",
      "Epoch 11/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.1292 - accuracy: 0.9776\n",
      "Epoch 11: val_loss improved from 0.12977 to 0.12808, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9777 - val_loss: 0.1281 - val_accuracy: 0.9784\n",
      "Epoch 12/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.1264 - accuracy: 0.9779\n",
      "Epoch 12: val_loss improved from 0.12808 to 0.12654, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9777 - val_loss: 0.1265 - val_accuracy: 0.9784\n",
      "Epoch 13/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.1261 - accuracy: 0.9778\n",
      "Epoch 13: val_loss improved from 0.12654 to 0.12526, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9777 - val_loss: 0.1253 - val_accuracy: 0.9784\n",
      "Epoch 14/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.1237 - accuracy: 0.9778\n",
      "Epoch 14: val_loss improved from 0.12526 to 0.12414, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9777 - val_loss: 0.1241 - val_accuracy: 0.9784\n",
      "Epoch 15/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.1256 - accuracy: 0.9775\n",
      "Epoch 15: val_loss improved from 0.12414 to 0.12301, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9777 - val_loss: 0.1230 - val_accuracy: 0.9784\n",
      "Epoch 16/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.1229 - accuracy: 0.9778\n",
      "Epoch 16: val_loss improved from 0.12301 to 0.12203, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9777 - val_loss: 0.1220 - val_accuracy: 0.9784\n",
      "Epoch 17/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.1239 - accuracy: 0.9773\n",
      "Epoch 17: val_loss improved from 0.12203 to 0.12108, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9777 - val_loss: 0.1211 - val_accuracy: 0.9784\n",
      "Epoch 18/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.1235 - accuracy: 0.9772\n",
      "Epoch 18: val_loss improved from 0.12108 to 0.12011, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9777 - val_loss: 0.1201 - val_accuracy: 0.9784\n",
      "Epoch 19/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.1204 - accuracy: 0.9777\n",
      "Epoch 19: val_loss improved from 0.12011 to 0.11908, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9777 - val_loss: 0.1191 - val_accuracy: 0.9784\n",
      "Epoch 20/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.1190 - accuracy: 0.9778\n",
      "Epoch 20: val_loss improved from 0.11908 to 0.11801, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9777 - val_loss: 0.1180 - val_accuracy: 0.9784\n",
      "Epoch 21/400\n",
      "66/91 [====================>.........] - ETA: 0s - loss: 0.1178 - accuracy: 0.9777\n",
      "Epoch 21: val_loss improved from 0.11801 to 0.11736, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9777 - val_loss: 0.1174 - val_accuracy: 0.9784\n",
      "Epoch 22/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.1184 - accuracy: 0.9777\n",
      "Epoch 22: val_loss improved from 0.11736 to 0.11709, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9777 - val_loss: 0.1171 - val_accuracy: 0.9784\n",
      "Epoch 23/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.1171 - accuracy: 0.9780\n",
      "Epoch 23: val_loss improved from 0.11709 to 0.11693, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9777 - val_loss: 0.1169 - val_accuracy: 0.9784\n",
      "Epoch 24/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1159 - accuracy: 0.9782\n",
      "Epoch 24: val_loss improved from 0.11693 to 0.11678, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9777 - val_loss: 0.1168 - val_accuracy: 0.9784\n",
      "Epoch 25/400\n",
      "64/91 [====================>.........] - ETA: 0s - loss: 0.1228 - accuracy: 0.9766\n",
      "Epoch 25: val_loss improved from 0.11678 to 0.11665, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9777 - val_loss: 0.1167 - val_accuracy: 0.9784\n",
      "Epoch 26/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.1200 - accuracy: 0.9772\n",
      "Epoch 26: val_loss improved from 0.11665 to 0.11653, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9777 - val_loss: 0.1165 - val_accuracy: 0.9784\n",
      "Epoch 27/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.1195 - accuracy: 0.9772\n",
      "Epoch 27: val_loss improved from 0.11653 to 0.11644, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9777 - val_loss: 0.1164 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.1171 - accuracy: 0.9778\n",
      "Epoch 28: val_loss improved from 0.11644 to 0.11632, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9777 - val_loss: 0.1163 - val_accuracy: 0.9784\n",
      "Epoch 29/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.1166 - accuracy: 0.9779\n",
      "Epoch 29: val_loss improved from 0.11632 to 0.11622, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9777 - val_loss: 0.1162 - val_accuracy: 0.9784\n",
      "Epoch 30/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.1162 - accuracy: 0.9779\n",
      "Epoch 30: val_loss improved from 0.11622 to 0.11611, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9777 - val_loss: 0.1161 - val_accuracy: 0.9784\n",
      "Epoch 31/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.1154 - accuracy: 0.9781\n",
      "Epoch 31: val_loss improved from 0.11611 to 0.11598, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9777 - val_loss: 0.1160 - val_accuracy: 0.9784\n",
      "Epoch 32/400\n",
      "60/91 [==================>...........] - ETA: 0s - loss: 0.1148 - accuracy: 0.9783\n",
      "Epoch 32: val_loss improved from 0.11598 to 0.11587, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9777 - val_loss: 0.1159 - val_accuracy: 0.9784\n",
      "Epoch 33/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.1164 - accuracy: 0.9777\n",
      "Epoch 33: val_loss improved from 0.11587 to 0.11575, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9777 - val_loss: 0.1158 - val_accuracy: 0.9784\n",
      "Epoch 34/400\n",
      "60/91 [==================>...........] - ETA: 0s - loss: 0.1088 - accuracy: 0.9795\n",
      "Epoch 34: val_loss improved from 0.11575 to 0.11560, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.9777 - val_loss: 0.1156 - val_accuracy: 0.9784\n",
      "Epoch 35/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1186 - accuracy: 0.9773\n",
      "Epoch 35: val_loss improved from 0.11560 to 0.11543, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9777 - val_loss: 0.1154 - val_accuracy: 0.9784\n",
      "Epoch 36/400\n",
      "66/91 [====================>.........] - ETA: 0s - loss: 0.1119 - accuracy: 0.9788\n",
      "Epoch 36: val_loss improved from 0.11543 to 0.11523, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9777 - val_loss: 0.1152 - val_accuracy: 0.9784\n",
      "Epoch 37/400\n",
      "68/91 [=====================>........] - ETA: 0s - loss: 0.1118 - accuracy: 0.9787\n",
      "Epoch 37: val_loss improved from 0.11523 to 0.11513, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9777 - val_loss: 0.1151 - val_accuracy: 0.9784\n",
      "Epoch 38/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.1153 - accuracy: 0.9779\n",
      "Epoch 38: val_loss improved from 0.11513 to 0.11501, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9777 - val_loss: 0.1150 - val_accuracy: 0.9784\n",
      "Epoch 39/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.1149 - accuracy: 0.9779\n",
      "Epoch 39: val_loss improved from 0.11501 to 0.11490, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9777 - val_loss: 0.1149 - val_accuracy: 0.9784\n",
      "Epoch 40/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.1157 - accuracy: 0.9777\n",
      "Epoch 40: val_loss improved from 0.11490 to 0.11475, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9777 - val_loss: 0.1147 - val_accuracy: 0.9784\n",
      "Epoch 41/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.1152 - accuracy: 0.9777\n",
      "Epoch 41: val_loss improved from 0.11475 to 0.11465, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9777 - val_loss: 0.1146 - val_accuracy: 0.9784\n",
      "Epoch 42/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.1169 - accuracy: 0.9774\n",
      "Epoch 42: val_loss improved from 0.11465 to 0.11452, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9777 - val_loss: 0.1145 - val_accuracy: 0.9784\n",
      "Epoch 43/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1172 - accuracy: 0.9773\n",
      "Epoch 43: val_loss improved from 0.11452 to 0.11439, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9777 - val_loss: 0.1144 - val_accuracy: 0.9784\n",
      "Epoch 44/400\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.1160 - accuracy: 0.9775\n",
      "Epoch 44: val_loss improved from 0.11439 to 0.11424, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 996us/step - loss: 0.1152 - accuracy: 0.9777 - val_loss: 0.1142 - val_accuracy: 0.9784\n",
      "Epoch 45/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.1145 - accuracy: 0.9778\n",
      "Epoch 45: val_loss improved from 0.11424 to 0.11409, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9777 - val_loss: 0.1141 - val_accuracy: 0.9784\n",
      "Epoch 46/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.1150 - accuracy: 0.9777\n",
      "Epoch 46: val_loss improved from 0.11409 to 0.11404, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9777 - val_loss: 0.1140 - val_accuracy: 0.9784\n",
      "Epoch 47/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.1157 - accuracy: 0.9776\n",
      "Epoch 47: val_loss improved from 0.11404 to 0.11384, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9777 - val_loss: 0.1138 - val_accuracy: 0.9784\n",
      "Epoch 48/400\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.1136 - accuracy: 0.9780\n",
      "Epoch 48: val_loss improved from 0.11384 to 0.11370, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9777 - val_loss: 0.1137 - val_accuracy: 0.9784\n",
      "Epoch 49/400\n",
      "87/91 [===========================>..] - ETA: 0s - loss: 0.1146 - accuracy: 0.9777\n",
      "Epoch 49: val_loss improved from 0.11370 to 0.11353, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9777 - val_loss: 0.1135 - val_accuracy: 0.9784\n",
      "Epoch 50/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.1103 - accuracy: 0.9787\n",
      "Epoch 50: val_loss improved from 0.11353 to 0.11335, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9777 - val_loss: 0.1134 - val_accuracy: 0.9784\n",
      "Epoch 51/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.1140 - accuracy: 0.9777\n",
      "Epoch 51: val_loss improved from 0.11335 to 0.11316, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9777 - val_loss: 0.1132 - val_accuracy: 0.9784\n",
      "Epoch 52/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/91 [===========================>..] - ETA: 0s - loss: 0.1123 - accuracy: 0.9781\n",
      "Epoch 52: val_loss improved from 0.11316 to 0.11297, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9777 - val_loss: 0.1130 - val_accuracy: 0.9784\n",
      "Epoch 53/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.1120 - accuracy: 0.9781\n",
      "Epoch 53: val_loss improved from 0.11297 to 0.11278, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9777 - val_loss: 0.1128 - val_accuracy: 0.9784\n",
      "Epoch 54/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.1115 - accuracy: 0.9782\n",
      "Epoch 54: val_loss improved from 0.11278 to 0.11261, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9777 - val_loss: 0.1126 - val_accuracy: 0.9784\n",
      "Epoch 55/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.1184 - accuracy: 0.9765\n",
      "Epoch 55: val_loss improved from 0.11261 to 0.11239, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.9777 - val_loss: 0.1124 - val_accuracy: 0.9784\n",
      "Epoch 56/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.1142 - accuracy: 0.9776\n",
      "Epoch 56: val_loss improved from 0.11239 to 0.11213, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9777 - val_loss: 0.1121 - val_accuracy: 0.9784\n",
      "Epoch 57/400\n",
      "68/91 [=====================>........] - ETA: 0s - loss: 0.1138 - accuracy: 0.9774\n",
      "Epoch 57: val_loss improved from 0.11213 to 0.11197, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9777 - val_loss: 0.1120 - val_accuracy: 0.9784\n",
      "Epoch 58/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.1145 - accuracy: 0.9773\n",
      "Epoch 58: val_loss improved from 0.11197 to 0.11165, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.9777 - val_loss: 0.1117 - val_accuracy: 0.9784\n",
      "Epoch 59/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.1127 - accuracy: 0.9776\n",
      "Epoch 59: val_loss improved from 0.11165 to 0.11142, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9777 - val_loss: 0.1114 - val_accuracy: 0.9784\n",
      "Epoch 60/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.1124 - accuracy: 0.9777\n",
      "Epoch 60: val_loss improved from 0.11142 to 0.11114, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1121 - accuracy: 0.9777 - val_loss: 0.1111 - val_accuracy: 0.9784\n",
      "Epoch 61/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.1122 - accuracy: 0.9777\n",
      "Epoch 61: val_loss improved from 0.11114 to 0.11088, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9777 - val_loss: 0.1109 - val_accuracy: 0.9784\n",
      "Epoch 62/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.1121 - accuracy: 0.9776\n",
      "Epoch 62: val_loss improved from 0.11088 to 0.11058, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9777 - val_loss: 0.1106 - val_accuracy: 0.9784\n",
      "Epoch 63/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.1106 - accuracy: 0.9778\n",
      "Epoch 63: val_loss improved from 0.11058 to 0.11031, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9777 - val_loss: 0.1103 - val_accuracy: 0.9784\n",
      "Epoch 64/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.1083 - accuracy: 0.9783\n",
      "Epoch 64: val_loss improved from 0.11031 to 0.11008, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9777 - val_loss: 0.1101 - val_accuracy: 0.9784\n",
      "Epoch 65/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1119 - accuracy: 0.9774\n",
      "Epoch 65: val_loss improved from 0.11008 to 0.10976, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9777 - val_loss: 0.1098 - val_accuracy: 0.9784\n",
      "Epoch 66/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.1113 - accuracy: 0.9775\n",
      "Epoch 66: val_loss improved from 0.10976 to 0.10945, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9777 - val_loss: 0.1094 - val_accuracy: 0.9784\n",
      "Epoch 67/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.1126 - accuracy: 0.9772\n",
      "Epoch 67: val_loss improved from 0.10945 to 0.10916, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9777 - val_loss: 0.1092 - val_accuracy: 0.9784\n",
      "Epoch 68/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.1102 - accuracy: 0.9776\n",
      "Epoch 68: val_loss improved from 0.10916 to 0.10888, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9777 - val_loss: 0.1089 - val_accuracy: 0.9784\n",
      "Epoch 69/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.1101 - accuracy: 0.9776\n",
      "Epoch 69: val_loss improved from 0.10888 to 0.10864, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9777 - val_loss: 0.1086 - val_accuracy: 0.9784\n",
      "Epoch 70/400\n",
      "87/91 [===========================>..] - ETA: 0s - loss: 0.1086 - accuracy: 0.9779\n",
      "Epoch 70: val_loss improved from 0.10864 to 0.10836, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 988us/step - loss: 0.1093 - accuracy: 0.9777 - val_loss: 0.1084 - val_accuracy: 0.9784\n",
      "Epoch 71/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.1069 - accuracy: 0.9782\n",
      "Epoch 71: val_loss improved from 0.10836 to 0.10825, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9777 - val_loss: 0.1082 - val_accuracy: 0.9784\n",
      "Epoch 72/400\n",
      "87/91 [===========================>..] - ETA: 0s - loss: 0.1079 - accuracy: 0.9779\n",
      "Epoch 72: val_loss improved from 0.10825 to 0.10782, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9777 - val_loss: 0.1078 - val_accuracy: 0.9784\n",
      "Epoch 73/400\n",
      "65/91 [====================>.........] - ETA: 0s - loss: 0.1125 - accuracy: 0.9766\n",
      "Epoch 73: val_loss improved from 0.10782 to 0.10764, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9777 - val_loss: 0.1076 - val_accuracy: 0.9784\n",
      "Epoch 74/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.1094 - accuracy: 0.9775\n",
      "Epoch 74: val_loss improved from 0.10764 to 0.10732, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9777 - val_loss: 0.1073 - val_accuracy: 0.9784\n",
      "Epoch 75/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.1044 - accuracy: 0.9786\n",
      "Epoch 75: val_loss improved from 0.10732 to 0.10704, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9777 - val_loss: 0.1070 - val_accuracy: 0.9784\n",
      "Epoch 76/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/91 [======================>.......] - ETA: 0s - loss: 0.1059 - accuracy: 0.9782\n",
      "Epoch 76: val_loss improved from 0.10704 to 0.10680, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9777 - val_loss: 0.1068 - val_accuracy: 0.9784\n",
      "Epoch 77/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.1066 - accuracy: 0.9780\n",
      "Epoch 77: val_loss improved from 0.10680 to 0.10655, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9777 - val_loss: 0.1066 - val_accuracy: 0.9784\n",
      "Epoch 78/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1064 - accuracy: 0.9779\n",
      "Epoch 78: val_loss improved from 0.10655 to 0.10647, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9777 - val_loss: 0.1065 - val_accuracy: 0.9784\n",
      "Epoch 79/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1082 - accuracy: 0.9774\n",
      "Epoch 79: val_loss improved from 0.10647 to 0.10616, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9777 - val_loss: 0.1062 - val_accuracy: 0.9784\n",
      "Epoch 80/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.1046 - accuracy: 0.9783\n",
      "Epoch 80: val_loss improved from 0.10616 to 0.10592, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9777 - val_loss: 0.1059 - val_accuracy: 0.9784\n",
      "Epoch 81/400\n",
      "64/91 [====================>.........] - ETA: 0s - loss: 0.1086 - accuracy: 0.9772\n",
      "Epoch 81: val_loss improved from 0.10592 to 0.10567, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9777 - val_loss: 0.1057 - val_accuracy: 0.9784\n",
      "Epoch 82/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.1074 - accuracy: 0.9775\n",
      "Epoch 82: val_loss improved from 0.10567 to 0.10543, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9777 - val_loss: 0.1054 - val_accuracy: 0.9784\n",
      "Epoch 83/400\n",
      "68/91 [=====================>........] - ETA: 0s - loss: 0.1058 - accuracy: 0.9778\n",
      "Epoch 83: val_loss improved from 0.10543 to 0.10519, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9777 - val_loss: 0.1052 - val_accuracy: 0.9784\n",
      "Epoch 84/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.1056 - accuracy: 0.9777\n",
      "Epoch 84: val_loss improved from 0.10519 to 0.10511, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9777 - val_loss: 0.1051 - val_accuracy: 0.9784\n",
      "Epoch 85/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.1054 - accuracy: 0.9778\n",
      "Epoch 85: val_loss improved from 0.10511 to 0.10483, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9777 - val_loss: 0.1048 - val_accuracy: 0.9784\n",
      "Epoch 86/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.1039 - accuracy: 0.9781\n",
      "Epoch 86: val_loss improved from 0.10483 to 0.10466, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9777 - val_loss: 0.1047 - val_accuracy: 0.9784\n",
      "Epoch 87/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.1072 - accuracy: 0.9772\n",
      "Epoch 87: val_loss improved from 0.10466 to 0.10456, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9777 - val_loss: 0.1046 - val_accuracy: 0.9784\n",
      "Epoch 88/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.1068 - accuracy: 0.9771\n",
      "Epoch 88: val_loss improved from 0.10456 to 0.10440, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9777 - val_loss: 0.1044 - val_accuracy: 0.9784\n",
      "Epoch 89/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.1058 - accuracy: 0.9774\n",
      "Epoch 89: val_loss improved from 0.10440 to 0.10432, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9777 - val_loss: 0.1043 - val_accuracy: 0.9784\n",
      "Epoch 90/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.1015 - accuracy: 0.9785\n",
      "Epoch 90: val_loss improved from 0.10432 to 0.10415, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9777 - val_loss: 0.1041 - val_accuracy: 0.9784\n",
      "Epoch 91/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.1036 - accuracy: 0.9780\n",
      "Epoch 91: val_loss improved from 0.10415 to 0.10383, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9777 - val_loss: 0.1038 - val_accuracy: 0.9784\n",
      "Epoch 92/400\n",
      "64/91 [====================>.........] - ETA: 0s - loss: 0.1069 - accuracy: 0.9770\n",
      "Epoch 92: val_loss improved from 0.10383 to 0.10367, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9777 - val_loss: 0.1037 - val_accuracy: 0.9784\n",
      "Epoch 93/400\n",
      "87/91 [===========================>..] - ETA: 0s - loss: 0.1044 - accuracy: 0.9776\n",
      "Epoch 93: val_loss did not improve from 0.10367\n",
      "91/91 [==============================] - 0s 891us/step - loss: 0.1040 - accuracy: 0.9777 - val_loss: 0.1038 - val_accuracy: 0.9784\n",
      "Epoch 94/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.1012 - accuracy: 0.9784\n",
      "Epoch 94: val_loss improved from 0.10367 to 0.10336, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9777 - val_loss: 0.1034 - val_accuracy: 0.9784\n",
      "Epoch 95/400\n",
      "64/91 [====================>.........] - ETA: 0s - loss: 0.1011 - accuracy: 0.9785\n",
      "Epoch 95: val_loss improved from 0.10336 to 0.10325, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9777 - val_loss: 0.1033 - val_accuracy: 0.9784\n",
      "Epoch 96/400\n",
      "62/91 [===================>..........] - ETA: 0s - loss: 0.1046 - accuracy: 0.9772\n",
      "Epoch 96: val_loss improved from 0.10325 to 0.10310, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1035 - accuracy: 0.9777 - val_loss: 0.1031 - val_accuracy: 0.9784\n",
      "Epoch 97/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1040 - accuracy: 0.9777\n",
      "Epoch 97: val_loss improved from 0.10310 to 0.10298, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9777 - val_loss: 0.1030 - val_accuracy: 0.9784\n",
      "Epoch 98/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.1030 - accuracy: 0.9778\n",
      "Epoch 98: val_loss improved from 0.10298 to 0.10276, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9777 - val_loss: 0.1028 - val_accuracy: 0.9784\n",
      "Epoch 99/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.1052 - accuracy: 0.9771\n",
      "Epoch 99: val_loss improved from 0.10276 to 0.10267, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9777 - val_loss: 0.1027 - val_accuracy: 0.9784\n",
      "Epoch 100/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.1031 - accuracy: 0.9778\n",
      "Epoch 100: val_loss improved from 0.10267 to 0.10252, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9777 - val_loss: 0.1025 - val_accuracy: 0.9784\n",
      "Epoch 101/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1029 - accuracy: 0.9778\n",
      "Epoch 101: val_loss improved from 0.10252 to 0.10230, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9777 - val_loss: 0.1023 - val_accuracy: 0.9784\n",
      "Epoch 102/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.0997 - accuracy: 0.9787\n",
      "Epoch 102: val_loss did not improve from 0.10230\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9777 - val_loss: 0.1023 - val_accuracy: 0.9784\n",
      "Epoch 103/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.1041 - accuracy: 0.9774\n",
      "Epoch 103: val_loss improved from 0.10230 to 0.10215, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9777 - val_loss: 0.1021 - val_accuracy: 0.9784\n",
      "Epoch 104/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.1040 - accuracy: 0.9773\n",
      "Epoch 104: val_loss improved from 0.10215 to 0.10203, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9777 - val_loss: 0.1020 - val_accuracy: 0.9784\n",
      "Epoch 105/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.1014 - accuracy: 0.9779\n",
      "Epoch 105: val_loss improved from 0.10203 to 0.10200, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9777 - val_loss: 0.1020 - val_accuracy: 0.9784\n",
      "Epoch 106/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.1017 - accuracy: 0.9779\n",
      "Epoch 106: val_loss improved from 0.10200 to 0.10182, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9777 - val_loss: 0.1018 - val_accuracy: 0.9784\n",
      "Epoch 107/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.1034 - accuracy: 0.9772\n",
      "Epoch 107: val_loss improved from 0.10182 to 0.10178, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9777 - val_loss: 0.1018 - val_accuracy: 0.9784\n",
      "Epoch 108/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.1011 - accuracy: 0.9780\n",
      "Epoch 108: val_loss improved from 0.10178 to 0.10171, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9777 - val_loss: 0.1017 - val_accuracy: 0.9784\n",
      "Epoch 109/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.1028 - accuracy: 0.9774\n",
      "Epoch 109: val_loss improved from 0.10171 to 0.10160, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9777 - val_loss: 0.1016 - val_accuracy: 0.9784\n",
      "Epoch 110/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.1040 - accuracy: 0.9770\n",
      "Epoch 110: val_loss improved from 0.10160 to 0.10150, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9777 - val_loss: 0.1015 - val_accuracy: 0.9784\n",
      "Epoch 111/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.1016 - accuracy: 0.9777\n",
      "Epoch 111: val_loss did not improve from 0.10150\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9777 - val_loss: 0.1015 - val_accuracy: 0.9784\n",
      "Epoch 112/400\n",
      "57/91 [=================>............] - ETA: 0s - loss: 0.1035 - accuracy: 0.9772\n",
      "Epoch 112: val_loss improved from 0.10150 to 0.10136, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9777 - val_loss: 0.1014 - val_accuracy: 0.9784\n",
      "Epoch 113/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.1025 - accuracy: 0.9776\n",
      "Epoch 113: val_loss improved from 0.10136 to 0.10128, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9777 - val_loss: 0.1013 - val_accuracy: 0.9784\n",
      "Epoch 114/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1006 - accuracy: 0.9780\n",
      "Epoch 114: val_loss improved from 0.10128 to 0.10111, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9777 - val_loss: 0.1011 - val_accuracy: 0.9784\n",
      "Epoch 115/400\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.1023 - accuracy: 0.9775\n",
      "Epoch 115: val_loss did not improve from 0.10111\n",
      "91/91 [==============================] - 0s 879us/step - loss: 0.1013 - accuracy: 0.9777 - val_loss: 0.1013 - val_accuracy: 0.9784\n",
      "Epoch 116/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.1013 - accuracy: 0.9777\n",
      "Epoch 116: val_loss improved from 0.10111 to 0.10097, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9777 - val_loss: 0.1010 - val_accuracy: 0.9784\n",
      "Epoch 117/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.1012 - accuracy: 0.9777\n",
      "Epoch 117: val_loss improved from 0.10097 to 0.10092, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9777 - val_loss: 0.1009 - val_accuracy: 0.9784\n",
      "Epoch 118/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.1012 - accuracy: 0.9777\n",
      "Epoch 118: val_loss improved from 0.10092 to 0.10077, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9777 - val_loss: 0.1008 - val_accuracy: 0.9784\n",
      "Epoch 119/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.0990 - accuracy: 0.9784\n",
      "Epoch 119: val_loss improved from 0.10077 to 0.10070, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9777 - val_loss: 0.1007 - val_accuracy: 0.9784\n",
      "Epoch 120/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.1002 - accuracy: 0.9778\n",
      "Epoch 120: val_loss improved from 0.10070 to 0.10060, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1009 - accuracy: 0.9777 - val_loss: 0.1006 - val_accuracy: 0.9784\n",
      "Epoch 121/400\n",
      "67/91 [=====================>........] - ETA: 0s - loss: 0.1019 - accuracy: 0.9774\n",
      "Epoch 121: val_loss improved from 0.10060 to 0.10055, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9777 - val_loss: 0.1005 - val_accuracy: 0.9784\n",
      "Epoch 122/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.1008 - accuracy: 0.9777\n",
      "Epoch 122: val_loss improved from 0.10055 to 0.10043, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9777 - val_loss: 0.1004 - val_accuracy: 0.9784\n",
      "Epoch 123/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.1029 - accuracy: 0.9771\n",
      "Epoch 123: val_loss improved from 0.10043 to 0.10042, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9777 - val_loss: 0.1004 - val_accuracy: 0.9784\n",
      "Epoch 124/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0990 - accuracy: 0.9780\n",
      "Epoch 124: val_loss improved from 0.10042 to 0.10035, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9777 - val_loss: 0.1004 - val_accuracy: 0.9784\n",
      "Epoch 125/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/91 [========================>.....] - ETA: 0s - loss: 0.1016 - accuracy: 0.9774\n",
      "Epoch 125: val_loss improved from 0.10035 to 0.10022, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9777 - val_loss: 0.1002 - val_accuracy: 0.9784\n",
      "Epoch 126/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.1032 - accuracy: 0.9769\n",
      "Epoch 126: val_loss improved from 0.10022 to 0.10017, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9777 - val_loss: 0.1002 - val_accuracy: 0.9784\n",
      "Epoch 127/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.1046 - accuracy: 0.9766\n",
      "Epoch 127: val_loss improved from 0.10017 to 0.10010, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9777 - val_loss: 0.1001 - val_accuracy: 0.9784\n",
      "Epoch 128/400\n",
      "66/91 [====================>.........] - ETA: 0s - loss: 0.1032 - accuracy: 0.9771\n",
      "Epoch 128: val_loss did not improve from 0.10010\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9777 - val_loss: 0.1002 - val_accuracy: 0.9784\n",
      "Epoch 129/400\n",
      "65/91 [====================>.........] - ETA: 0s - loss: 0.1040 - accuracy: 0.9766\n",
      "Epoch 129: val_loss improved from 0.10010 to 0.09999, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9777 - val_loss: 0.1000 - val_accuracy: 0.9784\n",
      "Epoch 130/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.1004 - accuracy: 0.9775\n",
      "Epoch 130: val_loss improved from 0.09999 to 0.09989, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9777 - val_loss: 0.0999 - val_accuracy: 0.9784\n",
      "Epoch 131/400\n",
      "65/91 [====================>.........] - ETA: 0s - loss: 0.1035 - accuracy: 0.9768\n",
      "Epoch 131: val_loss did not improve from 0.09989\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9777 - val_loss: 0.1000 - val_accuracy: 0.9784\n",
      "Epoch 132/400\n",
      "68/91 [=====================>........] - ETA: 0s - loss: 0.0989 - accuracy: 0.9781\n",
      "Epoch 132: val_loss improved from 0.09989 to 0.09979, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9777 - val_loss: 0.0998 - val_accuracy: 0.9784\n",
      "Epoch 133/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0985 - accuracy: 0.9781\n",
      "Epoch 133: val_loss did not improve from 0.09979\n",
      "91/91 [==============================] - 0s 951us/step - loss: 0.1000 - accuracy: 0.9777 - val_loss: 0.0998 - val_accuracy: 0.9784\n",
      "Epoch 134/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.1000 - accuracy: 0.9776\n",
      "Epoch 134: val_loss improved from 0.09979 to 0.09970, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9777 - val_loss: 0.0997 - val_accuracy: 0.9784\n",
      "Epoch 135/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.1004 - accuracy: 0.9775\n",
      "Epoch 135: val_loss did not improve from 0.09970\n",
      "91/91 [==============================] - 0s 945us/step - loss: 0.0998 - accuracy: 0.9777 - val_loss: 0.0997 - val_accuracy: 0.9784\n",
      "Epoch 136/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0977 - accuracy: 0.9782\n",
      "Epoch 136: val_loss improved from 0.09970 to 0.09954, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9777 - val_loss: 0.0995 - val_accuracy: 0.9784\n",
      "Epoch 137/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0994 - accuracy: 0.9778\n",
      "Epoch 137: val_loss improved from 0.09954 to 0.09949, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9777 - val_loss: 0.0995 - val_accuracy: 0.9784\n",
      "Epoch 138/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.1007 - accuracy: 0.9773\n",
      "Epoch 138: val_loss improved from 0.09949 to 0.09938, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9777 - val_loss: 0.0994 - val_accuracy: 0.9784\n",
      "Epoch 139/400\n",
      "65/91 [====================>.........] - ETA: 0s - loss: 0.0999 - accuracy: 0.9776\n",
      "Epoch 139: val_loss improved from 0.09938 to 0.09927, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0995 - accuracy: 0.9777 - val_loss: 0.0993 - val_accuracy: 0.9784\n",
      "Epoch 140/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.1009 - accuracy: 0.9771\n",
      "Epoch 140: val_loss did not improve from 0.09927\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9777 - val_loss: 0.0993 - val_accuracy: 0.9784\n",
      "Epoch 141/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.0970 - accuracy: 0.9784\n",
      "Epoch 141: val_loss improved from 0.09927 to 0.09924, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9777 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
      "Epoch 142/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0978 - accuracy: 0.9782\n",
      "Epoch 142: val_loss improved from 0.09924 to 0.09921, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9777 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
      "Epoch 143/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0997 - accuracy: 0.9776\n",
      "Epoch 143: val_loss improved from 0.09921 to 0.09908, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9777 - val_loss: 0.0991 - val_accuracy: 0.9784\n",
      "Epoch 144/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.1000 - accuracy: 0.9776\n",
      "Epoch 144: val_loss improved from 0.09908 to 0.09895, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9777 - val_loss: 0.0989 - val_accuracy: 0.9784\n",
      "Epoch 145/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0984 - accuracy: 0.9780\n",
      "Epoch 145: val_loss did not improve from 0.09895\n",
      "91/91 [==============================] - 0s 998us/step - loss: 0.0991 - accuracy: 0.9777 - val_loss: 0.0991 - val_accuracy: 0.9784\n",
      "Epoch 146/400\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.0989 - accuracy: 0.9777\n",
      "Epoch 146: val_loss did not improve from 0.09895\n",
      "91/91 [==============================] - 0s 870us/step - loss: 0.0992 - accuracy: 0.9777 - val_loss: 0.0990 - val_accuracy: 0.9784\n",
      "Epoch 147/400\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.0996 - accuracy: 0.9775\n",
      "Epoch 147: val_loss improved from 0.09895 to 0.09894, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0990 - accuracy: 0.9777 - val_loss: 0.0989 - val_accuracy: 0.9784\n",
      "Epoch 148/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0990 - accuracy: 0.9777\n",
      "Epoch 148: val_loss did not improve from 0.09894\n",
      "91/91 [==============================] - 0s 963us/step - loss: 0.0989 - accuracy: 0.9777 - val_loss: 0.0990 - val_accuracy: 0.9784\n",
      "Epoch 149/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0998 - accuracy: 0.9775\n",
      "Epoch 149: val_loss improved from 0.09894 to 0.09863, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9777 - val_loss: 0.0986 - val_accuracy: 0.9784\n",
      "Epoch 150/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0998 - accuracy: 0.9776\n",
      "Epoch 150: val_loss did not improve from 0.09863\n",
      "91/91 [==============================] - 0s 978us/step - loss: 0.0987 - accuracy: 0.9777 - val_loss: 0.0987 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0982 - accuracy: 0.9777\n",
      "Epoch 151: val_loss improved from 0.09863 to 0.09850, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9777 - val_loss: 0.0985 - val_accuracy: 0.9784\n",
      "Epoch 152/400\n",
      "67/91 [=====================>........] - ETA: 0s - loss: 0.0972 - accuracy: 0.9781\n",
      "Epoch 152: val_loss improved from 0.09850 to 0.09833, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9777 - val_loss: 0.0983 - val_accuracy: 0.9784\n",
      "Epoch 153/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.0955 - accuracy: 0.9784\n",
      "Epoch 153: val_loss improved from 0.09833 to 0.09831, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9777 - val_loss: 0.0983 - val_accuracy: 0.9784\n",
      "Epoch 154/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.1026 - accuracy: 0.9766\n",
      "Epoch 154: val_loss improved from 0.09831 to 0.09815, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9777 - val_loss: 0.0982 - val_accuracy: 0.9784\n",
      "Epoch 155/400\n",
      "68/91 [=====================>........] - ETA: 0s - loss: 0.0986 - accuracy: 0.9778\n",
      "Epoch 155: val_loss improved from 0.09815 to 0.09805, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.9777 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
      "Epoch 156/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.0999 - accuracy: 0.9772\n",
      "Epoch 156: val_loss improved from 0.09805 to 0.09792, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9777 - val_loss: 0.0979 - val_accuracy: 0.9784\n",
      "Epoch 157/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.0984 - accuracy: 0.9775\n",
      "Epoch 157: val_loss improved from 0.09792 to 0.09778, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9777 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
      "Epoch 158/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.0970 - accuracy: 0.9781\n",
      "Epoch 158: val_loss did not improve from 0.09778\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9777 - val_loss: 0.0979 - val_accuracy: 0.9784\n",
      "Epoch 159/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.0987 - accuracy: 0.9775\n",
      "Epoch 159: val_loss did not improve from 0.09778\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9777 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
      "Epoch 160/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.1002 - accuracy: 0.9770\n",
      "Epoch 160: val_loss improved from 0.09778 to 0.09763, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9777 - val_loss: 0.0976 - val_accuracy: 0.9784\n",
      "Epoch 161/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0965 - accuracy: 0.9780\n",
      "Epoch 161: val_loss improved from 0.09763 to 0.09751, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9777 - val_loss: 0.0975 - val_accuracy: 0.9784\n",
      "Epoch 162/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0966 - accuracy: 0.9781\n",
      "Epoch 162: val_loss improved from 0.09751 to 0.09738, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9777 - val_loss: 0.0974 - val_accuracy: 0.9784\n",
      "Epoch 163/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0984 - accuracy: 0.9775\n",
      "Epoch 163: val_loss did not improve from 0.09738\n",
      "91/91 [==============================] - 0s 944us/step - loss: 0.0974 - accuracy: 0.9777 - val_loss: 0.0974 - val_accuracy: 0.9784\n",
      "Epoch 164/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0965 - accuracy: 0.9778\n",
      "Epoch 164: val_loss improved from 0.09738 to 0.09735, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9777 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
      "Epoch 165/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.0970 - accuracy: 0.9778\n",
      "Epoch 165: val_loss improved from 0.09735 to 0.09729, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9777 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
      "Epoch 166/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0964 - accuracy: 0.9780\n",
      "Epoch 166: val_loss improved from 0.09729 to 0.09729, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9777 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
      "Epoch 167/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0972 - accuracy: 0.9777\n",
      "Epoch 167: val_loss improved from 0.09729 to 0.09718, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9777 - val_loss: 0.0972 - val_accuracy: 0.9784\n",
      "Epoch 168/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0978 - accuracy: 0.9776\n",
      "Epoch 168: val_loss improved from 0.09718 to 0.09710, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9777 - val_loss: 0.0971 - val_accuracy: 0.9784\n",
      "Epoch 169/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0976 - accuracy: 0.9776\n",
      "Epoch 169: val_loss improved from 0.09710 to 0.09707, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9777 - val_loss: 0.0971 - val_accuracy: 0.9784\n",
      "Epoch 170/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0960 - accuracy: 0.9780\n",
      "Epoch 170: val_loss improved from 0.09707 to 0.09702, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9777 - val_loss: 0.0970 - val_accuracy: 0.9784\n",
      "Epoch 171/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.0950 - accuracy: 0.9785\n",
      "Epoch 171: val_loss improved from 0.09702 to 0.09693, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9777 - val_loss: 0.0969 - val_accuracy: 0.9784\n",
      "Epoch 172/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0986 - accuracy: 0.9773\n",
      "Epoch 172: val_loss did not improve from 0.09693\n",
      "91/91 [==============================] - 0s 958us/step - loss: 0.0970 - accuracy: 0.9777 - val_loss: 0.0970 - val_accuracy: 0.9784\n",
      "Epoch 173/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0968 - accuracy: 0.9777\n",
      "Epoch 173: val_loss improved from 0.09693 to 0.09691, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9777 - val_loss: 0.0969 - val_accuracy: 0.9784\n",
      "Epoch 174/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0982 - accuracy: 0.9773\n",
      "Epoch 174: val_loss improved from 0.09691 to 0.09689, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9777 - val_loss: 0.0969 - val_accuracy: 0.9784\n",
      "Epoch 175/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0939 - accuracy: 0.9785\n",
      "Epoch 175: val_loss improved from 0.09689 to 0.09685, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9777 - val_loss: 0.0968 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0970 - accuracy: 0.9776\n",
      "Epoch 176: val_loss improved from 0.09685 to 0.09678, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9777 - val_loss: 0.0968 - val_accuracy: 0.9784\n",
      "Epoch 177/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0971 - accuracy: 0.9779\n",
      "Epoch 177: val_loss improved from 0.09678 to 0.09675, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9777 - val_loss: 0.0967 - val_accuracy: 0.9784\n",
      "Epoch 178/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0946 - accuracy: 0.9783\n",
      "Epoch 178: val_loss did not improve from 0.09675\n",
      "91/91 [==============================] - 0s 975us/step - loss: 0.0967 - accuracy: 0.9777 - val_loss: 0.0967 - val_accuracy: 0.9784\n",
      "Epoch 179/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0983 - accuracy: 0.9774\n",
      "Epoch 179: val_loss improved from 0.09675 to 0.09662, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9777 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
      "Epoch 180/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0979 - accuracy: 0.9774\n",
      "Epoch 180: val_loss did not improve from 0.09662\n",
      "91/91 [==============================] - 0s 953us/step - loss: 0.0965 - accuracy: 0.9777 - val_loss: 0.0968 - val_accuracy: 0.9784\n",
      "Epoch 181/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0966 - accuracy: 0.9779\n",
      "Epoch 181: val_loss did not improve from 0.09662\n",
      "91/91 [==============================] - 0s 946us/step - loss: 0.0966 - accuracy: 0.9777 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
      "Epoch 182/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0950 - accuracy: 0.9780\n",
      "Epoch 182: val_loss improved from 0.09662 to 0.09654, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9777 - val_loss: 0.0965 - val_accuracy: 0.9784\n",
      "Epoch 183/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0948 - accuracy: 0.9782\n",
      "Epoch 183: val_loss did not improve from 0.09654\n",
      "91/91 [==============================] - 0s 979us/step - loss: 0.0966 - accuracy: 0.9777 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
      "Epoch 184/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.0959 - accuracy: 0.9777\n",
      "Epoch 184: val_loss improved from 0.09654 to 0.09638, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9777 - val_loss: 0.0964 - val_accuracy: 0.9784\n",
      "Epoch 185/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0958 - accuracy: 0.9780\n",
      "Epoch 185: val_loss improved from 0.09638 to 0.09634, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9777 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
      "Epoch 186/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0962 - accuracy: 0.9777\n",
      "Epoch 186: val_loss did not improve from 0.09634\n",
      "91/91 [==============================] - 0s 969us/step - loss: 0.0963 - accuracy: 0.9777 - val_loss: 0.0964 - val_accuracy: 0.9784\n",
      "Epoch 187/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0965 - accuracy: 0.9776\n",
      "Epoch 187: val_loss improved from 0.09634 to 0.09625, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9777 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
      "Epoch 188/400\n",
      "64/91 [====================>.........] - ETA: 0s - loss: 0.0907 - accuracy: 0.9791\n",
      "Epoch 188: val_loss did not improve from 0.09625\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9777 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
      "Epoch 189/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.0965 - accuracy: 0.9776\n",
      "Epoch 189: val_loss did not improve from 0.09625\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9777 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
      "Epoch 190/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0985 - accuracy: 0.9769\n",
      "Epoch 190: val_loss improved from 0.09625 to 0.09625, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9777 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
      "Epoch 191/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0968 - accuracy: 0.9776\n",
      "Epoch 191: val_loss improved from 0.09625 to 0.09617, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9777 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
      "Epoch 192/400\n",
      "66/91 [====================>.........] - ETA: 0s - loss: 0.1003 - accuracy: 0.9765\n",
      "Epoch 192: val_loss did not improve from 0.09617\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9777 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
      "Epoch 193/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0973 - accuracy: 0.9774\n",
      "Epoch 193: val_loss improved from 0.09617 to 0.09617, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9777 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
      "Epoch 194/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0966 - accuracy: 0.9775\n",
      "Epoch 194: val_loss improved from 0.09617 to 0.09603, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9777 - val_loss: 0.0960 - val_accuracy: 0.9784\n",
      "Epoch 195/400\n",
      "68/91 [=====================>........] - ETA: 0s - loss: 0.0966 - accuracy: 0.9774\n",
      "Epoch 195: val_loss did not improve from 0.09603\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9777 - val_loss: 0.0961 - val_accuracy: 0.9784\n",
      "Epoch 196/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.0949 - accuracy: 0.9783\n",
      "Epoch 196: val_loss improved from 0.09603 to 0.09590, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9777 - val_loss: 0.0959 - val_accuracy: 0.9784\n",
      "Epoch 197/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.0937 - accuracy: 0.9784\n",
      "Epoch 197: val_loss improved from 0.09590 to 0.09586, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9777 - val_loss: 0.0959 - val_accuracy: 0.9784\n",
      "Epoch 198/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0961 - accuracy: 0.9775\n",
      "Epoch 198: val_loss improved from 0.09586 to 0.09580, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9777 - val_loss: 0.0958 - val_accuracy: 0.9784\n",
      "Epoch 199/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.0949 - accuracy: 0.9779\n",
      "Epoch 199: val_loss improved from 0.09580 to 0.09577, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9777 - val_loss: 0.0958 - val_accuracy: 0.9784\n",
      "Epoch 200/400\n",
      "63/91 [===================>..........] - ETA: 0s - loss: 0.0983 - accuracy: 0.9771\n",
      "Epoch 200: val_loss improved from 0.09577 to 0.09574, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9777 - val_loss: 0.0957 - val_accuracy: 0.9784\n",
      "Epoch 201/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.0962 - accuracy: 0.9776\n",
      "Epoch 201: val_loss did not improve from 0.09574\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9777 - val_loss: 0.0958 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0930 - accuracy: 0.9783\n",
      "Epoch 202: val_loss improved from 0.09574 to 0.09564, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9777 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
      "Epoch 203/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0941 - accuracy: 0.9784\n",
      "Epoch 203: val_loss improved from 0.09564 to 0.09560, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9777 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
      "Epoch 204/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0960 - accuracy: 0.9778\n",
      "Epoch 204: val_loss did not improve from 0.09560\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9777 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
      "Epoch 205/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.0947 - accuracy: 0.9780\n",
      "Epoch 205: val_loss did not improve from 0.09560\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9777 - val_loss: 0.0957 - val_accuracy: 0.9784\n",
      "Epoch 206/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0963 - accuracy: 0.9775\n",
      "Epoch 206: val_loss improved from 0.09560 to 0.09557, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9777 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
      "Epoch 207/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0952 - accuracy: 0.9777\n",
      "Epoch 207: val_loss improved from 0.09557 to 0.09549, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9777 - val_loss: 0.0955 - val_accuracy: 0.9784\n",
      "Epoch 208/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0960 - accuracy: 0.9776\n",
      "Epoch 208: val_loss improved from 0.09549 to 0.09549, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9777 - val_loss: 0.0955 - val_accuracy: 0.9784\n",
      "Epoch 209/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0948 - accuracy: 0.9777\n",
      "Epoch 209: val_loss improved from 0.09549 to 0.09539, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9777 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
      "Epoch 210/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0948 - accuracy: 0.9777\n",
      "Epoch 210: val_loss did not improve from 0.09539\n",
      "91/91 [==============================] - 0s 947us/step - loss: 0.0954 - accuracy: 0.9777 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
      "Epoch 211/400\n",
      "68/91 [=====================>........] - ETA: 0s - loss: 0.0969 - accuracy: 0.9775\n",
      "Epoch 211: val_loss improved from 0.09539 to 0.09532, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9777 - val_loss: 0.0953 - val_accuracy: 0.9784\n",
      "Epoch 212/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.0974 - accuracy: 0.9771\n",
      "Epoch 212: val_loss improved from 0.09532 to 0.09528, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9777 - val_loss: 0.0953 - val_accuracy: 0.9784\n",
      "Epoch 213/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0943 - accuracy: 0.9779\n",
      "Epoch 213: val_loss improved from 0.09528 to 0.09527, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9777 - val_loss: 0.0953 - val_accuracy: 0.9784\n",
      "Epoch 214/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0929 - accuracy: 0.9784\n",
      "Epoch 214: val_loss improved from 0.09527 to 0.09523, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9777 - val_loss: 0.0952 - val_accuracy: 0.9784\n",
      "Epoch 215/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0944 - accuracy: 0.9780\n",
      "Epoch 215: val_loss improved from 0.09523 to 0.09513, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9777 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
      "Epoch 216/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.0941 - accuracy: 0.9782\n",
      "Epoch 216: val_loss did not improve from 0.09513\n",
      "91/91 [==============================] - 0s 992us/step - loss: 0.0952 - accuracy: 0.9777 - val_loss: 0.0952 - val_accuracy: 0.9784\n",
      "Epoch 217/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0946 - accuracy: 0.9780\n",
      "Epoch 217: val_loss did not improve from 0.09513\n",
      "91/91 [==============================] - 0s 967us/step - loss: 0.0951 - accuracy: 0.9777 - val_loss: 0.0952 - val_accuracy: 0.9784\n",
      "Epoch 218/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0952 - accuracy: 0.9778\n",
      "Epoch 218: val_loss did not improve from 0.09513\n",
      "91/91 [==============================] - 0s 958us/step - loss: 0.0951 - accuracy: 0.9777 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
      "Epoch 219/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0967 - accuracy: 0.9773\n",
      "Epoch 219: val_loss improved from 0.09513 to 0.09504, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9777 - val_loss: 0.0950 - val_accuracy: 0.9784\n",
      "Epoch 220/400\n",
      "87/91 [===========================>..] - ETA: 0s - loss: 0.0954 - accuracy: 0.9775\n",
      "Epoch 220: val_loss did not improve from 0.09504\n",
      "91/91 [==============================] - 0s 886us/step - loss: 0.0949 - accuracy: 0.9777 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
      "Epoch 221/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.0945 - accuracy: 0.9778\n",
      "Epoch 221: val_loss did not improve from 0.09504\n",
      "91/91 [==============================] - 0s 890us/step - loss: 0.0950 - accuracy: 0.9777 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
      "Epoch 222/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.0955 - accuracy: 0.9776\n",
      "Epoch 222: val_loss improved from 0.09504 to 0.09494, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9777 - val_loss: 0.0949 - val_accuracy: 0.9784\n",
      "Epoch 223/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0957 - accuracy: 0.9775\n",
      "Epoch 223: val_loss improved from 0.09494 to 0.09485, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9777 - val_loss: 0.0948 - val_accuracy: 0.9784\n",
      "Epoch 224/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0960 - accuracy: 0.9773\n",
      "Epoch 224: val_loss did not improve from 0.09485\n",
      "91/91 [==============================] - 0s 898us/step - loss: 0.0947 - accuracy: 0.9777 - val_loss: 0.0952 - val_accuracy: 0.9784\n",
      "Epoch 225/400\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.0960 - accuracy: 0.9774\n",
      "Epoch 225: val_loss did not improve from 0.09485\n",
      "91/91 [==============================] - 0s 885us/step - loss: 0.0948 - accuracy: 0.9777 - val_loss: 0.0950 - val_accuracy: 0.9784\n",
      "Epoch 226/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0934 - accuracy: 0.9782\n",
      "Epoch 226: val_loss improved from 0.09485 to 0.09476, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9777 - val_loss: 0.0948 - val_accuracy: 0.9784\n",
      "Epoch 227/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0939 - accuracy: 0.9781\n",
      "Epoch 227: val_loss did not improve from 0.09476\n",
      "91/91 [==============================] - 0s 993us/step - loss: 0.0947 - accuracy: 0.9777 - val_loss: 0.0948 - val_accuracy: 0.9784\n",
      "Epoch 228/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0942 - accuracy: 0.9779\n",
      "Epoch 228: val_loss did not improve from 0.09476\n",
      "91/91 [==============================] - 0s 919us/step - loss: 0.0947 - accuracy: 0.9777 - val_loss: 0.0948 - val_accuracy: 0.9784\n",
      "Epoch 229/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.0959 - accuracy: 0.9773\n",
      "Epoch 229: val_loss improved from 0.09476 to 0.09470, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9777 - val_loss: 0.0947 - val_accuracy: 0.9784\n",
      "Epoch 230/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0953 - accuracy: 0.9775\n",
      "Epoch 230: val_loss did not improve from 0.09470\n",
      "91/91 [==============================] - 0s 958us/step - loss: 0.0948 - accuracy: 0.9777 - val_loss: 0.0948 - val_accuracy: 0.9784\n",
      "Epoch 231/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0948 - accuracy: 0.9778\n",
      "Epoch 231: val_loss improved from 0.09470 to 0.09468, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9777 - val_loss: 0.0947 - val_accuracy: 0.9784\n",
      "Epoch 232/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0936 - accuracy: 0.9780\n",
      "Epoch 232: val_loss improved from 0.09468 to 0.09468, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9777 - val_loss: 0.0947 - val_accuracy: 0.9784\n",
      "Epoch 233/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.0945 - accuracy: 0.9777\n",
      "Epoch 233: val_loss improved from 0.09468 to 0.09463, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9777 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
      "Epoch 234/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.0979 - accuracy: 0.9768\n",
      "Epoch 234: val_loss improved from 0.09463 to 0.09457, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9777 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
      "Epoch 235/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.0953 - accuracy: 0.9774\n",
      "Epoch 235: val_loss improved from 0.09457 to 0.09455, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9777 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
      "Epoch 236/400\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.0953 - accuracy: 0.9775\n",
      "Epoch 236: val_loss did not improve from 0.09455\n",
      "91/91 [==============================] - 0s 887us/step - loss: 0.0944 - accuracy: 0.9777 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
      "Epoch 237/400\n",
      "87/91 [===========================>..] - ETA: 0s - loss: 0.0948 - accuracy: 0.9777\n",
      "Epoch 237: val_loss improved from 0.09455 to 0.09452, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9777 - val_loss: 0.0945 - val_accuracy: 0.9784\n",
      "Epoch 238/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0938 - accuracy: 0.9778\n",
      "Epoch 238: val_loss improved from 0.09452 to 0.09445, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.9777 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
      "Epoch 239/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0958 - accuracy: 0.9774\n",
      "Epoch 239: val_loss did not improve from 0.09445\n",
      "91/91 [==============================] - 0s 928us/step - loss: 0.0943 - accuracy: 0.9777 - val_loss: 0.0947 - val_accuracy: 0.9784\n",
      "Epoch 240/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0941 - accuracy: 0.9779\n",
      "Epoch 240: val_loss improved from 0.09445 to 0.09442, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9777 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
      "Epoch 241/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0931 - accuracy: 0.9780\n",
      "Epoch 241: val_loss did not improve from 0.09442\n",
      "91/91 [==============================] - 0s 913us/step - loss: 0.0942 - accuracy: 0.9777 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
      "Epoch 242/400\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.0954 - accuracy: 0.9774\n",
      "Epoch 242: val_loss improved from 0.09442 to 0.09430, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 986us/step - loss: 0.0943 - accuracy: 0.9777 - val_loss: 0.0943 - val_accuracy: 0.9784\n",
      "Epoch 243/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0941 - accuracy: 0.9777\n",
      "Epoch 243: val_loss improved from 0.09430 to 0.09420, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0942 - accuracy: 0.9777 - val_loss: 0.0942 - val_accuracy: 0.9784\n",
      "Epoch 244/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0958 - accuracy: 0.9774\n",
      "Epoch 244: val_loss did not improve from 0.09420\n",
      "91/91 [==============================] - 0s 951us/step - loss: 0.0942 - accuracy: 0.9777 - val_loss: 0.0942 - val_accuracy: 0.9784\n",
      "Epoch 245/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0954 - accuracy: 0.9775\n",
      "Epoch 245: val_loss did not improve from 0.09420\n",
      "91/91 [==============================] - 0s 912us/step - loss: 0.0941 - accuracy: 0.9777 - val_loss: 0.0943 - val_accuracy: 0.9784\n",
      "Epoch 246/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0933 - accuracy: 0.9781\n",
      "Epoch 246: val_loss did not improve from 0.09420\n",
      "91/91 [==============================] - 0s 947us/step - loss: 0.0942 - accuracy: 0.9777 - val_loss: 0.0942 - val_accuracy: 0.9784\n",
      "Epoch 247/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0942 - accuracy: 0.9777\n",
      "Epoch 247: val_loss did not improve from 0.09420\n",
      "91/91 [==============================] - 0s 965us/step - loss: 0.0941 - accuracy: 0.9777 - val_loss: 0.0943 - val_accuracy: 0.9784\n",
      "Epoch 248/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.0958 - accuracy: 0.9770\n",
      "Epoch 248: val_loss improved from 0.09420 to 0.09418, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9777 - val_loss: 0.0942 - val_accuracy: 0.9784\n",
      "Epoch 249/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0946 - accuracy: 0.9777\n",
      "Epoch 249: val_loss improved from 0.09418 to 0.09416, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9777 - val_loss: 0.0942 - val_accuracy: 0.9784\n",
      "Epoch 250/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0957 - accuracy: 0.9773\n",
      "Epoch 250: val_loss improved from 0.09416 to 0.09408, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9777 - val_loss: 0.0941 - val_accuracy: 0.9784\n",
      "Epoch 251/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0931 - accuracy: 0.9779\n",
      "Epoch 251: val_loss did not improve from 0.09408\n",
      "91/91 [==============================] - 0s 948us/step - loss: 0.0941 - accuracy: 0.9777 - val_loss: 0.0943 - val_accuracy: 0.9784\n",
      "Epoch 252/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0935 - accuracy: 0.9780\n",
      "Epoch 252: val_loss did not improve from 0.09408\n",
      "91/91 [==============================] - 0s 936us/step - loss: 0.0941 - accuracy: 0.9777 - val_loss: 0.0941 - val_accuracy: 0.9784\n",
      "Epoch 253/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0940 - accuracy: 0.9777\n",
      "Epoch 253: val_loss improved from 0.09408 to 0.09400, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9777 - val_loss: 0.0940 - val_accuracy: 0.9784\n",
      "Epoch 254/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/91 [=====================>........] - ETA: 0s - loss: 0.0922 - accuracy: 0.9784\n",
      "Epoch 254: val_loss improved from 0.09400 to 0.09398, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9777 - val_loss: 0.0940 - val_accuracy: 0.9784\n",
      "Epoch 255/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0924 - accuracy: 0.9780\n",
      "Epoch 255: val_loss improved from 0.09398 to 0.09396, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9777 - val_loss: 0.0940 - val_accuracy: 0.9784\n",
      "Epoch 256/400\n",
      "68/91 [=====================>........] - ETA: 0s - loss: 0.0928 - accuracy: 0.9782\n",
      "Epoch 256: val_loss improved from 0.09396 to 0.09387, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9777 - val_loss: 0.0939 - val_accuracy: 0.9784\n",
      "Epoch 257/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0933 - accuracy: 0.9778\n",
      "Epoch 257: val_loss did not improve from 0.09387\n",
      "91/91 [==============================] - 0s 947us/step - loss: 0.0938 - accuracy: 0.9777 - val_loss: 0.0939 - val_accuracy: 0.9784\n",
      "Epoch 258/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0934 - accuracy: 0.9779\n",
      "Epoch 258: val_loss improved from 0.09387 to 0.09386, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9777 - val_loss: 0.0939 - val_accuracy: 0.9784\n",
      "Epoch 259/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0959 - accuracy: 0.9772\n",
      "Epoch 259: val_loss did not improve from 0.09386\n",
      "91/91 [==============================] - 0s 976us/step - loss: 0.0937 - accuracy: 0.9777 - val_loss: 0.0939 - val_accuracy: 0.9784\n",
      "Epoch 260/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0924 - accuracy: 0.9780\n",
      "Epoch 260: val_loss improved from 0.09386 to 0.09386, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.9777 - val_loss: 0.0939 - val_accuracy: 0.9784\n",
      "Epoch 261/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0955 - accuracy: 0.9771\n",
      "Epoch 261: val_loss improved from 0.09386 to 0.09373, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9777 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
      "Epoch 262/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0932 - accuracy: 0.9779\n",
      "Epoch 262: val_loss did not improve from 0.09373\n",
      "91/91 [==============================] - 0s 953us/step - loss: 0.0936 - accuracy: 0.9777 - val_loss: 0.0938 - val_accuracy: 0.9784\n",
      "Epoch 263/400\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.0941 - accuracy: 0.9777\n",
      "Epoch 263: val_loss improved from 0.09373 to 0.09368, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 994us/step - loss: 0.0937 - accuracy: 0.9777 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
      "Epoch 264/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0939 - accuracy: 0.9777\n",
      "Epoch 264: val_loss did not improve from 0.09368\n",
      "91/91 [==============================] - 0s 911us/step - loss: 0.0936 - accuracy: 0.9777 - val_loss: 0.0938 - val_accuracy: 0.9784\n",
      "Epoch 265/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0948 - accuracy: 0.9773\n",
      "Epoch 265: val_loss did not improve from 0.09368\n",
      "91/91 [==============================] - 0s 914us/step - loss: 0.0936 - accuracy: 0.9777 - val_loss: 0.0939 - val_accuracy: 0.9784\n",
      "Epoch 266/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0942 - accuracy: 0.9775\n",
      "Epoch 266: val_loss did not improve from 0.09368\n",
      "91/91 [==============================] - 0s 905us/step - loss: 0.0937 - accuracy: 0.9777 - val_loss: 0.0939 - val_accuracy: 0.9784\n",
      "Epoch 267/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0915 - accuracy: 0.9783\n",
      "Epoch 267: val_loss did not improve from 0.09368\n",
      "91/91 [==============================] - 0s 919us/step - loss: 0.0935 - accuracy: 0.9777 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
      "Epoch 268/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0922 - accuracy: 0.9779\n",
      "Epoch 268: val_loss did not improve from 0.09368\n",
      "91/91 [==============================] - 0s 902us/step - loss: 0.0935 - accuracy: 0.9777 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
      "Epoch 269/400\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.0937 - accuracy: 0.9776\n",
      "Epoch 269: val_loss did not improve from 0.09368\n",
      "91/91 [==============================] - 0s 906us/step - loss: 0.0934 - accuracy: 0.9777 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
      "Epoch 270/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0936 - accuracy: 0.9777\n",
      "Epoch 270: val_loss improved from 0.09368 to 0.09361, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9777 - val_loss: 0.0936 - val_accuracy: 0.9784\n",
      "Epoch 271/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0947 - accuracy: 0.9774\n",
      "Epoch 271: val_loss improved from 0.09361 to 0.09356, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9777 - val_loss: 0.0936 - val_accuracy: 0.9784\n",
      "Epoch 272/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.0936 - accuracy: 0.9776\n",
      "Epoch 272: val_loss improved from 0.09356 to 0.09352, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9777 - val_loss: 0.0935 - val_accuracy: 0.9784\n",
      "Epoch 273/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0939 - accuracy: 0.9776\n",
      "Epoch 273: val_loss did not improve from 0.09352\n",
      "91/91 [==============================] - 0s 967us/step - loss: 0.0933 - accuracy: 0.9777 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
      "Epoch 274/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0935 - accuracy: 0.9776\n",
      "Epoch 274: val_loss did not improve from 0.09352\n",
      "91/91 [==============================] - 0s 922us/step - loss: 0.0934 - accuracy: 0.9777 - val_loss: 0.0936 - val_accuracy: 0.9784\n",
      "Epoch 275/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0953 - accuracy: 0.9771\n",
      "Epoch 275: val_loss did not improve from 0.09352\n",
      "91/91 [==============================] - 0s 999us/step - loss: 0.0933 - accuracy: 0.9777 - val_loss: 0.0935 - val_accuracy: 0.9784\n",
      "Epoch 276/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0931 - accuracy: 0.9777\n",
      "Epoch 276: val_loss improved from 0.09352 to 0.09335, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9777 - val_loss: 0.0934 - val_accuracy: 0.9784\n",
      "Epoch 277/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0935 - accuracy: 0.9778\n",
      "Epoch 277: val_loss did not improve from 0.09335\n",
      "91/91 [==============================] - 0s 995us/step - loss: 0.0933 - accuracy: 0.9777 - val_loss: 0.0935 - val_accuracy: 0.9784\n",
      "Epoch 278/400\n",
      "63/91 [===================>..........] - ETA: 0s - loss: 0.0959 - accuracy: 0.9769\n",
      "Epoch 278: val_loss did not improve from 0.09335\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9777 - val_loss: 0.0935 - val_accuracy: 0.9784\n",
      "Epoch 279/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0912 - accuracy: 0.9783\n",
      "Epoch 279: val_loss improved from 0.09335 to 0.09332, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9777 - val_loss: 0.0933 - val_accuracy: 0.9784\n",
      "Epoch 280/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0929 - accuracy: 0.9778\n",
      "Epoch 280: val_loss improved from 0.09332 to 0.09325, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9777 - val_loss: 0.0933 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0946 - accuracy: 0.9774\n",
      "Epoch 281: val_loss did not improve from 0.09325\n",
      "91/91 [==============================] - 0s 981us/step - loss: 0.0931 - accuracy: 0.9777 - val_loss: 0.0934 - val_accuracy: 0.9784\n",
      "Epoch 282/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0921 - accuracy: 0.9779\n",
      "Epoch 282: val_loss did not improve from 0.09325\n",
      "91/91 [==============================] - 0s 944us/step - loss: 0.0931 - accuracy: 0.9777 - val_loss: 0.0933 - val_accuracy: 0.9784\n",
      "Epoch 283/400\n",
      "87/91 [===========================>..] - ETA: 0s - loss: 0.0930 - accuracy: 0.9778\n",
      "Epoch 283: val_loss did not improve from 0.09325\n",
      "91/91 [==============================] - 0s 881us/step - loss: 0.0931 - accuracy: 0.9777 - val_loss: 0.0933 - val_accuracy: 0.9784\n",
      "Epoch 284/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0951 - accuracy: 0.9771\n",
      "Epoch 284: val_loss improved from 0.09325 to 0.09323, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9777 - val_loss: 0.0932 - val_accuracy: 0.9784\n",
      "Epoch 285/400\n",
      "68/91 [=====================>........] - ETA: 0s - loss: 0.0919 - accuracy: 0.9781\n",
      "Epoch 285: val_loss improved from 0.09323 to 0.09313, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9777 - val_loss: 0.0931 - val_accuracy: 0.9784\n",
      "Epoch 286/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0925 - accuracy: 0.9778\n",
      "Epoch 286: val_loss improved from 0.09313 to 0.09300, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9777 - val_loss: 0.0930 - val_accuracy: 0.9784\n",
      "Epoch 287/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0927 - accuracy: 0.9777\n",
      "Epoch 287: val_loss did not improve from 0.09300\n",
      "91/91 [==============================] - 0s 971us/step - loss: 0.0930 - accuracy: 0.9777 - val_loss: 0.0931 - val_accuracy: 0.9784\n",
      "Epoch 288/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0922 - accuracy: 0.9780\n",
      "Epoch 288: val_loss did not improve from 0.09300\n",
      "91/91 [==============================] - 0s 937us/step - loss: 0.0929 - accuracy: 0.9777 - val_loss: 0.0930 - val_accuracy: 0.9784\n",
      "Epoch 289/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0929 - accuracy: 0.9777\n",
      "Epoch 289: val_loss did not improve from 0.09300\n",
      "91/91 [==============================] - 0s 898us/step - loss: 0.0929 - accuracy: 0.9777 - val_loss: 0.0930 - val_accuracy: 0.9784\n",
      "Epoch 290/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0916 - accuracy: 0.9781\n",
      "Epoch 290: val_loss did not improve from 0.09300\n",
      "91/91 [==============================] - 0s 901us/step - loss: 0.0929 - accuracy: 0.9777 - val_loss: 0.0931 - val_accuracy: 0.9784\n",
      "Epoch 291/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0935 - accuracy: 0.9776\n",
      "Epoch 291: val_loss did not improve from 0.09300\n",
      "91/91 [==============================] - 0s 914us/step - loss: 0.0930 - accuracy: 0.9777 - val_loss: 0.0930 - val_accuracy: 0.9784\n",
      "Epoch 292/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0927 - accuracy: 0.9777\n",
      "Epoch 292: val_loss improved from 0.09300 to 0.09297, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9777 - val_loss: 0.0930 - val_accuracy: 0.9784\n",
      "Epoch 293/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0930 - accuracy: 0.9777\n",
      "Epoch 293: val_loss improved from 0.09297 to 0.09292, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9777 - val_loss: 0.0929 - val_accuracy: 0.9784\n",
      "Epoch 294/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0909 - accuracy: 0.9783\n",
      "Epoch 294: val_loss improved from 0.09292 to 0.09286, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9777 - val_loss: 0.0929 - val_accuracy: 0.9784\n",
      "Epoch 295/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0936 - accuracy: 0.9774\n",
      "Epoch 295: val_loss did not improve from 0.09286\n",
      "91/91 [==============================] - 0s 917us/step - loss: 0.0928 - accuracy: 0.9777 - val_loss: 0.0929 - val_accuracy: 0.9784\n",
      "Epoch 296/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0924 - accuracy: 0.9779\n",
      "Epoch 296: val_loss improved from 0.09286 to 0.09285, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9777 - val_loss: 0.0928 - val_accuracy: 0.9784\n",
      "Epoch 297/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0920 - accuracy: 0.9780\n",
      "Epoch 297: val_loss improved from 0.09285 to 0.09279, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9777 - val_loss: 0.0928 - val_accuracy: 0.9784\n",
      "Epoch 298/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0926 - accuracy: 0.9777\n",
      "Epoch 298: val_loss improved from 0.09279 to 0.09277, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9777 - val_loss: 0.0928 - val_accuracy: 0.9784\n",
      "Epoch 299/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0958 - accuracy: 0.9768\n",
      "Epoch 299: val_loss did not improve from 0.09277\n",
      "91/91 [==============================] - 0s 937us/step - loss: 0.0926 - accuracy: 0.9777 - val_loss: 0.0931 - val_accuracy: 0.9784\n",
      "Epoch 300/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.0959 - accuracy: 0.9767\n",
      "Epoch 300: val_loss did not improve from 0.09277\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9777 - val_loss: 0.0932 - val_accuracy: 0.9784\n",
      "Epoch 301/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.0959 - accuracy: 0.9767\n",
      "Epoch 301: val_loss did not improve from 0.09277\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9777 - val_loss: 0.0929 - val_accuracy: 0.9784\n",
      "Epoch 302/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0928 - accuracy: 0.9777\n",
      "Epoch 302: val_loss did not improve from 0.09277\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9777 - val_loss: 0.0928 - val_accuracy: 0.9784\n",
      "Epoch 303/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0909 - accuracy: 0.9782\n",
      "Epoch 303: val_loss improved from 0.09277 to 0.09273, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9777 - val_loss: 0.0927 - val_accuracy: 0.9784\n",
      "Epoch 304/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0929 - accuracy: 0.9777\n",
      "Epoch 304: val_loss improved from 0.09273 to 0.09271, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9777 - val_loss: 0.0927 - val_accuracy: 0.9784\n",
      "Epoch 305/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.0886 - accuracy: 0.9788\n",
      "Epoch 305: val_loss improved from 0.09271 to 0.09270, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9777 - val_loss: 0.0927 - val_accuracy: 0.9784\n",
      "Epoch 306/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0937 - accuracy: 0.9774\n",
      "Epoch 306: val_loss did not improve from 0.09270\n",
      "91/91 [==============================] - 0s 980us/step - loss: 0.0923 - accuracy: 0.9777 - val_loss: 0.0927 - val_accuracy: 0.9784\n",
      "Epoch 307/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0899 - accuracy: 0.9784\n",
      "Epoch 307: val_loss did not improve from 0.09270\n",
      "91/91 [==============================] - 0s 986us/step - loss: 0.0924 - accuracy: 0.9777 - val_loss: 0.0930 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0921 - accuracy: 0.9779\n",
      "Epoch 308: val_loss improved from 0.09270 to 0.09267, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9777 - val_loss: 0.0927 - val_accuracy: 0.9784\n",
      "Epoch 309/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0946 - accuracy: 0.9770\n",
      "Epoch 309: val_loss did not improve from 0.09267\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9777 - val_loss: 0.0927 - val_accuracy: 0.9784\n",
      "Epoch 310/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.0927 - accuracy: 0.9780\n",
      "Epoch 310: val_loss improved from 0.09267 to 0.09247, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9777 - val_loss: 0.0925 - val_accuracy: 0.9784\n",
      "Epoch 311/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0940 - accuracy: 0.9772\n",
      "Epoch 311: val_loss improved from 0.09247 to 0.09244, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9777 - val_loss: 0.0924 - val_accuracy: 0.9784\n",
      "Epoch 312/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0922 - accuracy: 0.9777\n",
      "Epoch 312: val_loss did not improve from 0.09244\n",
      "91/91 [==============================] - 0s 955us/step - loss: 0.0923 - accuracy: 0.9777 - val_loss: 0.0926 - val_accuracy: 0.9784\n",
      "Epoch 313/400\n",
      "67/91 [=====================>........] - ETA: 0s - loss: 0.0917 - accuracy: 0.9778\n",
      "Epoch 313: val_loss did not improve from 0.09244\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9777 - val_loss: 0.0925 - val_accuracy: 0.9784\n",
      "Epoch 314/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0928 - accuracy: 0.9775\n",
      "Epoch 314: val_loss improved from 0.09244 to 0.09234, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9777 - val_loss: 0.0923 - val_accuracy: 0.9784\n",
      "Epoch 315/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.0894 - accuracy: 0.9783\n",
      "Epoch 315: val_loss improved from 0.09234 to 0.09228, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9777 - val_loss: 0.0923 - val_accuracy: 0.9784\n",
      "Epoch 316/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0919 - accuracy: 0.9778\n",
      "Epoch 316: val_loss did not improve from 0.09228\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9777 - val_loss: 0.0923 - val_accuracy: 0.9784\n",
      "Epoch 317/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0914 - accuracy: 0.9778\n",
      "Epoch 317: val_loss did not improve from 0.09228\n",
      "91/91 [==============================] - 0s 986us/step - loss: 0.0920 - accuracy: 0.9777 - val_loss: 0.0924 - val_accuracy: 0.9784\n",
      "Epoch 318/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0910 - accuracy: 0.9780\n",
      "Epoch 318: val_loss improved from 0.09228 to 0.09221, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9777 - val_loss: 0.0922 - val_accuracy: 0.9784\n",
      "Epoch 319/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0917 - accuracy: 0.9779\n",
      "Epoch 319: val_loss improved from 0.09221 to 0.09220, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9777 - val_loss: 0.0922 - val_accuracy: 0.9784\n",
      "Epoch 320/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0918 - accuracy: 0.9777\n",
      "Epoch 320: val_loss did not improve from 0.09220\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9777 - val_loss: 0.0922 - val_accuracy: 0.9784\n",
      "Epoch 321/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0935 - accuracy: 0.9772\n",
      "Epoch 321: val_loss did not improve from 0.09220\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9777 - val_loss: 0.0925 - val_accuracy: 0.9784\n",
      "Epoch 322/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.0888 - accuracy: 0.9789\n",
      "Epoch 322: val_loss improved from 0.09220 to 0.09211, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9777 - val_loss: 0.0921 - val_accuracy: 0.9784\n",
      "Epoch 323/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.0910 - accuracy: 0.9782\n",
      "Epoch 323: val_loss did not improve from 0.09211\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9777 - val_loss: 0.0924 - val_accuracy: 0.9784\n",
      "Epoch 324/400\n",
      "65/91 [====================>.........] - ETA: 0s - loss: 0.0950 - accuracy: 0.9772\n",
      "Epoch 324: val_loss did not improve from 0.09211\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9777 - val_loss: 0.0922 - val_accuracy: 0.9784\n",
      "Epoch 325/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0898 - accuracy: 0.9783\n",
      "Epoch 325: val_loss improved from 0.09211 to 0.09204, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9777 - val_loss: 0.0920 - val_accuracy: 0.9784\n",
      "Epoch 326/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0943 - accuracy: 0.9767\n",
      "Epoch 326: val_loss did not improve from 0.09204\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9777 - val_loss: 0.0922 - val_accuracy: 0.9784\n",
      "Epoch 327/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0916 - accuracy: 0.9778\n",
      "Epoch 327: val_loss did not improve from 0.09204\n",
      "91/91 [==============================] - 0s 962us/step - loss: 0.0918 - accuracy: 0.9777 - val_loss: 0.0921 - val_accuracy: 0.9784\n",
      "Epoch 328/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0927 - accuracy: 0.9775\n",
      "Epoch 328: val_loss did not improve from 0.09204\n",
      "91/91 [==============================] - 0s 930us/step - loss: 0.0918 - accuracy: 0.9777 - val_loss: 0.0922 - val_accuracy: 0.9784\n",
      "Epoch 329/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0928 - accuracy: 0.9773\n",
      "Epoch 329: val_loss improved from 0.09204 to 0.09193, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9777 - val_loss: 0.0919 - val_accuracy: 0.9784\n",
      "Epoch 330/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.0911 - accuracy: 0.9781\n",
      "Epoch 330: val_loss did not improve from 0.09193\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9777 - val_loss: 0.0920 - val_accuracy: 0.9784\n",
      "Epoch 331/400\n",
      "70/91 [======================>.......] - ETA: 0s - loss: 0.0906 - accuracy: 0.9780\n",
      "Epoch 331: val_loss improved from 0.09193 to 0.09192, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9777 - val_loss: 0.0919 - val_accuracy: 0.9784\n",
      "Epoch 332/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0944 - accuracy: 0.9768\n",
      "Epoch 332: val_loss did not improve from 0.09192\n",
      "91/91 [==============================] - 0s 975us/step - loss: 0.0916 - accuracy: 0.9777 - val_loss: 0.0921 - val_accuracy: 0.9784\n",
      "Epoch 333/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0888 - accuracy: 0.9783\n",
      "Epoch 333: val_loss improved from 0.09192 to 0.09181, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9777 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
      "Epoch 334/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0903 - accuracy: 0.9781\n",
      "Epoch 334: val_loss did not improve from 0.09181\n",
      "91/91 [==============================] - 0s 973us/step - loss: 0.0917 - accuracy: 0.9777 - val_loss: 0.0918 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0938 - accuracy: 0.9771\n",
      "Epoch 335: val_loss did not improve from 0.09181\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9777 - val_loss: 0.0923 - val_accuracy: 0.9784\n",
      "Epoch 336/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.0924 - accuracy: 0.9778\n",
      "Epoch 336: val_loss did not improve from 0.09181\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9777 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
      "Epoch 337/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0907 - accuracy: 0.9781\n",
      "Epoch 337: val_loss did not improve from 0.09181\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9777 - val_loss: 0.0919 - val_accuracy: 0.9784\n",
      "Epoch 338/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0907 - accuracy: 0.9782\n",
      "Epoch 338: val_loss improved from 0.09181 to 0.09170, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9777 - val_loss: 0.0917 - val_accuracy: 0.9784\n",
      "Epoch 339/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0925 - accuracy: 0.9775\n",
      "Epoch 339: val_loss did not improve from 0.09170\n",
      "91/91 [==============================] - 0s 910us/step - loss: 0.0915 - accuracy: 0.9777 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
      "Epoch 340/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0909 - accuracy: 0.9779\n",
      "Epoch 340: val_loss did not improve from 0.09170\n",
      "91/91 [==============================] - 0s 993us/step - loss: 0.0915 - accuracy: 0.9777 - val_loss: 0.0917 - val_accuracy: 0.9784\n",
      "Epoch 341/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0928 - accuracy: 0.9773\n",
      "Epoch 341: val_loss improved from 0.09170 to 0.09159, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9777 - val_loss: 0.0916 - val_accuracy: 0.9784\n",
      "Epoch 342/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0920 - accuracy: 0.9774\n",
      "Epoch 342: val_loss did not improve from 0.09159\n",
      "91/91 [==============================] - 0s 927us/step - loss: 0.0914 - accuracy: 0.9777 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
      "Epoch 343/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0936 - accuracy: 0.9772\n",
      "Epoch 343: val_loss did not improve from 0.09159\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9777 - val_loss: 0.0917 - val_accuracy: 0.9784\n",
      "Epoch 344/400\n",
      "72/91 [======================>.......] - ETA: 0s - loss: 0.0911 - accuracy: 0.9777\n",
      "Epoch 344: val_loss improved from 0.09159 to 0.09156, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9777 - val_loss: 0.0916 - val_accuracy: 0.9784\n",
      "Epoch 345/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0930 - accuracy: 0.9771\n",
      "Epoch 345: val_loss did not improve from 0.09156\n",
      "91/91 [==============================] - 0s 941us/step - loss: 0.0912 - accuracy: 0.9777 - val_loss: 0.0917 - val_accuracy: 0.9784\n",
      "Epoch 346/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0918 - accuracy: 0.9776\n",
      "Epoch 346: val_loss improved from 0.09156 to 0.09155, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9777 - val_loss: 0.0916 - val_accuracy: 0.9784\n",
      "Epoch 347/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0929 - accuracy: 0.9771\n",
      "Epoch 347: val_loss did not improve from 0.09155\n",
      "91/91 [==============================] - 0s 980us/step - loss: 0.0912 - accuracy: 0.9777 - val_loss: 0.0917 - val_accuracy: 0.9784\n",
      "Epoch 348/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0890 - accuracy: 0.9785\n",
      "Epoch 348: val_loss improved from 0.09155 to 0.09145, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9777 - val_loss: 0.0915 - val_accuracy: 0.9784\n",
      "Epoch 349/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0896 - accuracy: 0.9781\n",
      "Epoch 349: val_loss did not improve from 0.09145\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9777 - val_loss: 0.0915 - val_accuracy: 0.9784\n",
      "Epoch 350/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.0915 - accuracy: 0.9775\n",
      "Epoch 350: val_loss did not improve from 0.09145\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9777 - val_loss: 0.0915 - val_accuracy: 0.9784\n",
      "Epoch 351/400\n",
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0904 - accuracy: 0.9781\n",
      "Epoch 351: val_loss improved from 0.09145 to 0.09132, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9777 - val_loss: 0.0913 - val_accuracy: 0.9784\n",
      "Epoch 352/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0910 - accuracy: 0.9777\n",
      "Epoch 352: val_loss did not improve from 0.09132\n",
      "91/91 [==============================] - 0s 975us/step - loss: 0.0912 - accuracy: 0.9777 - val_loss: 0.0913 - val_accuracy: 0.9784\n",
      "Epoch 353/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0898 - accuracy: 0.9780\n",
      "Epoch 353: val_loss improved from 0.09132 to 0.09130, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9777 - val_loss: 0.0913 - val_accuracy: 0.9784\n",
      "Epoch 354/400\n",
      "74/91 [=======================>......] - ETA: 0s - loss: 0.0908 - accuracy: 0.9777\n",
      "Epoch 354: val_loss did not improve from 0.09130\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9777 - val_loss: 0.0913 - val_accuracy: 0.9784\n",
      "Epoch 355/400\n",
      "71/91 [======================>.......] - ETA: 0s - loss: 0.0905 - accuracy: 0.9780\n",
      "Epoch 355: val_loss did not improve from 0.09130\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9777 - val_loss: 0.0913 - val_accuracy: 0.9784\n",
      "Epoch 356/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0925 - accuracy: 0.9772\n",
      "Epoch 356: val_loss did not improve from 0.09130\n",
      "91/91 [==============================] - 0s 977us/step - loss: 0.0910 - accuracy: 0.9777 - val_loss: 0.0913 - val_accuracy: 0.9784\n",
      "Epoch 357/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0916 - accuracy: 0.9775\n",
      "Epoch 357: val_loss improved from 0.09130 to 0.09130, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9777 - val_loss: 0.0913 - val_accuracy: 0.9784\n",
      "Epoch 358/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0895 - accuracy: 0.9781\n",
      "Epoch 358: val_loss did not improve from 0.09130\n",
      "91/91 [==============================] - 0s 969us/step - loss: 0.0910 - accuracy: 0.9777 - val_loss: 0.0914 - val_accuracy: 0.9784\n",
      "Epoch 359/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0902 - accuracy: 0.9779\n",
      "Epoch 359: val_loss improved from 0.09130 to 0.09119, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9777 - val_loss: 0.0912 - val_accuracy: 0.9784\n",
      "Epoch 360/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.0913 - accuracy: 0.9777\n",
      "Epoch 360: val_loss improved from 0.09119 to 0.09109, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9777 - val_loss: 0.0911 - val_accuracy: 0.9784\n",
      "Epoch 361/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0903 - accuracy: 0.9778\n",
      "Epoch 361: val_loss improved from 0.09109 to 0.09106, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9777 - val_loss: 0.0911 - val_accuracy: 0.9784\n",
      "Epoch 362/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/91 [========================>.....] - ETA: 0s - loss: 0.0915 - accuracy: 0.9775\n",
      "Epoch 362: val_loss did not improve from 0.09106\n",
      "91/91 [==============================] - 0s 928us/step - loss: 0.0907 - accuracy: 0.9777 - val_loss: 0.0913 - val_accuracy: 0.9784\n",
      "Epoch 363/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0924 - accuracy: 0.9775\n",
      "Epoch 363: val_loss did not improve from 0.09106\n",
      "91/91 [==============================] - 0s 886us/step - loss: 0.0910 - accuracy: 0.9777 - val_loss: 0.0911 - val_accuracy: 0.9784\n",
      "Epoch 364/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0897 - accuracy: 0.9777\n",
      "Epoch 364: val_loss improved from 0.09106 to 0.09103, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9777 - val_loss: 0.0910 - val_accuracy: 0.9784\n",
      "Epoch 365/400\n",
      "69/91 [=====================>........] - ETA: 0s - loss: 0.0907 - accuracy: 0.9779\n",
      "Epoch 365: val_loss did not improve from 0.09103\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9777 - val_loss: 0.0911 - val_accuracy: 0.9784\n",
      "Epoch 366/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0929 - accuracy: 0.9770\n",
      "Epoch 366: val_loss did not improve from 0.09103\n",
      "91/91 [==============================] - 0s 904us/step - loss: 0.0907 - accuracy: 0.9777 - val_loss: 0.0911 - val_accuracy: 0.9784\n",
      "Epoch 367/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.0899 - accuracy: 0.9779\n",
      "Epoch 367: val_loss improved from 0.09103 to 0.09095, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9777 - val_loss: 0.0910 - val_accuracy: 0.9784\n",
      "Epoch 368/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0906 - accuracy: 0.9778\n",
      "Epoch 368: val_loss improved from 0.09095 to 0.09088, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9777 - val_loss: 0.0909 - val_accuracy: 0.9784\n",
      "Epoch 369/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0890 - accuracy: 0.9783\n",
      "Epoch 369: val_loss improved from 0.09088 to 0.09088, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9777 - val_loss: 0.0909 - val_accuracy: 0.9784\n",
      "Epoch 370/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0918 - accuracy: 0.9774\n",
      "Epoch 370: val_loss did not improve from 0.09088\n",
      "91/91 [==============================] - 0s 909us/step - loss: 0.0905 - accuracy: 0.9777 - val_loss: 0.0910 - val_accuracy: 0.9784\n",
      "Epoch 371/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.0901 - accuracy: 0.9779\n",
      "Epoch 371: val_loss did not improve from 0.09088\n",
      "91/91 [==============================] - 0s 881us/step - loss: 0.0905 - accuracy: 0.9777 - val_loss: 0.0910 - val_accuracy: 0.9784\n",
      "Epoch 372/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0911 - accuracy: 0.9776\n",
      "Epoch 372: val_loss did not improve from 0.09088\n",
      "91/91 [==============================] - 0s 897us/step - loss: 0.0907 - accuracy: 0.9777 - val_loss: 0.0910 - val_accuracy: 0.9784\n",
      "Epoch 373/400\n",
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0907 - accuracy: 0.9777\n",
      "Epoch 373: val_loss did not improve from 0.09088\n",
      "91/91 [==============================] - 0s 914us/step - loss: 0.0904 - accuracy: 0.9777 - val_loss: 0.0910 - val_accuracy: 0.9784\n",
      "Epoch 374/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0893 - accuracy: 0.9780\n",
      "Epoch 374: val_loss improved from 0.09088 to 0.09074, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9777 - val_loss: 0.0907 - val_accuracy: 0.9784\n",
      "Epoch 375/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0917 - accuracy: 0.9772\n",
      "Epoch 375: val_loss improved from 0.09074 to 0.09066, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9777 - val_loss: 0.0907 - val_accuracy: 0.9784\n",
      "Epoch 376/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0913 - accuracy: 0.9774\n",
      "Epoch 376: val_loss did not improve from 0.09066\n",
      "91/91 [==============================] - 0s 957us/step - loss: 0.0906 - accuracy: 0.9777 - val_loss: 0.0908 - val_accuracy: 0.9784\n",
      "Epoch 377/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0909 - accuracy: 0.9776\n",
      "Epoch 377: val_loss improved from 0.09066 to 0.09065, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9777 - val_loss: 0.0906 - val_accuracy: 0.9784\n",
      "Epoch 378/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0897 - accuracy: 0.9780\n",
      "Epoch 378: val_loss did not improve from 0.09065\n",
      "91/91 [==============================] - 0s 903us/step - loss: 0.0903 - accuracy: 0.9777 - val_loss: 0.0907 - val_accuracy: 0.9784\n",
      "Epoch 379/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0885 - accuracy: 0.9784\n",
      "Epoch 379: val_loss did not improve from 0.09065\n",
      "91/91 [==============================] - 0s 903us/step - loss: 0.0902 - accuracy: 0.9777 - val_loss: 0.0909 - val_accuracy: 0.9784\n",
      "Epoch 380/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0894 - accuracy: 0.9779\n",
      "Epoch 380: val_loss improved from 0.09065 to 0.09049, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9777 - val_loss: 0.0905 - val_accuracy: 0.9784\n",
      "Epoch 381/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0912 - accuracy: 0.9776\n",
      "Epoch 381: val_loss did not improve from 0.09049\n",
      "91/91 [==============================] - 0s 993us/step - loss: 0.0903 - accuracy: 0.9777 - val_loss: 0.0905 - val_accuracy: 0.9784\n",
      "Epoch 382/400\n",
      "76/91 [========================>.....] - ETA: 0s - loss: 0.0895 - accuracy: 0.9777\n",
      "Epoch 382: val_loss did not improve from 0.09049\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9777 - val_loss: 0.0906 - val_accuracy: 0.9784\n",
      "Epoch 383/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0907 - accuracy: 0.9774\n",
      "Epoch 383: val_loss improved from 0.09049 to 0.09043, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9777 - val_loss: 0.0904 - val_accuracy: 0.9784\n",
      "Epoch 384/400\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 0.0898 - accuracy: 0.9777\n",
      "Epoch 384: val_loss did not improve from 0.09043\n",
      "91/91 [==============================] - 0s 916us/step - loss: 0.0902 - accuracy: 0.9777 - val_loss: 0.0905 - val_accuracy: 0.9784\n",
      "Epoch 385/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.0897 - accuracy: 0.9779\n",
      "Epoch 385: val_loss did not improve from 0.09043\n",
      "91/91 [==============================] - 0s 898us/step - loss: 0.0900 - accuracy: 0.9777 - val_loss: 0.0906 - val_accuracy: 0.9784\n",
      "Epoch 386/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0899 - accuracy: 0.9778\n",
      "Epoch 386: val_loss improved from 0.09043 to 0.09037, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9777 - val_loss: 0.0904 - val_accuracy: 0.9784\n",
      "Epoch 387/400\n",
      "75/91 [=======================>......] - ETA: 0s - loss: 0.0901 - accuracy: 0.9780\n",
      "Epoch 387: val_loss did not improve from 0.09037\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9777 - val_loss: 0.0905 - val_accuracy: 0.9784\n",
      "Epoch 388/400\n",
      "73/91 [=======================>......] - ETA: 0s - loss: 0.0905 - accuracy: 0.9777\n",
      "Epoch 388: val_loss improved from 0.09037 to 0.09030, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9777 - val_loss: 0.0903 - val_accuracy: 0.9784\n",
      "Epoch 389/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/91 [=========================>....] - ETA: 0s - loss: 0.0911 - accuracy: 0.9775\n",
      "Epoch 389: val_loss did not improve from 0.09030\n",
      "91/91 [==============================] - 0s 964us/step - loss: 0.0900 - accuracy: 0.9777 - val_loss: 0.0906 - val_accuracy: 0.9784\n",
      "Epoch 390/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0891 - accuracy: 0.9780\n",
      "Epoch 390: val_loss did not improve from 0.09030\n",
      "91/91 [==============================] - 0s 889us/step - loss: 0.0901 - accuracy: 0.9777 - val_loss: 0.0905 - val_accuracy: 0.9784\n",
      "Epoch 391/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0895 - accuracy: 0.9779\n",
      "Epoch 391: val_loss did not improve from 0.09030\n",
      "91/91 [==============================] - 0s 936us/step - loss: 0.0899 - accuracy: 0.9777 - val_loss: 0.0903 - val_accuracy: 0.9784\n",
      "Epoch 392/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0900 - accuracy: 0.9776\n",
      "Epoch 392: val_loss improved from 0.09030 to 0.09017, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9777 - val_loss: 0.0902 - val_accuracy: 0.9784\n",
      "Epoch 393/400\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.0906 - accuracy: 0.9775\n",
      "Epoch 393: val_loss improved from 0.09017 to 0.09016, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9777 - val_loss: 0.0902 - val_accuracy: 0.9784\n",
      "Epoch 394/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0906 - accuracy: 0.9775\n",
      "Epoch 394: val_loss improved from 0.09016 to 0.09015, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9777 - val_loss: 0.0902 - val_accuracy: 0.9784\n",
      "Epoch 395/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0897 - accuracy: 0.9777\n",
      "Epoch 395: val_loss did not improve from 0.09015\n",
      "91/91 [==============================] - 0s 904us/step - loss: 0.0898 - accuracy: 0.9777 - val_loss: 0.0902 - val_accuracy: 0.9784\n",
      "Epoch 396/400\n",
      "82/91 [==========================>...] - ETA: 0s - loss: 0.0884 - accuracy: 0.9781\n",
      "Epoch 396: val_loss improved from 0.09015 to 0.09001, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9777 - val_loss: 0.0900 - val_accuracy: 0.9784\n",
      "Epoch 397/400\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 0.0911 - accuracy: 0.9772\n",
      "Epoch 397: val_loss did not improve from 0.09001\n",
      "91/91 [==============================] - 0s 944us/step - loss: 0.0896 - accuracy: 0.9777 - val_loss: 0.0902 - val_accuracy: 0.9784\n",
      "Epoch 398/400\n",
      "77/91 [========================>.....] - ETA: 0s - loss: 0.0918 - accuracy: 0.9772\n",
      "Epoch 398: val_loss improved from 0.09001 to 0.09000, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9777 - val_loss: 0.0900 - val_accuracy: 0.9784\n",
      "Epoch 399/400\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0896 - accuracy: 0.9778\n",
      "Epoch 399: val_loss improved from 0.09000 to 0.08988, saving model to WENO3//Details\\best_modelHn_7smoothdata.hdf5\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9777 - val_loss: 0.0899 - val_accuracy: 0.9784\n",
      "Epoch 400/400\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 0.0899 - accuracy: 0.9778\n",
      "Epoch 400: val_loss did not improve from 0.08988\n",
      "91/91 [==============================] - 0s 940us/step - loss: 0.0899 - accuracy: 0.9777 - val_loss: 0.0899 - val_accuracy: 0.9784\n",
      "name weight WENO3//model/trained_weights_Hn_7smoothdata.mat\n",
      "150/150 [==============================] - 0s 528us/step\n",
      "here\n",
      "Accuracy  : 0.9761904761904762\n",
      "Precision : 0.9529478458049886\n",
      "f1Score : 0.9644291451520367\n",
      "[[   0   51    0]\n",
      " [   0 4674    0]\n",
      " [   0   63    0]]\n",
      "train history is strored in WENO3/History/history-Hn_7smoothdata.dat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\xai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is nonsmoothdata\n",
      "Data file being used is: WENO3/train_input_nonsmoothdata.csv\n",
      "In load data (32500, 4) (32500,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 35        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59 (472.00 Byte)\n",
      "Trainable params: 59 (472.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "42/92 [============>.................] - ETA: 0s - loss: 1.3235 - accuracy: 0.2682 \n",
      "Epoch 1: val_loss improved from inf to 1.12052, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 1s 4ms/step - loss: 1.2455 - accuracy: 0.3457 - val_loss: 1.1205 - val_accuracy: 0.4790\n",
      "Epoch 2/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 1.0524 - accuracy: 0.4916\n",
      "Epoch 2: val_loss improved from 1.12052 to 0.98414, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0452 - accuracy: 0.4864 - val_loss: 0.9841 - val_accuracy: 0.4624\n",
      "Epoch 3/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.9571 - accuracy: 0.5079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\xai\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss improved from 0.98414 to 0.91975, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9541 - accuracy: 0.5145 - val_loss: 0.9197 - val_accuracy: 0.5777\n",
      "Epoch 4/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.9067 - accuracy: 0.5699\n",
      "Epoch 4: val_loss improved from 0.91975 to 0.87868, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9048 - accuracy: 0.5692 - val_loss: 0.8787 - val_accuracy: 0.5806\n",
      "Epoch 5/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.8662 - accuracy: 0.5720\n",
      "Epoch 5: val_loss improved from 0.87868 to 0.83975, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8645 - accuracy: 0.5707 - val_loss: 0.8398 - val_accuracy: 0.5833\n",
      "Epoch 6/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.8252 - accuracy: 0.5754\n",
      "Epoch 6: val_loss improved from 0.83975 to 0.79642, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8229 - accuracy: 0.5757 - val_loss: 0.7964 - val_accuracy: 0.5893\n",
      "Epoch 7/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.7793 - accuracy: 0.5829\n",
      "Epoch 7: val_loss improved from 0.79642 to 0.74891, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7756 - accuracy: 0.5851 - val_loss: 0.7489 - val_accuracy: 0.6047\n",
      "Epoch 8/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.7288 - accuracy: 0.6037\n",
      "Epoch 8: val_loss improved from 0.74891 to 0.70079, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.6020 - val_loss: 0.7008 - val_accuracy: 0.6103\n",
      "Epoch 9/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.6790 - accuracy: 0.6082\n",
      "Epoch 9: val_loss improved from 0.70079 to 0.65083, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.6111 - val_loss: 0.6508 - val_accuracy: 0.6783\n",
      "Epoch 10/400\n",
      "71/92 [======================>.......] - ETA: 0s - loss: 0.6317 - accuracy: 0.7314\n",
      "Epoch 10: val_loss improved from 0.65083 to 0.60112, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.7389 - val_loss: 0.6011 - val_accuracy: 0.7657\n",
      "Epoch 11/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.5797 - accuracy: 0.8157\n",
      "Epoch 11: val_loss improved from 0.60112 to 0.55268, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5753 - accuracy: 0.8247 - val_loss: 0.5527 - val_accuracy: 0.8687\n",
      "Epoch 12/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.5299 - accuracy: 0.8860\n",
      "Epoch 12: val_loss improved from 0.55268 to 0.50634, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.8874 - val_loss: 0.5063 - val_accuracy: 0.9095\n",
      "Epoch 13/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.4844 - accuracy: 0.9160\n",
      "Epoch 13: val_loss improved from 0.50634 to 0.46445, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.9174 - val_loss: 0.4645 - val_accuracy: 0.9276\n",
      "Epoch 14/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.4443 - accuracy: 0.9320\n",
      "Epoch 14: val_loss improved from 0.46445 to 0.42759, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.9340 - val_loss: 0.4276 - val_accuracy: 0.9380\n",
      "Epoch 15/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.4089 - accuracy: 0.9430\n",
      "Epoch 15: val_loss improved from 0.42759 to 0.39576, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.9431 - val_loss: 0.3958 - val_accuracy: 0.9476\n",
      "Epoch 16/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.3804 - accuracy: 0.9505\n",
      "Epoch 16: val_loss improved from 0.39576 to 0.36828, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.9513 - val_loss: 0.3683 - val_accuracy: 0.9542\n",
      "Epoch 17/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.3544 - accuracy: 0.9543\n",
      "Epoch 17: val_loss improved from 0.36828 to 0.34426, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.9550 - val_loss: 0.3443 - val_accuracy: 0.9609\n",
      "Epoch 18/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.3306 - accuracy: 0.9602\n",
      "Epoch 18: val_loss improved from 0.34426 to 0.32311, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.9599 - val_loss: 0.3231 - val_accuracy: 0.9616\n",
      "Epoch 19/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.3114 - accuracy: 0.9614\n",
      "Epoch 19: val_loss improved from 0.32311 to 0.30427, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.9609 - val_loss: 0.3043 - val_accuracy: 0.9638\n",
      "Epoch 20/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.2927 - accuracy: 0.9629\n",
      "Epoch 20: val_loss improved from 0.30427 to 0.28761, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.9626 - val_loss: 0.2876 - val_accuracy: 0.9645\n",
      "Epoch 21/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.2783 - accuracy: 0.9626\n",
      "Epoch 21: val_loss improved from 0.28761 to 0.27249, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.2762 - accuracy: 0.9634 - val_loss: 0.2725 - val_accuracy: 0.9657\n",
      "Epoch 22/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.2622 - accuracy: 0.9644\n",
      "Epoch 22: val_loss improved from 0.27249 to 0.25883, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.9638 - val_loss: 0.2588 - val_accuracy: 0.9662\n",
      "Epoch 23/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.2498 - accuracy: 0.9647\n",
      "Epoch 23: val_loss improved from 0.25883 to 0.24645, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.9644 - val_loss: 0.2465 - val_accuracy: 0.9667\n",
      "Epoch 24/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.2381 - accuracy: 0.9647\n",
      "Epoch 24: val_loss improved from 0.24645 to 0.23493, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.9649 - val_loss: 0.2349 - val_accuracy: 0.9665\n",
      "Epoch 25/400\n",
      "87/92 [===========================>..] - ETA: 0s - loss: 0.2264 - accuracy: 0.9652\n",
      "Epoch 25: val_loss improved from 0.23493 to 0.22445, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 997us/step - loss: 0.2264 - accuracy: 0.9651 - val_loss: 0.2245 - val_accuracy: 0.9674\n",
      "Epoch 26/400\n",
      "85/92 [==========================>...] - ETA: 0s - loss: 0.2165 - accuracy: 0.9661\n",
      "Epoch 26: val_loss improved from 0.22445 to 0.21475, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9658 - val_loss: 0.2147 - val_accuracy: 0.9674\n",
      "Epoch 27/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/92 [========================>.....] - ETA: 0s - loss: 0.2086 - accuracy: 0.9657\n",
      "Epoch 27: val_loss improved from 0.21475 to 0.20582, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9664 - val_loss: 0.2058 - val_accuracy: 0.9672\n",
      "Epoch 28/400\n",
      "85/92 [==========================>...] - ETA: 0s - loss: 0.1989 - accuracy: 0.9670\n",
      "Epoch 28: val_loss improved from 0.20582 to 0.19757, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.9667 - val_loss: 0.1976 - val_accuracy: 0.9684\n",
      "Epoch 29/400\n",
      "86/92 [===========================>..] - ETA: 0s - loss: 0.1914 - accuracy: 0.9678\n",
      "Epoch 29: val_loss improved from 0.19757 to 0.18991, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9681 - val_loss: 0.1899 - val_accuracy: 0.9691\n",
      "Epoch 30/400\n",
      "73/92 [======================>.......] - ETA: 0s - loss: 0.1836 - accuracy: 0.9688\n",
      "Epoch 30: val_loss improved from 0.18991 to 0.18273, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.9679 - val_loss: 0.1827 - val_accuracy: 0.9694\n",
      "Epoch 31/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.1781 - accuracy: 0.9671\n",
      "Epoch 31: val_loss improved from 0.18273 to 0.17610, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.9678 - val_loss: 0.1761 - val_accuracy: 0.9701\n",
      "Epoch 32/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.1704 - accuracy: 0.9683\n",
      "Epoch 32: val_loss improved from 0.17610 to 0.16993, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9681 - val_loss: 0.1699 - val_accuracy: 0.9701\n",
      "Epoch 33/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.1658 - accuracy: 0.9685\n",
      "Epoch 33: val_loss improved from 0.16993 to 0.16401, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9682 - val_loss: 0.1640 - val_accuracy: 0.9708\n",
      "Epoch 34/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.1594 - accuracy: 0.9686\n",
      "Epoch 34: val_loss improved from 0.16401 to 0.15863, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.9687 - val_loss: 0.1586 - val_accuracy: 0.9713\n",
      "Epoch 35/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.1538 - accuracy: 0.9689\n",
      "Epoch 35: val_loss improved from 0.15863 to 0.15354, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9693 - val_loss: 0.1535 - val_accuracy: 0.9720\n",
      "Epoch 36/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.1507 - accuracy: 0.9687\n",
      "Epoch 36: val_loss improved from 0.15354 to 0.14876, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9694 - val_loss: 0.1488 - val_accuracy: 0.9708\n",
      "Epoch 37/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.1459 - accuracy: 0.9689\n",
      "Epoch 37: val_loss improved from 0.14876 to 0.14416, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9698 - val_loss: 0.1442 - val_accuracy: 0.9720\n",
      "Epoch 38/400\n",
      "69/92 [=====================>........] - ETA: 0s - loss: 0.1402 - accuracy: 0.9698\n",
      "Epoch 38: val_loss improved from 0.14416 to 0.13997, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9698 - val_loss: 0.1400 - val_accuracy: 0.9718\n",
      "Epoch 39/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.1358 - accuracy: 0.9709\n",
      "Epoch 39: val_loss improved from 0.13997 to 0.13592, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.9704 - val_loss: 0.1359 - val_accuracy: 0.9722\n",
      "Epoch 40/400\n",
      "60/92 [==================>...........] - ETA: 0s - loss: 0.1338 - accuracy: 0.9705\n",
      "Epoch 40: val_loss improved from 0.13592 to 0.13213, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9710 - val_loss: 0.1321 - val_accuracy: 0.9727\n",
      "Epoch 41/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.1285 - accuracy: 0.9716\n",
      "Epoch 41: val_loss improved from 0.13213 to 0.12839, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9716 - val_loss: 0.1284 - val_accuracy: 0.9718\n",
      "Epoch 42/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.1256 - accuracy: 0.9714\n",
      "Epoch 42: val_loss improved from 0.12839 to 0.12515, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9715 - val_loss: 0.1252 - val_accuracy: 0.9722\n",
      "Epoch 43/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.1209 - accuracy: 0.9734\n",
      "Epoch 43: val_loss improved from 0.12515 to 0.12189, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.9725 - val_loss: 0.1219 - val_accuracy: 0.9730\n",
      "Epoch 44/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.1188 - accuracy: 0.9734\n",
      "Epoch 44: val_loss improved from 0.12189 to 0.11877, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9729 - val_loss: 0.1188 - val_accuracy: 0.9735\n",
      "Epoch 45/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.1156 - accuracy: 0.9742\n",
      "Epoch 45: val_loss improved from 0.11877 to 0.11588, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9738 - val_loss: 0.1159 - val_accuracy: 0.9747\n",
      "Epoch 46/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.1136 - accuracy: 0.9741\n",
      "Epoch 46: val_loss improved from 0.11588 to 0.11303, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9741 - val_loss: 0.1130 - val_accuracy: 0.9747\n",
      "Epoch 47/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.1106 - accuracy: 0.9741\n",
      "Epoch 47: val_loss improved from 0.11303 to 0.11042, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9743 - val_loss: 0.1104 - val_accuracy: 0.9747\n",
      "Epoch 48/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.1077 - accuracy: 0.9738\n",
      "Epoch 48: val_loss improved from 0.11042 to 0.10807, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9746 - val_loss: 0.1081 - val_accuracy: 0.9749\n",
      "Epoch 49/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.1057 - accuracy: 0.9741\n",
      "Epoch 49: val_loss improved from 0.10807 to 0.10548, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9750 - val_loss: 0.1055 - val_accuracy: 0.9754\n",
      "Epoch 50/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.1028 - accuracy: 0.9757\n",
      "Epoch 50: val_loss improved from 0.10548 to 0.10292, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9752 - val_loss: 0.1029 - val_accuracy: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.1007 - accuracy: 0.9754\n",
      "Epoch 51: val_loss improved from 0.10292 to 0.10083, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9756 - val_loss: 0.1008 - val_accuracy: 0.9761\n",
      "Epoch 52/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0979 - accuracy: 0.9765\n",
      "Epoch 52: val_loss improved from 0.10083 to 0.09857, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9761 - val_loss: 0.0986 - val_accuracy: 0.9756\n",
      "Epoch 53/400\n",
      "86/92 [===========================>..] - ETA: 0s - loss: 0.0965 - accuracy: 0.9765\n",
      "Epoch 53: val_loss improved from 0.09857 to 0.09648, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9766 - val_loss: 0.0965 - val_accuracy: 0.9756\n",
      "Epoch 54/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0947 - accuracy: 0.9765\n",
      "Epoch 54: val_loss improved from 0.09648 to 0.09457, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.9762 - val_loss: 0.0946 - val_accuracy: 0.9759\n",
      "Epoch 55/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0930 - accuracy: 0.9763\n",
      "Epoch 55: val_loss improved from 0.09457 to 0.09257, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9767 - val_loss: 0.0926 - val_accuracy: 0.9768\n",
      "Epoch 56/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0908 - accuracy: 0.9763\n",
      "Epoch 56: val_loss improved from 0.09257 to 0.09079, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9767 - val_loss: 0.0908 - val_accuracy: 0.9778\n",
      "Epoch 57/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0883 - accuracy: 0.9778\n",
      "Epoch 57: val_loss improved from 0.09079 to 0.08895, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0887 - accuracy: 0.9774 - val_loss: 0.0890 - val_accuracy: 0.9776\n",
      "Epoch 58/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0863 - accuracy: 0.9780\n",
      "Epoch 58: val_loss improved from 0.08895 to 0.08763, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9777 - val_loss: 0.0876 - val_accuracy: 0.9776\n",
      "Epoch 59/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0849 - accuracy: 0.9785\n",
      "Epoch 59: val_loss improved from 0.08763 to 0.08572, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9781 - val_loss: 0.0857 - val_accuracy: 0.9780\n",
      "Epoch 60/400\n",
      "63/92 [===================>..........] - ETA: 0s - loss: 0.0834 - accuracy: 0.9786\n",
      "Epoch 60: val_loss improved from 0.08572 to 0.08410, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9782 - val_loss: 0.0841 - val_accuracy: 0.9783\n",
      "Epoch 61/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0817 - accuracy: 0.9788\n",
      "Epoch 61: val_loss improved from 0.08410 to 0.08233, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9788 - val_loss: 0.0823 - val_accuracy: 0.9795\n",
      "Epoch 62/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0810 - accuracy: 0.9792\n",
      "Epoch 62: val_loss improved from 0.08233 to 0.08085, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9795 - val_loss: 0.0809 - val_accuracy: 0.9797\n",
      "Epoch 63/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0793 - accuracy: 0.9792\n",
      "Epoch 63: val_loss improved from 0.08085 to 0.07954, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9793 - val_loss: 0.0795 - val_accuracy: 0.9790\n",
      "Epoch 64/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0785 - accuracy: 0.9792\n",
      "Epoch 64: val_loss improved from 0.07954 to 0.07806, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9798 - val_loss: 0.0781 - val_accuracy: 0.9807\n",
      "Epoch 65/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0762 - accuracy: 0.9808\n",
      "Epoch 65: val_loss improved from 0.07806 to 0.07683, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9806 - val_loss: 0.0768 - val_accuracy: 0.9805\n",
      "Epoch 66/400\n",
      "51/92 [===============>..............] - ETA: 0s - loss: 0.0756 - accuracy: 0.9802\n",
      "Epoch 66: val_loss improved from 0.07683 to 0.07549, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9804 - val_loss: 0.0755 - val_accuracy: 0.9819\n",
      "Epoch 67/400\n",
      "68/92 [=====================>........] - ETA: 0s - loss: 0.0751 - accuracy: 0.9806\n",
      "Epoch 67: val_loss improved from 0.07549 to 0.07482, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9808 - val_loss: 0.0748 - val_accuracy: 0.9800\n",
      "Epoch 68/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0741 - accuracy: 0.9812\n",
      "Epoch 68: val_loss improved from 0.07482 to 0.07306, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9816 - val_loss: 0.0731 - val_accuracy: 0.9831\n",
      "Epoch 69/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0724 - accuracy: 0.9818\n",
      "Epoch 69: val_loss improved from 0.07306 to 0.07183, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 0.9825 - val_loss: 0.0718 - val_accuracy: 0.9841\n",
      "Epoch 70/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0712 - accuracy: 0.9821\n",
      "Epoch 70: val_loss improved from 0.07183 to 0.07071, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9820 - val_loss: 0.0707 - val_accuracy: 0.9843\n",
      "Epoch 71/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0698 - accuracy: 0.9831\n",
      "Epoch 71: val_loss improved from 0.07071 to 0.07001, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9828 - val_loss: 0.0700 - val_accuracy: 0.9819\n",
      "Epoch 72/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.0687 - accuracy: 0.9835\n",
      "Epoch 72: val_loss improved from 0.07001 to 0.06876, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0689 - accuracy: 0.9832 - val_loss: 0.0688 - val_accuracy: 0.9836\n",
      "Epoch 73/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0677 - accuracy: 0.9834\n",
      "Epoch 73: val_loss improved from 0.06876 to 0.06784, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9832 - val_loss: 0.0678 - val_accuracy: 0.9841\n",
      "Epoch 74/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0665 - accuracy: 0.9839\n",
      "Epoch 74: val_loss improved from 0.06784 to 0.06668, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9839 - val_loss: 0.0667 - val_accuracy: 0.9843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0667 - accuracy: 0.9840\n",
      "Epoch 75: val_loss improved from 0.06668 to 0.06568, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9841 - val_loss: 0.0657 - val_accuracy: 0.9846\n",
      "Epoch 76/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0650 - accuracy: 0.9841\n",
      "Epoch 76: val_loss improved from 0.06568 to 0.06501, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9840 - val_loss: 0.0650 - val_accuracy: 0.9850\n",
      "Epoch 77/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0645 - accuracy: 0.9842\n",
      "Epoch 77: val_loss improved from 0.06501 to 0.06413, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9845 - val_loss: 0.0641 - val_accuracy: 0.9841\n",
      "Epoch 78/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0640 - accuracy: 0.9839\n",
      "Epoch 78: val_loss improved from 0.06413 to 0.06321, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9839 - val_loss: 0.0632 - val_accuracy: 0.9846\n",
      "Epoch 79/400\n",
      "73/92 [======================>.......] - ETA: 0s - loss: 0.0626 - accuracy: 0.9847\n",
      "Epoch 79: val_loss improved from 0.06321 to 0.06249, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 0.9846 - val_loss: 0.0625 - val_accuracy: 0.9850\n",
      "Epoch 80/400\n",
      "69/92 [=====================>........] - ETA: 0s - loss: 0.0626 - accuracy: 0.9851\n",
      "Epoch 80: val_loss improved from 0.06249 to 0.06160, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9853 - val_loss: 0.0616 - val_accuracy: 0.9848\n",
      "Epoch 81/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0610 - accuracy: 0.9851\n",
      "Epoch 81: val_loss improved from 0.06160 to 0.06105, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9850 - val_loss: 0.0611 - val_accuracy: 0.9841\n",
      "Epoch 82/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0618 - accuracy: 0.9850\n",
      "Epoch 82: val_loss improved from 0.06105 to 0.06036, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9853 - val_loss: 0.0604 - val_accuracy: 0.9838\n",
      "Epoch 83/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0595 - accuracy: 0.9859\n",
      "Epoch 83: val_loss improved from 0.06036 to 0.05943, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9859 - val_loss: 0.0594 - val_accuracy: 0.9853\n",
      "Epoch 84/400\n",
      "85/92 [==========================>...] - ETA: 0s - loss: 0.0595 - accuracy: 0.9857\n",
      "Epoch 84: val_loss improved from 0.05943 to 0.05876, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.9856 - val_loss: 0.0588 - val_accuracy: 0.9858\n",
      "Epoch 85/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0584 - accuracy: 0.9856\n",
      "Epoch 85: val_loss improved from 0.05876 to 0.05834, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.9858 - val_loss: 0.0583 - val_accuracy: 0.9848\n",
      "Epoch 86/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0574 - accuracy: 0.9862\n",
      "Epoch 86: val_loss improved from 0.05834 to 0.05757, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9859 - val_loss: 0.0576 - val_accuracy: 0.9846\n",
      "Epoch 87/400\n",
      "87/92 [===========================>..] - ETA: 0s - loss: 0.0578 - accuracy: 0.9856\n",
      "Epoch 87: val_loss improved from 0.05757 to 0.05695, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 0.9857 - val_loss: 0.0569 - val_accuracy: 0.9860\n",
      "Epoch 88/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0574 - accuracy: 0.9859\n",
      "Epoch 88: val_loss improved from 0.05695 to 0.05627, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9861 - val_loss: 0.0563 - val_accuracy: 0.9860\n",
      "Epoch 89/400\n",
      "66/92 [====================>.........] - ETA: 0s - loss: 0.0574 - accuracy: 0.9856\n",
      "Epoch 89: val_loss improved from 0.05627 to 0.05586, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9861 - val_loss: 0.0559 - val_accuracy: 0.9850\n",
      "Epoch 90/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0559 - accuracy: 0.9867\n",
      "Epoch 90: val_loss improved from 0.05586 to 0.05533, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9865 - val_loss: 0.0553 - val_accuracy: 0.9858\n",
      "Epoch 91/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0560 - accuracy: 0.9863\n",
      "Epoch 91: val_loss improved from 0.05533 to 0.05444, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9865 - val_loss: 0.0544 - val_accuracy: 0.9870\n",
      "Epoch 92/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0551 - accuracy: 0.9867\n",
      "Epoch 92: val_loss improved from 0.05444 to 0.05399, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9865 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
      "Epoch 93/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0541 - accuracy: 0.9868\n",
      "Epoch 93: val_loss improved from 0.05399 to 0.05358, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0545 - accuracy: 0.9865 - val_loss: 0.0536 - val_accuracy: 0.9870\n",
      "Epoch 94/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0536 - accuracy: 0.9866\n",
      "Epoch 94: val_loss improved from 0.05358 to 0.05327, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0540 - accuracy: 0.9865 - val_loss: 0.0533 - val_accuracy: 0.9867\n",
      "Epoch 95/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0528 - accuracy: 0.9874\n",
      "Epoch 95: val_loss improved from 0.05327 to 0.05247, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9865 - val_loss: 0.0525 - val_accuracy: 0.9870\n",
      "Epoch 96/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0529 - accuracy: 0.9868\n",
      "Epoch 96: val_loss improved from 0.05247 to 0.05225, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9868 - val_loss: 0.0522 - val_accuracy: 0.9867\n",
      "Epoch 97/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0525 - accuracy: 0.9869\n",
      "Epoch 97: val_loss improved from 0.05225 to 0.05159, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9869 - val_loss: 0.0516 - val_accuracy: 0.9872\n",
      "Epoch 98/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0528 - accuracy: 0.9866\n",
      "Epoch 98: val_loss improved from 0.05159 to 0.05128, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9868 - val_loss: 0.0513 - val_accuracy: 0.9875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0515 - accuracy: 0.9875\n",
      "Epoch 99: val_loss improved from 0.05128 to 0.05057, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0518 - accuracy: 0.9873 - val_loss: 0.0506 - val_accuracy: 0.9877\n",
      "Epoch 100/400\n",
      "73/92 [======================>.......] - ETA: 0s - loss: 0.0507 - accuracy: 0.9873\n",
      "Epoch 100: val_loss improved from 0.05057 to 0.05048, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9871 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
      "Epoch 101/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0512 - accuracy: 0.9872\n",
      "Epoch 101: val_loss improved from 0.05048 to 0.04988, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9872 - val_loss: 0.0499 - val_accuracy: 0.9882\n",
      "Epoch 102/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9870\n",
      "Epoch 102: val_loss improved from 0.04988 to 0.04964, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9872 - val_loss: 0.0496 - val_accuracy: 0.9882\n",
      "Epoch 103/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0509 - accuracy: 0.9872\n",
      "Epoch 103: val_loss improved from 0.04964 to 0.04936, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9876 - val_loss: 0.0494 - val_accuracy: 0.9879\n",
      "Epoch 104/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0493 - accuracy: 0.9886\n",
      "Epoch 104: val_loss improved from 0.04936 to 0.04874, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9876 - val_loss: 0.0487 - val_accuracy: 0.9882\n",
      "Epoch 105/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9866\n",
      "Epoch 105: val_loss improved from 0.04874 to 0.04845, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9874 - val_loss: 0.0484 - val_accuracy: 0.9877\n",
      "Epoch 106/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0484 - accuracy: 0.9877\n",
      "Epoch 106: val_loss improved from 0.04845 to 0.04774, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9876 - val_loss: 0.0477 - val_accuracy: 0.9882\n",
      "Epoch 107/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0491 - accuracy: 0.9869\n",
      "Epoch 107: val_loss improved from 0.04774 to 0.04744, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9874 - val_loss: 0.0474 - val_accuracy: 0.9889\n",
      "Epoch 108/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0484 - accuracy: 0.9877\n",
      "Epoch 108: val_loss improved from 0.04744 to 0.04710, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9878 - val_loss: 0.0471 - val_accuracy: 0.9896\n",
      "Epoch 109/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0478 - accuracy: 0.9877\n",
      "Epoch 109: val_loss improved from 0.04710 to 0.04670, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9876 - val_loss: 0.0467 - val_accuracy: 0.9884\n",
      "Epoch 110/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0483 - accuracy: 0.9880\n",
      "Epoch 110: val_loss improved from 0.04670 to 0.04649, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9880 - val_loss: 0.0465 - val_accuracy: 0.9887\n",
      "Epoch 111/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0476 - accuracy: 0.9881\n",
      "Epoch 111: val_loss improved from 0.04649 to 0.04620, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0477 - accuracy: 0.9879 - val_loss: 0.0462 - val_accuracy: 0.9889\n",
      "Epoch 112/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0470 - accuracy: 0.9885\n",
      "Epoch 112: val_loss improved from 0.04620 to 0.04576, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9882 - val_loss: 0.0458 - val_accuracy: 0.9889\n",
      "Epoch 113/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0475 - accuracy: 0.9881\n",
      "Epoch 113: val_loss improved from 0.04576 to 0.04553, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9883 - val_loss: 0.0455 - val_accuracy: 0.9896\n",
      "Epoch 114/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0463 - accuracy: 0.9879\n",
      "Epoch 114: val_loss improved from 0.04553 to 0.04522, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9881 - val_loss: 0.0452 - val_accuracy: 0.9884\n",
      "Epoch 115/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0466 - accuracy: 0.9883\n",
      "Epoch 115: val_loss improved from 0.04522 to 0.04484, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9882 - val_loss: 0.0448 - val_accuracy: 0.9889\n",
      "Epoch 116/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0465 - accuracy: 0.9881\n",
      "Epoch 116: val_loss improved from 0.04484 to 0.04453, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9883 - val_loss: 0.0445 - val_accuracy: 0.9887\n",
      "Epoch 117/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0459 - accuracy: 0.9880\n",
      "Epoch 117: val_loss improved from 0.04453 to 0.04434, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9882 - val_loss: 0.0443 - val_accuracy: 0.9891\n",
      "Epoch 118/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0452 - accuracy: 0.9886\n",
      "Epoch 118: val_loss improved from 0.04434 to 0.04388, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9885 - val_loss: 0.0439 - val_accuracy: 0.9896\n",
      "Epoch 119/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0448 - accuracy: 0.9892\n",
      "Epoch 119: val_loss improved from 0.04388 to 0.04383, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 0.9884 - val_loss: 0.0438 - val_accuracy: 0.9891\n",
      "Epoch 120/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0452 - accuracy: 0.9886\n",
      "Epoch 120: val_loss improved from 0.04383 to 0.04343, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9881 - val_loss: 0.0434 - val_accuracy: 0.9894\n",
      "Epoch 121/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0451 - accuracy: 0.9889\n",
      "Epoch 121: val_loss improved from 0.04343 to 0.04332, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9888 - val_loss: 0.0433 - val_accuracy: 0.9891\n",
      "Epoch 122/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0440 - accuracy: 0.9892\n",
      "Epoch 122: val_loss improved from 0.04332 to 0.04282, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9888 - val_loss: 0.0428 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0441 - accuracy: 0.9888\n",
      "Epoch 123: val_loss improved from 0.04282 to 0.04266, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9887 - val_loss: 0.0427 - val_accuracy: 0.9899\n",
      "Epoch 124/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0438 - accuracy: 0.9894\n",
      "Epoch 124: val_loss improved from 0.04266 to 0.04264, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9891 - val_loss: 0.0426 - val_accuracy: 0.9896\n",
      "Epoch 125/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0442 - accuracy: 0.9886\n",
      "Epoch 125: val_loss improved from 0.04264 to 0.04213, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0439 - accuracy: 0.9888 - val_loss: 0.0421 - val_accuracy: 0.9899\n",
      "Epoch 126/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0441 - accuracy: 0.9887\n",
      "Epoch 126: val_loss improved from 0.04213 to 0.04187, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 0.9889 - val_loss: 0.0419 - val_accuracy: 0.9899\n",
      "Epoch 127/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0437 - accuracy: 0.9889\n",
      "Epoch 127: val_loss improved from 0.04187 to 0.04185, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9892 - val_loss: 0.0419 - val_accuracy: 0.9894\n",
      "Epoch 128/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0430 - accuracy: 0.9890\n",
      "Epoch 128: val_loss improved from 0.04185 to 0.04164, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9889 - val_loss: 0.0416 - val_accuracy: 0.9894\n",
      "Epoch 129/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0422 - accuracy: 0.9897\n",
      "Epoch 129: val_loss improved from 0.04164 to 0.04132, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9891 - val_loss: 0.0413 - val_accuracy: 0.9908\n",
      "Epoch 130/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0434 - accuracy: 0.9882\n",
      "Epoch 130: val_loss improved from 0.04132 to 0.04096, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9888 - val_loss: 0.0410 - val_accuracy: 0.9911\n",
      "Epoch 131/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0422 - accuracy: 0.9894\n",
      "Epoch 131: val_loss did not improve from 0.04096\n",
      "92/92 [==============================] - 0s 984us/step - loss: 0.0425 - accuracy: 0.9897 - val_loss: 0.0415 - val_accuracy: 0.9882\n",
      "Epoch 132/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0428 - accuracy: 0.9887\n",
      "Epoch 132: val_loss did not improve from 0.04096\n",
      "92/92 [==============================] - 0s 994us/step - loss: 0.0424 - accuracy: 0.9892 - val_loss: 0.0411 - val_accuracy: 0.9889\n",
      "Epoch 133/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0422 - accuracy: 0.9893\n",
      "Epoch 133: val_loss improved from 0.04096 to 0.04092, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9892 - val_loss: 0.0409 - val_accuracy: 0.9891\n",
      "Epoch 134/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0426 - accuracy: 0.9888\n",
      "Epoch 134: val_loss improved from 0.04092 to 0.04022, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9892 - val_loss: 0.0402 - val_accuracy: 0.9911\n",
      "Epoch 135/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0420 - accuracy: 0.9890\n",
      "Epoch 135: val_loss improved from 0.04022 to 0.04006, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9894 - val_loss: 0.0401 - val_accuracy: 0.9913\n",
      "Epoch 136/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0415 - accuracy: 0.9893\n",
      "Epoch 136: val_loss improved from 0.04006 to 0.03955, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9893 - val_loss: 0.0395 - val_accuracy: 0.9913\n",
      "Epoch 137/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0412 - accuracy: 0.9895\n",
      "Epoch 137: val_loss improved from 0.03955 to 0.03951, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9895 - val_loss: 0.0395 - val_accuracy: 0.9913\n",
      "Epoch 138/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0410 - accuracy: 0.9892\n",
      "Epoch 138: val_loss improved from 0.03951 to 0.03927, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9892 - val_loss: 0.0393 - val_accuracy: 0.9918\n",
      "Epoch 139/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0411 - accuracy: 0.9897\n",
      "Epoch 139: val_loss improved from 0.03927 to 0.03912, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9899 - val_loss: 0.0391 - val_accuracy: 0.9918\n",
      "Epoch 140/400\n",
      "73/92 [======================>.......] - ETA: 0s - loss: 0.0409 - accuracy: 0.9892\n",
      "Epoch 140: val_loss improved from 0.03912 to 0.03882, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9892 - val_loss: 0.0388 - val_accuracy: 0.9923\n",
      "Epoch 141/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0406 - accuracy: 0.9901\n",
      "Epoch 141: val_loss improved from 0.03882 to 0.03879, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9899 - val_loss: 0.0388 - val_accuracy: 0.9918\n",
      "Epoch 142/400\n",
      "66/92 [====================>.........] - ETA: 0s - loss: 0.0409 - accuracy: 0.9896\n",
      "Epoch 142: val_loss improved from 0.03879 to 0.03863, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9897 - val_loss: 0.0386 - val_accuracy: 0.9908\n",
      "Epoch 143/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0398 - accuracy: 0.9897\n",
      "Epoch 143: val_loss improved from 0.03863 to 0.03848, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9894 - val_loss: 0.0385 - val_accuracy: 0.9913\n",
      "Epoch 144/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0398 - accuracy: 0.9900\n",
      "Epoch 144: val_loss improved from 0.03848 to 0.03835, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9899 - val_loss: 0.0384 - val_accuracy: 0.9908\n",
      "Epoch 145/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0407 - accuracy: 0.9890\n",
      "Epoch 145: val_loss improved from 0.03835 to 0.03813, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 0.9892 - val_loss: 0.0381 - val_accuracy: 0.9911\n",
      "Epoch 146/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0398 - accuracy: 0.9899\n",
      "Epoch 146: val_loss improved from 0.03813 to 0.03800, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9898 - val_loss: 0.0380 - val_accuracy: 0.9913\n",
      "Epoch 147/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0396 - accuracy: 0.9899\n",
      "Epoch 147: val_loss improved from 0.03800 to 0.03792, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9897 - val_loss: 0.0379 - val_accuracy: 0.9911\n",
      "Epoch 148/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0388 - accuracy: 0.9902\n",
      "Epoch 148: val_loss improved from 0.03792 to 0.03774, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9899 - val_loss: 0.0377 - val_accuracy: 0.9911\n",
      "Epoch 149/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0389 - accuracy: 0.9902\n",
      "Epoch 149: val_loss improved from 0.03774 to 0.03745, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9899 - val_loss: 0.0375 - val_accuracy: 0.9920\n",
      "Epoch 150/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0393 - accuracy: 0.9895\n",
      "Epoch 150: val_loss improved from 0.03745 to 0.03738, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9898 - val_loss: 0.0374 - val_accuracy: 0.9913\n",
      "Epoch 151/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0391 - accuracy: 0.9894\n",
      "Epoch 151: val_loss improved from 0.03738 to 0.03725, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9898 - val_loss: 0.0373 - val_accuracy: 0.9916\n",
      "Epoch 152/400\n",
      "63/92 [===================>..........] - ETA: 0s - loss: 0.0377 - accuracy: 0.9910\n",
      "Epoch 152: val_loss improved from 0.03725 to 0.03692, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 0.9906 - val_loss: 0.0369 - val_accuracy: 0.9920\n",
      "Epoch 153/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0390 - accuracy: 0.9896\n",
      "Epoch 153: val_loss improved from 0.03692 to 0.03668, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9899 - val_loss: 0.0367 - val_accuracy: 0.9918\n",
      "Epoch 154/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0385 - accuracy: 0.9901\n",
      "Epoch 154: val_loss improved from 0.03668 to 0.03663, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9904 - val_loss: 0.0366 - val_accuracy: 0.9923\n",
      "Epoch 155/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0380 - accuracy: 0.9905\n",
      "Epoch 155: val_loss improved from 0.03663 to 0.03633, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9902 - val_loss: 0.0363 - val_accuracy: 0.9925\n",
      "Epoch 156/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0386 - accuracy: 0.9899\n",
      "Epoch 156: val_loss did not improve from 0.03633\n",
      "92/92 [==============================] - 0s 965us/step - loss: 0.0383 - accuracy: 0.9903 - val_loss: 0.0365 - val_accuracy: 0.9918\n",
      "Epoch 157/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0381 - accuracy: 0.9904\n",
      "Epoch 157: val_loss improved from 0.03633 to 0.03609, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9905 - val_loss: 0.0361 - val_accuracy: 0.9918\n",
      "Epoch 158/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0379 - accuracy: 0.9905\n",
      "Epoch 158: val_loss improved from 0.03609 to 0.03600, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9904 - val_loss: 0.0360 - val_accuracy: 0.9923\n",
      "Epoch 159/400\n",
      "73/92 [======================>.......] - ETA: 0s - loss: 0.0377 - accuracy: 0.9900\n",
      "Epoch 159: val_loss improved from 0.03600 to 0.03599, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9900 - val_loss: 0.0360 - val_accuracy: 0.9923\n",
      "Epoch 160/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0374 - accuracy: 0.9905\n",
      "Epoch 160: val_loss improved from 0.03599 to 0.03559, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9904 - val_loss: 0.0356 - val_accuracy: 0.9925\n",
      "Epoch 161/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0369 - accuracy: 0.9909\n",
      "Epoch 161: val_loss improved from 0.03559 to 0.03547, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9905 - val_loss: 0.0355 - val_accuracy: 0.9925\n",
      "Epoch 162/400\n",
      "67/92 [====================>.........] - ETA: 0s - loss: 0.0365 - accuracy: 0.9910\n",
      "Epoch 162: val_loss did not improve from 0.03547\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9905 - val_loss: 0.0361 - val_accuracy: 0.9903\n",
      "Epoch 163/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0371 - accuracy: 0.9906\n",
      "Epoch 163: val_loss improved from 0.03547 to 0.03530, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9905 - val_loss: 0.0353 - val_accuracy: 0.9925\n",
      "Epoch 164/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0364 - accuracy: 0.9911\n",
      "Epoch 164: val_loss did not improve from 0.03530\n",
      "92/92 [==============================] - 0s 973us/step - loss: 0.0371 - accuracy: 0.9908 - val_loss: 0.0354 - val_accuracy: 0.9923\n",
      "Epoch 165/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0363 - accuracy: 0.9910\n",
      "Epoch 165: val_loss improved from 0.03530 to 0.03513, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9905 - val_loss: 0.0351 - val_accuracy: 0.9928\n",
      "Epoch 166/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0365 - accuracy: 0.9910\n",
      "Epoch 166: val_loss improved from 0.03513 to 0.03501, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9906 - val_loss: 0.0350 - val_accuracy: 0.9923\n",
      "Epoch 167/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0369 - accuracy: 0.9914\n",
      "Epoch 167: val_loss improved from 0.03501 to 0.03488, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9910 - val_loss: 0.0349 - val_accuracy: 0.9923\n",
      "Epoch 168/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0364 - accuracy: 0.9910\n",
      "Epoch 168: val_loss improved from 0.03488 to 0.03485, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9908 - val_loss: 0.0348 - val_accuracy: 0.9923\n",
      "Epoch 169/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0367 - accuracy: 0.9910\n",
      "Epoch 169: val_loss improved from 0.03485 to 0.03448, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.0345 - val_accuracy: 0.9928\n",
      "Epoch 170/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0360 - accuracy: 0.9909\n",
      "Epoch 170: val_loss improved from 0.03448 to 0.03440, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9908 - val_loss: 0.0344 - val_accuracy: 0.9913\n",
      "Epoch 171/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0358 - accuracy: 0.9907\n",
      "Epoch 171: val_loss improved from 0.03440 to 0.03319, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9909 - val_loss: 0.0332 - val_accuracy: 0.9920\n",
      "Epoch 172/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0357 - accuracy: 0.9904\n",
      "Epoch 172: val_loss improved from 0.03319 to 0.03297, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9908 - val_loss: 0.0330 - val_accuracy: 0.9918\n",
      "Epoch 173/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0344 - accuracy: 0.9909\n",
      "Epoch 173: val_loss improved from 0.03297 to 0.03279, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9907 - val_loss: 0.0328 - val_accuracy: 0.9918\n",
      "Epoch 174/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0347 - accuracy: 0.9905\n",
      "Epoch 174: val_loss improved from 0.03279 to 0.03190, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9908 - val_loss: 0.0319 - val_accuracy: 0.9928\n",
      "Epoch 175/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0333 - accuracy: 0.9912\n",
      "Epoch 175: val_loss improved from 0.03190 to 0.03185, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 0.0318 - val_accuracy: 0.9935\n",
      "Epoch 176/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0338 - accuracy: 0.9911\n",
      "Epoch 176: val_loss improved from 0.03185 to 0.03169, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9911 - val_loss: 0.0317 - val_accuracy: 0.9930\n",
      "Epoch 177/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0342 - accuracy: 0.9909\n",
      "Epoch 177: val_loss improved from 0.03169 to 0.03132, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9911 - val_loss: 0.0313 - val_accuracy: 0.9928\n",
      "Epoch 178/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0336 - accuracy: 0.9910\n",
      "Epoch 178: val_loss improved from 0.03132 to 0.03098, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9913 - val_loss: 0.0310 - val_accuracy: 0.9937\n",
      "Epoch 179/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0331 - accuracy: 0.9911\n",
      "Epoch 179: val_loss improved from 0.03098 to 0.03096, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 0.0310 - val_accuracy: 0.9932\n",
      "Epoch 180/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0329 - accuracy: 0.9917\n",
      "Epoch 180: val_loss improved from 0.03096 to 0.03061, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9917 - val_loss: 0.0306 - val_accuracy: 0.9940\n",
      "Epoch 181/400\n",
      "71/92 [======================>.......] - ETA: 0s - loss: 0.0330 - accuracy: 0.9914\n",
      "Epoch 181: val_loss did not improve from 0.03061\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9915 - val_loss: 0.0306 - val_accuracy: 0.9940\n",
      "Epoch 182/400\n",
      "67/92 [====================>.........] - ETA: 0s - loss: 0.0326 - accuracy: 0.9915\n",
      "Epoch 182: val_loss improved from 0.03061 to 0.03037, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9915 - val_loss: 0.0304 - val_accuracy: 0.9942\n",
      "Epoch 183/400\n",
      "73/92 [======================>.......] - ETA: 0s - loss: 0.0328 - accuracy: 0.9914\n",
      "Epoch 183: val_loss did not improve from 0.03037\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9919 - val_loss: 0.0306 - val_accuracy: 0.9930\n",
      "Epoch 184/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0325 - accuracy: 0.9919\n",
      "Epoch 184: val_loss improved from 0.03037 to 0.03030, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9919 - val_loss: 0.0303 - val_accuracy: 0.9928\n",
      "Epoch 185/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0322 - accuracy: 0.9915\n",
      "Epoch 185: val_loss improved from 0.03030 to 0.03017, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9916 - val_loss: 0.0302 - val_accuracy: 0.9940\n",
      "Epoch 186/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0321 - accuracy: 0.9921\n",
      "Epoch 186: val_loss improved from 0.03017 to 0.03011, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9921 - val_loss: 0.0301 - val_accuracy: 0.9930\n",
      "Epoch 187/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0317 - accuracy: 0.9919\n",
      "Epoch 187: val_loss improved from 0.03011 to 0.02960, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.0296 - val_accuracy: 0.9937\n",
      "Epoch 188/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0315 - accuracy: 0.9919\n",
      "Epoch 188: val_loss did not improve from 0.02960\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.9921 - val_loss: 0.0298 - val_accuracy: 0.9937\n",
      "Epoch 189/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0322 - accuracy: 0.9923\n",
      "Epoch 189: val_loss did not improve from 0.02960\n",
      "92/92 [==============================] - 0s 992us/step - loss: 0.0316 - accuracy: 0.9923 - val_loss: 0.0297 - val_accuracy: 0.9930\n",
      "Epoch 190/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0314 - accuracy: 0.9927\n",
      "Epoch 190: val_loss improved from 0.02960 to 0.02930, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9925 - val_loss: 0.0293 - val_accuracy: 0.9932\n",
      "Epoch 191/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0317 - accuracy: 0.9916\n",
      "Epoch 191: val_loss did not improve from 0.02930\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9920 - val_loss: 0.0294 - val_accuracy: 0.9937\n",
      "Epoch 192/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0316 - accuracy: 0.9924\n",
      "Epoch 192: val_loss improved from 0.02930 to 0.02893, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9926 - val_loss: 0.0289 - val_accuracy: 0.9959\n",
      "Epoch 193/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0313 - accuracy: 0.9927\n",
      "Epoch 193: val_loss did not improve from 0.02893\n",
      "92/92 [==============================] - 0s 955us/step - loss: 0.0312 - accuracy: 0.9928 - val_loss: 0.0291 - val_accuracy: 0.9940\n",
      "Epoch 194/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0308 - accuracy: 0.9926\n",
      "Epoch 194: val_loss did not improve from 0.02893\n",
      "92/92 [==============================] - 0s 973us/step - loss: 0.0311 - accuracy: 0.9927 - val_loss: 0.0291 - val_accuracy: 0.9942\n",
      "Epoch 195/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0309 - accuracy: 0.9924\n",
      "Epoch 195: val_loss improved from 0.02893 to 0.02881, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9924 - val_loss: 0.0288 - val_accuracy: 0.9954\n",
      "Epoch 196/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0312 - accuracy: 0.9921\n",
      "Epoch 196: val_loss improved from 0.02881 to 0.02848, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9921 - val_loss: 0.0285 - val_accuracy: 0.9947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0310 - accuracy: 0.9926\n",
      "Epoch 197: val_loss improved from 0.02848 to 0.02842, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9927 - val_loss: 0.0284 - val_accuracy: 0.9954\n",
      "Epoch 198/400\n",
      "60/92 [==================>...........] - ETA: 0s - loss: 0.0307 - accuracy: 0.9925\n",
      "Epoch 198: val_loss improved from 0.02842 to 0.02821, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9930 - val_loss: 0.0282 - val_accuracy: 0.9959\n",
      "Epoch 199/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0311 - accuracy: 0.9924\n",
      "Epoch 199: val_loss did not improve from 0.02821\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9929 - val_loss: 0.0284 - val_accuracy: 0.9947\n",
      "Epoch 200/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0303 - accuracy: 0.9930\n",
      "Epoch 200: val_loss improved from 0.02821 to 0.02795, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9930 - val_loss: 0.0279 - val_accuracy: 0.9957\n",
      "Epoch 201/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0306 - accuracy: 0.9927\n",
      "Epoch 201: val_loss did not improve from 0.02795\n",
      "92/92 [==============================] - 0s 953us/step - loss: 0.0303 - accuracy: 0.9927 - val_loss: 0.0283 - val_accuracy: 0.9930\n",
      "Epoch 202/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0301 - accuracy: 0.9922\n",
      "Epoch 202: val_loss improved from 0.02795 to 0.02779, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9925 - val_loss: 0.0278 - val_accuracy: 0.9954\n",
      "Epoch 203/400\n",
      "69/92 [=====================>........] - ETA: 0s - loss: 0.0300 - accuracy: 0.9927\n",
      "Epoch 203: val_loss did not improve from 0.02779\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9928 - val_loss: 0.0280 - val_accuracy: 0.9952\n",
      "Epoch 204/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0300 - accuracy: 0.9931\n",
      "Epoch 204: val_loss improved from 0.02779 to 0.02755, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9932 - val_loss: 0.0275 - val_accuracy: 0.9957\n",
      "Epoch 205/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0299 - accuracy: 0.9930\n",
      "Epoch 205: val_loss did not improve from 0.02755\n",
      "92/92 [==============================] - 0s 947us/step - loss: 0.0299 - accuracy: 0.9931 - val_loss: 0.0277 - val_accuracy: 0.9949\n",
      "Epoch 206/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0297 - accuracy: 0.9932\n",
      "Epoch 206: val_loss improved from 0.02755 to 0.02738, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9933 - val_loss: 0.0274 - val_accuracy: 0.9949\n",
      "Epoch 207/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0304 - accuracy: 0.9926\n",
      "Epoch 207: val_loss did not improve from 0.02738\n",
      "92/92 [==============================] - 0s 980us/step - loss: 0.0298 - accuracy: 0.9930 - val_loss: 0.0274 - val_accuracy: 0.9954\n",
      "Epoch 208/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0295 - accuracy: 0.9935\n",
      "Epoch 208: val_loss improved from 0.02738 to 0.02738, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9935 - val_loss: 0.0274 - val_accuracy: 0.9952\n",
      "Epoch 209/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0288 - accuracy: 0.9930\n",
      "Epoch 209: val_loss improved from 0.02738 to 0.02718, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9928 - val_loss: 0.0272 - val_accuracy: 0.9957\n",
      "Epoch 210/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0294 - accuracy: 0.9932\n",
      "Epoch 210: val_loss improved from 0.02718 to 0.02704, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9933 - val_loss: 0.0270 - val_accuracy: 0.9949\n",
      "Epoch 211/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0297 - accuracy: 0.9930\n",
      "Epoch 211: val_loss did not improve from 0.02704\n",
      "92/92 [==============================] - 0s 985us/step - loss: 0.0293 - accuracy: 0.9931 - val_loss: 0.0271 - val_accuracy: 0.9957\n",
      "Epoch 212/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0290 - accuracy: 0.9930\n",
      "Epoch 212: val_loss improved from 0.02704 to 0.02692, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9932 - val_loss: 0.0269 - val_accuracy: 0.9949\n",
      "Epoch 213/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0288 - accuracy: 0.9933\n",
      "Epoch 213: val_loss improved from 0.02692 to 0.02686, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9930 - val_loss: 0.0269 - val_accuracy: 0.9954\n",
      "Epoch 214/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0291 - accuracy: 0.9933\n",
      "Epoch 214: val_loss improved from 0.02686 to 0.02669, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9932 - val_loss: 0.0267 - val_accuracy: 0.9957\n",
      "Epoch 215/400\n",
      "86/92 [===========================>..] - ETA: 0s - loss: 0.0290 - accuracy: 0.9931\n",
      "Epoch 215: val_loss did not improve from 0.02669\n",
      "92/92 [==============================] - 0s 895us/step - loss: 0.0290 - accuracy: 0.9930 - val_loss: 0.0268 - val_accuracy: 0.9949\n",
      "Epoch 216/400\n",
      "85/92 [==========================>...] - ETA: 0s - loss: 0.0289 - accuracy: 0.9931\n",
      "Epoch 216: val_loss improved from 0.02669 to 0.02636, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9931 - val_loss: 0.0264 - val_accuracy: 0.9964\n",
      "Epoch 217/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0285 - accuracy: 0.9936\n",
      "Epoch 217: val_loss improved from 0.02636 to 0.02634, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9934 - val_loss: 0.0263 - val_accuracy: 0.9961\n",
      "Epoch 218/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0287 - accuracy: 0.9931\n",
      "Epoch 218: val_loss did not improve from 0.02634\n",
      "92/92 [==============================] - 0s 923us/step - loss: 0.0288 - accuracy: 0.9931 - val_loss: 0.0266 - val_accuracy: 0.9949\n",
      "Epoch 219/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0284 - accuracy: 0.9935\n",
      "Epoch 219: val_loss did not improve from 0.02634\n",
      "92/92 [==============================] - 0s 916us/step - loss: 0.0287 - accuracy: 0.9932 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
      "Epoch 220/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0286 - accuracy: 0.9935\n",
      "Epoch 220: val_loss did not improve from 0.02634\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9934 - val_loss: 0.0264 - val_accuracy: 0.9942\n",
      "Epoch 221/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.0293 - accuracy: 0.9927\n",
      "Epoch 221: val_loss did not improve from 0.02634\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9932 - val_loss: 0.0263 - val_accuracy: 0.9949\n",
      "Epoch 222/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0284 - accuracy: 0.9937\n",
      "Epoch 222: val_loss improved from 0.02634 to 0.02593, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9935 - val_loss: 0.0259 - val_accuracy: 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0285 - accuracy: 0.9934\n",
      "Epoch 223: val_loss did not improve from 0.02593\n",
      "92/92 [==============================] - 0s 942us/step - loss: 0.0283 - accuracy: 0.9936 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
      "Epoch 224/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0285 - accuracy: 0.9934\n",
      "Epoch 224: val_loss improved from 0.02593 to 0.02578, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9934 - val_loss: 0.0258 - val_accuracy: 0.9957\n",
      "Epoch 225/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0278 - accuracy: 0.9936\n",
      "Epoch 225: val_loss did not improve from 0.02578\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.9933 - val_loss: 0.0258 - val_accuracy: 0.9959\n",
      "Epoch 226/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0288 - accuracy: 0.9930\n",
      "Epoch 226: val_loss improved from 0.02578 to 0.02563, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9936 - val_loss: 0.0256 - val_accuracy: 0.9954\n",
      "Epoch 227/400\n",
      "84/92 [==========================>...] - ETA: 0s - loss: 0.0280 - accuracy: 0.9932\n",
      "Epoch 227: val_loss did not improve from 0.02563\n",
      "92/92 [==============================] - 0s 920us/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 0.0257 - val_accuracy: 0.9952\n",
      "Epoch 228/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0282 - accuracy: 0.9933\n",
      "Epoch 228: val_loss improved from 0.02563 to 0.02544, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9935 - val_loss: 0.0254 - val_accuracy: 0.9959\n",
      "Epoch 229/400\n",
      "84/92 [==========================>...] - ETA: 0s - loss: 0.0280 - accuracy: 0.9935\n",
      "Epoch 229: val_loss did not improve from 0.02544\n",
      "92/92 [==============================] - 0s 914us/step - loss: 0.0278 - accuracy: 0.9937 - val_loss: 0.0255 - val_accuracy: 0.9954\n",
      "Epoch 230/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0278 - accuracy: 0.9932\n",
      "Epoch 230: val_loss did not improve from 0.02544\n",
      "92/92 [==============================] - 0s 939us/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.0257 - val_accuracy: 0.9942\n",
      "Epoch 231/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0277 - accuracy: 0.9938\n",
      "Epoch 231: val_loss improved from 0.02544 to 0.02508, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9939 - val_loss: 0.0251 - val_accuracy: 0.9964\n",
      "Epoch 232/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0276 - accuracy: 0.9931\n",
      "Epoch 232: val_loss improved from 0.02508 to 0.02496, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9933 - val_loss: 0.0250 - val_accuracy: 0.9961\n",
      "Epoch 233/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0277 - accuracy: 0.9931\n",
      "Epoch 233: val_loss did not improve from 0.02496\n",
      "92/92 [==============================] - 0s 908us/step - loss: 0.0276 - accuracy: 0.9934 - val_loss: 0.0254 - val_accuracy: 0.9952\n",
      "Epoch 234/400\n",
      "84/92 [==========================>...] - ETA: 0s - loss: 0.0275 - accuracy: 0.9937\n",
      "Epoch 234: val_loss did not improve from 0.02496\n",
      "92/92 [==============================] - 0s 915us/step - loss: 0.0275 - accuracy: 0.9938 - val_loss: 0.0251 - val_accuracy: 0.9957\n",
      "Epoch 235/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0277 - accuracy: 0.9929\n",
      "Epoch 235: val_loss did not improve from 0.02496\n",
      "92/92 [==============================] - 0s 970us/step - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.0254 - val_accuracy: 0.9952\n",
      "Epoch 236/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0276 - accuracy: 0.9937\n",
      "Epoch 236: val_loss did not improve from 0.02496\n",
      "92/92 [==============================] - 0s 964us/step - loss: 0.0273 - accuracy: 0.9938 - val_loss: 0.0254 - val_accuracy: 0.9947\n",
      "Epoch 237/400\n",
      "68/92 [=====================>........] - ETA: 0s - loss: 0.0277 - accuracy: 0.9933\n",
      "Epoch 237: val_loss did not improve from 0.02496\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9934 - val_loss: 0.0252 - val_accuracy: 0.9942\n",
      "Epoch 238/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0272 - accuracy: 0.9935\n",
      "Epoch 238: val_loss did not improve from 0.02496\n",
      "92/92 [==============================] - 0s 959us/step - loss: 0.0272 - accuracy: 0.9935 - val_loss: 0.0250 - val_accuracy: 0.9952\n",
      "Epoch 239/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0273 - accuracy: 0.9936\n",
      "Epoch 239: val_loss improved from 0.02496 to 0.02468, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9935 - val_loss: 0.0247 - val_accuracy: 0.9959\n",
      "Epoch 240/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0268 - accuracy: 0.9938\n",
      "Epoch 240: val_loss did not improve from 0.02468\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9936 - val_loss: 0.0248 - val_accuracy: 0.9959\n",
      "Epoch 241/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0273 - accuracy: 0.9939\n",
      "Epoch 241: val_loss improved from 0.02468 to 0.02454, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9937 - val_loss: 0.0245 - val_accuracy: 0.9959\n",
      "Epoch 242/400\n",
      "85/92 [==========================>...] - ETA: 0s - loss: 0.0269 - accuracy: 0.9933\n",
      "Epoch 242: val_loss did not improve from 0.02454\n",
      "92/92 [==============================] - 0s 893us/step - loss: 0.0270 - accuracy: 0.9934 - val_loss: 0.0249 - val_accuracy: 0.9947\n",
      "Epoch 243/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0267 - accuracy: 0.9938\n",
      "Epoch 243: val_loss improved from 0.02454 to 0.02423, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9937 - val_loss: 0.0242 - val_accuracy: 0.9959\n",
      "Epoch 244/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0268 - accuracy: 0.9938\n",
      "Epoch 244: val_loss did not improve from 0.02423\n",
      "92/92 [==============================] - 0s 929us/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.0245 - val_accuracy: 0.9952\n",
      "Epoch 245/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0269 - accuracy: 0.9938\n",
      "Epoch 245: val_loss did not improve from 0.02423\n",
      "92/92 [==============================] - 0s 964us/step - loss: 0.0267 - accuracy: 0.9937 - val_loss: 0.0243 - val_accuracy: 0.9959\n",
      "Epoch 246/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0273 - accuracy: 0.9933\n",
      "Epoch 246: val_loss did not improve from 0.02423\n",
      "92/92 [==============================] - 0s 978us/step - loss: 0.0267 - accuracy: 0.9935 - val_loss: 0.0243 - val_accuracy: 0.9964\n",
      "Epoch 247/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0270 - accuracy: 0.9934\n",
      "Epoch 247: val_loss did not improve from 0.02423\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9938 - val_loss: 0.0245 - val_accuracy: 0.9961\n",
      "Epoch 248/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0262 - accuracy: 0.9938\n",
      "Epoch 248: val_loss did not improve from 0.02423\n",
      "92/92 [==============================] - 0s 934us/step - loss: 0.0265 - accuracy: 0.9936 - val_loss: 0.0244 - val_accuracy: 0.9942\n",
      "Epoch 249/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0267 - accuracy: 0.9936\n",
      "Epoch 249: val_loss improved from 0.02423 to 0.02408, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9935 - val_loss: 0.0241 - val_accuracy: 0.9954\n",
      "Epoch 250/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0267 - accuracy: 0.9937\n",
      "Epoch 250: val_loss improved from 0.02408 to 0.02396, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9937 - val_loss: 0.0240 - val_accuracy: 0.9959\n",
      "Epoch 251/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0264 - accuracy: 0.9933\n",
      "Epoch 251: val_loss improved from 0.02396 to 0.02394, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9937 - val_loss: 0.0239 - val_accuracy: 0.9957\n",
      "Epoch 252/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0258 - accuracy: 0.9941\n",
      "Epoch 252: val_loss improved from 0.02394 to 0.02378, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9938 - val_loss: 0.0238 - val_accuracy: 0.9957\n",
      "Epoch 253/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0264 - accuracy: 0.9941\n",
      "Epoch 253: val_loss improved from 0.02378 to 0.02367, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9942 - val_loss: 0.0237 - val_accuracy: 0.9959\n",
      "Epoch 254/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0263 - accuracy: 0.9939\n",
      "Epoch 254: val_loss did not improve from 0.02367\n",
      "92/92 [==============================] - 0s 972us/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.0237 - val_accuracy: 0.9954\n",
      "Epoch 255/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0262 - accuracy: 0.9941\n",
      "Epoch 255: val_loss improved from 0.02367 to 0.02349, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9941 - val_loss: 0.0235 - val_accuracy: 0.9961\n",
      "Epoch 256/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0259 - accuracy: 0.9943\n",
      "Epoch 256: val_loss did not improve from 0.02349\n",
      "92/92 [==============================] - 0s 962us/step - loss: 0.0261 - accuracy: 0.9942 - val_loss: 0.0236 - val_accuracy: 0.9954\n",
      "Epoch 257/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0260 - accuracy: 0.9937\n",
      "Epoch 257: val_loss did not improve from 0.02349\n",
      "92/92 [==============================] - 0s 924us/step - loss: 0.0260 - accuracy: 0.9938 - val_loss: 0.0235 - val_accuracy: 0.9959\n",
      "Epoch 258/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0261 - accuracy: 0.9940\n",
      "Epoch 258: val_loss improved from 0.02349 to 0.02334, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9942 - val_loss: 0.0233 - val_accuracy: 0.9964\n",
      "Epoch 259/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0257 - accuracy: 0.9942\n",
      "Epoch 259: val_loss did not improve from 0.02334\n",
      "92/92 [==============================] - 0s 973us/step - loss: 0.0259 - accuracy: 0.9941 - val_loss: 0.0235 - val_accuracy: 0.9959\n",
      "Epoch 260/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0262 - accuracy: 0.9935\n",
      "Epoch 260: val_loss did not improve from 0.02334\n",
      "92/92 [==============================] - 0s 979us/step - loss: 0.0258 - accuracy: 0.9938 - val_loss: 0.0238 - val_accuracy: 0.9947\n",
      "Epoch 261/400\n",
      "84/92 [==========================>...] - ETA: 0s - loss: 0.0256 - accuracy: 0.9946\n",
      "Epoch 261: val_loss did not improve from 0.02334\n",
      "92/92 [==============================] - 0s 900us/step - loss: 0.0257 - accuracy: 0.9945 - val_loss: 0.0234 - val_accuracy: 0.9952\n",
      "Epoch 262/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0259 - accuracy: 0.9938\n",
      "Epoch 262: val_loss improved from 0.02334 to 0.02307, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9938 - val_loss: 0.0231 - val_accuracy: 0.9964\n",
      "Epoch 263/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0260 - accuracy: 0.9941\n",
      "Epoch 263: val_loss did not improve from 0.02307\n",
      "92/92 [==============================] - 0s 934us/step - loss: 0.0256 - accuracy: 0.9942 - val_loss: 0.0235 - val_accuracy: 0.9947\n",
      "Epoch 264/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0258 - accuracy: 0.9941\n",
      "Epoch 264: val_loss did not improve from 0.02307\n",
      "92/92 [==============================] - 0s 935us/step - loss: 0.0256 - accuracy: 0.9942 - val_loss: 0.0236 - val_accuracy: 0.9947\n",
      "Epoch 265/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0252 - accuracy: 0.9949\n",
      "Epoch 265: val_loss did not improve from 0.02307\n",
      "92/92 [==============================] - 0s 935us/step - loss: 0.0255 - accuracy: 0.9946 - val_loss: 0.0234 - val_accuracy: 0.9942\n",
      "Epoch 266/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0256 - accuracy: 0.9940\n",
      "Epoch 266: val_loss did not improve from 0.02307\n",
      "92/92 [==============================] - 0s 925us/step - loss: 0.0255 - accuracy: 0.9940 - val_loss: 0.0233 - val_accuracy: 0.9952\n",
      "Epoch 267/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0254 - accuracy: 0.9943\n",
      "Epoch 267: val_loss improved from 0.02307 to 0.02306, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9941 - val_loss: 0.0231 - val_accuracy: 0.9961\n",
      "Epoch 268/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0256 - accuracy: 0.9943\n",
      "Epoch 268: val_loss improved from 0.02306 to 0.02299, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9944 - val_loss: 0.0230 - val_accuracy: 0.9954\n",
      "Epoch 269/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0260 - accuracy: 0.9942\n",
      "Epoch 269: val_loss improved from 0.02299 to 0.02292, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9943 - val_loss: 0.0229 - val_accuracy: 0.9957\n",
      "Epoch 270/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0249 - accuracy: 0.9945\n",
      "Epoch 270: val_loss improved from 0.02292 to 0.02290, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9944 - val_loss: 0.0229 - val_accuracy: 0.9959\n",
      "Epoch 271/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0249 - accuracy: 0.9944\n",
      "Epoch 271: val_loss improved from 0.02290 to 0.02267, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9943 - val_loss: 0.0227 - val_accuracy: 0.9966\n",
      "Epoch 272/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0249 - accuracy: 0.9940\n",
      "Epoch 272: val_loss improved from 0.02267 to 0.02266, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 0.0227 - val_accuracy: 0.9961\n",
      "Epoch 273/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0257 - accuracy: 0.9939\n",
      "Epoch 273: val_loss did not improve from 0.02266\n",
      "92/92 [==============================] - 0s 933us/step - loss: 0.0251 - accuracy: 0.9943 - val_loss: 0.0228 - val_accuracy: 0.9952\n",
      "Epoch 274/400\n",
      "84/92 [==========================>...] - ETA: 0s - loss: 0.0249 - accuracy: 0.9940\n",
      "Epoch 274: val_loss improved from 0.02266 to 0.02264, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9943 - val_loss: 0.0226 - val_accuracy: 0.9954\n",
      "Epoch 275/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0250 - accuracy: 0.9944\n",
      "Epoch 275: val_loss improved from 0.02264 to 0.02245, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9943 - val_loss: 0.0224 - val_accuracy: 0.9961\n",
      "Epoch 276/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0248 - accuracy: 0.9947\n",
      "Epoch 276: val_loss improved from 0.02245 to 0.02231, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9946 - val_loss: 0.0223 - val_accuracy: 0.9959\n",
      "Epoch 277/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0249 - accuracy: 0.9943\n",
      "Epoch 277: val_loss did not improve from 0.02231\n",
      "92/92 [==============================] - 0s 963us/step - loss: 0.0248 - accuracy: 0.9943 - val_loss: 0.0226 - val_accuracy: 0.9957\n",
      "Epoch 278/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0246 - accuracy: 0.9945\n",
      "Epoch 278: val_loss improved from 0.02231 to 0.02215, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9945 - val_loss: 0.0221 - val_accuracy: 0.9957\n",
      "Epoch 279/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0245 - accuracy: 0.9946\n",
      "Epoch 279: val_loss did not improve from 0.02215\n",
      "92/92 [==============================] - 0s 959us/step - loss: 0.0247 - accuracy: 0.9943 - val_loss: 0.0223 - val_accuracy: 0.9959\n",
      "Epoch 280/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0244 - accuracy: 0.9946\n",
      "Epoch 280: val_loss did not improve from 0.02215\n",
      "92/92 [==============================] - 0s 929us/step - loss: 0.0247 - accuracy: 0.9945 - val_loss: 0.0224 - val_accuracy: 0.9964\n",
      "Epoch 281/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0244 - accuracy: 0.9941\n",
      "Epoch 281: val_loss did not improve from 0.02215\n",
      "92/92 [==============================] - 0s 981us/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 0.0225 - val_accuracy: 0.9964\n",
      "Epoch 282/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0241 - accuracy: 0.9950\n",
      "Epoch 282: val_loss improved from 0.02215 to 0.02208, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9946 - val_loss: 0.0221 - val_accuracy: 0.9966\n",
      "Epoch 283/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0240 - accuracy: 0.9949\n",
      "Epoch 283: val_loss improved from 0.02208 to 0.02207, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9946 - val_loss: 0.0221 - val_accuracy: 0.9964\n",
      "Epoch 284/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0249 - accuracy: 0.9944\n",
      "Epoch 284: val_loss improved from 0.02207 to 0.02191, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9944 - val_loss: 0.0219 - val_accuracy: 0.9969\n",
      "Epoch 285/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.0243 - accuracy: 0.9944\n",
      "Epoch 285: val_loss did not improve from 0.02191\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9944 - val_loss: 0.0220 - val_accuracy: 0.9959\n",
      "Epoch 286/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0242 - accuracy: 0.9951\n",
      "Epoch 286: val_loss did not improve from 0.02191\n",
      "92/92 [==============================] - 0s 963us/step - loss: 0.0244 - accuracy: 0.9948 - val_loss: 0.0221 - val_accuracy: 0.9959\n",
      "Epoch 287/400\n",
      "84/92 [==========================>...] - ETA: 0s - loss: 0.0244 - accuracy: 0.9948\n",
      "Epoch 287: val_loss did not improve from 0.02191\n",
      "92/92 [==============================] - 0s 923us/step - loss: 0.0244 - accuracy: 0.9947 - val_loss: 0.0220 - val_accuracy: 0.9957\n",
      "Epoch 288/400\n",
      "84/92 [==========================>...] - ETA: 0s - loss: 0.0241 - accuracy: 0.9940\n",
      "Epoch 288: val_loss did not improve from 0.02191\n",
      "92/92 [==============================] - 0s 925us/step - loss: 0.0243 - accuracy: 0.9940 - val_loss: 0.0222 - val_accuracy: 0.9957\n",
      "Epoch 289/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0237 - accuracy: 0.9948\n",
      "Epoch 289: val_loss improved from 0.02191 to 0.02187, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9948 - val_loss: 0.0219 - val_accuracy: 0.9959\n",
      "Epoch 290/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0237 - accuracy: 0.9947\n",
      "Epoch 290: val_loss did not improve from 0.02187\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9946 - val_loss: 0.0220 - val_accuracy: 0.9961\n",
      "Epoch 291/400\n",
      "61/92 [==================>...........] - ETA: 0s - loss: 0.0247 - accuracy: 0.9940\n",
      "Epoch 291: val_loss improved from 0.02187 to 0.02181, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9949 - val_loss: 0.0218 - val_accuracy: 0.9957\n",
      "Epoch 292/400\n",
      "66/92 [====================>.........] - ETA: 0s - loss: 0.0241 - accuracy: 0.9946\n",
      "Epoch 292: val_loss did not improve from 0.02181\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9947 - val_loss: 0.0218 - val_accuracy: 0.9957\n",
      "Epoch 293/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0236 - accuracy: 0.9948\n",
      "Epoch 293: val_loss did not improve from 0.02181\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.0220 - val_accuracy: 0.9957\n",
      "Epoch 294/400\n",
      "71/92 [======================>.......] - ETA: 0s - loss: 0.0238 - accuracy: 0.9947\n",
      "Epoch 294: val_loss improved from 0.02181 to 0.02150, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9948 - val_loss: 0.0215 - val_accuracy: 0.9961\n",
      "Epoch 295/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0241 - accuracy: 0.9944\n",
      "Epoch 295: val_loss did not improve from 0.02150\n",
      "92/92 [==============================] - 0s 928us/step - loss: 0.0240 - accuracy: 0.9945 - val_loss: 0.0215 - val_accuracy: 0.9964\n",
      "Epoch 296/400\n",
      "81/92 [=========================>....] - ETA: 0s - loss: 0.0239 - accuracy: 0.9946\n",
      "Epoch 296: val_loss improved from 0.02150 to 0.02148, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9948 - val_loss: 0.0215 - val_accuracy: 0.9961\n",
      "Epoch 297/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0239 - accuracy: 0.9946\n",
      "Epoch 297: val_loss did not improve from 0.02148\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.0219 - val_accuracy: 0.9959\n",
      "Epoch 298/400\n",
      "59/92 [==================>...........] - ETA: 0s - loss: 0.0238 - accuracy: 0.9942\n",
      "Epoch 298: val_loss did not improve from 0.02148\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9943 - val_loss: 0.0216 - val_accuracy: 0.9964\n",
      "Epoch 299/400\n",
      "73/92 [======================>.......] - ETA: 0s - loss: 0.0236 - accuracy: 0.9949\n",
      "Epoch 299: val_loss did not improve from 0.02148\n",
      "92/92 [==============================] - 0s 988us/step - loss: 0.0237 - accuracy: 0.9950 - val_loss: 0.0216 - val_accuracy: 0.9959\n",
      "Epoch 300/400\n",
      "71/92 [======================>.......] - ETA: 0s - loss: 0.0237 - accuracy: 0.9947\n",
      "Epoch 300: val_loss improved from 0.02148 to 0.02124, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9948 - val_loss: 0.0212 - val_accuracy: 0.9969\n",
      "Epoch 301/400\n",
      "66/92 [====================>.........] - ETA: 0s - loss: 0.0229 - accuracy: 0.9953\n",
      "Epoch 301: val_loss did not improve from 0.02124\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9947 - val_loss: 0.0214 - val_accuracy: 0.9961\n",
      "Epoch 302/400\n",
      "69/92 [=====================>........] - ETA: 0s - loss: 0.0228 - accuracy: 0.9947\n",
      "Epoch 302: val_loss did not improve from 0.02124\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9947 - val_loss: 0.0213 - val_accuracy: 0.9964\n",
      "Epoch 303/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0236 - accuracy: 0.9947\n",
      "Epoch 303: val_loss improved from 0.02124 to 0.02114, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9948 - val_loss: 0.0211 - val_accuracy: 0.9969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0236 - accuracy: 0.9947\n",
      "Epoch 304: val_loss did not improve from 0.02114\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9948 - val_loss: 0.0212 - val_accuracy: 0.9964\n",
      "Epoch 305/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.0233 - accuracy: 0.9949\n",
      "Epoch 305: val_loss improved from 0.02114 to 0.02099, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9948 - val_loss: 0.0210 - val_accuracy: 0.9969\n",
      "Epoch 306/400\n",
      "67/92 [====================>.........] - ETA: 0s - loss: 0.0232 - accuracy: 0.9949\n",
      "Epoch 306: val_loss did not improve from 0.02099\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9947 - val_loss: 0.0215 - val_accuracy: 0.9954\n",
      "Epoch 307/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0229 - accuracy: 0.9952\n",
      "Epoch 307: val_loss did not improve from 0.02099\n",
      "92/92 [==============================] - 0s 992us/step - loss: 0.0233 - accuracy: 0.9948 - val_loss: 0.0210 - val_accuracy: 0.9964\n",
      "Epoch 308/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0229 - accuracy: 0.9950\n",
      "Epoch 308: val_loss improved from 0.02099 to 0.02094, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9947 - val_loss: 0.0209 - val_accuracy: 0.9966\n",
      "Epoch 309/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0233 - accuracy: 0.9948\n",
      "Epoch 309: val_loss improved from 0.02094 to 0.02091, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9947 - val_loss: 0.0209 - val_accuracy: 0.9966\n",
      "Epoch 310/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0232 - accuracy: 0.9948\n",
      "Epoch 310: val_loss improved from 0.02091 to 0.02089, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9948 - val_loss: 0.0209 - val_accuracy: 0.9961\n",
      "Epoch 311/400\n",
      "66/92 [====================>.........] - ETA: 0s - loss: 0.0230 - accuracy: 0.9945\n",
      "Epoch 311: val_loss did not improve from 0.02089\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9949 - val_loss: 0.0210 - val_accuracy: 0.9961\n",
      "Epoch 312/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0229 - accuracy: 0.9951\n",
      "Epoch 312: val_loss improved from 0.02089 to 0.02074, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9950 - val_loss: 0.0207 - val_accuracy: 0.9961\n",
      "Epoch 313/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0232 - accuracy: 0.9946\n",
      "Epoch 313: val_loss did not improve from 0.02074\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9946 - val_loss: 0.0210 - val_accuracy: 0.9959\n",
      "Epoch 314/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0235 - accuracy: 0.9948\n",
      "Epoch 314: val_loss did not improve from 0.02074\n",
      "92/92 [==============================] - 0s 999us/step - loss: 0.0230 - accuracy: 0.9950 - val_loss: 0.0210 - val_accuracy: 0.9954\n",
      "Epoch 315/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0227 - accuracy: 0.9951\n",
      "Epoch 315: val_loss improved from 0.02074 to 0.02070, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9950 - val_loss: 0.0207 - val_accuracy: 0.9964\n",
      "Epoch 316/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.0235 - accuracy: 0.9937\n",
      "Epoch 316: val_loss did not improve from 0.02070\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0211 - val_accuracy: 0.9952\n",
      "Epoch 317/400\n",
      "57/92 [=================>............] - ETA: 0s - loss: 0.0227 - accuracy: 0.9949\n",
      "Epoch 317: val_loss improved from 0.02070 to 0.02058, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9949 - val_loss: 0.0206 - val_accuracy: 0.9964\n",
      "Epoch 318/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0228 - accuracy: 0.9947\n",
      "Epoch 318: val_loss did not improve from 0.02058\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.0206 - val_accuracy: 0.9964\n",
      "Epoch 319/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0229 - accuracy: 0.9950\n",
      "Epoch 319: val_loss improved from 0.02058 to 0.02047, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9950 - val_loss: 0.0205 - val_accuracy: 0.9966\n",
      "Epoch 320/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0225 - accuracy: 0.9950\n",
      "Epoch 320: val_loss did not improve from 0.02047\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9948 - val_loss: 0.0205 - val_accuracy: 0.9964\n",
      "Epoch 321/400\n",
      "73/92 [======================>.......] - ETA: 0s - loss: 0.0227 - accuracy: 0.9951\n",
      "Epoch 321: val_loss did not improve from 0.02047\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.0206 - val_accuracy: 0.9961\n",
      "Epoch 322/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0226 - accuracy: 0.9951\n",
      "Epoch 322: val_loss did not improve from 0.02047\n",
      "92/92 [==============================] - 0s 968us/step - loss: 0.0228 - accuracy: 0.9951 - val_loss: 0.0207 - val_accuracy: 0.9961\n",
      "Epoch 323/400\n",
      "71/92 [======================>.......] - ETA: 0s - loss: 0.0223 - accuracy: 0.9954\n",
      "Epoch 323: val_loss improved from 0.02047 to 0.02032, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9951 - val_loss: 0.0203 - val_accuracy: 0.9966\n",
      "Epoch 324/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.0224 - accuracy: 0.9950\n",
      "Epoch 324: val_loss did not improve from 0.02032\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9951 - val_loss: 0.0205 - val_accuracy: 0.9961\n",
      "Epoch 325/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0226 - accuracy: 0.9950\n",
      "Epoch 325: val_loss did not improve from 0.02032\n",
      "92/92 [==============================] - 0s 978us/step - loss: 0.0226 - accuracy: 0.9951 - val_loss: 0.0204 - val_accuracy: 0.9961\n",
      "Epoch 326/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0221 - accuracy: 0.9953\n",
      "Epoch 326: val_loss improved from 0.02032 to 0.02018, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9949 - val_loss: 0.0202 - val_accuracy: 0.9964\n",
      "Epoch 327/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0221 - accuracy: 0.9949\n",
      "Epoch 327: val_loss did not improve from 0.02018\n",
      "92/92 [==============================] - 0s 947us/step - loss: 0.0225 - accuracy: 0.9948 - val_loss: 0.0204 - val_accuracy: 0.9961\n",
      "Epoch 328/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0227 - accuracy: 0.9947\n",
      "Epoch 328: val_loss did not improve from 0.02018\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.0202 - val_accuracy: 0.9961\n",
      "Epoch 329/400\n",
      "59/92 [==================>...........] - ETA: 0s - loss: 0.0226 - accuracy: 0.9950\n",
      "Epoch 329: val_loss improved from 0.02018 to 0.02008, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9951 - val_loss: 0.0201 - val_accuracy: 0.9964\n",
      "Epoch 330/400\n",
      "73/92 [======================>.......] - ETA: 0s - loss: 0.0227 - accuracy: 0.9950\n",
      "Epoch 330: val_loss improved from 0.02008 to 0.02000, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9951 - val_loss: 0.0200 - val_accuracy: 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/400\n",
      "65/92 [====================>.........] - ETA: 0s - loss: 0.0220 - accuracy: 0.9954\n",
      "Epoch 331: val_loss did not improve from 0.02000\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9951 - val_loss: 0.0203 - val_accuracy: 0.9959\n",
      "Epoch 332/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0225 - accuracy: 0.9952\n",
      "Epoch 332: val_loss did not improve from 0.02000\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9951 - val_loss: 0.0200 - val_accuracy: 0.9966\n",
      "Epoch 333/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0232 - accuracy: 0.9943\n",
      "Epoch 333: val_loss did not improve from 0.02000\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 0.0202 - val_accuracy: 0.9961\n",
      "Epoch 334/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0225 - accuracy: 0.9952\n",
      "Epoch 334: val_loss improved from 0.02000 to 0.01989, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9953 - val_loss: 0.0199 - val_accuracy: 0.9966\n",
      "Epoch 335/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0224 - accuracy: 0.9949\n",
      "Epoch 335: val_loss did not improve from 0.01989\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9949 - val_loss: 0.0200 - val_accuracy: 0.9966\n",
      "Epoch 336/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0223 - accuracy: 0.9950\n",
      "Epoch 336: val_loss improved from 0.01989 to 0.01984, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9951 - val_loss: 0.0198 - val_accuracy: 0.9961\n",
      "Epoch 337/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0223 - accuracy: 0.9944\n",
      "Epoch 337: val_loss improved from 0.01984 to 0.01972, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9945 - val_loss: 0.0197 - val_accuracy: 0.9966\n",
      "Epoch 338/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0220 - accuracy: 0.9951\n",
      "Epoch 338: val_loss did not improve from 0.01972\n",
      "92/92 [==============================] - 0s 915us/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.0199 - val_accuracy: 0.9959\n",
      "Epoch 339/400\n",
      "86/92 [===========================>..] - ETA: 0s - loss: 0.0219 - accuracy: 0.9953\n",
      "Epoch 339: val_loss improved from 0.01972 to 0.01970, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 992us/step - loss: 0.0221 - accuracy: 0.9953 - val_loss: 0.0197 - val_accuracy: 0.9966\n",
      "Epoch 340/400\n",
      "65/92 [====================>.........] - ETA: 0s - loss: 0.0218 - accuracy: 0.9954\n",
      "Epoch 340: val_loss did not improve from 0.01970\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9950 - val_loss: 0.0198 - val_accuracy: 0.9964\n",
      "Epoch 341/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0216 - accuracy: 0.9953\n",
      "Epoch 341: val_loss improved from 0.01970 to 0.01954, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9953 - val_loss: 0.0195 - val_accuracy: 0.9969\n",
      "Epoch 342/400\n",
      "68/92 [=====================>........] - ETA: 0s - loss: 0.0218 - accuracy: 0.9952\n",
      "Epoch 342: val_loss did not improve from 0.01954\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9950 - val_loss: 0.0197 - val_accuracy: 0.9959\n",
      "Epoch 343/400\n",
      "69/92 [=====================>........] - ETA: 0s - loss: 0.0219 - accuracy: 0.9951\n",
      "Epoch 343: val_loss did not improve from 0.01954\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9951 - val_loss: 0.0198 - val_accuracy: 0.9961\n",
      "Epoch 344/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0216 - accuracy: 0.9950\n",
      "Epoch 344: val_loss did not improve from 0.01954\n",
      "92/92 [==============================] - 0s 999us/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.0195 - val_accuracy: 0.9964\n",
      "Epoch 345/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0218 - accuracy: 0.9949\n",
      "Epoch 345: val_loss improved from 0.01954 to 0.01951, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.0195 - val_accuracy: 0.9964\n",
      "Epoch 346/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0217 - accuracy: 0.9951\n",
      "Epoch 346: val_loss did not improve from 0.01951\n",
      "92/92 [==============================] - 0s 928us/step - loss: 0.0217 - accuracy: 0.9950 - val_loss: 0.0196 - val_accuracy: 0.9959\n",
      "Epoch 347/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0222 - accuracy: 0.9946\n",
      "Epoch 347: val_loss improved from 0.01951 to 0.01950, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9950 - val_loss: 0.0195 - val_accuracy: 0.9961\n",
      "Epoch 348/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0216 - accuracy: 0.9951\n",
      "Epoch 348: val_loss did not improve from 0.01950\n",
      "92/92 [==============================] - 0s 937us/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.0197 - val_accuracy: 0.9961\n",
      "Epoch 349/400\n",
      "84/92 [==========================>...] - ETA: 0s - loss: 0.0215 - accuracy: 0.9951\n",
      "Epoch 349: val_loss did not improve from 0.01950\n",
      "92/92 [==============================] - 0s 957us/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.0195 - val_accuracy: 0.9961\n",
      "Epoch 350/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.0214 - accuracy: 0.9953\n",
      "Epoch 350: val_loss improved from 0.01950 to 0.01925, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.0192 - val_accuracy: 0.9966\n",
      "Epoch 351/400\n",
      "71/92 [======================>.......] - ETA: 0s - loss: 0.0217 - accuracy: 0.9949\n",
      "Epoch 351: val_loss did not improve from 0.01925\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9951 - val_loss: 0.0195 - val_accuracy: 0.9964\n",
      "Epoch 352/400\n",
      "64/92 [===================>..........] - ETA: 0s - loss: 0.0216 - accuracy: 0.9949\n",
      "Epoch 352: val_loss did not improve from 0.01925\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.0198 - val_accuracy: 0.9957\n",
      "Epoch 353/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0217 - accuracy: 0.9953\n",
      "Epoch 353: val_loss did not improve from 0.01925\n",
      "92/92 [==============================] - 0s 915us/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.0194 - val_accuracy: 0.9964\n",
      "Epoch 354/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0213 - accuracy: 0.9954\n",
      "Epoch 354: val_loss did not improve from 0.01925\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.0196 - val_accuracy: 0.9966\n",
      "Epoch 355/400\n",
      "73/92 [======================>.......] - ETA: 0s - loss: 0.0212 - accuracy: 0.9955\n",
      "Epoch 355: val_loss improved from 0.01925 to 0.01916, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.0192 - val_accuracy: 0.9964\n",
      "Epoch 356/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0212 - accuracy: 0.9954\n",
      "Epoch 356: val_loss did not improve from 0.01916\n",
      "92/92 [==============================] - 0s 992us/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.0198 - val_accuracy: 0.9954\n",
      "Epoch 357/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0214 - accuracy: 0.9950\n",
      "Epoch 357: val_loss did not improve from 0.01916\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 0.0193 - val_accuracy: 0.9961\n",
      "Epoch 358/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0212 - accuracy: 0.9948\n",
      "Epoch 358: val_loss improved from 0.01916 to 0.01900, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9949 - val_loss: 0.0190 - val_accuracy: 0.9969\n",
      "Epoch 359/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0214 - accuracy: 0.9953\n",
      "Epoch 359: val_loss did not improve from 0.01900\n",
      "92/92 [==============================] - 0s 968us/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.0192 - val_accuracy: 0.9964\n",
      "Epoch 360/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0211 - accuracy: 0.9954\n",
      "Epoch 360: val_loss did not improve from 0.01900\n",
      "92/92 [==============================] - 0s 944us/step - loss: 0.0213 - accuracy: 0.9950 - val_loss: 0.0191 - val_accuracy: 0.9969\n",
      "Epoch 361/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0217 - accuracy: 0.9949\n",
      "Epoch 361: val_loss did not improve from 0.01900\n",
      "92/92 [==============================] - 0s 941us/step - loss: 0.0213 - accuracy: 0.9950 - val_loss: 0.0191 - val_accuracy: 0.9964\n",
      "Epoch 362/400\n",
      "83/92 [==========================>...] - ETA: 0s - loss: 0.0215 - accuracy: 0.9950\n",
      "Epoch 362: val_loss did not improve from 0.01900\n",
      "92/92 [==============================] - 0s 930us/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.0192 - val_accuracy: 0.9959\n",
      "Epoch 363/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0217 - accuracy: 0.9949\n",
      "Epoch 363: val_loss did not improve from 0.01900\n",
      "92/92 [==============================] - 0s 952us/step - loss: 0.0212 - accuracy: 0.9952 - val_loss: 0.0191 - val_accuracy: 0.9961\n",
      "Epoch 364/400\n",
      "85/92 [==========================>...] - ETA: 0s - loss: 0.0211 - accuracy: 0.9951\n",
      "Epoch 364: val_loss improved from 0.01900 to 0.01899, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 0.0190 - val_accuracy: 0.9964\n",
      "Epoch 365/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0217 - accuracy: 0.9948\n",
      "Epoch 365: val_loss improved from 0.01899 to 0.01886, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 0.0189 - val_accuracy: 0.9966\n",
      "Epoch 366/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0209 - accuracy: 0.9955\n",
      "Epoch 366: val_loss did not improve from 0.01886\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9953 - val_loss: 0.0192 - val_accuracy: 0.9961\n",
      "Epoch 367/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0210 - accuracy: 0.9949\n",
      "Epoch 367: val_loss did not improve from 0.01886\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 0.0195 - val_accuracy: 0.9952\n",
      "Epoch 368/400\n",
      "74/92 [=======================>......] - ETA: 0s - loss: 0.0210 - accuracy: 0.9955\n",
      "Epoch 368: val_loss did not improve from 0.01886\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9955 - val_loss: 0.0189 - val_accuracy: 0.9959\n",
      "Epoch 369/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0207 - accuracy: 0.9956\n",
      "Epoch 369: val_loss improved from 0.01886 to 0.01864, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9954 - val_loss: 0.0186 - val_accuracy: 0.9969\n",
      "Epoch 370/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0211 - accuracy: 0.9951\n",
      "Epoch 370: val_loss improved from 0.01864 to 0.01862, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9952 - val_loss: 0.0186 - val_accuracy: 0.9971\n",
      "Epoch 371/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.0209 - accuracy: 0.9950\n",
      "Epoch 371: val_loss did not improve from 0.01862\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9952 - val_loss: 0.0188 - val_accuracy: 0.9966\n",
      "Epoch 372/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0209 - accuracy: 0.9954\n",
      "Epoch 372: val_loss improved from 0.01862 to 0.01852, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9954 - val_loss: 0.0185 - val_accuracy: 0.9966\n",
      "Epoch 373/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0209 - accuracy: 0.9954\n",
      "Epoch 373: val_loss did not improve from 0.01852\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9952 - val_loss: 0.0187 - val_accuracy: 0.9964\n",
      "Epoch 374/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0210 - accuracy: 0.9954\n",
      "Epoch 374: val_loss did not improve from 0.01852\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.0186 - val_accuracy: 0.9966\n",
      "Epoch 375/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0205 - accuracy: 0.9954\n",
      "Epoch 375: val_loss did not improve from 0.01852\n",
      "92/92 [==============================] - 0s 959us/step - loss: 0.0208 - accuracy: 0.9953 - val_loss: 0.0188 - val_accuracy: 0.9964\n",
      "Epoch 376/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.0206 - accuracy: 0.9956\n",
      "Epoch 376: val_loss improved from 0.01852 to 0.01849, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9953 - val_loss: 0.0185 - val_accuracy: 0.9966\n",
      "Epoch 377/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0211 - accuracy: 0.9955\n",
      "Epoch 377: val_loss did not improve from 0.01849\n",
      "92/92 [==============================] - 0s 948us/step - loss: 0.0207 - accuracy: 0.9956 - val_loss: 0.0187 - val_accuracy: 0.9966\n",
      "Epoch 378/400\n",
      "75/92 [=======================>......] - ETA: 0s - loss: 0.0209 - accuracy: 0.9953\n",
      "Epoch 378: val_loss did not improve from 0.01849\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9952 - val_loss: 0.0187 - val_accuracy: 0.9964\n",
      "Epoch 379/400\n",
      "65/92 [====================>.........] - ETA: 0s - loss: 0.0206 - accuracy: 0.9956\n",
      "Epoch 379: val_loss improved from 0.01849 to 0.01830, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9954 - val_loss: 0.0183 - val_accuracy: 0.9971\n",
      "Epoch 380/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0206 - accuracy: 0.9951\n",
      "Epoch 380: val_loss did not improve from 0.01830\n",
      "92/92 [==============================] - 0s 935us/step - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.0183 - val_accuracy: 0.9969\n",
      "Epoch 381/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0209 - accuracy: 0.9951\n",
      "Epoch 381: val_loss did not improve from 0.01830\n",
      "92/92 [==============================] - 0s 955us/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.0185 - val_accuracy: 0.9964\n",
      "Epoch 382/400\n",
      "85/92 [==========================>...] - ETA: 0s - loss: 0.0204 - accuracy: 0.9958\n",
      "Epoch 382: val_loss did not improve from 0.01830\n",
      "92/92 [==============================] - 0s 909us/step - loss: 0.0206 - accuracy: 0.9956 - val_loss: 0.0186 - val_accuracy: 0.9964\n",
      "Epoch 383/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0203 - accuracy: 0.9954\n",
      "Epoch 383: val_loss did not improve from 0.01830\n",
      "92/92 [==============================] - 0s 966us/step - loss: 0.0206 - accuracy: 0.9954 - val_loss: 0.0184 - val_accuracy: 0.9966\n",
      "Epoch 384/400\n",
      "82/92 [=========================>....] - ETA: 0s - loss: 0.0207 - accuracy: 0.9956\n",
      "Epoch 384: val_loss improved from 0.01830 to 0.01826, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9955 - val_loss: 0.0183 - val_accuracy: 0.9971\n",
      "Epoch 385/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0203 - accuracy: 0.9954\n",
      "Epoch 385: val_loss did not improve from 0.01826\n",
      "92/92 [==============================] - 0s 983us/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.0185 - val_accuracy: 0.9961\n",
      "Epoch 386/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0202 - accuracy: 0.9958\n",
      "Epoch 386: val_loss did not improve from 0.01826\n",
      "92/92 [==============================] - 0s 965us/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 0.0184 - val_accuracy: 0.9964\n",
      "Epoch 387/400\n",
      "80/92 [=========================>....] - ETA: 0s - loss: 0.0204 - accuracy: 0.9953\n",
      "Epoch 387: val_loss did not improve from 0.01826\n",
      "92/92 [==============================] - 0s 959us/step - loss: 0.0205 - accuracy: 0.9952 - val_loss: 0.0185 - val_accuracy: 0.9964\n",
      "Epoch 388/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0204 - accuracy: 0.9951\n",
      "Epoch 388: val_loss did not improve from 0.01826\n",
      "92/92 [==============================] - 0s 980us/step - loss: 0.0204 - accuracy: 0.9953 - val_loss: 0.0186 - val_accuracy: 0.9954\n",
      "Epoch 389/400\n",
      "68/92 [=====================>........] - ETA: 0s - loss: 0.0199 - accuracy: 0.9956\n",
      "Epoch 389: val_loss improved from 0.01826 to 0.01819, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9948 - val_loss: 0.0182 - val_accuracy: 0.9957\n",
      "Epoch 390/400\n",
      "77/92 [========================>.....] - ETA: 0s - loss: 0.0204 - accuracy: 0.9956\n",
      "Epoch 390: val_loss did not improve from 0.01819\n",
      "92/92 [==============================] - 0s 945us/step - loss: 0.0203 - accuracy: 0.9954 - val_loss: 0.0183 - val_accuracy: 0.9957\n",
      "Epoch 391/400\n",
      "76/92 [=======================>......] - ETA: 0s - loss: 0.0203 - accuracy: 0.9949\n",
      "Epoch 391: val_loss did not improve from 0.01819\n",
      "92/92 [==============================] - 0s 964us/step - loss: 0.0204 - accuracy: 0.9950 - val_loss: 0.0182 - val_accuracy: 0.9964\n",
      "Epoch 392/400\n",
      "79/92 [========================>.....] - ETA: 0s - loss: 0.0205 - accuracy: 0.9954\n",
      "Epoch 392: val_loss improved from 0.01819 to 0.01793, saving model to WENO3//Details\\best_modelHn_7nonsmoothdata.hdf5\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9956 - val_loss: 0.0179 - val_accuracy: 0.9966\n",
      "Epoch 393/400\n",
      "69/92 [=====================>........] - ETA: 0s - loss: 0.0204 - accuracy: 0.9956\n",
      "Epoch 393: val_loss did not improve from 0.01793\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.0183 - val_accuracy: 0.9966\n",
      "Epoch 394/400\n",
      "84/92 [==========================>...] - ETA: 0s - loss: 0.0201 - accuracy: 0.9954\n",
      "Epoch 394: val_loss did not improve from 0.01793\n",
      "92/92 [==============================] - 0s 906us/step - loss: 0.0202 - accuracy: 0.9955 - val_loss: 0.0182 - val_accuracy: 0.9964\n",
      "Epoch 395/400\n",
      "72/92 [======================>.......] - ETA: 0s - loss: 0.0198 - accuracy: 0.9954\n",
      "Epoch 395: val_loss did not improve from 0.01793\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9956 - val_loss: 0.0181 - val_accuracy: 0.9964\n",
      "Epoch 396/400\n",
      "70/92 [=====================>........] - ETA: 0s - loss: 0.0202 - accuracy: 0.9953\n",
      "Epoch 396: val_loss did not improve from 0.01793\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9955 - val_loss: 0.0183 - val_accuracy: 0.9961\n",
      "Epoch 397/400\n",
      "67/92 [====================>.........] - ETA: 0s - loss: 0.0201 - accuracy: 0.9956\n",
      "Epoch 397: val_loss did not improve from 0.01793\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9955 - val_loss: 0.0180 - val_accuracy: 0.9964\n",
      "Epoch 398/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0202 - accuracy: 0.9954\n",
      "Epoch 398: val_loss did not improve from 0.01793\n",
      "92/92 [==============================] - 0s 991us/step - loss: 0.0200 - accuracy: 0.9956 - val_loss: 0.0180 - val_accuracy: 0.9961\n",
      "Epoch 399/400\n",
      "56/92 [=================>............] - ETA: 0s - loss: 0.0201 - accuracy: 0.9960\n",
      "Epoch 399: val_loss did not improve from 0.01793\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9957 - val_loss: 0.0181 - val_accuracy: 0.9964\n",
      "Epoch 400/400\n",
      "78/92 [========================>.....] - ETA: 0s - loss: 0.0196 - accuracy: 0.9956\n",
      "Epoch 400: val_loss did not improve from 0.01793\n",
      "92/92 [==============================] - 0s 975us/step - loss: 0.0200 - accuracy: 0.9955 - val_loss: 0.0181 - val_accuracy: 0.9966\n",
      "name weight WENO3//model/trained_weights_Hn_7nonsmoothdata.mat\n",
      "153/153 [==============================] - 0s 479us/step\n",
      "here\n",
      "Accuracy  : 0.9954871794871795\n",
      "Precision : 0.9954912410722048\n",
      "f1Score : 0.9954847198151965\n",
      "[[1141   13    0]\n",
      " [   6 2820    0]\n",
      " [   0    3  892]]\n",
      "train history is strored in WENO3/History/history-Hn_7nonsmoothdata.dat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is union_data\n",
      "Data file being used is: WENO3/train_input_union_data.csv\n",
      "In load data (64420, 4) (64420,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 35        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59 (472.00 Byte)\n",
      "Trainable params: 59 (472.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.9798 - accuracy: 0.6231\n",
      "Epoch 1: val_loss improved from inf to 0.79301, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 1s 1ms/step - loss: 0.9550 - accuracy: 0.6428 - val_loss: 0.7930 - val_accuracy: 0.7670\n",
      "Epoch 2/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.7480 - accuracy: 0.7658\n",
      "Epoch 2: val_loss improved from 0.79301 to 0.69619, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 897us/step - loss: 0.7421 - accuracy: 0.7660 - val_loss: 0.6962 - val_accuracy: 0.7704\n",
      "Epoch 3/400\n",
      "  1/182 [..............................] - ETA: 0s - loss: 0.7196 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\xai\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/182 [==========================>...] - ETA: 0s - loss: 0.6802 - accuracy: 0.7630\n",
      "Epoch 3: val_loss improved from 0.69619 to 0.63852, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 896us/step - loss: 0.6770 - accuracy: 0.7637 - val_loss: 0.6385 - val_accuracy: 0.7701\n",
      "Epoch 4/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.6317 - accuracy: 0.7630\n",
      "Epoch 4: val_loss improved from 0.63852 to 0.59669, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 920us/step - loss: 0.6299 - accuracy: 0.7630 - val_loss: 0.5967 - val_accuracy: 0.7686\n",
      "Epoch 5/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.5967 - accuracy: 0.7625\n",
      "Epoch 5: val_loss improved from 0.59669 to 0.56049, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 911us/step - loss: 0.5929 - accuracy: 0.7634 - val_loss: 0.5605 - val_accuracy: 0.7686\n",
      "Epoch 6/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.5602 - accuracy: 0.7650\n",
      "Epoch 6: val_loss improved from 0.56049 to 0.52765, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 896us/step - loss: 0.5586 - accuracy: 0.7649 - val_loss: 0.5277 - val_accuracy: 0.7706\n",
      "Epoch 7/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.5297 - accuracy: 0.7666\n",
      "Epoch 7: val_loss improved from 0.52765 to 0.49744, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 888us/step - loss: 0.5279 - accuracy: 0.7671 - val_loss: 0.4974 - val_accuracy: 0.7764\n",
      "Epoch 8/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.5007 - accuracy: 0.7722\n",
      "Epoch 8: val_loss improved from 0.49744 to 0.47288, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 942us/step - loss: 0.4994 - accuracy: 0.7717 - val_loss: 0.4729 - val_accuracy: 0.7790\n",
      "Epoch 9/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.4780 - accuracy: 0.7740\n",
      "Epoch 9: val_loss improved from 0.47288 to 0.45514, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 882us/step - loss: 0.4788 - accuracy: 0.7734 - val_loss: 0.4551 - val_accuracy: 0.7807\n",
      "Epoch 10/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.4609 - accuracy: 0.7733\n",
      "Epoch 10: val_loss improved from 0.45514 to 0.44084, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 877us/step - loss: 0.4625 - accuracy: 0.7710 - val_loss: 0.4408 - val_accuracy: 0.7745\n",
      "Epoch 11/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.4498 - accuracy: 0.7713\n",
      "Epoch 11: val_loss improved from 0.44084 to 0.42726, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 903us/step - loss: 0.4485 - accuracy: 0.7717 - val_loss: 0.4273 - val_accuracy: 0.7754\n",
      "Epoch 12/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.4375 - accuracy: 0.7848\n",
      "Epoch 12: val_loss improved from 0.42726 to 0.41510, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 908us/step - loss: 0.4358 - accuracy: 0.7851 - val_loss: 0.4151 - val_accuracy: 0.7911\n",
      "Epoch 13/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.4254 - accuracy: 0.7922\n",
      "Epoch 13: val_loss improved from 0.41510 to 0.40445, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 882us/step - loss: 0.4241 - accuracy: 0.7927 - val_loss: 0.4045 - val_accuracy: 0.8067\n",
      "Epoch 14/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.4112 - accuracy: 0.8079\n",
      "Epoch 14: val_loss improved from 0.40445 to 0.39222, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 899us/step - loss: 0.4122 - accuracy: 0.8084 - val_loss: 0.3922 - val_accuracy: 0.8272\n",
      "Epoch 15/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.4025 - accuracy: 0.8180\n",
      "Epoch 15: val_loss improved from 0.39222 to 0.38079, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 910us/step - loss: 0.4006 - accuracy: 0.8183 - val_loss: 0.3808 - val_accuracy: 0.8313\n",
      "Epoch 16/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.3895 - accuracy: 0.8217\n",
      "Epoch 16: val_loss improved from 0.38079 to 0.36923, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 877us/step - loss: 0.3888 - accuracy: 0.8229 - val_loss: 0.3692 - val_accuracy: 0.8579\n",
      "Epoch 17/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.3787 - accuracy: 0.8457\n",
      "Epoch 17: val_loss improved from 0.36923 to 0.35715, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 941us/step - loss: 0.3765 - accuracy: 0.8462 - val_loss: 0.3571 - val_accuracy: 0.8548\n",
      "Epoch 18/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.3623 - accuracy: 0.8506\n",
      "Epoch 18: val_loss improved from 0.35715 to 0.33940, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 882us/step - loss: 0.3630 - accuracy: 0.8494 - val_loss: 0.3394 - val_accuracy: 0.8576\n",
      "Epoch 19/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.3427 - accuracy: 0.8645\n",
      "Epoch 19: val_loss improved from 0.33940 to 0.31664, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 910us/step - loss: 0.3408 - accuracy: 0.8654 - val_loss: 0.3166 - val_accuracy: 0.9014\n",
      "Epoch 20/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.3212 - accuracy: 0.8929\n",
      "Epoch 20: val_loss improved from 0.31664 to 0.29683, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 882us/step - loss: 0.3202 - accuracy: 0.8930 - val_loss: 0.2968 - val_accuracy: 0.9145\n",
      "Epoch 21/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.3030 - accuracy: 0.9090\n",
      "Epoch 21: val_loss improved from 0.29683 to 0.28042, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 911us/step - loss: 0.3020 - accuracy: 0.9094 - val_loss: 0.2804 - val_accuracy: 0.9242\n",
      "Epoch 22/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.2880 - accuracy: 0.9194\n",
      "Epoch 22: val_loss improved from 0.28042 to 0.26833, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 877us/step - loss: 0.2874 - accuracy: 0.9198 - val_loss: 0.2683 - val_accuracy: 0.9306\n",
      "Epoch 23/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.2773 - accuracy: 0.9236\n",
      "Epoch 23: val_loss improved from 0.26833 to 0.25708, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 898us/step - loss: 0.2753 - accuracy: 0.9244 - val_loss: 0.2571 - val_accuracy: 0.9358\n",
      "Epoch 24/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.2651 - accuracy: 0.9272\n",
      "Epoch 24: val_loss improved from 0.25708 to 0.24705, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 918us/step - loss: 0.2643 - accuracy: 0.9277 - val_loss: 0.2470 - val_accuracy: 0.9378\n",
      "Epoch 25/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.2555 - accuracy: 0.9307\n",
      "Epoch 25: val_loss improved from 0.24705 to 0.23806, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 897us/step - loss: 0.2546 - accuracy: 0.9308 - val_loss: 0.2381 - val_accuracy: 0.9413\n",
      "Epoch 26/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.2470 - accuracy: 0.9330\n",
      "Epoch 26: val_loss improved from 0.23806 to 0.23040, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 903us/step - loss: 0.2459 - accuracy: 0.9333 - val_loss: 0.2304 - val_accuracy: 0.9438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/400\n",
      "126/182 [===================>..........] - ETA: 0s - loss: 0.2387 - accuracy: 0.9365\n",
      "Epoch 27: val_loss improved from 0.23040 to 0.22315, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.9364 - val_loss: 0.2232 - val_accuracy: 0.9441\n",
      "Epoch 28/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.2321 - accuracy: 0.9383\n",
      "Epoch 28: val_loss improved from 0.22315 to 0.21687, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 959us/step - loss: 0.2314 - accuracy: 0.9384 - val_loss: 0.2169 - val_accuracy: 0.9455\n",
      "Epoch 29/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.2261 - accuracy: 0.9395\n",
      "Epoch 29: val_loss improved from 0.21687 to 0.21144, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 965us/step - loss: 0.2254 - accuracy: 0.9393 - val_loss: 0.2114 - val_accuracy: 0.9461\n",
      "Epoch 30/400\n",
      "146/182 [=======================>......] - ETA: 0s - loss: 0.2202 - accuracy: 0.9394\n",
      "Epoch 30: val_loss improved from 0.21144 to 0.20611, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9400 - val_loss: 0.2061 - val_accuracy: 0.9475\n",
      "Epoch 31/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.2160 - accuracy: 0.9411\n",
      "Epoch 31: val_loss improved from 0.20611 to 0.20148, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 911us/step - loss: 0.2149 - accuracy: 0.9412 - val_loss: 0.2015 - val_accuracy: 0.9484\n",
      "Epoch 32/400\n",
      "153/182 [========================>.....] - ETA: 0s - loss: 0.2121 - accuracy: 0.9415\n",
      "Epoch 32: val_loss improved from 0.20148 to 0.19759, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 931us/step - loss: 0.2106 - accuracy: 0.9420 - val_loss: 0.1976 - val_accuracy: 0.9485\n",
      "Epoch 33/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.2060 - accuracy: 0.9429\n",
      "Epoch 33: val_loss improved from 0.19759 to 0.19394, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 906us/step - loss: 0.2066 - accuracy: 0.9427 - val_loss: 0.1939 - val_accuracy: 0.9498\n",
      "Epoch 34/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.2034 - accuracy: 0.9430\n",
      "Epoch 34: val_loss improved from 0.19394 to 0.19111, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 878us/step - loss: 0.2030 - accuracy: 0.9435 - val_loss: 0.1911 - val_accuracy: 0.9509\n",
      "Epoch 35/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.2000 - accuracy: 0.9448\n",
      "Epoch 35: val_loss improved from 0.19111 to 0.18786, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 944us/step - loss: 0.1998 - accuracy: 0.9446 - val_loss: 0.1879 - val_accuracy: 0.9513\n",
      "Epoch 36/400\n",
      "144/182 [======================>.......] - ETA: 0s - loss: 0.1942 - accuracy: 0.9465\n",
      "Epoch 36: val_loss improved from 0.18786 to 0.18553, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 980us/step - loss: 0.1969 - accuracy: 0.9451 - val_loss: 0.1855 - val_accuracy: 0.9511\n",
      "Epoch 37/400\n",
      "138/182 [=====================>........] - ETA: 0s - loss: 0.1919 - accuracy: 0.9468\n",
      "Epoch 37: val_loss improved from 0.18553 to 0.18220, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 952us/step - loss: 0.1942 - accuracy: 0.9460 - val_loss: 0.1822 - val_accuracy: 0.9519\n",
      "Epoch 38/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.1918 - accuracy: 0.9464\n",
      "Epoch 38: val_loss improved from 0.18220 to 0.18005, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 912us/step - loss: 0.1917 - accuracy: 0.9463 - val_loss: 0.1800 - val_accuracy: 0.9526\n",
      "Epoch 39/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.1899 - accuracy: 0.9467\n",
      "Epoch 39: val_loss improved from 0.18005 to 0.17795, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 918us/step - loss: 0.1895 - accuracy: 0.9470 - val_loss: 0.1779 - val_accuracy: 0.9528\n",
      "Epoch 40/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.1883 - accuracy: 0.9474\n",
      "Epoch 40: val_loss improved from 0.17795 to 0.17612, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 930us/step - loss: 0.1872 - accuracy: 0.9476 - val_loss: 0.1761 - val_accuracy: 0.9535\n",
      "Epoch 41/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.1860 - accuracy: 0.9476\n",
      "Epoch 41: val_loss improved from 0.17612 to 0.17403, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 937us/step - loss: 0.1851 - accuracy: 0.9481 - val_loss: 0.1740 - val_accuracy: 0.9541\n",
      "Epoch 42/400\n",
      "144/182 [======================>.......] - ETA: 0s - loss: 0.1827 - accuracy: 0.9482\n",
      "Epoch 42: val_loss improved from 0.17403 to 0.17174, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 967us/step - loss: 0.1829 - accuracy: 0.9485 - val_loss: 0.1717 - val_accuracy: 0.9545\n",
      "Epoch 43/400\n",
      "151/182 [=======================>......] - ETA: 0s - loss: 0.1821 - accuracy: 0.9481\n",
      "Epoch 43: val_loss improved from 0.17174 to 0.16976, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 946us/step - loss: 0.1807 - accuracy: 0.9491 - val_loss: 0.1698 - val_accuracy: 0.9551\n",
      "Epoch 44/400\n",
      "147/182 [=======================>......] - ETA: 0s - loss: 0.1784 - accuracy: 0.9493\n",
      "Epoch 44: val_loss improved from 0.16976 to 0.16774, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 964us/step - loss: 0.1786 - accuracy: 0.9496 - val_loss: 0.1677 - val_accuracy: 0.9559\n",
      "Epoch 45/400\n",
      "151/182 [=======================>......] - ETA: 0s - loss: 0.1786 - accuracy: 0.9500\n",
      "Epoch 45: val_loss improved from 0.16774 to 0.16624, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 940us/step - loss: 0.1768 - accuracy: 0.9501 - val_loss: 0.1662 - val_accuracy: 0.9563\n",
      "Epoch 46/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.1756 - accuracy: 0.9504\n",
      "Epoch 46: val_loss improved from 0.16624 to 0.16419, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 954us/step - loss: 0.1749 - accuracy: 0.9504 - val_loss: 0.1642 - val_accuracy: 0.9563\n",
      "Epoch 47/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.1732 - accuracy: 0.9511\n",
      "Epoch 47: val_loss improved from 0.16419 to 0.16232, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 946us/step - loss: 0.1729 - accuracy: 0.9509 - val_loss: 0.1623 - val_accuracy: 0.9579\n",
      "Epoch 48/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.1734 - accuracy: 0.9502\n",
      "Epoch 48: val_loss improved from 0.16232 to 0.16080, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 933us/step - loss: 0.1710 - accuracy: 0.9512 - val_loss: 0.1608 - val_accuracy: 0.9571\n",
      "Epoch 49/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.1676 - accuracy: 0.9518\n",
      "Epoch 49: val_loss improved from 0.16080 to 0.15856, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 952us/step - loss: 0.1690 - accuracy: 0.9515 - val_loss: 0.1586 - val_accuracy: 0.9584\n",
      "Epoch 50/400\n",
      "151/182 [=======================>......] - ETA: 0s - loss: 0.1673 - accuracy: 0.9527\n",
      "Epoch 50: val_loss improved from 0.15856 to 0.15674, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 974us/step - loss: 0.1670 - accuracy: 0.9523 - val_loss: 0.1567 - val_accuracy: 0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.1668 - accuracy: 0.9524\n",
      "Epoch 51: val_loss improved from 0.15674 to 0.15508, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 929us/step - loss: 0.1649 - accuracy: 0.9532 - val_loss: 0.1551 - val_accuracy: 0.9593\n",
      "Epoch 52/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.1632 - accuracy: 0.9531\n",
      "Epoch 52: val_loss improved from 0.15508 to 0.15171, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 931us/step - loss: 0.1620 - accuracy: 0.9538 - val_loss: 0.1517 - val_accuracy: 0.9599\n",
      "Epoch 53/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.1591 - accuracy: 0.9546\n",
      "Epoch 53: val_loss improved from 0.15171 to 0.14783, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 977us/step - loss: 0.1583 - accuracy: 0.9545 - val_loss: 0.1478 - val_accuracy: 0.9606\n",
      "Epoch 54/400\n",
      "137/182 [=====================>........] - ETA: 0s - loss: 0.1534 - accuracy: 0.9552\n",
      "Epoch 54: val_loss improved from 0.14783 to 0.14527, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9556 - val_loss: 0.1453 - val_accuracy: 0.9654\n",
      "Epoch 55/400\n",
      "141/182 [======================>.......] - ETA: 0s - loss: 0.1520 - accuracy: 0.9618\n",
      "Epoch 55: val_loss improved from 0.14527 to 0.14205, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9617 - val_loss: 0.1421 - val_accuracy: 0.9655\n",
      "Epoch 56/400\n",
      "139/182 [=====================>........] - ETA: 0s - loss: 0.1439 - accuracy: 0.9629\n",
      "Epoch 56: val_loss improved from 0.14205 to 0.13725, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9624 - val_loss: 0.1372 - val_accuracy: 0.9668\n",
      "Epoch 57/400\n",
      "145/182 [======================>.......] - ETA: 0s - loss: 0.1454 - accuracy: 0.9626\n",
      "Epoch 57: val_loss improved from 0.13725 to 0.13344, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 997us/step - loss: 0.1420 - accuracy: 0.9634 - val_loss: 0.1334 - val_accuracy: 0.9674\n",
      "Epoch 58/400\n",
      "146/182 [=======================>......] - ETA: 0s - loss: 0.1390 - accuracy: 0.9641\n",
      "Epoch 58: val_loss improved from 0.13344 to 0.13008, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 990us/step - loss: 0.1378 - accuracy: 0.9648 - val_loss: 0.1301 - val_accuracy: 0.9671\n",
      "Epoch 59/400\n",
      "146/182 [=======================>......] - ETA: 0s - loss: 0.1325 - accuracy: 0.9658\n",
      "Epoch 59: val_loss improved from 0.13008 to 0.12627, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 982us/step - loss: 0.1335 - accuracy: 0.9657 - val_loss: 0.1263 - val_accuracy: 0.9685\n",
      "Epoch 60/400\n",
      "153/182 [========================>.....] - ETA: 0s - loss: 0.1300 - accuracy: 0.9667\n",
      "Epoch 60: val_loss improved from 0.12627 to 0.12137, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 944us/step - loss: 0.1293 - accuracy: 0.9667 - val_loss: 0.1214 - val_accuracy: 0.9693\n",
      "Epoch 61/400\n",
      "149/182 [=======================>......] - ETA: 0s - loss: 0.1266 - accuracy: 0.9670\n",
      "Epoch 61: val_loss improved from 0.12137 to 0.11782, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 940us/step - loss: 0.1254 - accuracy: 0.9677 - val_loss: 0.1178 - val_accuracy: 0.9697\n",
      "Epoch 62/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.1218 - accuracy: 0.9683\n",
      "Epoch 62: val_loss improved from 0.11782 to 0.11423, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 874us/step - loss: 0.1217 - accuracy: 0.9682 - val_loss: 0.1142 - val_accuracy: 0.9710\n",
      "Epoch 63/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.1190 - accuracy: 0.9685\n",
      "Epoch 63: val_loss improved from 0.11423 to 0.11117, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 908us/step - loss: 0.1183 - accuracy: 0.9690 - val_loss: 0.1112 - val_accuracy: 0.9731\n",
      "Epoch 64/400\n",
      "170/182 [===========================>..] - ETA: 0s - loss: 0.1144 - accuracy: 0.9702\n",
      "Epoch 64: val_loss improved from 0.11117 to 0.10756, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 866us/step - loss: 0.1149 - accuracy: 0.9699 - val_loss: 0.1076 - val_accuracy: 0.9735\n",
      "Epoch 65/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.1123 - accuracy: 0.9705\n",
      "Epoch 65: val_loss improved from 0.10756 to 0.10458, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 975us/step - loss: 0.1118 - accuracy: 0.9705 - val_loss: 0.1046 - val_accuracy: 0.9737\n",
      "Epoch 66/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.1086 - accuracy: 0.9709\n",
      "Epoch 66: val_loss improved from 0.10458 to 0.10249, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 921us/step - loss: 0.1089 - accuracy: 0.9710 - val_loss: 0.1025 - val_accuracy: 0.9743\n",
      "Epoch 67/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.1072 - accuracy: 0.9717\n",
      "Epoch 67: val_loss improved from 0.10249 to 0.10082, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 919us/step - loss: 0.1065 - accuracy: 0.9718 - val_loss: 0.1008 - val_accuracy: 0.9754\n",
      "Epoch 68/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.1027 - accuracy: 0.9733\n",
      "Epoch 68: val_loss improved from 0.10082 to 0.09875, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 888us/step - loss: 0.1044 - accuracy: 0.9726 - val_loss: 0.0987 - val_accuracy: 0.9753\n",
      "Epoch 69/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.1026 - accuracy: 0.9726\n",
      "Epoch 69: val_loss improved from 0.09875 to 0.09707, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 917us/step - loss: 0.1026 - accuracy: 0.9728 - val_loss: 0.0971 - val_accuracy: 0.9760\n",
      "Epoch 70/400\n",
      "165/182 [==========================>...] - ETA: 0s - loss: 0.1005 - accuracy: 0.9733\n",
      "Epoch 70: val_loss improved from 0.09707 to 0.09514, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 866us/step - loss: 0.1008 - accuracy: 0.9732 - val_loss: 0.0951 - val_accuracy: 0.9760\n",
      "Epoch 71/400\n",
      "165/182 [==========================>...] - ETA: 0s - loss: 0.0979 - accuracy: 0.9740\n",
      "Epoch 71: val_loss improved from 0.09514 to 0.09398, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 869us/step - loss: 0.0994 - accuracy: 0.9734 - val_loss: 0.0940 - val_accuracy: 0.9760\n",
      "Epoch 72/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0973 - accuracy: 0.9739\n",
      "Epoch 72: val_loss improved from 0.09398 to 0.09323, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 914us/step - loss: 0.0979 - accuracy: 0.9736 - val_loss: 0.0932 - val_accuracy: 0.9767\n",
      "Epoch 73/400\n",
      "143/182 [======================>.......] - ETA: 0s - loss: 0.0970 - accuracy: 0.9737\n",
      "Epoch 73: val_loss improved from 0.09323 to 0.09206, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9737 - val_loss: 0.0921 - val_accuracy: 0.9766\n",
      "Epoch 74/400\n",
      "146/182 [=======================>......] - ETA: 0s - loss: 0.0945 - accuracy: 0.9746\n",
      "Epoch 74: val_loss improved from 0.09206 to 0.09122, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 994us/step - loss: 0.0952 - accuracy: 0.9741 - val_loss: 0.0912 - val_accuracy: 0.9774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/400\n",
      "148/182 [=======================>......] - ETA: 0s - loss: 0.0944 - accuracy: 0.9742\n",
      "Epoch 75: val_loss improved from 0.09122 to 0.08945, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 986us/step - loss: 0.0942 - accuracy: 0.9743 - val_loss: 0.0894 - val_accuracy: 0.9766\n",
      "Epoch 76/400\n",
      "157/182 [========================>.....] - ETA: 0s - loss: 0.0941 - accuracy: 0.9745\n",
      "Epoch 76: val_loss improved from 0.08945 to 0.08777, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 915us/step - loss: 0.0930 - accuracy: 0.9746 - val_loss: 0.0878 - val_accuracy: 0.9772\n",
      "Epoch 77/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0915 - accuracy: 0.9747\n",
      "Epoch 77: val_loss improved from 0.08777 to 0.08760, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 982us/step - loss: 0.0919 - accuracy: 0.9744 - val_loss: 0.0876 - val_accuracy: 0.9776\n",
      "Epoch 78/400\n",
      "153/182 [========================>.....] - ETA: 0s - loss: 0.0910 - accuracy: 0.9752\n",
      "Epoch 78: val_loss improved from 0.08760 to 0.08607, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 914us/step - loss: 0.0909 - accuracy: 0.9751 - val_loss: 0.0861 - val_accuracy: 0.9772\n",
      "Epoch 79/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0897 - accuracy: 0.9751\n",
      "Epoch 79: val_loss improved from 0.08607 to 0.08450, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 869us/step - loss: 0.0900 - accuracy: 0.9751 - val_loss: 0.0845 - val_accuracy: 0.9777\n",
      "Epoch 80/400\n",
      "169/182 [==========================>...] - ETA: 0s - loss: 0.0894 - accuracy: 0.9753\n",
      "Epoch 80: val_loss improved from 0.08450 to 0.08387, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 845us/step - loss: 0.0891 - accuracy: 0.9755 - val_loss: 0.0839 - val_accuracy: 0.9785\n",
      "Epoch 81/400\n",
      "166/182 [==========================>...] - ETA: 0s - loss: 0.0884 - accuracy: 0.9756\n",
      "Epoch 81: val_loss improved from 0.08387 to 0.08329, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 912us/step - loss: 0.0883 - accuracy: 0.9754 - val_loss: 0.0833 - val_accuracy: 0.9789\n",
      "Epoch 82/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0882 - accuracy: 0.9757\n",
      "Epoch 82: val_loss improved from 0.08329 to 0.08220, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 938us/step - loss: 0.0875 - accuracy: 0.9760 - val_loss: 0.0822 - val_accuracy: 0.9781\n",
      "Epoch 83/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0861 - accuracy: 0.9762\n",
      "Epoch 83: val_loss improved from 0.08220 to 0.08148, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 959us/step - loss: 0.0866 - accuracy: 0.9759 - val_loss: 0.0815 - val_accuracy: 0.9786\n",
      "Epoch 84/400\n",
      "149/182 [=======================>......] - ETA: 0s - loss: 0.0867 - accuracy: 0.9753\n",
      "Epoch 84: val_loss improved from 0.08148 to 0.08077, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 986us/step - loss: 0.0860 - accuracy: 0.9759 - val_loss: 0.0808 - val_accuracy: 0.9795\n",
      "Epoch 85/400\n",
      "124/182 [===================>..........] - ETA: 0s - loss: 0.0856 - accuracy: 0.9761\n",
      "Epoch 85: val_loss improved from 0.08077 to 0.08042, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9761 - val_loss: 0.0804 - val_accuracy: 0.9793\n",
      "Epoch 86/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0832 - accuracy: 0.9770\n",
      "Epoch 86: val_loss improved from 0.08042 to 0.07996, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 925us/step - loss: 0.0847 - accuracy: 0.9763 - val_loss: 0.0800 - val_accuracy: 0.9793\n",
      "Epoch 87/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0839 - accuracy: 0.9765\n",
      "Epoch 87: val_loss improved from 0.07996 to 0.07970, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 858us/step - loss: 0.0841 - accuracy: 0.9765 - val_loss: 0.0797 - val_accuracy: 0.9799\n",
      "Epoch 88/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0831 - accuracy: 0.9771\n",
      "Epoch 88: val_loss improved from 0.07970 to 0.07868, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 923us/step - loss: 0.0836 - accuracy: 0.9768 - val_loss: 0.0787 - val_accuracy: 0.9800\n",
      "Epoch 89/400\n",
      "169/182 [==========================>...] - ETA: 0s - loss: 0.0823 - accuracy: 0.9770\n",
      "Epoch 89: val_loss improved from 0.07868 to 0.07749, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 881us/step - loss: 0.0830 - accuracy: 0.9769 - val_loss: 0.0775 - val_accuracy: 0.9795\n",
      "Epoch 90/400\n",
      "137/182 [=====================>........] - ETA: 0s - loss: 0.0832 - accuracy: 0.9770\n",
      "Epoch 90: val_loss did not improve from 0.07749\n",
      "182/182 [==============================] - 0s 949us/step - loss: 0.0824 - accuracy: 0.9770 - val_loss: 0.0776 - val_accuracy: 0.9803\n",
      "Epoch 91/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0821 - accuracy: 0.9772\n",
      "Epoch 91: val_loss improved from 0.07749 to 0.07660, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 917us/step - loss: 0.0819 - accuracy: 0.9772 - val_loss: 0.0766 - val_accuracy: 0.9800\n",
      "Epoch 92/400\n",
      "145/182 [======================>.......] - ETA: 0s - loss: 0.0806 - accuracy: 0.9779\n",
      "Epoch 92: val_loss improved from 0.07660 to 0.07591, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 991us/step - loss: 0.0815 - accuracy: 0.9773 - val_loss: 0.0759 - val_accuracy: 0.9797\n",
      "Epoch 93/400\n",
      "140/182 [======================>.......] - ETA: 0s - loss: 0.0810 - accuracy: 0.9773\n",
      "Epoch 93: val_loss improved from 0.07591 to 0.07561, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9774 - val_loss: 0.0756 - val_accuracy: 0.9804\n",
      "Epoch 94/400\n",
      "142/182 [======================>.......] - ETA: 0s - loss: 0.0817 - accuracy: 0.9772\n",
      "Epoch 94: val_loss improved from 0.07561 to 0.07475, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 995us/step - loss: 0.0805 - accuracy: 0.9773 - val_loss: 0.0748 - val_accuracy: 0.9803\n",
      "Epoch 95/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0820 - accuracy: 0.9768\n",
      "Epoch 95: val_loss improved from 0.07475 to 0.07468, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 912us/step - loss: 0.0799 - accuracy: 0.9776 - val_loss: 0.0747 - val_accuracy: 0.9802\n",
      "Epoch 96/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0803 - accuracy: 0.9774\n",
      "Epoch 96: val_loss improved from 0.07468 to 0.07442, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 916us/step - loss: 0.0795 - accuracy: 0.9777 - val_loss: 0.0744 - val_accuracy: 0.9804\n",
      "Epoch 97/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0792 - accuracy: 0.9777\n",
      "Epoch 97: val_loss improved from 0.07442 to 0.07365, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 894us/step - loss: 0.0791 - accuracy: 0.9778 - val_loss: 0.0736 - val_accuracy: 0.9803\n",
      "Epoch 98/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0784 - accuracy: 0.9780\n",
      "Epoch 98: val_loss did not improve from 0.07365\n",
      "182/182 [==============================] - 0s 829us/step - loss: 0.0789 - accuracy: 0.9778 - val_loss: 0.0739 - val_accuracy: 0.9809\n",
      "Epoch 99/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/182 [========================>.....] - ETA: 0s - loss: 0.0791 - accuracy: 0.9776\n",
      "Epoch 99: val_loss improved from 0.07365 to 0.07328, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 939us/step - loss: 0.0783 - accuracy: 0.9779 - val_loss: 0.0733 - val_accuracy: 0.9805\n",
      "Epoch 100/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0777 - accuracy: 0.9781\n",
      "Epoch 100: val_loss improved from 0.07328 to 0.07292, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 873us/step - loss: 0.0779 - accuracy: 0.9781 - val_loss: 0.0729 - val_accuracy: 0.9806\n",
      "Epoch 101/400\n",
      "165/182 [==========================>...] - ETA: 0s - loss: 0.0785 - accuracy: 0.9775\n",
      "Epoch 101: val_loss improved from 0.07292 to 0.07245, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 876us/step - loss: 0.0776 - accuracy: 0.9778 - val_loss: 0.0725 - val_accuracy: 0.9808\n",
      "Epoch 102/400\n",
      "151/182 [=======================>......] - ETA: 0s - loss: 0.0771 - accuracy: 0.9786\n",
      "Epoch 102: val_loss did not improve from 0.07245\n",
      "182/182 [==============================] - 0s 914us/step - loss: 0.0772 - accuracy: 0.9784 - val_loss: 0.0725 - val_accuracy: 0.9808\n",
      "Epoch 103/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0769 - accuracy: 0.9782\n",
      "Epoch 103: val_loss improved from 0.07245 to 0.07137, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 857us/step - loss: 0.0769 - accuracy: 0.9783 - val_loss: 0.0714 - val_accuracy: 0.9810\n",
      "Epoch 104/400\n",
      "170/182 [===========================>..] - ETA: 0s - loss: 0.0761 - accuracy: 0.9787\n",
      "Epoch 104: val_loss improved from 0.07137 to 0.07129, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 840us/step - loss: 0.0765 - accuracy: 0.9785 - val_loss: 0.0713 - val_accuracy: 0.9809\n",
      "Epoch 105/400\n",
      "151/182 [=======================>......] - ETA: 0s - loss: 0.0761 - accuracy: 0.9786\n",
      "Epoch 105: val_loss did not improve from 0.07129\n",
      "182/182 [==============================] - 0s 884us/step - loss: 0.0762 - accuracy: 0.9784 - val_loss: 0.0717 - val_accuracy: 0.9809\n",
      "Epoch 106/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0753 - accuracy: 0.9787\n",
      "Epoch 106: val_loss improved from 0.07129 to 0.07086, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 982us/step - loss: 0.0760 - accuracy: 0.9787 - val_loss: 0.0709 - val_accuracy: 0.9813\n",
      "Epoch 107/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0758 - accuracy: 0.9789\n",
      "Epoch 107: val_loss improved from 0.07086 to 0.07080, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 911us/step - loss: 0.0755 - accuracy: 0.9788 - val_loss: 0.0708 - val_accuracy: 0.9814\n",
      "Epoch 108/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0744 - accuracy: 0.9793\n",
      "Epoch 108: val_loss improved from 0.07080 to 0.06980, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 857us/step - loss: 0.0752 - accuracy: 0.9790 - val_loss: 0.0698 - val_accuracy: 0.9813\n",
      "Epoch 109/400\n",
      "153/182 [========================>.....] - ETA: 0s - loss: 0.0746 - accuracy: 0.9791\n",
      "Epoch 109: val_loss did not improve from 0.06980\n",
      "182/182 [==============================] - 0s 884us/step - loss: 0.0749 - accuracy: 0.9791 - val_loss: 0.0700 - val_accuracy: 0.9816\n",
      "Epoch 110/400\n",
      "157/182 [========================>.....] - ETA: 0s - loss: 0.0753 - accuracy: 0.9789\n",
      "Epoch 110: val_loss improved from 0.06980 to 0.06931, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 909us/step - loss: 0.0746 - accuracy: 0.9792 - val_loss: 0.0693 - val_accuracy: 0.9810\n",
      "Epoch 111/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0742 - accuracy: 0.9792\n",
      "Epoch 111: val_loss did not improve from 0.06931\n",
      "182/182 [==============================] - 0s 887us/step - loss: 0.0744 - accuracy: 0.9790 - val_loss: 0.0701 - val_accuracy: 0.9815\n",
      "Epoch 112/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0735 - accuracy: 0.9794\n",
      "Epoch 112: val_loss improved from 0.06931 to 0.06895, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 951us/step - loss: 0.0742 - accuracy: 0.9792 - val_loss: 0.0690 - val_accuracy: 0.9816\n",
      "Epoch 113/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0746 - accuracy: 0.9791\n",
      "Epoch 113: val_loss did not improve from 0.06895\n",
      "182/182 [==============================] - 0s 832us/step - loss: 0.0738 - accuracy: 0.9793 - val_loss: 0.0693 - val_accuracy: 0.9817\n",
      "Epoch 114/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0732 - accuracy: 0.9792\n",
      "Epoch 114: val_loss improved from 0.06895 to 0.06801, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 933us/step - loss: 0.0735 - accuracy: 0.9792 - val_loss: 0.0680 - val_accuracy: 0.9820\n",
      "Epoch 115/400\n",
      "133/182 [====================>.........] - ETA: 0s - loss: 0.0719 - accuracy: 0.9801\n",
      "Epoch 115: val_loss did not improve from 0.06801\n",
      "182/182 [==============================] - 0s 976us/step - loss: 0.0733 - accuracy: 0.9795 - val_loss: 0.0684 - val_accuracy: 0.9817\n",
      "Epoch 116/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0730 - accuracy: 0.9795\n",
      "Epoch 116: val_loss did not improve from 0.06801\n",
      "182/182 [==============================] - 0s 812us/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 0.0685 - val_accuracy: 0.9819\n",
      "Epoch 117/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0735 - accuracy: 0.9794\n",
      "Epoch 117: val_loss did not improve from 0.06801\n",
      "182/182 [==============================] - 0s 841us/step - loss: 0.0727 - accuracy: 0.9797 - val_loss: 0.0680 - val_accuracy: 0.9816\n",
      "Epoch 118/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0729 - accuracy: 0.9795\n",
      "Epoch 118: val_loss improved from 0.06801 to 0.06723, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 869us/step - loss: 0.0725 - accuracy: 0.9796 - val_loss: 0.0672 - val_accuracy: 0.9823\n",
      "Epoch 119/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0729 - accuracy: 0.9792\n",
      "Epoch 119: val_loss improved from 0.06723 to 0.06694, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 889us/step - loss: 0.0723 - accuracy: 0.9796 - val_loss: 0.0669 - val_accuracy: 0.9816\n",
      "Epoch 120/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0726 - accuracy: 0.9796\n",
      "Epoch 120: val_loss improved from 0.06694 to 0.06662, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 894us/step - loss: 0.0720 - accuracy: 0.9798 - val_loss: 0.0666 - val_accuracy: 0.9822\n",
      "Epoch 121/400\n",
      "142/182 [======================>.......] - ETA: 0s - loss: 0.0724 - accuracy: 0.9796\n",
      "Epoch 121: val_loss did not improve from 0.06662\n",
      "182/182 [==============================] - 0s 936us/step - loss: 0.0718 - accuracy: 0.9798 - val_loss: 0.0667 - val_accuracy: 0.9825\n",
      "Epoch 122/400\n",
      "146/182 [=======================>......] - ETA: 0s - loss: 0.0726 - accuracy: 0.9793\n",
      "Epoch 122: val_loss improved from 0.06662 to 0.06645, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 993us/step - loss: 0.0716 - accuracy: 0.9797 - val_loss: 0.0664 - val_accuracy: 0.9822\n",
      "Epoch 123/400\n",
      "147/182 [=======================>......] - ETA: 0s - loss: 0.0713 - accuracy: 0.9798\n",
      "Epoch 123: val_loss improved from 0.06645 to 0.06620, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 969us/step - loss: 0.0713 - accuracy: 0.9799 - val_loss: 0.0662 - val_accuracy: 0.9825\n",
      "Epoch 124/400\n",
      "146/182 [=======================>......] - ETA: 0s - loss: 0.0721 - accuracy: 0.9797\n",
      "Epoch 124: val_loss improved from 0.06620 to 0.06609, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 0s 993us/step - loss: 0.0711 - accuracy: 0.9801 - val_loss: 0.0661 - val_accuracy: 0.9827\n",
      "Epoch 125/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.0709 - accuracy: 0.9799\n",
      "Epoch 125: val_loss improved from 0.06609 to 0.06598, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 972us/step - loss: 0.0709 - accuracy: 0.9799 - val_loss: 0.0660 - val_accuracy: 0.9826\n",
      "Epoch 126/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0698 - accuracy: 0.9807\n",
      "Epoch 126: val_loss improved from 0.06598 to 0.06584, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 933us/step - loss: 0.0706 - accuracy: 0.9805 - val_loss: 0.0658 - val_accuracy: 0.9830\n",
      "Epoch 127/400\n",
      "148/182 [=======================>......] - ETA: 0s - loss: 0.0691 - accuracy: 0.9808\n",
      "Epoch 127: val_loss did not improve from 0.06584\n",
      "182/182 [==============================] - 0s 925us/step - loss: 0.0706 - accuracy: 0.9801 - val_loss: 0.0660 - val_accuracy: 0.9823\n",
      "Epoch 128/400\n",
      "157/182 [========================>.....] - ETA: 0s - loss: 0.0713 - accuracy: 0.9800\n",
      "Epoch 128: val_loss improved from 0.06584 to 0.06516, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 923us/step - loss: 0.0702 - accuracy: 0.9802 - val_loss: 0.0652 - val_accuracy: 0.9826\n",
      "Epoch 129/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0707 - accuracy: 0.9801\n",
      "Epoch 129: val_loss improved from 0.06516 to 0.06484, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 900us/step - loss: 0.0701 - accuracy: 0.9804 - val_loss: 0.0648 - val_accuracy: 0.9828\n",
      "Epoch 130/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0705 - accuracy: 0.9799\n",
      "Epoch 130: val_loss improved from 0.06484 to 0.06470, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 908us/step - loss: 0.0698 - accuracy: 0.9801 - val_loss: 0.0647 - val_accuracy: 0.9827\n",
      "Epoch 131/400\n",
      "148/182 [=======================>......] - ETA: 0s - loss: 0.0704 - accuracy: 0.9798\n",
      "Epoch 131: val_loss improved from 0.06470 to 0.06459, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 974us/step - loss: 0.0696 - accuracy: 0.9802 - val_loss: 0.0646 - val_accuracy: 0.9819\n",
      "Epoch 132/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0699 - accuracy: 0.9800\n",
      "Epoch 132: val_loss improved from 0.06459 to 0.06411, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9803 - val_loss: 0.0641 - val_accuracy: 0.9821\n",
      "Epoch 133/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0692 - accuracy: 0.9806\n",
      "Epoch 133: val_loss did not improve from 0.06411\n",
      "182/182 [==============================] - 0s 836us/step - loss: 0.0692 - accuracy: 0.9806 - val_loss: 0.0645 - val_accuracy: 0.9825\n",
      "Epoch 134/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0687 - accuracy: 0.9806\n",
      "Epoch 134: val_loss improved from 0.06411 to 0.06403, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 875us/step - loss: 0.0691 - accuracy: 0.9803 - val_loss: 0.0640 - val_accuracy: 0.9828\n",
      "Epoch 135/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0692 - accuracy: 0.9802\n",
      "Epoch 135: val_loss improved from 0.06403 to 0.06342, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 927us/step - loss: 0.0688 - accuracy: 0.9805 - val_loss: 0.0634 - val_accuracy: 0.9830\n",
      "Epoch 136/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0689 - accuracy: 0.9805\n",
      "Epoch 136: val_loss did not improve from 0.06342\n",
      "182/182 [==============================] - 0s 830us/step - loss: 0.0687 - accuracy: 0.9806 - val_loss: 0.0634 - val_accuracy: 0.9830\n",
      "Epoch 137/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0688 - accuracy: 0.9805\n",
      "Epoch 137: val_loss improved from 0.06342 to 0.06330, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 906us/step - loss: 0.0685 - accuracy: 0.9806 - val_loss: 0.0633 - val_accuracy: 0.9827\n",
      "Epoch 138/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0689 - accuracy: 0.9805\n",
      "Epoch 138: val_loss improved from 0.06330 to 0.06292, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 884us/step - loss: 0.0683 - accuracy: 0.9807 - val_loss: 0.0629 - val_accuracy: 0.9833\n",
      "Epoch 139/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0671 - accuracy: 0.9810\n",
      "Epoch 139: val_loss did not improve from 0.06292\n",
      "182/182 [==============================] - 0s 856us/step - loss: 0.0681 - accuracy: 0.9806 - val_loss: 0.0630 - val_accuracy: 0.9832\n",
      "Epoch 140/400\n",
      "133/182 [====================>.........] - ETA: 0s - loss: 0.0674 - accuracy: 0.9807\n",
      "Epoch 140: val_loss did not improve from 0.06292\n",
      "182/182 [==============================] - 0s 942us/step - loss: 0.0679 - accuracy: 0.9807 - val_loss: 0.0634 - val_accuracy: 0.9828\n",
      "Epoch 141/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0685 - accuracy: 0.9807\n",
      "Epoch 141: val_loss improved from 0.06292 to 0.06246, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 920us/step - loss: 0.0678 - accuracy: 0.9809 - val_loss: 0.0625 - val_accuracy: 0.9833\n",
      "Epoch 142/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0670 - accuracy: 0.9811\n",
      "Epoch 142: val_loss did not improve from 0.06246\n",
      "182/182 [==============================] - 0s 852us/step - loss: 0.0675 - accuracy: 0.9809 - val_loss: 0.0627 - val_accuracy: 0.9836\n",
      "Epoch 143/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0665 - accuracy: 0.9811\n",
      "Epoch 143: val_loss did not improve from 0.06246\n",
      "182/182 [==============================] - 0s 829us/step - loss: 0.0674 - accuracy: 0.9808 - val_loss: 0.0625 - val_accuracy: 0.9833\n",
      "Epoch 144/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0674 - accuracy: 0.9811\n",
      "Epoch 144: val_loss improved from 0.06246 to 0.06180, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 929us/step - loss: 0.0674 - accuracy: 0.9810 - val_loss: 0.0618 - val_accuracy: 0.9833\n",
      "Epoch 145/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0680 - accuracy: 0.9804\n",
      "Epoch 145: val_loss did not improve from 0.06180\n",
      "182/182 [==============================] - 0s 850us/step - loss: 0.0670 - accuracy: 0.9807 - val_loss: 0.0620 - val_accuracy: 0.9830\n",
      "Epoch 146/400\n",
      "166/182 [==========================>...] - ETA: 0s - loss: 0.0663 - accuracy: 0.9813\n",
      "Epoch 146: val_loss did not improve from 0.06180\n",
      "182/182 [==============================] - 0s 819us/step - loss: 0.0670 - accuracy: 0.9811 - val_loss: 0.0619 - val_accuracy: 0.9832\n",
      "Epoch 147/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0664 - accuracy: 0.9814\n",
      "Epoch 147: val_loss did not improve from 0.06180\n",
      "182/182 [==============================] - 0s 809us/step - loss: 0.0667 - accuracy: 0.9812 - val_loss: 0.0620 - val_accuracy: 0.9831\n",
      "Epoch 148/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0663 - accuracy: 0.9814\n",
      "Epoch 148: val_loss did not improve from 0.06180\n",
      "182/182 [==============================] - 0s 820us/step - loss: 0.0665 - accuracy: 0.9811 - val_loss: 0.0625 - val_accuracy: 0.9837\n",
      "Epoch 149/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0662 - accuracy: 0.9812\n",
      "Epoch 149: val_loss improved from 0.06180 to 0.06125, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 931us/step - loss: 0.0665 - accuracy: 0.9810 - val_loss: 0.0612 - val_accuracy: 0.9833\n",
      "Epoch 150/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0660 - accuracy: 0.9815\n",
      "Epoch 150: val_loss improved from 0.06125 to 0.06102, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 0s 911us/step - loss: 0.0662 - accuracy: 0.9814 - val_loss: 0.0610 - val_accuracy: 0.9833\n",
      "Epoch 151/400\n",
      "153/182 [========================>.....] - ETA: 0s - loss: 0.0662 - accuracy: 0.9810\n",
      "Epoch 151: val_loss did not improve from 0.06102\n",
      "182/182 [==============================] - 0s 880us/step - loss: 0.0662 - accuracy: 0.9809 - val_loss: 0.0614 - val_accuracy: 0.9831\n",
      "Epoch 152/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0663 - accuracy: 0.9810\n",
      "Epoch 152: val_loss did not improve from 0.06102\n",
      "182/182 [==============================] - 0s 846us/step - loss: 0.0660 - accuracy: 0.9810 - val_loss: 0.0611 - val_accuracy: 0.9843\n",
      "Epoch 153/400\n",
      "130/182 [====================>.........] - ETA: 0s - loss: 0.0655 - accuracy: 0.9816\n",
      "Epoch 153: val_loss improved from 0.06102 to 0.06085, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9813 - val_loss: 0.0609 - val_accuracy: 0.9826\n",
      "Epoch 154/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0649 - accuracy: 0.9814\n",
      "Epoch 154: val_loss improved from 0.06085 to 0.06051, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 913us/step - loss: 0.0657 - accuracy: 0.9812 - val_loss: 0.0605 - val_accuracy: 0.9838\n",
      "Epoch 155/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0651 - accuracy: 0.9814\n",
      "Epoch 155: val_loss improved from 0.06051 to 0.06023, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 874us/step - loss: 0.0655 - accuracy: 0.9813 - val_loss: 0.0602 - val_accuracy: 0.9830\n",
      "Epoch 156/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0652 - accuracy: 0.9815\n",
      "Epoch 156: val_loss did not improve from 0.06023\n",
      "182/182 [==============================] - 0s 837us/step - loss: 0.0653 - accuracy: 0.9814 - val_loss: 0.0602 - val_accuracy: 0.9839\n",
      "Epoch 157/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0656 - accuracy: 0.9812\n",
      "Epoch 157: val_loss did not improve from 0.06023\n",
      "182/182 [==============================] - 0s 875us/step - loss: 0.0652 - accuracy: 0.9815 - val_loss: 0.0607 - val_accuracy: 0.9832\n",
      "Epoch 158/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0658 - accuracy: 0.9810\n",
      "Epoch 158: val_loss improved from 0.06023 to 0.06017, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 922us/step - loss: 0.0652 - accuracy: 0.9812 - val_loss: 0.0602 - val_accuracy: 0.9838\n",
      "Epoch 159/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.0645 - accuracy: 0.9817\n",
      "Epoch 159: val_loss improved from 0.06017 to 0.05987, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 968us/step - loss: 0.0650 - accuracy: 0.9815 - val_loss: 0.0599 - val_accuracy: 0.9839\n",
      "Epoch 160/400\n",
      "153/182 [========================>.....] - ETA: 0s - loss: 0.0653 - accuracy: 0.9810\n",
      "Epoch 160: val_loss improved from 0.05987 to 0.05963, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 943us/step - loss: 0.0648 - accuracy: 0.9813 - val_loss: 0.0596 - val_accuracy: 0.9837\n",
      "Epoch 161/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0640 - accuracy: 0.9817\n",
      "Epoch 161: val_loss did not improve from 0.05963\n",
      "182/182 [==============================] - 0s 865us/step - loss: 0.0646 - accuracy: 0.9814 - val_loss: 0.0600 - val_accuracy: 0.9837\n",
      "Epoch 162/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0653 - accuracy: 0.9812\n",
      "Epoch 162: val_loss improved from 0.05963 to 0.05939, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 876us/step - loss: 0.0645 - accuracy: 0.9814 - val_loss: 0.0594 - val_accuracy: 0.9836\n",
      "Epoch 163/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0638 - accuracy: 0.9819\n",
      "Epoch 163: val_loss improved from 0.05939 to 0.05901, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 885us/step - loss: 0.0644 - accuracy: 0.9817 - val_loss: 0.0590 - val_accuracy: 0.9838\n",
      "Epoch 164/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0647 - accuracy: 0.9815\n",
      "Epoch 164: val_loss did not improve from 0.05901\n",
      "182/182 [==============================] - 0s 841us/step - loss: 0.0643 - accuracy: 0.9816 - val_loss: 0.0591 - val_accuracy: 0.9838\n",
      "Epoch 165/400\n",
      "171/182 [===========================>..] - ETA: 0s - loss: 0.0639 - accuracy: 0.9817\n",
      "Epoch 165: val_loss improved from 0.05901 to 0.05875, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 915us/step - loss: 0.0641 - accuracy: 0.9816 - val_loss: 0.0588 - val_accuracy: 0.9836\n",
      "Epoch 166/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.0626 - accuracy: 0.9821\n",
      "Epoch 166: val_loss did not improve from 0.05875\n",
      "182/182 [==============================] - 0s 861us/step - loss: 0.0640 - accuracy: 0.9817 - val_loss: 0.0593 - val_accuracy: 0.9841\n",
      "Epoch 167/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0635 - accuracy: 0.9816\n",
      "Epoch 167: val_loss improved from 0.05875 to 0.05852, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 872us/step - loss: 0.0639 - accuracy: 0.9814 - val_loss: 0.0585 - val_accuracy: 0.9831\n",
      "Epoch 168/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0633 - accuracy: 0.9817\n",
      "Epoch 168: val_loss did not improve from 0.05852\n",
      "182/182 [==============================] - 0s 821us/step - loss: 0.0637 - accuracy: 0.9816 - val_loss: 0.0594 - val_accuracy: 0.9838\n",
      "Epoch 169/400\n",
      "173/182 [===========================>..] - ETA: 0s - loss: 0.0632 - accuracy: 0.9817\n",
      "Epoch 169: val_loss improved from 0.05852 to 0.05837, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 886us/step - loss: 0.0635 - accuracy: 0.9816 - val_loss: 0.0584 - val_accuracy: 0.9841\n",
      "Epoch 170/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0637 - accuracy: 0.9818\n",
      "Epoch 170: val_loss did not improve from 0.05837\n",
      "182/182 [==============================] - 0s 829us/step - loss: 0.0635 - accuracy: 0.9817 - val_loss: 0.0585 - val_accuracy: 0.9847\n",
      "Epoch 171/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0640 - accuracy: 0.9814\n",
      "Epoch 171: val_loss improved from 0.05837 to 0.05815, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 889us/step - loss: 0.0634 - accuracy: 0.9816 - val_loss: 0.0582 - val_accuracy: 0.9845\n",
      "Epoch 172/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0639 - accuracy: 0.9817\n",
      "Epoch 172: val_loss improved from 0.05815 to 0.05782, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 897us/step - loss: 0.0632 - accuracy: 0.9819 - val_loss: 0.0578 - val_accuracy: 0.9832\n",
      "Epoch 173/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0627 - accuracy: 0.9819\n",
      "Epoch 173: val_loss did not improve from 0.05782\n",
      "182/182 [==============================] - 0s 854us/step - loss: 0.0631 - accuracy: 0.9817 - val_loss: 0.0589 - val_accuracy: 0.9842\n",
      "Epoch 174/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0629 - accuracy: 0.9820\n",
      "Epoch 174: val_loss did not improve from 0.05782\n",
      "182/182 [==============================] - 0s 841us/step - loss: 0.0630 - accuracy: 0.9819 - val_loss: 0.0582 - val_accuracy: 0.9841\n",
      "Epoch 175/400\n",
      "166/182 [==========================>...] - ETA: 0s - loss: 0.0621 - accuracy: 0.9823\n",
      "Epoch 175: val_loss did not improve from 0.05782\n",
      "182/182 [==============================] - 0s 817us/step - loss: 0.0627 - accuracy: 0.9820 - val_loss: 0.0581 - val_accuracy: 0.9842\n",
      "Epoch 176/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0623 - accuracy: 0.9818\n",
      "Epoch 176: val_loss improved from 0.05782 to 0.05738, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 0s 890us/step - loss: 0.0628 - accuracy: 0.9818 - val_loss: 0.0574 - val_accuracy: 0.9842\n",
      "Epoch 177/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0627 - accuracy: 0.9817\n",
      "Epoch 177: val_loss did not improve from 0.05738\n",
      "182/182 [==============================] - 0s 837us/step - loss: 0.0626 - accuracy: 0.9817 - val_loss: 0.0576 - val_accuracy: 0.9845\n",
      "Epoch 178/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0625 - accuracy: 0.9817\n",
      "Epoch 178: val_loss did not improve from 0.05738\n",
      "182/182 [==============================] - 0s 853us/step - loss: 0.0625 - accuracy: 0.9818 - val_loss: 0.0574 - val_accuracy: 0.9845\n",
      "Epoch 179/400\n",
      "138/182 [=====================>........] - ETA: 0s - loss: 0.0618 - accuracy: 0.9822\n",
      "Epoch 179: val_loss improved from 0.05738 to 0.05727, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 977us/step - loss: 0.0624 - accuracy: 0.9821 - val_loss: 0.0573 - val_accuracy: 0.9844\n",
      "Epoch 180/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0624 - accuracy: 0.9818\n",
      "Epoch 180: val_loss improved from 0.05727 to 0.05699, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 889us/step - loss: 0.0622 - accuracy: 0.9820 - val_loss: 0.0570 - val_accuracy: 0.9848\n",
      "Epoch 181/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0617 - accuracy: 0.9822\n",
      "Epoch 181: val_loss did not improve from 0.05699\n",
      "182/182 [==============================] - 0s 819us/step - loss: 0.0621 - accuracy: 0.9820 - val_loss: 0.0577 - val_accuracy: 0.9844\n",
      "Epoch 182/400\n",
      "166/182 [==========================>...] - ETA: 0s - loss: 0.0618 - accuracy: 0.9822\n",
      "Epoch 182: val_loss did not improve from 0.05699\n",
      "182/182 [==============================] - 0s 821us/step - loss: 0.0619 - accuracy: 0.9821 - val_loss: 0.0576 - val_accuracy: 0.9843\n",
      "Epoch 183/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0615 - accuracy: 0.9822\n",
      "Epoch 183: val_loss improved from 0.05699 to 0.05682, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 916us/step - loss: 0.0619 - accuracy: 0.9821 - val_loss: 0.0568 - val_accuracy: 0.9845\n",
      "Epoch 184/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0619 - accuracy: 0.9821\n",
      "Epoch 184: val_loss improved from 0.05682 to 0.05674, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 904us/step - loss: 0.0617 - accuracy: 0.9822 - val_loss: 0.0567 - val_accuracy: 0.9847\n",
      "Epoch 185/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0612 - accuracy: 0.9822\n",
      "Epoch 185: val_loss improved from 0.05674 to 0.05634, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 915us/step - loss: 0.0616 - accuracy: 0.9821 - val_loss: 0.0563 - val_accuracy: 0.9842\n",
      "Epoch 186/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0619 - accuracy: 0.9821\n",
      "Epoch 186: val_loss did not improve from 0.05634\n",
      "182/182 [==============================] - 0s 848us/step - loss: 0.0615 - accuracy: 0.9822 - val_loss: 0.0567 - val_accuracy: 0.9841\n",
      "Epoch 187/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0606 - accuracy: 0.9825\n",
      "Epoch 187: val_loss improved from 0.05634 to 0.05614, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 921us/step - loss: 0.0614 - accuracy: 0.9821 - val_loss: 0.0561 - val_accuracy: 0.9848\n",
      "Epoch 188/400\n",
      "157/182 [========================>.....] - ETA: 0s - loss: 0.0614 - accuracy: 0.9819\n",
      "Epoch 188: val_loss improved from 0.05614 to 0.05612, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 928us/step - loss: 0.0613 - accuracy: 0.9821 - val_loss: 0.0561 - val_accuracy: 0.9843\n",
      "Epoch 189/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0623 - accuracy: 0.9817\n",
      "Epoch 189: val_loss did not improve from 0.05612\n",
      "182/182 [==============================] - 0s 857us/step - loss: 0.0612 - accuracy: 0.9821 - val_loss: 0.0566 - val_accuracy: 0.9848\n",
      "Epoch 190/400\n",
      "151/182 [=======================>......] - ETA: 0s - loss: 0.0608 - accuracy: 0.9823\n",
      "Epoch 190: val_loss improved from 0.05612 to 0.05585, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 958us/step - loss: 0.0611 - accuracy: 0.9822 - val_loss: 0.0559 - val_accuracy: 0.9849\n",
      "Epoch 191/400\n",
      "143/182 [======================>.......] - ETA: 0s - loss: 0.0603 - accuracy: 0.9824\n",
      "Epoch 191: val_loss improved from 0.05585 to 0.05579, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0610 - accuracy: 0.9822 - val_loss: 0.0558 - val_accuracy: 0.9847\n",
      "Epoch 192/400\n",
      "149/182 [=======================>......] - ETA: 0s - loss: 0.0606 - accuracy: 0.9826\n",
      "Epoch 192: val_loss did not improve from 0.05579\n",
      "182/182 [==============================] - 0s 875us/step - loss: 0.0609 - accuracy: 0.9825 - val_loss: 0.0563 - val_accuracy: 0.9847\n",
      "Epoch 193/400\n",
      "147/182 [=======================>......] - ETA: 0s - loss: 0.0615 - accuracy: 0.9821\n",
      "Epoch 193: val_loss improved from 0.05579 to 0.05527, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 964us/step - loss: 0.0609 - accuracy: 0.9822 - val_loss: 0.0553 - val_accuracy: 0.9848\n",
      "Epoch 194/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0609 - accuracy: 0.9822\n",
      "Epoch 194: val_loss did not improve from 0.05527\n",
      "182/182 [==============================] - 0s 890us/step - loss: 0.0607 - accuracy: 0.9824 - val_loss: 0.0556 - val_accuracy: 0.9848\n",
      "Epoch 195/400\n",
      "147/182 [=======================>......] - ETA: 0s - loss: 0.0616 - accuracy: 0.9819\n",
      "Epoch 195: val_loss did not improve from 0.05527\n",
      "182/182 [==============================] - 0s 924us/step - loss: 0.0605 - accuracy: 0.9823 - val_loss: 0.0557 - val_accuracy: 0.9850\n",
      "Epoch 196/400\n",
      "151/182 [=======================>......] - ETA: 0s - loss: 0.0596 - accuracy: 0.9829\n",
      "Epoch 196: val_loss did not improve from 0.05527\n",
      "182/182 [==============================] - 0s 907us/step - loss: 0.0605 - accuracy: 0.9827 - val_loss: 0.0554 - val_accuracy: 0.9845\n",
      "Epoch 197/400\n",
      "146/182 [=======================>......] - ETA: 0s - loss: 0.0607 - accuracy: 0.9822\n",
      "Epoch 197: val_loss did not improve from 0.05527\n",
      "182/182 [==============================] - 0s 919us/step - loss: 0.0603 - accuracy: 0.9823 - val_loss: 0.0555 - val_accuracy: 0.9848\n",
      "Epoch 198/400\n",
      "147/182 [=======================>......] - ETA: 0s - loss: 0.0603 - accuracy: 0.9824\n",
      "Epoch 198: val_loss improved from 0.05527 to 0.05504, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9824 - val_loss: 0.0550 - val_accuracy: 0.9848\n",
      "Epoch 199/400\n",
      "140/182 [======================>.......] - ETA: 0s - loss: 0.0609 - accuracy: 0.9822\n",
      "Epoch 199: val_loss did not improve from 0.05504\n",
      "182/182 [==============================] - 0s 953us/step - loss: 0.0601 - accuracy: 0.9825 - val_loss: 0.0554 - val_accuracy: 0.9849\n",
      "Epoch 200/400\n",
      "151/182 [=======================>......] - ETA: 0s - loss: 0.0602 - accuracy: 0.9825\n",
      "Epoch 200: val_loss did not improve from 0.05504\n",
      "182/182 [==============================] - 0s 877us/step - loss: 0.0600 - accuracy: 0.9825 - val_loss: 0.0557 - val_accuracy: 0.9850\n",
      "Epoch 201/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0602 - accuracy: 0.9823\n",
      "Epoch 201: val_loss improved from 0.05504 to 0.05467, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 971us/step - loss: 0.0599 - accuracy: 0.9825 - val_loss: 0.0547 - val_accuracy: 0.9848\n",
      "Epoch 202/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0610 - accuracy: 0.9821\n",
      "Epoch 202: val_loss did not improve from 0.05467\n",
      "182/182 [==============================] - 0s 889us/step - loss: 0.0599 - accuracy: 0.9826 - val_loss: 0.0547 - val_accuracy: 0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.0603 - accuracy: 0.9822\n",
      "Epoch 203: val_loss improved from 0.05467 to 0.05451, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9824 - val_loss: 0.0545 - val_accuracy: 0.9850\n",
      "Epoch 204/400\n",
      "147/182 [=======================>......] - ETA: 0s - loss: 0.0577 - accuracy: 0.9834\n",
      "Epoch 204: val_loss did not improve from 0.05451\n",
      "182/182 [==============================] - 0s 897us/step - loss: 0.0596 - accuracy: 0.9827 - val_loss: 0.0549 - val_accuracy: 0.9853\n",
      "Epoch 205/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0596 - accuracy: 0.9826\n",
      "Epoch 205: val_loss improved from 0.05451 to 0.05420, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 958us/step - loss: 0.0596 - accuracy: 0.9827 - val_loss: 0.0542 - val_accuracy: 0.9847\n",
      "Epoch 206/400\n",
      "153/182 [========================>.....] - ETA: 0s - loss: 0.0596 - accuracy: 0.9824\n",
      "Epoch 206: val_loss improved from 0.05420 to 0.05413, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 929us/step - loss: 0.0594 - accuracy: 0.9825 - val_loss: 0.0541 - val_accuracy: 0.9850\n",
      "Epoch 207/400\n",
      "149/182 [=======================>......] - ETA: 0s - loss: 0.0603 - accuracy: 0.9824\n",
      "Epoch 207: val_loss did not improve from 0.05413\n",
      "182/182 [==============================] - 0s 962us/step - loss: 0.0594 - accuracy: 0.9827 - val_loss: 0.0550 - val_accuracy: 0.9850\n",
      "Epoch 208/400\n",
      "153/182 [========================>.....] - ETA: 0s - loss: 0.0589 - accuracy: 0.9829\n",
      "Epoch 208: val_loss did not improve from 0.05413\n",
      "182/182 [==============================] - 0s 872us/step - loss: 0.0593 - accuracy: 0.9827 - val_loss: 0.0545 - val_accuracy: 0.9851\n",
      "Epoch 209/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0598 - accuracy: 0.9822\n",
      "Epoch 209: val_loss improved from 0.05413 to 0.05381, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 944us/step - loss: 0.0592 - accuracy: 0.9826 - val_loss: 0.0538 - val_accuracy: 0.9847\n",
      "Epoch 210/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0592 - accuracy: 0.9825\n",
      "Epoch 210: val_loss improved from 0.05381 to 0.05378, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 922us/step - loss: 0.0591 - accuracy: 0.9826 - val_loss: 0.0538 - val_accuracy: 0.9849\n",
      "Epoch 211/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0587 - accuracy: 0.9824\n",
      "Epoch 211: val_loss did not improve from 0.05378\n",
      "182/182 [==============================] - 0s 837us/step - loss: 0.0590 - accuracy: 0.9824 - val_loss: 0.0540 - val_accuracy: 0.9851\n",
      "Epoch 212/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0591 - accuracy: 0.9822\n",
      "Epoch 212: val_loss did not improve from 0.05378\n",
      "182/182 [==============================] - 0s 858us/step - loss: 0.0589 - accuracy: 0.9824 - val_loss: 0.0539 - val_accuracy: 0.9848\n",
      "Epoch 213/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0597 - accuracy: 0.9823\n",
      "Epoch 213: val_loss did not improve from 0.05378\n",
      "182/182 [==============================] - 0s 835us/step - loss: 0.0587 - accuracy: 0.9826 - val_loss: 0.0543 - val_accuracy: 0.9853\n",
      "Epoch 214/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0591 - accuracy: 0.9825\n",
      "Epoch 214: val_loss did not improve from 0.05378\n",
      "182/182 [==============================] - 0s 837us/step - loss: 0.0587 - accuracy: 0.9827 - val_loss: 0.0542 - val_accuracy: 0.9851\n",
      "Epoch 215/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0590 - accuracy: 0.9827\n",
      "Epoch 215: val_loss improved from 0.05378 to 0.05373, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 927us/step - loss: 0.0586 - accuracy: 0.9827 - val_loss: 0.0537 - val_accuracy: 0.9847\n",
      "Epoch 216/400\n",
      "145/182 [======================>.......] - ETA: 0s - loss: 0.0579 - accuracy: 0.9830\n",
      "Epoch 216: val_loss improved from 0.05373 to 0.05343, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0585 - accuracy: 0.9827 - val_loss: 0.0534 - val_accuracy: 0.9848\n",
      "Epoch 217/400\n",
      "171/182 [===========================>..] - ETA: 0s - loss: 0.0588 - accuracy: 0.9825\n",
      "Epoch 217: val_loss did not improve from 0.05343\n",
      "182/182 [==============================] - 0s 804us/step - loss: 0.0584 - accuracy: 0.9827 - val_loss: 0.0538 - val_accuracy: 0.9850\n",
      "Epoch 218/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0594 - accuracy: 0.9823\n",
      "Epoch 218: val_loss improved from 0.05343 to 0.05298, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 934us/step - loss: 0.0583 - accuracy: 0.9826 - val_loss: 0.0530 - val_accuracy: 0.9851\n",
      "Epoch 219/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0579 - accuracy: 0.9830\n",
      "Epoch 219: val_loss did not improve from 0.05298\n",
      "182/182 [==============================] - 0s 848us/step - loss: 0.0582 - accuracy: 0.9829 - val_loss: 0.0532 - val_accuracy: 0.9849\n",
      "Epoch 220/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0578 - accuracy: 0.9829\n",
      "Epoch 220: val_loss did not improve from 0.05298\n",
      "182/182 [==============================] - 0s 832us/step - loss: 0.0582 - accuracy: 0.9827 - val_loss: 0.0533 - val_accuracy: 0.9850\n",
      "Epoch 221/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0573 - accuracy: 0.9831\n",
      "Epoch 221: val_loss did not improve from 0.05298\n",
      "182/182 [==============================] - 0s 834us/step - loss: 0.0580 - accuracy: 0.9829 - val_loss: 0.0539 - val_accuracy: 0.9854\n",
      "Epoch 222/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0587 - accuracy: 0.9827\n",
      "Epoch 222: val_loss did not improve from 0.05298\n",
      "182/182 [==============================] - 0s 837us/step - loss: 0.0581 - accuracy: 0.9828 - val_loss: 0.0530 - val_accuracy: 0.9853\n",
      "Epoch 223/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0574 - accuracy: 0.9831\n",
      "Epoch 223: val_loss improved from 0.05298 to 0.05267, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 904us/step - loss: 0.0579 - accuracy: 0.9827 - val_loss: 0.0527 - val_accuracy: 0.9849\n",
      "Epoch 224/400\n",
      "165/182 [==========================>...] - ETA: 0s - loss: 0.0576 - accuracy: 0.9830\n",
      "Epoch 224: val_loss did not improve from 0.05267\n",
      "182/182 [==============================] - 0s 813us/step - loss: 0.0579 - accuracy: 0.9827 - val_loss: 0.0528 - val_accuracy: 0.9855\n",
      "Epoch 225/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0580 - accuracy: 0.9826\n",
      "Epoch 225: val_loss did not improve from 0.05267\n",
      "182/182 [==============================] - 0s 844us/step - loss: 0.0577 - accuracy: 0.9829 - val_loss: 0.0531 - val_accuracy: 0.9855\n",
      "Epoch 226/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0576 - accuracy: 0.9829\n",
      "Epoch 226: val_loss improved from 0.05267 to 0.05245, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 943us/step - loss: 0.0577 - accuracy: 0.9828 - val_loss: 0.0524 - val_accuracy: 0.9853\n",
      "Epoch 227/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0580 - accuracy: 0.9827\n",
      "Epoch 227: val_loss did not improve from 0.05245\n",
      "182/182 [==============================] - 0s 833us/step - loss: 0.0576 - accuracy: 0.9829 - val_loss: 0.0526 - val_accuracy: 0.9850\n",
      "Epoch 228/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0563 - accuracy: 0.9832\n",
      "Epoch 228: val_loss did not improve from 0.05245\n",
      "182/182 [==============================] - 0s 863us/step - loss: 0.0575 - accuracy: 0.9829 - val_loss: 0.0529 - val_accuracy: 0.9855\n",
      "Epoch 229/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0569 - accuracy: 0.9831\n",
      "Epoch 229: val_loss improved from 0.05245 to 0.05221, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 997us/step - loss: 0.0574 - accuracy: 0.9827 - val_loss: 0.0522 - val_accuracy: 0.9853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0570 - accuracy: 0.9830\n",
      "Epoch 230: val_loss did not improve from 0.05221\n",
      "182/182 [==============================] - 0s 886us/step - loss: 0.0573 - accuracy: 0.9830 - val_loss: 0.0535 - val_accuracy: 0.9853\n",
      "Epoch 231/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0570 - accuracy: 0.9833\n",
      "Epoch 231: val_loss did not improve from 0.05221\n",
      "182/182 [==============================] - 0s 840us/step - loss: 0.0572 - accuracy: 0.9832 - val_loss: 0.0528 - val_accuracy: 0.9854\n",
      "Epoch 232/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0560 - accuracy: 0.9834\n",
      "Epoch 232: val_loss did not improve from 0.05221\n",
      "182/182 [==============================] - 0s 848us/step - loss: 0.0573 - accuracy: 0.9828 - val_loss: 0.0523 - val_accuracy: 0.9851\n",
      "Epoch 233/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0575 - accuracy: 0.9827\n",
      "Epoch 233: val_loss did not improve from 0.05221\n",
      "182/182 [==============================] - 0s 847us/step - loss: 0.0571 - accuracy: 0.9828 - val_loss: 0.0526 - val_accuracy: 0.9855\n",
      "Epoch 234/400\n",
      "165/182 [==========================>...] - ETA: 0s - loss: 0.0572 - accuracy: 0.9829\n",
      "Epoch 234: val_loss did not improve from 0.05221\n",
      "182/182 [==============================] - 0s 821us/step - loss: 0.0570 - accuracy: 0.9830 - val_loss: 0.0523 - val_accuracy: 0.9856\n",
      "Epoch 235/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0565 - accuracy: 0.9832\n",
      "Epoch 235: val_loss did not improve from 0.05221\n",
      "182/182 [==============================] - 0s 834us/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 0.0524 - val_accuracy: 0.9853\n",
      "Epoch 236/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0576 - accuracy: 0.9828\n",
      "Epoch 236: val_loss did not improve from 0.05221\n",
      "182/182 [==============================] - 0s 797us/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 0.0523 - val_accuracy: 0.9854\n",
      "Epoch 237/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0564 - accuracy: 0.9832\n",
      "Epoch 237: val_loss improved from 0.05221 to 0.05195, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 894us/step - loss: 0.0567 - accuracy: 0.9829 - val_loss: 0.0520 - val_accuracy: 0.9850\n",
      "Epoch 238/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0582 - accuracy: 0.9824\n",
      "Epoch 238: val_loss improved from 0.05195 to 0.05164, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 906us/step - loss: 0.0567 - accuracy: 0.9831 - val_loss: 0.0516 - val_accuracy: 0.9853\n",
      "Epoch 239/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0558 - accuracy: 0.9833\n",
      "Epoch 239: val_loss improved from 0.05164 to 0.05149, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 897us/step - loss: 0.0566 - accuracy: 0.9830 - val_loss: 0.0515 - val_accuracy: 0.9856\n",
      "Epoch 240/400\n",
      "172/182 [===========================>..] - ETA: 0s - loss: 0.0564 - accuracy: 0.9831\n",
      "Epoch 240: val_loss did not improve from 0.05149\n",
      "182/182 [==============================] - 0s 789us/step - loss: 0.0564 - accuracy: 0.9831 - val_loss: 0.0518 - val_accuracy: 0.9855\n",
      "Epoch 241/400\n",
      "171/182 [===========================>..] - ETA: 0s - loss: 0.0563 - accuracy: 0.9831\n",
      "Epoch 241: val_loss did not improve from 0.05149\n",
      "182/182 [==============================] - 0s 792us/step - loss: 0.0564 - accuracy: 0.9830 - val_loss: 0.0517 - val_accuracy: 0.9858\n",
      "Epoch 242/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0558 - accuracy: 0.9833\n",
      "Epoch 242: val_loss did not improve from 0.05149\n",
      "182/182 [==============================] - 0s 846us/step - loss: 0.0564 - accuracy: 0.9831 - val_loss: 0.0518 - val_accuracy: 0.9855\n",
      "Epoch 243/400\n",
      "137/182 [=====================>........] - ETA: 0s - loss: 0.0564 - accuracy: 0.9832\n",
      "Epoch 243: val_loss did not improve from 0.05149\n",
      "182/182 [==============================] - 0s 928us/step - loss: 0.0563 - accuracy: 0.9833 - val_loss: 0.0515 - val_accuracy: 0.9856\n",
      "Epoch 244/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0561 - accuracy: 0.9831\n",
      "Epoch 244: val_loss did not improve from 0.05149\n",
      "182/182 [==============================] - 0s 806us/step - loss: 0.0563 - accuracy: 0.9830 - val_loss: 0.0515 - val_accuracy: 0.9855\n",
      "Epoch 245/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0562 - accuracy: 0.9831\n",
      "Epoch 245: val_loss improved from 0.05149 to 0.05115, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 911us/step - loss: 0.0562 - accuracy: 0.9832 - val_loss: 0.0511 - val_accuracy: 0.9851\n",
      "Epoch 246/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0562 - accuracy: 0.9831\n",
      "Epoch 246: val_loss did not improve from 0.05115\n",
      "182/182 [==============================] - 0s 831us/step - loss: 0.0561 - accuracy: 0.9830 - val_loss: 0.0518 - val_accuracy: 0.9855\n",
      "Epoch 247/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0557 - accuracy: 0.9833\n",
      "Epoch 247: val_loss did not improve from 0.05115\n",
      "182/182 [==============================] - 0s 809us/step - loss: 0.0560 - accuracy: 0.9832 - val_loss: 0.0516 - val_accuracy: 0.9853\n",
      "Epoch 248/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0557 - accuracy: 0.9833\n",
      "Epoch 248: val_loss did not improve from 0.05115\n",
      "182/182 [==============================] - 0s 869us/step - loss: 0.0559 - accuracy: 0.9832 - val_loss: 0.0515 - val_accuracy: 0.9856\n",
      "Epoch 249/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0559 - accuracy: 0.9835\n",
      "Epoch 249: val_loss improved from 0.05115 to 0.05100, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 932us/step - loss: 0.0559 - accuracy: 0.9832 - val_loss: 0.0510 - val_accuracy: 0.9856\n",
      "Epoch 250/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0561 - accuracy: 0.9833\n",
      "Epoch 250: val_loss improved from 0.05100 to 0.05072, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 856us/step - loss: 0.0557 - accuracy: 0.9833 - val_loss: 0.0507 - val_accuracy: 0.9855\n",
      "Epoch 251/400\n",
      "171/182 [===========================>..] - ETA: 0s - loss: 0.0560 - accuracy: 0.9830\n",
      "Epoch 251: val_loss did not improve from 0.05072\n",
      "182/182 [==============================] - 0s 786us/step - loss: 0.0557 - accuracy: 0.9831 - val_loss: 0.0511 - val_accuracy: 0.9853\n",
      "Epoch 252/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0547 - accuracy: 0.9837\n",
      "Epoch 252: val_loss did not improve from 0.05072\n",
      "182/182 [==============================] - 0s 843us/step - loss: 0.0556 - accuracy: 0.9832 - val_loss: 0.0509 - val_accuracy: 0.9855\n",
      "Epoch 253/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0558 - accuracy: 0.9833\n",
      "Epoch 253: val_loss did not improve from 0.05072\n",
      "182/182 [==============================] - 0s 806us/step - loss: 0.0556 - accuracy: 0.9834 - val_loss: 0.0511 - val_accuracy: 0.9854\n",
      "Epoch 254/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0560 - accuracy: 0.9832\n",
      "Epoch 254: val_loss improved from 0.05072 to 0.05060, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 905us/step - loss: 0.0555 - accuracy: 0.9835 - val_loss: 0.0506 - val_accuracy: 0.9854\n",
      "Epoch 255/400\n",
      "166/182 [==========================>...] - ETA: 0s - loss: 0.0553 - accuracy: 0.9833\n",
      "Epoch 255: val_loss did not improve from 0.05060\n",
      "182/182 [==============================] - 0s 814us/step - loss: 0.0554 - accuracy: 0.9832 - val_loss: 0.0509 - val_accuracy: 0.9850\n",
      "Epoch 256/400\n",
      "137/182 [=====================>........] - ETA: 0s - loss: 0.0556 - accuracy: 0.9835\n",
      "Epoch 256: val_loss did not improve from 0.05060\n",
      "182/182 [==============================] - 0s 947us/step - loss: 0.0553 - accuracy: 0.9835 - val_loss: 0.0507 - val_accuracy: 0.9854\n",
      "Epoch 257/400\n",
      "170/182 [===========================>..] - ETA: 0s - loss: 0.0549 - accuracy: 0.9833\n",
      "Epoch 257: val_loss did not improve from 0.05060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 0s 806us/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.0513 - val_accuracy: 0.9856\n",
      "Epoch 258/400\n",
      "170/182 [===========================>..] - ETA: 0s - loss: 0.0552 - accuracy: 0.9836\n",
      "Epoch 258: val_loss improved from 0.05060 to 0.05025, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 894us/step - loss: 0.0552 - accuracy: 0.9835 - val_loss: 0.0503 - val_accuracy: 0.9853\n",
      "Epoch 259/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0545 - accuracy: 0.9835\n",
      "Epoch 259: val_loss did not improve from 0.05025\n",
      "182/182 [==============================] - 0s 808us/step - loss: 0.0551 - accuracy: 0.9834 - val_loss: 0.0506 - val_accuracy: 0.9855\n",
      "Epoch 260/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0557 - accuracy: 0.9831\n",
      "Epoch 260: val_loss improved from 0.05025 to 0.05019, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 971us/step - loss: 0.0550 - accuracy: 0.9835 - val_loss: 0.0502 - val_accuracy: 0.9860\n",
      "Epoch 261/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0554 - accuracy: 0.9832\n",
      "Epoch 261: val_loss did not improve from 0.05019\n",
      "182/182 [==============================] - 0s 850us/step - loss: 0.0550 - accuracy: 0.9835 - val_loss: 0.0504 - val_accuracy: 0.9854\n",
      "Epoch 262/400\n",
      "166/182 [==========================>...] - ETA: 0s - loss: 0.0555 - accuracy: 0.9832\n",
      "Epoch 262: val_loss did not improve from 0.05019\n",
      "182/182 [==============================] - 0s 826us/step - loss: 0.0549 - accuracy: 0.9834 - val_loss: 0.0505 - val_accuracy: 0.9856\n",
      "Epoch 263/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0547 - accuracy: 0.9837\n",
      "Epoch 263: val_loss improved from 0.05019 to 0.05006, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 913us/step - loss: 0.0548 - accuracy: 0.9835 - val_loss: 0.0501 - val_accuracy: 0.9859\n",
      "Epoch 264/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0547 - accuracy: 0.9834\n",
      "Epoch 264: val_loss improved from 0.05006 to 0.04990, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 928us/step - loss: 0.0548 - accuracy: 0.9834 - val_loss: 0.0499 - val_accuracy: 0.9858\n",
      "Epoch 265/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0551 - accuracy: 0.9832\n",
      "Epoch 265: val_loss improved from 0.04990 to 0.04978, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 901us/step - loss: 0.0547 - accuracy: 0.9836 - val_loss: 0.0498 - val_accuracy: 0.9859\n",
      "Epoch 266/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0548 - accuracy: 0.9832\n",
      "Epoch 266: val_loss improved from 0.04978 to 0.04958, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 931us/step - loss: 0.0546 - accuracy: 0.9834 - val_loss: 0.0496 - val_accuracy: 0.9858\n",
      "Epoch 267/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0542 - accuracy: 0.9835\n",
      "Epoch 267: val_loss did not improve from 0.04958\n",
      "182/182 [==============================] - 0s 816us/step - loss: 0.0545 - accuracy: 0.9835 - val_loss: 0.0498 - val_accuracy: 0.9860\n",
      "Epoch 268/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0545 - accuracy: 0.9836\n",
      "Epoch 268: val_loss did not improve from 0.04958\n",
      "182/182 [==============================] - 0s 822us/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.0500 - val_accuracy: 0.9855\n",
      "Epoch 269/400\n",
      "135/182 [=====================>........] - ETA: 0s - loss: 0.0539 - accuracy: 0.9839\n",
      "Epoch 269: val_loss did not improve from 0.04958\n",
      "182/182 [==============================] - 0s 984us/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.0499 - val_accuracy: 0.9856\n",
      "Epoch 270/400\n",
      "157/182 [========================>.....] - ETA: 0s - loss: 0.0543 - accuracy: 0.9835\n",
      "Epoch 270: val_loss improved from 0.04958 to 0.04945, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 895us/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.0494 - val_accuracy: 0.9856\n",
      "Epoch 271/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0545 - accuracy: 0.9832\n",
      "Epoch 271: val_loss improved from 0.04945 to 0.04940, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 875us/step - loss: 0.0543 - accuracy: 0.9834 - val_loss: 0.0494 - val_accuracy: 0.9858\n",
      "Epoch 272/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0548 - accuracy: 0.9833\n",
      "Epoch 272: val_loss did not improve from 0.04940\n",
      "182/182 [==============================] - 0s 827us/step - loss: 0.0542 - accuracy: 0.9834 - val_loss: 0.0498 - val_accuracy: 0.9855\n",
      "Epoch 273/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0538 - accuracy: 0.9837\n",
      "Epoch 273: val_loss did not improve from 0.04940\n",
      "182/182 [==============================] - 0s 859us/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.0495 - val_accuracy: 0.9856\n",
      "Epoch 274/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0542 - accuracy: 0.9835\n",
      "Epoch 274: val_loss improved from 0.04940 to 0.04934, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 881us/step - loss: 0.0541 - accuracy: 0.9834 - val_loss: 0.0493 - val_accuracy: 0.9854\n",
      "Epoch 275/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0546 - accuracy: 0.9833\n",
      "Epoch 275: val_loss did not improve from 0.04934\n",
      "182/182 [==============================] - 0s 846us/step - loss: 0.0540 - accuracy: 0.9836 - val_loss: 0.0493 - val_accuracy: 0.9858\n",
      "Epoch 276/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0542 - accuracy: 0.9836\n",
      "Epoch 276: val_loss improved from 0.04934 to 0.04920, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 906us/step - loss: 0.0539 - accuracy: 0.9839 - val_loss: 0.0492 - val_accuracy: 0.9858\n",
      "Epoch 277/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0544 - accuracy: 0.9834\n",
      "Epoch 277: val_loss did not improve from 0.04920\n",
      "182/182 [==============================] - 0s 813us/step - loss: 0.0540 - accuracy: 0.9837 - val_loss: 0.0492 - val_accuracy: 0.9858\n",
      "Epoch 278/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0536 - accuracy: 0.9837\n",
      "Epoch 278: val_loss did not improve from 0.04920\n",
      "182/182 [==============================] - 0s 823us/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 0.0492 - val_accuracy: 0.9858\n",
      "Epoch 279/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0533 - accuracy: 0.9838\n",
      "Epoch 279: val_loss did not improve from 0.04920\n",
      "182/182 [==============================] - 0s 836us/step - loss: 0.0537 - accuracy: 0.9837 - val_loss: 0.0495 - val_accuracy: 0.9854\n",
      "Epoch 280/400\n",
      "157/182 [========================>.....] - ETA: 0s - loss: 0.0530 - accuracy: 0.9837\n",
      "Epoch 280: val_loss improved from 0.04920 to 0.04917, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 914us/step - loss: 0.0537 - accuracy: 0.9836 - val_loss: 0.0492 - val_accuracy: 0.9856\n",
      "Epoch 281/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0536 - accuracy: 0.9836\n",
      "Epoch 281: val_loss improved from 0.04917 to 0.04914, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 881us/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 0.0491 - val_accuracy: 0.9860\n",
      "Epoch 282/400\n",
      "140/182 [======================>.......] - ETA: 0s - loss: 0.0543 - accuracy: 0.9833\n",
      "Epoch 282: val_loss did not improve from 0.04914\n",
      "182/182 [==============================] - 0s 945us/step - loss: 0.0536 - accuracy: 0.9836 - val_loss: 0.0493 - val_accuracy: 0.9855\n",
      "Epoch 283/400\n",
      "166/182 [==========================>...] - ETA: 0s - loss: 0.0533 - accuracy: 0.9837\n",
      "Epoch 283: val_loss improved from 0.04914 to 0.04886, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 896us/step - loss: 0.0536 - accuracy: 0.9836 - val_loss: 0.0489 - val_accuracy: 0.9856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/400\n",
      "137/182 [=====================>........] - ETA: 0s - loss: 0.0526 - accuracy: 0.9840\n",
      "Epoch 284: val_loss improved from 0.04886 to 0.04870, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 977us/step - loss: 0.0535 - accuracy: 0.9838 - val_loss: 0.0487 - val_accuracy: 0.9859\n",
      "Epoch 285/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0530 - accuracy: 0.9840\n",
      "Epoch 285: val_loss improved from 0.04870 to 0.04865, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 928us/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.0487 - val_accuracy: 0.9859\n",
      "Epoch 286/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0520 - accuracy: 0.9845\n",
      "Epoch 286: val_loss did not improve from 0.04865\n",
      "182/182 [==============================] - 0s 848us/step - loss: 0.0533 - accuracy: 0.9839 - val_loss: 0.0501 - val_accuracy: 0.9855\n",
      "Epoch 287/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0533 - accuracy: 0.9837\n",
      "Epoch 287: val_loss did not improve from 0.04865\n",
      "182/182 [==============================] - 0s 837us/step - loss: 0.0533 - accuracy: 0.9837 - val_loss: 0.0499 - val_accuracy: 0.9853\n",
      "Epoch 288/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0532 - accuracy: 0.9838\n",
      "Epoch 288: val_loss improved from 0.04865 to 0.04862, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 906us/step - loss: 0.0532 - accuracy: 0.9837 - val_loss: 0.0486 - val_accuracy: 0.9858\n",
      "Epoch 289/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0525 - accuracy: 0.9839\n",
      "Epoch 289: val_loss did not improve from 0.04862\n",
      "182/182 [==============================] - 0s 843us/step - loss: 0.0531 - accuracy: 0.9838 - val_loss: 0.0488 - val_accuracy: 0.9858\n",
      "Epoch 290/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0530 - accuracy: 0.9838\n",
      "Epoch 290: val_loss improved from 0.04862 to 0.04847, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 919us/step - loss: 0.0532 - accuracy: 0.9838 - val_loss: 0.0485 - val_accuracy: 0.9858\n",
      "Epoch 291/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0536 - accuracy: 0.9837\n",
      "Epoch 291: val_loss improved from 0.04847 to 0.04846, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 933us/step - loss: 0.0530 - accuracy: 0.9838 - val_loss: 0.0485 - val_accuracy: 0.9856\n",
      "Epoch 292/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0532 - accuracy: 0.9837\n",
      "Epoch 292: val_loss improved from 0.04846 to 0.04824, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 913us/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 0.0482 - val_accuracy: 0.9858\n",
      "Epoch 293/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0531 - accuracy: 0.9838\n",
      "Epoch 293: val_loss improved from 0.04824 to 0.04813, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 893us/step - loss: 0.0529 - accuracy: 0.9838 - val_loss: 0.0481 - val_accuracy: 0.9858\n",
      "Epoch 294/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0530 - accuracy: 0.9838\n",
      "Epoch 294: val_loss did not improve from 0.04813\n",
      "182/182 [==============================] - 0s 842us/step - loss: 0.0528 - accuracy: 0.9839 - val_loss: 0.0488 - val_accuracy: 0.9856\n",
      "Epoch 295/400\n",
      "139/182 [=====================>........] - ETA: 0s - loss: 0.0517 - accuracy: 0.9844\n",
      "Epoch 295: val_loss did not improve from 0.04813\n",
      "182/182 [==============================] - 0s 898us/step - loss: 0.0528 - accuracy: 0.9839 - val_loss: 0.0487 - val_accuracy: 0.9856\n",
      "Epoch 296/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0524 - accuracy: 0.9839\n",
      "Epoch 296: val_loss did not improve from 0.04813\n",
      "182/182 [==============================] - 0s 828us/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.0486 - val_accuracy: 0.9859\n",
      "Epoch 297/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0524 - accuracy: 0.9839\n",
      "Epoch 297: val_loss improved from 0.04813 to 0.04806, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 890us/step - loss: 0.0527 - accuracy: 0.9838 - val_loss: 0.0481 - val_accuracy: 0.9860\n",
      "Epoch 298/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0533 - accuracy: 0.9836\n",
      "Epoch 298: val_loss improved from 0.04806 to 0.04775, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 903us/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.0478 - val_accuracy: 0.9860\n",
      "Epoch 299/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0525 - accuracy: 0.9840\n",
      "Epoch 299: val_loss did not improve from 0.04775\n",
      "182/182 [==============================] - 0s 822us/step - loss: 0.0526 - accuracy: 0.9840 - val_loss: 0.0478 - val_accuracy: 0.9859\n",
      "Epoch 300/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0524 - accuracy: 0.9838\n",
      "Epoch 300: val_loss improved from 0.04775 to 0.04751, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 942us/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.0475 - val_accuracy: 0.9862\n",
      "Epoch 301/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0521 - accuracy: 0.9842\n",
      "Epoch 301: val_loss did not improve from 0.04751\n",
      "182/182 [==============================] - 0s 818us/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.0476 - val_accuracy: 0.9862\n",
      "Epoch 302/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0526 - accuracy: 0.9838\n",
      "Epoch 302: val_loss improved from 0.04751 to 0.04731, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 900us/step - loss: 0.0524 - accuracy: 0.9839 - val_loss: 0.0473 - val_accuracy: 0.9865\n",
      "Epoch 303/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0521 - accuracy: 0.9840\n",
      "Epoch 303: val_loss did not improve from 0.04731\n",
      "182/182 [==============================] - 0s 842us/step - loss: 0.0524 - accuracy: 0.9841 - val_loss: 0.0479 - val_accuracy: 0.9861\n",
      "Epoch 304/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0516 - accuracy: 0.9841\n",
      "Epoch 304: val_loss did not improve from 0.04731\n",
      "182/182 [==============================] - 0s 852us/step - loss: 0.0523 - accuracy: 0.9839 - val_loss: 0.0476 - val_accuracy: 0.9860\n",
      "Epoch 305/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0523 - accuracy: 0.9843\n",
      "Epoch 305: val_loss improved from 0.04731 to 0.04714, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 898us/step - loss: 0.0522 - accuracy: 0.9842 - val_loss: 0.0471 - val_accuracy: 0.9861\n",
      "Epoch 306/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0519 - accuracy: 0.9840\n",
      "Epoch 306: val_loss did not improve from 0.04714\n",
      "182/182 [==============================] - 0s 834us/step - loss: 0.0521 - accuracy: 0.9840 - val_loss: 0.0481 - val_accuracy: 0.9861\n",
      "Epoch 307/400\n",
      "166/182 [==========================>...] - ETA: 0s - loss: 0.0521 - accuracy: 0.9841\n",
      "Epoch 307: val_loss did not improve from 0.04714\n",
      "182/182 [==============================] - 0s 817us/step - loss: 0.0521 - accuracy: 0.9841 - val_loss: 0.0474 - val_accuracy: 0.9864\n",
      "Epoch 308/400\n",
      "137/182 [=====================>........] - ETA: 0s - loss: 0.0528 - accuracy: 0.9839\n",
      "Epoch 308: val_loss did not improve from 0.04714\n",
      "182/182 [==============================] - 0s 935us/step - loss: 0.0521 - accuracy: 0.9840 - val_loss: 0.0475 - val_accuracy: 0.9860\n",
      "Epoch 309/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0520 - accuracy: 0.9841\n",
      "Epoch 309: val_loss did not improve from 0.04714\n",
      "182/182 [==============================] - 0s 844us/step - loss: 0.0520 - accuracy: 0.9841 - val_loss: 0.0473 - val_accuracy: 0.9861\n",
      "Epoch 310/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0510 - accuracy: 0.9844\n",
      "Epoch 310: val_loss did not improve from 0.04714\n",
      "182/182 [==============================] - 0s 837us/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.0476 - val_accuracy: 0.9860\n",
      "Epoch 311/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0525 - accuracy: 0.9839\n",
      "Epoch 311: val_loss did not improve from 0.04714\n",
      "182/182 [==============================] - 0s 834us/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.0472 - val_accuracy: 0.9860\n",
      "Epoch 312/400\n",
      "173/182 [===========================>..] - ETA: 0s - loss: 0.0516 - accuracy: 0.9842\n",
      "Epoch 312: val_loss did not improve from 0.04714\n",
      "182/182 [==============================] - 0s 788us/step - loss: 0.0517 - accuracy: 0.9841 - val_loss: 0.0477 - val_accuracy: 0.9860\n",
      "Epoch 313/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.0521 - accuracy: 0.9840\n",
      "Epoch 313: val_loss improved from 0.04714 to 0.04698, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 940us/step - loss: 0.0517 - accuracy: 0.9842 - val_loss: 0.0470 - val_accuracy: 0.9861\n",
      "Epoch 314/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0513 - accuracy: 0.9843\n",
      "Epoch 314: val_loss did not improve from 0.04698\n",
      "182/182 [==============================] - 0s 842us/step - loss: 0.0516 - accuracy: 0.9841 - val_loss: 0.0478 - val_accuracy: 0.9860\n",
      "Epoch 315/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0515 - accuracy: 0.9842\n",
      "Epoch 315: val_loss did not improve from 0.04698\n",
      "182/182 [==============================] - 0s 830us/step - loss: 0.0516 - accuracy: 0.9841 - val_loss: 0.0471 - val_accuracy: 0.9862\n",
      "Epoch 316/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0513 - accuracy: 0.9840\n",
      "Epoch 316: val_loss improved from 0.04698 to 0.04696, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 898us/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.0470 - val_accuracy: 0.9864\n",
      "Epoch 317/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0511 - accuracy: 0.9845\n",
      "Epoch 317: val_loss did not improve from 0.04696\n",
      "182/182 [==============================] - 0s 857us/step - loss: 0.0516 - accuracy: 0.9843 - val_loss: 0.0474 - val_accuracy: 0.9862\n",
      "Epoch 318/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0508 - accuracy: 0.9845\n",
      "Epoch 318: val_loss did not improve from 0.04696\n",
      "182/182 [==============================] - 0s 840us/step - loss: 0.0514 - accuracy: 0.9843 - val_loss: 0.0471 - val_accuracy: 0.9862\n",
      "Epoch 319/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0505 - accuracy: 0.9846\n",
      "Epoch 319: val_loss did not improve from 0.04696\n",
      "182/182 [==============================] - 0s 839us/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.0474 - val_accuracy: 0.9860\n",
      "Epoch 320/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0517 - accuracy: 0.9841\n",
      "Epoch 320: val_loss improved from 0.04696 to 0.04657, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 884us/step - loss: 0.0514 - accuracy: 0.9843 - val_loss: 0.0466 - val_accuracy: 0.9864\n",
      "Epoch 321/400\n",
      "143/182 [======================>.......] - ETA: 0s - loss: 0.0523 - accuracy: 0.9838\n",
      "Epoch 321: val_loss did not improve from 0.04657\n",
      "182/182 [==============================] - 0s 938us/step - loss: 0.0513 - accuracy: 0.9843 - val_loss: 0.0468 - val_accuracy: 0.9862\n",
      "Epoch 322/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0517 - accuracy: 0.9839\n",
      "Epoch 322: val_loss did not improve from 0.04657\n",
      "182/182 [==============================] - 0s 827us/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 0.0468 - val_accuracy: 0.9862\n",
      "Epoch 323/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0512 - accuracy: 0.9842\n",
      "Epoch 323: val_loss did not improve from 0.04657\n",
      "182/182 [==============================] - 0s 822us/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 0.0467 - val_accuracy: 0.9859\n",
      "Epoch 324/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9844\n",
      "Epoch 324: val_loss did not improve from 0.04657\n",
      "182/182 [==============================] - 0s 847us/step - loss: 0.0511 - accuracy: 0.9842 - val_loss: 0.0471 - val_accuracy: 0.9861\n",
      "Epoch 325/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0510 - accuracy: 0.9841\n",
      "Epoch 325: val_loss improved from 0.04657 to 0.04626, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 914us/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.0463 - val_accuracy: 0.9865\n",
      "Epoch 326/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0512 - accuracy: 0.9842\n",
      "Epoch 326: val_loss improved from 0.04626 to 0.04602, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 900us/step - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.0460 - val_accuracy: 0.9865\n",
      "Epoch 327/400\n",
      "165/182 [==========================>...] - ETA: 0s - loss: 0.0509 - accuracy: 0.9842\n",
      "Epoch 327: val_loss did not improve from 0.04602\n",
      "182/182 [==============================] - 0s 818us/step - loss: 0.0510 - accuracy: 0.9841 - val_loss: 0.0467 - val_accuracy: 0.9861\n",
      "Epoch 328/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9844\n",
      "Epoch 328: val_loss did not improve from 0.04602\n",
      "182/182 [==============================] - 0s 840us/step - loss: 0.0509 - accuracy: 0.9844 - val_loss: 0.0463 - val_accuracy: 0.9864\n",
      "Epoch 329/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0507 - accuracy: 0.9844\n",
      "Epoch 329: val_loss did not improve from 0.04602\n",
      "182/182 [==============================] - 0s 832us/step - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.0477 - val_accuracy: 0.9860\n",
      "Epoch 330/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0517 - accuracy: 0.9839\n",
      "Epoch 330: val_loss did not improve from 0.04602\n",
      "182/182 [==============================] - 0s 850us/step - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.0466 - val_accuracy: 0.9860\n",
      "Epoch 331/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0508 - accuracy: 0.9841\n",
      "Epoch 331: val_loss improved from 0.04602 to 0.04587, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 874us/step - loss: 0.0508 - accuracy: 0.9841 - val_loss: 0.0459 - val_accuracy: 0.9865\n",
      "Epoch 332/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0509 - accuracy: 0.9842\n",
      "Epoch 332: val_loss did not improve from 0.04587\n",
      "182/182 [==============================] - 0s 845us/step - loss: 0.0507 - accuracy: 0.9843 - val_loss: 0.0466 - val_accuracy: 0.9861\n",
      "Epoch 333/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9841\n",
      "Epoch 333: val_loss did not improve from 0.04587\n",
      "182/182 [==============================] - 0s 837us/step - loss: 0.0507 - accuracy: 0.9842 - val_loss: 0.0462 - val_accuracy: 0.9864\n",
      "Epoch 334/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0499 - accuracy: 0.9844\n",
      "Epoch 334: val_loss did not improve from 0.04587\n",
      "182/182 [==============================] - 0s 919us/step - loss: 0.0506 - accuracy: 0.9841 - val_loss: 0.0460 - val_accuracy: 0.9864\n",
      "Epoch 335/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0509 - accuracy: 0.9843\n",
      "Epoch 335: val_loss did not improve from 0.04587\n",
      "182/182 [==============================] - 0s 854us/step - loss: 0.0506 - accuracy: 0.9844 - val_loss: 0.0462 - val_accuracy: 0.9862\n",
      "Epoch 336/400\n",
      "165/182 [==========================>...] - ETA: 0s - loss: 0.0508 - accuracy: 0.9842\n",
      "Epoch 336: val_loss did not improve from 0.04587\n",
      "182/182 [==============================] - 0s 811us/step - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.0463 - val_accuracy: 0.9861\n",
      "Epoch 337/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0507 - accuracy: 0.9840\n",
      "Epoch 337: val_loss improved from 0.04587 to 0.04578, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 878us/step - loss: 0.0504 - accuracy: 0.9842 - val_loss: 0.0458 - val_accuracy: 0.9862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0507 - accuracy: 0.9844\n",
      "Epoch 338: val_loss did not improve from 0.04578\n",
      "182/182 [==============================] - 0s 832us/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 0.0463 - val_accuracy: 0.9861\n",
      "Epoch 339/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0502 - accuracy: 0.9844\n",
      "Epoch 339: val_loss did not improve from 0.04578\n",
      "182/182 [==============================] - 0s 823us/step - loss: 0.0504 - accuracy: 0.9843 - val_loss: 0.0462 - val_accuracy: 0.9864\n",
      "Epoch 340/400\n",
      "168/182 [==========================>...] - ETA: 0s - loss: 0.0508 - accuracy: 0.9841\n",
      "Epoch 340: val_loss did not improve from 0.04578\n",
      "182/182 [==============================] - 0s 810us/step - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.0460 - val_accuracy: 0.9860\n",
      "Epoch 341/400\n",
      "167/182 [==========================>...] - ETA: 0s - loss: 0.0509 - accuracy: 0.9842\n",
      "Epoch 341: val_loss improved from 0.04578 to 0.04578, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 887us/step - loss: 0.0503 - accuracy: 0.9844 - val_loss: 0.0458 - val_accuracy: 0.9864\n",
      "Epoch 342/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0497 - accuracy: 0.9845\n",
      "Epoch 342: val_loss improved from 0.04578 to 0.04553, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 900us/step - loss: 0.0502 - accuracy: 0.9843 - val_loss: 0.0455 - val_accuracy: 0.9865\n",
      "Epoch 343/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.0494 - accuracy: 0.9845\n",
      "Epoch 343: val_loss did not improve from 0.04553\n",
      "182/182 [==============================] - 0s 898us/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.0456 - val_accuracy: 0.9864\n",
      "Epoch 344/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0498 - accuracy: 0.9843\n",
      "Epoch 344: val_loss improved from 0.04553 to 0.04546, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 900us/step - loss: 0.0501 - accuracy: 0.9842 - val_loss: 0.0455 - val_accuracy: 0.9862\n",
      "Epoch 345/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0498 - accuracy: 0.9844\n",
      "Epoch 345: val_loss did not improve from 0.04546\n",
      "182/182 [==============================] - 0s 809us/step - loss: 0.0501 - accuracy: 0.9843 - val_loss: 0.0461 - val_accuracy: 0.9862\n",
      "Epoch 346/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0504 - accuracy: 0.9844\n",
      "Epoch 346: val_loss improved from 0.04546 to 0.04521, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 939us/step - loss: 0.0501 - accuracy: 0.9843 - val_loss: 0.0452 - val_accuracy: 0.9867\n",
      "Epoch 347/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0487 - accuracy: 0.9850\n",
      "Epoch 347: val_loss did not improve from 0.04521\n",
      "182/182 [==============================] - 0s 896us/step - loss: 0.0499 - accuracy: 0.9845 - val_loss: 0.0464 - val_accuracy: 0.9860\n",
      "Epoch 348/400\n",
      "157/182 [========================>.....] - ETA: 0s - loss: 0.0505 - accuracy: 0.9841\n",
      "Epoch 348: val_loss improved from 0.04521 to 0.04508, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 903us/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 0.0451 - val_accuracy: 0.9865\n",
      "Epoch 349/400\n",
      "140/182 [======================>.......] - ETA: 0s - loss: 0.0505 - accuracy: 0.9841\n",
      "Epoch 349: val_loss did not improve from 0.04508\n",
      "182/182 [==============================] - 0s 907us/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0456 - val_accuracy: 0.9862\n",
      "Epoch 350/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0494 - accuracy: 0.9846\n",
      "Epoch 350: val_loss did not improve from 0.04508\n",
      "182/182 [==============================] - 0s 865us/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.0454 - val_accuracy: 0.9864\n",
      "Epoch 351/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0497 - accuracy: 0.9844\n",
      "Epoch 351: val_loss did not improve from 0.04508\n",
      "182/182 [==============================] - 0s 811us/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.0454 - val_accuracy: 0.9864\n",
      "Epoch 352/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0496 - accuracy: 0.9846\n",
      "Epoch 352: val_loss did not improve from 0.04508\n",
      "182/182 [==============================] - 0s 825us/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.0453 - val_accuracy: 0.9866\n",
      "Epoch 353/400\n",
      "165/182 [==========================>...] - ETA: 0s - loss: 0.0498 - accuracy: 0.9846\n",
      "Epoch 353: val_loss did not improve from 0.04508\n",
      "182/182 [==============================] - 0s 849us/step - loss: 0.0497 - accuracy: 0.9847 - val_loss: 0.0456 - val_accuracy: 0.9864\n",
      "Epoch 354/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0491 - accuracy: 0.9846\n",
      "Epoch 354: val_loss did not improve from 0.04508\n",
      "182/182 [==============================] - 0s 825us/step - loss: 0.0497 - accuracy: 0.9843 - val_loss: 0.0459 - val_accuracy: 0.9859\n",
      "Epoch 355/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0494 - accuracy: 0.9845\n",
      "Epoch 355: val_loss did not improve from 0.04508\n",
      "182/182 [==============================] - 0s 831us/step - loss: 0.0497 - accuracy: 0.9845 - val_loss: 0.0452 - val_accuracy: 0.9864\n",
      "Epoch 356/400\n",
      "151/182 [=======================>......] - ETA: 0s - loss: 0.0497 - accuracy: 0.9844\n",
      "Epoch 356: val_loss did not improve from 0.04508\n",
      "182/182 [==============================] - 0s 867us/step - loss: 0.0496 - accuracy: 0.9844 - val_loss: 0.0456 - val_accuracy: 0.9861\n",
      "Epoch 357/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0502 - accuracy: 0.9842\n",
      "Epoch 357: val_loss improved from 0.04508 to 0.04486, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 964us/step - loss: 0.0495 - accuracy: 0.9844 - val_loss: 0.0449 - val_accuracy: 0.9866\n",
      "Epoch 358/400\n",
      "153/182 [========================>.....] - ETA: 0s - loss: 0.0491 - accuracy: 0.9848\n",
      "Epoch 358: val_loss improved from 0.04486 to 0.04481, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 923us/step - loss: 0.0495 - accuracy: 0.9846 - val_loss: 0.0448 - val_accuracy: 0.9864\n",
      "Epoch 359/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0493 - accuracy: 0.9847\n",
      "Epoch 359: val_loss did not improve from 0.04481\n",
      "182/182 [==============================] - 0s 838us/step - loss: 0.0494 - accuracy: 0.9846 - val_loss: 0.0456 - val_accuracy: 0.9861\n",
      "Epoch 360/400\n",
      "162/182 [=========================>....] - ETA: 0s - loss: 0.0497 - accuracy: 0.9842\n",
      "Epoch 360: val_loss improved from 0.04481 to 0.04473, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 954us/step - loss: 0.0493 - accuracy: 0.9845 - val_loss: 0.0447 - val_accuracy: 0.9869\n",
      "Epoch 361/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.0487 - accuracy: 0.9848\n",
      "Epoch 361: val_loss did not improve from 0.04473\n",
      "182/182 [==============================] - 0s 869us/step - loss: 0.0493 - accuracy: 0.9846 - val_loss: 0.0453 - val_accuracy: 0.9864\n",
      "Epoch 362/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0493 - accuracy: 0.9844\n",
      "Epoch 362: val_loss did not improve from 0.04473\n",
      "182/182 [==============================] - 0s 850us/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.0448 - val_accuracy: 0.9864\n",
      "Epoch 363/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.0493 - accuracy: 0.9844\n",
      "Epoch 363: val_loss did not improve from 0.04473\n",
      "182/182 [==============================] - 0s 882us/step - loss: 0.0492 - accuracy: 0.9845 - val_loss: 0.0449 - val_accuracy: 0.9867\n",
      "Epoch 364/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0497 - accuracy: 0.9844\n",
      "Epoch 364: val_loss did not improve from 0.04473\n",
      "182/182 [==============================] - 0s 881us/step - loss: 0.0492 - accuracy: 0.9845 - val_loss: 0.0451 - val_accuracy: 0.9864\n",
      "Epoch 365/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/182 [=======================>......] - ETA: 0s - loss: 0.0494 - accuracy: 0.9843\n",
      "Epoch 365: val_loss did not improve from 0.04473\n",
      "182/182 [==============================] - 0s 887us/step - loss: 0.0491 - accuracy: 0.9845 - val_loss: 0.0453 - val_accuracy: 0.9865\n",
      "Epoch 366/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.0496 - accuracy: 0.9846\n",
      "Epoch 366: val_loss did not improve from 0.04473\n",
      "182/182 [==============================] - 0s 896us/step - loss: 0.0492 - accuracy: 0.9846 - val_loss: 0.0448 - val_accuracy: 0.9866\n",
      "Epoch 367/400\n",
      "150/182 [=======================>......] - ETA: 0s - loss: 0.0497 - accuracy: 0.9842\n",
      "Epoch 367: val_loss did not improve from 0.04473\n",
      "182/182 [==============================] - 0s 900us/step - loss: 0.0490 - accuracy: 0.9844 - val_loss: 0.0451 - val_accuracy: 0.9862\n",
      "Epoch 368/400\n",
      "151/182 [=======================>......] - ETA: 0s - loss: 0.0489 - accuracy: 0.9848\n",
      "Epoch 368: val_loss improved from 0.04473 to 0.04467, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 971us/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 0.0447 - val_accuracy: 0.9866\n",
      "Epoch 369/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0491 - accuracy: 0.9844\n",
      "Epoch 369: val_loss improved from 0.04467 to 0.04446, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 917us/step - loss: 0.0490 - accuracy: 0.9845 - val_loss: 0.0445 - val_accuracy: 0.9871\n",
      "Epoch 370/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0488 - accuracy: 0.9846\n",
      "Epoch 370: val_loss did not improve from 0.04446\n",
      "182/182 [==============================] - 0s 843us/step - loss: 0.0489 - accuracy: 0.9846 - val_loss: 0.0447 - val_accuracy: 0.9865\n",
      "Epoch 371/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0500 - accuracy: 0.9843\n",
      "Epoch 371: val_loss did not improve from 0.04446\n",
      "182/182 [==============================] - 0s 856us/step - loss: 0.0490 - accuracy: 0.9847 - val_loss: 0.0445 - val_accuracy: 0.9866\n",
      "Epoch 372/400\n",
      "156/182 [========================>.....] - ETA: 0s - loss: 0.0481 - accuracy: 0.9848\n",
      "Epoch 372: val_loss did not improve from 0.04446\n",
      "182/182 [==============================] - 0s 863us/step - loss: 0.0489 - accuracy: 0.9845 - val_loss: 0.0445 - val_accuracy: 0.9867\n",
      "Epoch 373/400\n",
      "146/182 [=======================>......] - ETA: 0s - loss: 0.0493 - accuracy: 0.9845\n",
      "Epoch 373: val_loss improved from 0.04446 to 0.04413, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9846 - val_loss: 0.0441 - val_accuracy: 0.9867\n",
      "Epoch 374/400\n",
      "144/182 [======================>.......] - ETA: 0s - loss: 0.0487 - accuracy: 0.9846\n",
      "Epoch 374: val_loss did not improve from 0.04413\n",
      "182/182 [==============================] - 0s 933us/step - loss: 0.0488 - accuracy: 0.9845 - val_loss: 0.0442 - val_accuracy: 0.9871\n",
      "Epoch 375/400\n",
      "152/182 [========================>.....] - ETA: 0s - loss: 0.0481 - accuracy: 0.9848\n",
      "Epoch 375: val_loss did not improve from 0.04413\n",
      "182/182 [==============================] - 0s 892us/step - loss: 0.0487 - accuracy: 0.9846 - val_loss: 0.0442 - val_accuracy: 0.9869\n",
      "Epoch 376/400\n",
      "142/182 [======================>.......] - ETA: 0s - loss: 0.0483 - accuracy: 0.9847\n",
      "Epoch 376: val_loss did not improve from 0.04413\n",
      "182/182 [==============================] - 0s 933us/step - loss: 0.0487 - accuracy: 0.9844 - val_loss: 0.0445 - val_accuracy: 0.9865\n",
      "Epoch 377/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0492 - accuracy: 0.9843\n",
      "Epoch 377: val_loss did not improve from 0.04413\n",
      "182/182 [==============================] - 0s 866us/step - loss: 0.0486 - accuracy: 0.9845 - val_loss: 0.0447 - val_accuracy: 0.9866\n",
      "Epoch 378/400\n",
      "148/182 [=======================>......] - ETA: 0s - loss: 0.0479 - accuracy: 0.9851\n",
      "Epoch 378: val_loss did not improve from 0.04413\n",
      "182/182 [==============================] - 0s 901us/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 0.0442 - val_accuracy: 0.9864\n",
      "Epoch 379/400\n",
      "142/182 [======================>.......] - ETA: 0s - loss: 0.0478 - accuracy: 0.9849\n",
      "Epoch 379: val_loss did not improve from 0.04413\n",
      "182/182 [==============================] - 0s 933us/step - loss: 0.0485 - accuracy: 0.9846 - val_loss: 0.0447 - val_accuracy: 0.9862\n",
      "Epoch 380/400\n",
      "149/182 [=======================>......] - ETA: 0s - loss: 0.0490 - accuracy: 0.9846\n",
      "Epoch 380: val_loss improved from 0.04413 to 0.04382, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 977us/step - loss: 0.0484 - accuracy: 0.9847 - val_loss: 0.0438 - val_accuracy: 0.9867\n",
      "Epoch 381/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0476 - accuracy: 0.9851\n",
      "Epoch 381: val_loss did not improve from 0.04382\n",
      "182/182 [==============================] - 0s 832us/step - loss: 0.0483 - accuracy: 0.9849 - val_loss: 0.0441 - val_accuracy: 0.9869\n",
      "Epoch 382/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0485 - accuracy: 0.9846\n",
      "Epoch 382: val_loss did not improve from 0.04382\n",
      "182/182 [==============================] - 0s 818us/step - loss: 0.0484 - accuracy: 0.9846 - val_loss: 0.0444 - val_accuracy: 0.9865\n",
      "Epoch 383/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0479 - accuracy: 0.9849\n",
      "Epoch 383: val_loss did not improve from 0.04382\n",
      "182/182 [==============================] - 0s 805us/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.0443 - val_accuracy: 0.9867\n",
      "Epoch 384/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0485 - accuracy: 0.9844\n",
      "Epoch 384: val_loss did not improve from 0.04382\n",
      "182/182 [==============================] - 0s 836us/step - loss: 0.0482 - accuracy: 0.9847 - val_loss: 0.0441 - val_accuracy: 0.9866\n",
      "Epoch 385/400\n",
      "155/182 [========================>.....] - ETA: 0s - loss: 0.0480 - accuracy: 0.9847\n",
      "Epoch 385: val_loss did not improve from 0.04382\n",
      "182/182 [==============================] - 0s 862us/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.0439 - val_accuracy: 0.9869\n",
      "Epoch 386/400\n",
      "131/182 [====================>.........] - ETA: 0s - loss: 0.0478 - accuracy: 0.9847\n",
      "Epoch 386: val_loss did not improve from 0.04382\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9846 - val_loss: 0.0439 - val_accuracy: 0.9867\n",
      "Epoch 387/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0476 - accuracy: 0.9851\n",
      "Epoch 387: val_loss did not improve from 0.04382\n",
      "182/182 [==============================] - 0s 846us/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.0439 - val_accuracy: 0.9866\n",
      "Epoch 388/400\n",
      "153/182 [========================>.....] - ETA: 0s - loss: 0.0476 - accuracy: 0.9849\n",
      "Epoch 388: val_loss improved from 0.04382 to 0.04375, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 917us/step - loss: 0.0482 - accuracy: 0.9847 - val_loss: 0.0437 - val_accuracy: 0.9866\n",
      "Epoch 389/400\n",
      "154/182 [========================>.....] - ETA: 0s - loss: 0.0485 - accuracy: 0.9845\n",
      "Epoch 389: val_loss improved from 0.04375 to 0.04357, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 928us/step - loss: 0.0481 - accuracy: 0.9846 - val_loss: 0.0436 - val_accuracy: 0.9867\n",
      "Epoch 390/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0487 - accuracy: 0.9842\n",
      "Epoch 390: val_loss did not improve from 0.04357\n",
      "182/182 [==============================] - 0s 848us/step - loss: 0.0481 - accuracy: 0.9845 - val_loss: 0.0439 - val_accuracy: 0.9867\n",
      "Epoch 391/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0474 - accuracy: 0.9848\n",
      "Epoch 391: val_loss improved from 0.04357 to 0.04351, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 923us/step - loss: 0.0480 - accuracy: 0.9845 - val_loss: 0.0435 - val_accuracy: 0.9867\n",
      "Epoch 392/400\n",
      "147/182 [=======================>......] - ETA: 0s - loss: 0.0472 - accuracy: 0.9851\n",
      "Epoch 392: val_loss did not improve from 0.04351\n",
      "182/182 [==============================] - 0s 885us/step - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.0447 - val_accuracy: 0.9860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/400\n",
      "161/182 [=========================>....] - ETA: 0s - loss: 0.0468 - accuracy: 0.9852\n",
      "Epoch 393: val_loss did not improve from 0.04351\n",
      "182/182 [==============================] - 0s 839us/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.0439 - val_accuracy: 0.9867\n",
      "Epoch 394/400\n",
      "157/182 [========================>.....] - ETA: 0s - loss: 0.0486 - accuracy: 0.9845\n",
      "Epoch 394: val_loss did not improve from 0.04351\n",
      "182/182 [==============================] - 0s 855us/step - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.0440 - val_accuracy: 0.9865\n",
      "Epoch 395/400\n",
      "158/182 [=========================>....] - ETA: 0s - loss: 0.0473 - accuracy: 0.9850\n",
      "Epoch 395: val_loss did not improve from 0.04351\n",
      "182/182 [==============================] - 0s 851us/step - loss: 0.0479 - accuracy: 0.9848 - val_loss: 0.0439 - val_accuracy: 0.9864\n",
      "Epoch 396/400\n",
      "160/182 [=========================>....] - ETA: 0s - loss: 0.0475 - accuracy: 0.9847\n",
      "Epoch 396: val_loss did not improve from 0.04351\n",
      "182/182 [==============================] - 0s 837us/step - loss: 0.0478 - accuracy: 0.9847 - val_loss: 0.0440 - val_accuracy: 0.9864\n",
      "Epoch 397/400\n",
      "164/182 [==========================>...] - ETA: 0s - loss: 0.0473 - accuracy: 0.9848\n",
      "Epoch 397: val_loss did not improve from 0.04351\n",
      "182/182 [==============================] - 0s 832us/step - loss: 0.0478 - accuracy: 0.9846 - val_loss: 0.0440 - val_accuracy: 0.9859\n",
      "Epoch 398/400\n",
      "159/182 [=========================>....] - ETA: 0s - loss: 0.0479 - accuracy: 0.9848\n",
      "Epoch 398: val_loss improved from 0.04351 to 0.04340, saving model to WENO3//Details\\best_modelHn_7union_data.hdf5\n",
      "182/182 [==============================] - 0s 886us/step - loss: 0.0477 - accuracy: 0.9849 - val_loss: 0.0434 - val_accuracy: 0.9867\n",
      "Epoch 399/400\n",
      "139/182 [=====================>........] - ETA: 0s - loss: 0.0472 - accuracy: 0.9847\n",
      "Epoch 399: val_loss did not improve from 0.04340\n",
      "182/182 [==============================] - 0s 964us/step - loss: 0.0476 - accuracy: 0.9847 - val_loss: 0.0434 - val_accuracy: 0.9866\n",
      "Epoch 400/400\n",
      "163/182 [=========================>....] - ETA: 0s - loss: 0.0478 - accuracy: 0.9848\n",
      "Epoch 400: val_loss did not improve from 0.04340\n",
      "182/182 [==============================] - 0s 832us/step - loss: 0.0477 - accuracy: 0.9849 - val_loss: 0.0440 - val_accuracy: 0.9860\n",
      "name weight WENO3//model/trained_weights_Hn_7union_data.mat\n",
      "302/302 [==============================] - 0s 490us/step\n",
      "here\n",
      "Accuracy  : 0.9857187208941323\n",
      "Precision : 0.9858700126504848\n",
      "f1Score : 0.9855652685449974\n",
      "[[1108   65    0]\n",
      " [   3 7533    6]\n",
      " [   0   64  884]]\n",
      "train history is strored in WENO3/History/history-Hn_7union_data.dat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  for reconst in range(3):\n",
    "    if reconst ==0 :\n",
    "      bsize= 64\n",
    "#       Best bsize is 16\n",
    "      in_dim =6\n",
    "    elif reconst ==1:\n",
    "      bsize=16\n",
    "      in_dim =6\n",
    "    else:\n",
    "      in_dim =4\n",
    "      bsize=256\n",
    "            \n",
    "    finaldir=['ENO3/', 'ENOL3/','WENO3/'][reconst]    \n",
    "    mylog_file=finaldir+\"Details/\"+\"models_info.csv\"\n",
    "    cmfile = finaldir+\"Details/\"+\"cm_detail.txt\" # file for confusion matrix details\n",
    "    mylog_file_kfold=finaldir+\"Details/\"+\"kfold_models_info.csv\"\n",
    "    try: \n",
    "        if os.path.exists(mylog_file):\n",
    "            os.remove(mylog_file)\n",
    "        if os.path.exists(cmfile):\n",
    "          os.remove(cmfile)\n",
    "        if os.path.exists(mylog_file_kfold):\n",
    "            os.remove(mylog_file_kfold)\n",
    "    except  NameError: \n",
    "        print(\"Log file is not found\")\n",
    "    finally: \n",
    "        file1=open(cmfile, \"a\")\n",
    "        listchoicer =[1] #choice of r\n",
    "        list_hn =[7]#,10,15,20] # number of neuron in the hidden layer \n",
    "        num_epochs=400\n",
    "#             whichdata = [\"union_data\"]  # \"smoothdata\",\n",
    "        whichdata = [\"smoothdata\",\"nonsmoothdata\", \"union_data\"]  # \"smoothdata\",\n",
    "\n",
    "        for i in whichdata:\n",
    "            print(\"i is\",i)                   \n",
    "            X, Y = load_data(data_dir = finaldir, datachoice=i)\n",
    "            xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.15)\n",
    "            scaler = StandardScaler()            \n",
    "            xTrain, dxTrain= xTrain[:,0:in_dim-1], xTrain[:,-1]\n",
    "            xTest, dxTest= xTest[:, 0:in_dim-1], xTest[:,-1]               \n",
    "            xTrain = scaler.fit_transform(xTrain)\n",
    "            xTest = scaler.transform(xTest)\n",
    "            xTrain = np.append(xTrain[:,0:in_dim-1], dxTrain[:,None], axis=1)\n",
    "            xTest = np.append(xTest[:,0:in_dim-1], dxTest[:,None], axis=1)\n",
    "\n",
    "\n",
    "            for k in list_hn:\n",
    "                model =get_model(in_dim=in_dim, hidden_layer_n=k)\n",
    "                # Run k kross validation. \n",
    "#                   run_k_fold_test(model=model,nfolds =5, xTrain=xTrain, yTrain=yTrain, log_file=mylog_file_kfold, hidden_layer_n=k, datachoice=i,epochs=num_epochs)  \n",
    "\n",
    "                # Train the model on the whole training data\n",
    "                log_dir,L = train_test_model(model=model, xTrain=xTrain, yTrain=yTrain, xTest =xTest, yTest=yTest, data_dir= finaldir,log_file=mylog_file,\n",
    "                                                    datachoice=i, hidden_layer_n=k, num_epochs=num_epochs,  batchsize=bsize)\n",
    "                for jj in [\"data:{}\".format(i), \"{}\".format(\" \"), \"Hn:{}\".format(k)]:\n",
    "                    file1.write(jj)\n",
    "                file1.write(\"\\n\")\n",
    "                for ii in L:                            \n",
    "                    file1.write(ii)\n",
    "                    file1.write(\"\\t\")\n",
    "                file1.write(\"\\n\")\n",
    "        file1.close()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 49        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73 (584.00 Byte)\n",
      "Trainable params: 73 (584.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "df_load =pd.read_csv(log_dir)\n",
    "model =get_model(in_dim=6, hidden_layer_n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WENO3/History/history-Hn_7union_data.dat'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":   \n",
    "    finaldir=['ENO3data/', 'ENOL3data/','WENO3data/'][1]    \n",
    "    mylog_file=finaldir+\"Details/\"+\"models_info.csv\"\n",
    "    mylog_file_kfold=finaldir+\"Details/\"+\"kfold_models_info.csv\"\n",
    "    try: \n",
    "        if os.path.exists(mylog_file):\n",
    "            os.remove(mylog_file)\n",
    "        if os.path.exists(mylog_file_kfold):\n",
    "            os.remove(mylog_file_kfold)\n",
    "    except  NameError: \n",
    "        print(\"Log file is not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load =pd.read_csv(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " mylog_file_kfold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
